2023-07-05 13:39:30,563 INFO    [main_contrastive.py, 199] batch size: 8
2023-07-05 13:39:30,751 INFO    [offset_helper.py, 51] engery/max-distance: 5 engery/min-distance: 0
2023-07-05 13:39:30,751 INFO    [offset_helper.py, 58] direction/num_classes: 8 scale: 1
2023-07-05 13:39:30,751 INFO    [offset_helper.py, 65] c4 align axis: False
2023-07-05 13:39:31,092 INFO    [module_runner.py, 46] BN Type is torchsyncbn.
2023-07-05 13:39:31,092 INFO    [__init__.py, 17] Using evaluator: StandardEvaluator
2023-07-05 13:39:31,092 INFO    [running_score.py, 129] 19
2023-07-05 13:39:31,635 INFO    [module_helper.py, 141] Loading pretrained model:/ws/external/hrnetv2_w48_imagenet_pretrained.pth
2023-07-05 13:39:31,898 INFO    [module_helper.py, 205] Missing keys: []
2023-07-05 13:39:32,272 INFO    [projection.py, 12] proj_dim: 256
2023-07-05 13:39:32,518 INFO    [trainer_contrastive.py, 57] Params Group Method: None
2023-07-05 13:39:32,529 INFO    [optim_scheduler.py, 96] Use lambda_poly policy with default power 0.9
2023-07-05 13:39:32,529 INFO    [data_loader.py, 132] use the DefaultLoader for train...
2023-07-05 13:39:32,564 INFO    [default_loader.py, 38] train 2975
2023-07-05 13:39:32,564 INFO    [data_loader.py, 164] use DefaultLoader for val ...
2023-07-05 13:39:32,571 INFO    [default_loader.py, 38] val 500
2023-07-05 13:39:32,571 INFO    [loss_manager.py, 66] use loss: contrast_ce_loss.
2023-07-05 13:39:32,571 INFO    [loss_contrast.py, 159] ignore_index: -1
2023-07-05 13:39:32,571 INFO    [loss_manager.py, 51] use distributed loss
2023-07-05 13:39:32,571 INFO    [trainer_contrastive.py, 85] with_contrast: True, warmup_iters: 5000, with_memory: False
2023-07-05 13:39:35,665 INFO    [data_helper.py, 126] Input keys: ['img']
2023-07-05 13:39:35,665 INFO    [data_helper.py, 127] Target keys: ['labelmap']
2023-07-05 13:39:54,188 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 10	Time 21.613s / 10iters, (2.161)	Forward Time 4.687s / 10iters, (0.469)	Backward Time 11.320s / 10iters, (1.132)	Loss Time 2.417s / 10iters, (0.242)	Data load 3.189s / 10iters, (0.318880)
Learning rate = [0.00999797497721687, 0.00999797497721687]	Loss = 1.09878302 (ave = 1.74517767)

2023-07-05 13:40:06,202 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 20	Time 12.014s / 10iters, (1.201)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.175s / 10iters, (0.818)	Loss Time 2.655s / 10iters, (0.265)	Data load 0.088s / 10iters, (0.008827)
Learning rate = [0.009995724898451063, 0.009995724898451063]	Loss = 0.94385737 (ave = 0.90807016)

2023-07-05 13:40:18,081 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 30	Time 11.879s / 10iters, (1.188)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.029s / 10iters, (0.803)	Loss Time 2.643s / 10iters, (0.264)	Data load 0.106s / 10iters, (0.010595)
Learning rate = [0.00999347476340585, 0.00999347476340585]	Loss = 0.53422099 (ave = 0.64659909)

2023-07-05 13:40:30,073 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 40	Time 11.993s / 10iters, (1.199)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.097s / 10iters, (0.810)	Loss Time 2.713s / 10iters, (0.271)	Data load 0.087s / 10iters, (0.008725)
Learning rate = [0.00999122457206574, 0.00999122457206574]	Loss = 0.53847295 (ave = 0.64071783)

2023-07-05 13:40:42,147 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 50	Time 12.074s / 10iters, (1.207)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.183s / 10iters, (0.818)	Loss Time 2.723s / 10iters, (0.272)	Data load 0.079s / 10iters, (0.007891)
Learning rate = [0.00998897432441524, 0.00998897432441524]	Loss = 0.64866644 (ave = 0.74894320)

2023-07-05 13:40:54,177 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 60	Time 12.030s / 10iters, (1.203)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.189s / 10iters, (0.819)	Loss Time 2.677s / 10iters, (0.268)	Data load 0.076s / 10iters, (0.007598)
Learning rate = [0.009986724020438846, 0.009986724020438846]	Loss = 0.73576021 (ave = 0.67902931)

2023-07-05 13:41:06,222 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 70	Time 12.045s / 10iters, (1.205)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.120s / 10iters, (0.812)	Loss Time 2.759s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007474)
Learning rate = [0.009984473660121045, 0.009984473660121045]	Loss = 0.39512756 (ave = 0.57501594)

2023-07-05 13:41:18,460 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 80	Time 12.237s / 10iters, (1.224)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.789s / 10iters, (0.279)	Data load 0.076s / 10iters, (0.007604)
Learning rate = [0.009982223243446315, 0.009982223243446315]	Loss = 0.63601726 (ave = 0.55780953)

2023-07-05 13:41:30,648 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 90	Time 12.188s / 10iters, (1.219)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007546)
Learning rate = [0.009979972770399127, 0.009979972770399127]	Loss = 0.52239239 (ave = 0.55682398)

2023-07-05 13:41:42,805 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 100	Time 12.157s / 10iters, (1.216)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.210s / 10iters, (0.821)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007441)
Learning rate = [0.009977722240963943, 0.009977722240963943]	Loss = 0.88285822 (ave = 0.54284659)

2023-07-05 13:41:55,010 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 110	Time 12.205s / 10iters, (1.221)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.201s / 10iters, (0.820)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007389)
Learning rate = [0.00997547165512522, 0.00997547165512522]	Loss = 0.38308504 (ave = 0.50679693)

2023-07-05 13:42:07,245 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 120	Time 12.236s / 10iters, (1.224)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.243s / 10iters, (0.824)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007414)
Learning rate = [0.009973221012867402, 0.009973221012867402]	Loss = 0.26321512 (ave = 0.38649122)

2023-07-05 13:42:19,389 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 130	Time 12.144s / 10iters, (1.214)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.166s / 10iters, (0.817)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007431)
Learning rate = [0.009970970314174928, 0.009970970314174928]	Loss = 0.56374514 (ave = 0.48104421)

2023-07-05 13:42:31,570 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 140	Time 12.181s / 10iters, (1.218)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007447)
Learning rate = [0.00996871955903223, 0.00996871955903223]	Loss = 0.47801441 (ave = 0.40765759)

2023-07-05 13:42:43,889 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 150	Time 12.319s / 10iters, (1.232)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.304s / 10iters, (0.830)	Loss Time 2.838s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007518)
Learning rate = [0.009966468747423728, 0.009966468747423728]	Loss = 0.43850097 (ave = 0.45520708)

2023-07-05 13:42:56,178 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 160	Time 12.289s / 10iters, (1.229)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.275s / 10iters, (0.828)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007469)
Learning rate = [0.009964217879333836, 0.009964217879333836]	Loss = 0.37434193 (ave = 0.55656864)

2023-07-05 13:43:08,471 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 170	Time 12.293s / 10iters, (1.229)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.282s / 10iters, (0.828)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.087s / 10iters, (0.008664)
Learning rate = [0.009961966954746958, 0.009961966954746958]	Loss = 0.32583985 (ave = 0.44671356)

2023-07-05 13:43:20,652 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 180	Time 12.181s / 10iters, (1.218)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.082s / 10iters, (0.008185)
Learning rate = [0.009959715973647493, 0.009959715973647493]	Loss = 0.38629970 (ave = 0.60059949)

2023-07-05 13:43:32,878 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 190	Time 12.225s / 10iters, (1.223)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007367)
Learning rate = [0.00995746493601983, 0.00995746493601983]	Loss = 0.37563446 (ave = 0.42471614)

2023-07-05 13:43:45,116 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 200	Time 12.238s / 10iters, (1.224)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.264s / 10iters, (0.826)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.086s / 10iters, (0.008581)
Learning rate = [0.00995521384184835, 0.00995521384184835]	Loss = 0.94535953 (ave = 0.64468488)

2023-07-05 13:43:57,311 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 210	Time 12.195s / 10iters, (1.220)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.169s / 10iters, (0.817)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007453)
Learning rate = [0.009952962691117425, 0.009952962691117425]	Loss = 0.57947308 (ave = 0.47075457)

2023-07-05 13:44:09,513 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 220	Time 12.202s / 10iters, (1.220)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007464)
Learning rate = [0.009950711483811419, 0.009950711483811419]	Loss = 0.37568870 (ave = 0.41385612)

2023-07-05 13:44:21,628 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 230	Time 12.115s / 10iters, (1.212)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.183s / 10iters, (0.818)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.074s / 10iters, (0.007446)
Learning rate = [0.009948460219914688, 0.009948460219914688]	Loss = 0.26589826 (ave = 0.40176314)

2023-07-05 13:44:33,874 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 240	Time 12.246s / 10iters, (1.225)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.227s / 10iters, (0.823)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.081s / 10iters, (0.008116)
Learning rate = [0.00994620889941158, 0.00994620889941158]	Loss = 0.50688517 (ave = 0.52997162)

2023-07-05 13:44:46,203 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 250	Time 12.328s / 10iters, (1.233)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007457)
Learning rate = [0.009943957522286433, 0.009943957522286433]	Loss = 0.36905360 (ave = 0.49216241)

2023-07-05 13:44:58,438 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 260	Time 12.235s / 10iters, (1.224)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.264s / 10iters, (0.826)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007389)
Learning rate = [0.00994170608852358, 0.00994170608852358]	Loss = 0.51586139 (ave = 0.56392292)

2023-07-05 13:45:10,774 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 270	Time 12.336s / 10iters, (1.234)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.345s / 10iters, (0.835)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007634)
Learning rate = [0.009939454598107345, 0.009939454598107345]	Loss = 0.19693880 (ave = 0.33399561)

2023-07-05 13:45:23,062 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 280	Time 12.288s / 10iters, (1.229)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.281s / 10iters, (0.828)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.081s / 10iters, (0.008117)
Learning rate = [0.00993720305102204, 0.00993720305102204]	Loss = 0.38575047 (ave = 0.38249217)

2023-07-05 13:45:35,255 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 290	Time 12.193s / 10iters, (1.219)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.226s / 10iters, (0.823)	Loss Time 2.786s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007398)
Learning rate = [0.009934951447251972, 0.009934951447251972]	Loss = 0.38270628 (ave = 0.46578680)

2023-07-05 13:45:47,422 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 300	Time 12.166s / 10iters, (1.217)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.184s / 10iters, (0.818)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007523)
Learning rate = [0.00993269978678144, 0.00993269978678144]	Loss = 0.39361560 (ave = 0.41024913)

2023-07-05 13:45:59,584 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 310	Time 12.163s / 10iters, (1.216)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.208s / 10iters, (0.821)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.074s / 10iters, (0.007408)
Learning rate = [0.009930448069594734, 0.009930448069594734]	Loss = 0.28250292 (ave = 0.41696705)

2023-07-05 13:46:11,860 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 320	Time 12.276s / 10iters, (1.228)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.329s / 10iters, (0.833)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.078s / 10iters, (0.007824)
Learning rate = [0.009928196295676135, 0.009928196295676135]	Loss = 0.33078167 (ave = 0.30353827)

2023-07-05 13:46:24,201 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 330	Time 12.341s / 10iters, (1.234)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.857s / 10iters, (0.286)	Data load 0.082s / 10iters, (0.008238)
Learning rate = [0.009925944465009913, 0.009925944465009913]	Loss = 0.31101745 (ave = 0.41517891)

2023-07-05 13:46:36,601 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 340	Time 12.400s / 10iters, (1.240)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.892s / 10iters, (0.289)	Data load 0.074s / 10iters, (0.007431)
Learning rate = [0.009923692577580339, 0.009923692577580339]	Loss = 0.46606395 (ave = 0.44262833)

2023-07-05 13:46:48,851 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 350	Time 12.250s / 10iters, (1.225)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.835s / 10iters, (0.284)	Data load 0.081s / 10iters, (0.008132)
Learning rate = [0.009921440633371664, 0.009921440633371664]	Loss = 0.62512279 (ave = 0.39604974)

2023-07-05 13:47:01,037 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 360	Time 12.186s / 10iters, (1.219)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.764s / 10iters, (0.276)	Data load 0.073s / 10iters, (0.007339)
Learning rate = [0.00991918863236814, 0.00991918863236814]	Loss = 0.30401668 (ave = 0.36449079)

2023-07-05 13:47:13,035 INFO    [trainer_contrastive.py, 272] Train Epoch: 0	Train Iteration: 370	Time 11.998s / 10iters, (1.200)	Forward Time 1.081s / 10iters, (0.108)	Backward Time 8.124s / 10iters, (0.812)	Loss Time 2.719s / 10iters, (0.272)	Data load 0.074s / 10iters, (0.007369)
Learning rate = [0.009916936574554001, 0.009916936574554001]	Loss = 0.24134512 (ave = 0.42282485)

2023-07-05 13:47:27,373 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 380	Time 14.232s / 10iters, (1.423)	Forward Time 1.298s / 10iters, (0.130)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.737s / 10iters, (0.274)	Data load 1.940s / 10iters, (0.193986)
Learning rate = [0.009914684459913486, 0.009914684459913486]	Loss = 0.95069486 (ave = 0.36079407)

2023-07-05 13:47:39,635 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 390	Time 12.262s / 10iters, (1.226)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.092s / 10iters, (0.009176)
Learning rate = [0.009912432288430814, 0.009912432288430814]	Loss = 0.29098633 (ave = 0.36298720)

2023-07-05 13:47:51,858 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 400	Time 12.223s / 10iters, (1.222)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.264s / 10iters, (0.826)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007543)
Learning rate = [0.0099101800600902, 0.0099101800600902]	Loss = 0.37043747 (ave = 0.37890434)

2023-07-05 13:48:04,050 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 410	Time 12.192s / 10iters, (1.219)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.076s / 10iters, (0.007559)
Learning rate = [0.009907927774875848, 0.009907927774875848]	Loss = 0.24011099 (ave = 0.27330074)

2023-07-05 13:48:16,336 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 420	Time 12.286s / 10iters, (1.229)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.282s / 10iters, (0.828)	Loss Time 2.815s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007568)
Learning rate = [0.009905675432771962, 0.009905675432771962]	Loss = 0.48542333 (ave = 0.32033748)

2023-07-05 13:48:28,515 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 430	Time 12.179s / 10iters, (1.218)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.759s / 10iters, (0.276)	Data load 0.077s / 10iters, (0.007698)
Learning rate = [0.009903423033762725, 0.009903423033762725]	Loss = 0.19366574 (ave = 0.27241750)

2023-07-05 13:48:40,733 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 440	Time 12.218s / 10iters, (1.222)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.204s / 10iters, (0.820)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.084s / 10iters, (0.008371)
Learning rate = [0.009901170577832323, 0.009901170577832323]	Loss = 0.32572827 (ave = 0.31846355)

2023-07-05 13:48:52,908 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 450	Time 12.175s / 10iters, (1.217)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.156s / 10iters, (0.816)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007421)
Learning rate = [0.009898918064964925, 0.009898918064964925]	Loss = 0.41484040 (ave = 0.40736138)

2023-07-05 13:49:05,167 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 460	Time 12.259s / 10iters, (1.226)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007425)
Learning rate = [0.009896665495144698, 0.009896665495144698]	Loss = 0.33588648 (ave = 0.39426933)

2023-07-05 13:49:17,352 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 470	Time 12.185s / 10iters, (1.218)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.225s / 10iters, (0.823)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007449)
Learning rate = [0.009894412868355799, 0.009894412868355799]	Loss = 0.38769281 (ave = 0.36487621)

2023-07-05 13:49:29,578 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 480	Time 12.226s / 10iters, (1.223)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.076s / 10iters, (0.007622)
Learning rate = [0.009892160184582372, 0.009892160184582372]	Loss = 0.25984675 (ave = 0.32704785)

2023-07-05 13:49:41,759 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 490	Time 12.181s / 10iters, (1.218)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.079s / 10iters, (0.007935)
Learning rate = [0.009889907443808557, 0.009889907443808557]	Loss = 0.40572697 (ave = 0.34505443)

2023-07-05 13:49:53,893 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 500	Time 12.135s / 10iters, (1.213)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.166s / 10iters, (0.817)	Loss Time 2.790s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007426)
Learning rate = [0.009887654646018488, 0.009887654646018488]	Loss = 0.27937528 (ave = 0.26485233)

2023-07-05 13:50:06,217 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 510	Time 12.323s / 10iters, (1.232)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.307s / 10iters, (0.831)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007500)
Learning rate = [0.009885401791196284, 0.009885401791196284]	Loss = 0.27757922 (ave = 0.34234582)

2023-07-05 13:50:18,444 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 520	Time 12.227s / 10iters, (1.223)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.184s / 10iters, (0.818)	Loss Time 2.873s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007455)
Learning rate = [0.00988314887932606, 0.00988314887932606]	Loss = 0.18194781 (ave = 0.32707388)

2023-07-05 13:50:30,676 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 530	Time 12.232s / 10iters, (1.223)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.169s / 10iters, (0.817)	Loss Time 2.885s / 10iters, (0.289)	Data load 0.074s / 10iters, (0.007410)
Learning rate = [0.009880895910391919, 0.009880895910391919]	Loss = 0.16822903 (ave = 0.30302306)

2023-07-05 13:50:42,941 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 540	Time 12.265s / 10iters, (1.227)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.192s / 10iters, (0.819)	Loss Time 2.889s / 10iters, (0.289)	Data load 0.080s / 10iters, (0.008039)
Learning rate = [0.009878642884377961, 0.009878642884377961]	Loss = 0.21449155 (ave = 0.32588027)

2023-07-05 13:50:55,173 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 550	Time 12.232s / 10iters, (1.223)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007405)
Learning rate = [0.009876389801268273, 0.009876389801268273]	Loss = 0.65735108 (ave = 0.37337911)

2023-07-05 13:51:07,487 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 560	Time 12.313s / 10iters, (1.231)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.295s / 10iters, (0.829)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007393)
Learning rate = [0.009874136661046938, 0.009874136661046938]	Loss = 0.35998970 (ave = 0.38089822)

2023-07-05 13:51:19,640 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 570	Time 12.153s / 10iters, (1.215)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.189s / 10iters, (0.819)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.081s / 10iters, (0.008085)
Learning rate = [0.00987188346369802, 0.00987188346369802]	Loss = 0.34050727 (ave = 0.35052323)

2023-07-05 13:51:31,787 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 580	Time 12.147s / 10iters, (1.215)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.183s / 10iters, (0.818)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007391)
Learning rate = [0.009869630209205593, 0.009869630209205593]	Loss = 0.18422997 (ave = 0.26400823)

2023-07-05 13:51:43,982 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 590	Time 12.195s / 10iters, (1.220)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.077s / 10iters, (0.007741)
Learning rate = [0.009867376897553702, 0.009867376897553702]	Loss = 0.25467873 (ave = 0.29897433)

2023-07-05 13:51:56,237 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 600	Time 12.255s / 10iters, (1.226)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.219s / 10iters, (0.822)	Loss Time 2.850s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007647)
Learning rate = [0.009865123528726396, 0.009865123528726396]	Loss = 0.22970457 (ave = 0.31735467)

2023-07-05 13:52:08,524 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 610	Time 12.286s / 10iters, (1.229)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.245s / 10iters, (0.825)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.079s / 10iters, (0.007855)
Learning rate = [0.009862870102707713, 0.009862870102707713]	Loss = 0.24710344 (ave = 0.27406606)

2023-07-05 13:52:20,896 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 620	Time 12.372s / 10iters, (1.237)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.903s / 10iters, (0.290)	Data load 0.074s / 10iters, (0.007406)
Learning rate = [0.009860616619481682, 0.009860616619481682]	Loss = 0.24340479 (ave = 0.38593484)

2023-07-05 13:52:33,191 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 630	Time 12.296s / 10iters, (1.230)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.225s / 10iters, (0.823)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007392)
Learning rate = [0.009858363079032324, 0.009858363079032324]	Loss = 0.28946322 (ave = 0.34321518)

2023-07-05 13:52:45,384 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 640	Time 12.193s / 10iters, (1.219)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.223s / 10iters, (0.822)	Loss Time 2.789s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007409)
Learning rate = [0.00985610948134365, 0.00985610948134365]	Loss = 0.45510501 (ave = 0.38564743)

2023-07-05 13:52:57,517 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 650	Time 12.132s / 10iters, (1.213)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.171s / 10iters, (0.817)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.084s / 10iters, (0.008440)
Learning rate = [0.009853855826399664, 0.009853855826399664]	Loss = 0.31873617 (ave = 0.39625559)

2023-07-05 13:53:09,911 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 660	Time 12.394s / 10iters, (1.239)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.368s / 10iters, (0.837)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.082s / 10iters, (0.008242)
Learning rate = [0.00985160211418436, 0.00985160211418436]	Loss = 0.27133268 (ave = 0.42583503)

2023-07-05 13:53:22,214 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 670	Time 12.303s / 10iters, (1.230)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.078s / 10iters, (0.007847)
Learning rate = [0.009849348344681727, 0.009849348344681727]	Loss = 0.40653554 (ave = 0.37609008)

2023-07-05 13:53:34,460 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 680	Time 12.246s / 10iters, (1.225)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.207s / 10iters, (0.821)	Loss Time 2.870s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007411)
Learning rate = [0.00984709451787574, 0.00984709451787574]	Loss = 0.28551367 (ave = 0.39301083)

2023-07-05 13:53:46,704 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 690	Time 12.245s / 10iters, (1.224)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.172s / 10iters, (0.817)	Loss Time 2.894s / 10iters, (0.289)	Data load 0.076s / 10iters, (0.007560)
Learning rate = [0.009844840633750369, 0.009844840633750369]	Loss = 0.36850828 (ave = 0.29508799)

2023-07-05 13:53:58,975 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 700	Time 12.271s / 10iters, (1.227)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007400)
Learning rate = [0.009842586692289575, 0.009842586692289575]	Loss = 0.22291076 (ave = 0.40533276)

2023-07-05 13:54:11,223 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 710	Time 12.248s / 10iters, (1.225)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.845s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007528)
Learning rate = [0.009840332693477309, 0.009840332693477309]	Loss = 0.74056059 (ave = 0.30197868)

2023-07-05 13:54:23,456 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 720	Time 12.233s / 10iters, (1.223)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.080s / 10iters, (0.008049)
Learning rate = [0.009838078637297517, 0.009838078637297517]	Loss = 0.88093317 (ave = 0.36591540)

2023-07-05 13:54:35,566 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 730	Time 12.111s / 10iters, (1.211)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.167s / 10iters, (0.817)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007379)
Learning rate = [0.00983582452373413, 0.00983582452373413]	Loss = 0.20968063 (ave = 0.26099691)

2023-07-05 13:54:47,572 INFO    [trainer_contrastive.py, 272] Train Epoch: 1	Train Iteration: 740	Time 12.006s / 10iters, (1.201)	Forward Time 1.079s / 10iters, (0.108)	Backward Time 8.121s / 10iters, (0.812)	Loss Time 2.732s / 10iters, (0.273)	Data load 0.074s / 10iters, (0.007363)
Learning rate = [0.009833570352771081, 0.009833570352771081]	Loss = 0.57794923 (ave = 0.42654817)

2023-07-05 13:55:02,307 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 750	Time 14.622s / 10iters, (1.462)	Forward Time 1.330s / 10iters, (0.133)	Backward Time 8.387s / 10iters, (0.839)	Loss Time 2.662s / 10iters, (0.266)	Data load 2.243s / 10iters, (0.224265)
Learning rate = [0.00983131612439228, 0.00983131612439228]	Loss = 0.31843275 (ave = 0.36043069)

2023-07-05 13:55:14,515 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 760	Time 12.208s / 10iters, (1.221)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007526)
Learning rate = [0.009829061838581643, 0.009829061838581643]	Loss = 0.53990579 (ave = 0.32833566)

2023-07-05 13:55:26,780 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 770	Time 12.264s / 10iters, (1.226)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.317s / 10iters, (0.832)	Loss Time 2.756s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007525)
Learning rate = [0.009826807495323065, 0.009826807495323065]	Loss = 0.18068980 (ave = 0.29274620)

2023-07-05 13:55:39,059 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 780	Time 12.280s / 10iters, (1.228)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.337s / 10iters, (0.834)	Loss Time 2.754s / 10iters, (0.275)	Data load 0.076s / 10iters, (0.007635)
Learning rate = [0.00982455309460044, 0.00982455309460044]	Loss = 0.35741428 (ave = 0.30391273)

2023-07-05 13:55:51,197 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 790	Time 12.138s / 10iters, (1.214)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.689s / 10iters, (0.269)	Data load 0.082s / 10iters, (0.008181)
Learning rate = [0.009822298636397653, 0.009822298636397653]	Loss = 0.31191909 (ave = 0.28422919)

2023-07-05 13:56:03,384 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 800	Time 12.187s / 10iters, (1.219)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.203s / 10iters, (0.820)	Loss Time 2.805s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007482)
Learning rate = [0.009820044120698578, 0.009820044120698578]	Loss = 0.14564195 (ave = 0.30627000)

2023-07-05 13:56:15,627 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 810	Time 12.244s / 10iters, (1.224)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.215s / 10iters, (0.822)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.084s / 10iters, (0.008395)
Learning rate = [0.009817789547487079, 0.009817789547487079]	Loss = 0.19499354 (ave = 0.23556450)

2023-07-05 13:56:27,822 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 820	Time 12.195s / 10iters, (1.220)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.175s / 10iters, (0.817)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007525)
Learning rate = [0.009815534916747014, 0.009815534916747014]	Loss = 0.24003200 (ave = 0.25470524)

2023-07-05 13:56:40,056 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 830	Time 12.233s / 10iters, (1.223)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.209s / 10iters, (0.821)	Loss Time 2.835s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007519)
Learning rate = [0.009813280228462234, 0.009813280228462234]	Loss = 0.29389977 (ave = 0.26199803)

2023-07-05 13:56:52,283 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 840	Time 12.228s / 10iters, (1.223)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.180s / 10iters, (0.818)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.077s / 10iters, (0.007676)
Learning rate = [0.009811025482616576, 0.009811025482616576]	Loss = 0.17303884 (ave = 0.36563881)

2023-07-05 13:57:04,559 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 850	Time 12.275s / 10iters, (1.228)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.180s / 10iters, (0.818)	Loss Time 2.908s / 10iters, (0.291)	Data load 0.075s / 10iters, (0.007485)
Learning rate = [0.009808770679193874, 0.009808770679193874]	Loss = 0.31803825 (ave = 0.32544833)

2023-07-05 13:57:16,844 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 860	Time 12.285s / 10iters, (1.229)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007592)
Learning rate = [0.00980651581817795, 0.00980651581817795]	Loss = 0.27364594 (ave = 0.28952862)

2023-07-05 13:57:29,066 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 870	Time 12.222s / 10iters, (1.222)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007525)
Learning rate = [0.009804260899552617, 0.009804260899552617]	Loss = 0.34985420 (ave = 0.29124009)

2023-07-05 13:57:41,219 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 880	Time 12.153s / 10iters, (1.215)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.160s / 10iters, (0.816)	Loss Time 2.803s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007499)
Learning rate = [0.009802005923301682, 0.009802005923301682]	Loss = 0.40822119 (ave = 0.35546519)

2023-07-05 13:57:53,384 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 890	Time 12.165s / 10iters, (1.217)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.149s / 10iters, (0.815)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007637)
Learning rate = [0.00979975088940894, 0.00979975088940894]	Loss = 0.28630346 (ave = 0.28795105)

2023-07-05 13:58:05,502 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 900	Time 12.117s / 10iters, (1.212)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.136s / 10iters, (0.814)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007493)
Learning rate = [0.00979749579785818, 0.00979749579785818]	Loss = 0.28237513 (ave = 0.24754214)

2023-07-05 13:58:17,753 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 910	Time 12.252s / 10iters, (1.225)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007593)
Learning rate = [0.009795240648633182, 0.009795240648633182]	Loss = 0.29033169 (ave = 0.33104009)

2023-07-05 13:58:29,976 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 920	Time 12.223s / 10iters, (1.222)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.086s / 10iters, (0.008601)
Learning rate = [0.009792985441717715, 0.009792985441717715]	Loss = 0.31967291 (ave = 0.25390387)

2023-07-05 13:58:42,169 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 930	Time 12.193s / 10iters, (1.219)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.215s / 10iters, (0.822)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007505)
Learning rate = [0.009790730177095542, 0.009790730177095542]	Loss = 0.24262789 (ave = 0.26878695)

2023-07-05 13:58:54,411 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 940	Time 12.243s / 10iters, (1.224)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.232s / 10iters, (0.823)	Loss Time 2.838s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007609)
Learning rate = [0.009788474854750415, 0.009788474854750415]	Loss = 0.39895853 (ave = 0.30603911)

2023-07-05 13:59:06,754 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 950	Time 12.343s / 10iters, (1.234)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.275s / 10iters, (0.828)	Loss Time 2.885s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007491)
Learning rate = [0.009786219474666081, 0.009786219474666081]	Loss = 0.24853472 (ave = 0.25746641)

2023-07-05 13:59:19,055 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 960	Time 12.301s / 10iters, (1.230)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.875s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007500)
Learning rate = [0.009783964036826272, 0.009783964036826272]	Loss = 0.18653513 (ave = 0.31139350)

2023-07-05 13:59:31,263 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 970	Time 12.208s / 10iters, (1.221)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007609)
Learning rate = [0.009781708541214715, 0.009781708541214715]	Loss = 0.22448020 (ave = 0.27732530)

2023-07-05 13:59:43,477 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 980	Time 12.214s / 10iters, (1.221)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.808s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007498)
Learning rate = [0.009779452987815133, 0.009779452987815133]	Loss = 0.21350347 (ave = 0.23158205)

2023-07-05 13:59:55,644 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 990	Time 12.166s / 10iters, (1.217)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.203s / 10iters, (0.820)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.076s / 10iters, (0.007577)
Learning rate = [0.009777197376611231, 0.009777197376611231]	Loss = 0.31204072 (ave = 0.36025514)

2023-07-05 14:00:07,879 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 1000	Time 12.236s / 10iters, (1.224)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.262s / 10iters, (0.826)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007510)
Learning rate = [0.00977494170758671, 0.00977494170758671]	Loss = 0.25075442 (ave = 0.29039464)

2023-07-05 14:00:10,808 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 14:00:40,935 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 14:01:05,300 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 14:01:29,233 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 14:01:53,044 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 14:02:16,579 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 14:02:39,980 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 14:02:48,519 INFO    [base.py, 84] Performance 0.0 -> 0.5938697415777189
2023-07-05 14:02:51,524 INFO    [trainer_contrastive.py, 391] Test Time 160.506s, (2.548)	Loss 0.24393438

2023-07-05 14:02:51,524 INFO    [base.py, 33] Result for seg
2023-07-05 14:02:51,525 INFO    [base.py, 49] Mean IOU: 0.5938697415777189

2023-07-05 14:02:51,525 INFO    [base.py, 50] Pixel ACC: 0.925371903815562

2023-07-05 14:03:03,765 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 1010	Time 175.886s / 10iters, (17.589)	Forward Time 1.138s / 10iters, (0.114)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.754s / 10iters, (0.275)	Data load 163.749s / 10iters, (16.374916)
Learning rate = [0.009772685980725263, 0.009772685980725263]	Loss = 0.29913375 (ave = 0.25529487)

2023-07-05 14:03:15,967 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 1020	Time 12.202s / 10iters, (1.220)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.077s / 10iters, (0.007703)
Learning rate = [0.009770430196010572, 0.009770430196010572]	Loss = 0.50911927 (ave = 0.37179887)

2023-07-05 14:03:28,126 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 1030	Time 12.159s / 10iters, (1.216)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.777s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007436)
Learning rate = [0.009768174353426312, 0.009768174353426312]	Loss = 0.42640120 (ave = 0.31015231)

2023-07-05 14:03:40,211 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 1040	Time 12.084s / 10iters, (1.208)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.137s / 10iters, (0.814)	Loss Time 2.727s / 10iters, (0.273)	Data load 0.100s / 10iters, (0.009961)
Learning rate = [0.00976591845295615, 0.00976591845295615]	Loss = 0.26581588 (ave = 0.25629983)

2023-07-05 14:03:52,354 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 1050	Time 12.144s / 10iters, (1.214)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.202s / 10iters, (0.820)	Loss Time 2.775s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007591)
Learning rate = [0.00976366249458374, 0.00976366249458374]	Loss = 0.35268894 (ave = 0.32280289)

2023-07-05 14:04:04,650 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 1060	Time 12.295s / 10iters, (1.230)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.329s / 10iters, (0.833)	Loss Time 2.777s / 10iters, (0.278)	Data load 0.082s / 10iters, (0.008238)
Learning rate = [0.009761406478292729, 0.009761406478292729]	Loss = 0.20246176 (ave = 0.31703103)

2023-07-05 14:04:16,863 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 1070	Time 12.214s / 10iters, (1.221)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.281s / 10iters, (0.828)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007491)
Learning rate = [0.009759150404066759, 0.009759150404066759]	Loss = 0.47485927 (ave = 0.23645632)

2023-07-05 14:04:29,060 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 1080	Time 12.197s / 10iters, (1.220)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.766s / 10iters, (0.277)	Data load 0.086s / 10iters, (0.008552)
Learning rate = [0.00975689427188946, 0.00975689427188946]	Loss = 0.25099680 (ave = 0.20461328)

2023-07-05 14:04:41,197 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 1090	Time 12.136s / 10iters, (1.214)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.205s / 10iters, (0.820)	Loss Time 2.740s / 10iters, (0.274)	Data load 0.075s / 10iters, (0.007488)
Learning rate = [0.009754638081744451, 0.009754638081744451]	Loss = 0.25765333 (ave = 0.34285014)

2023-07-05 14:04:53,326 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 1100	Time 12.129s / 10iters, (1.213)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.207s / 10iters, (0.821)	Loss Time 2.757s / 10iters, (0.276)	Data load 0.076s / 10iters, (0.007567)
Learning rate = [0.009752381833615346, 0.009752381833615346]	Loss = 0.28488228 (ave = 0.26898891)

2023-07-05 14:05:05,244 INFO    [trainer_contrastive.py, 272] Train Epoch: 2	Train Iteration: 1110	Time 11.918s / 10iters, (1.192)	Forward Time 1.076s / 10iters, (0.108)	Backward Time 8.063s / 10iters, (0.806)	Loss Time 2.703s / 10iters, (0.270)	Data load 0.076s / 10iters, (0.007560)
Learning rate = [0.00975012552748575, 0.00975012552748575]	Loss = 0.27942461 (ave = 0.28017865)

2023-07-05 14:05:20,241 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1120	Time 14.858s / 10iters, (1.486)	Forward Time 1.255s / 10iters, (0.125)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.747s / 10iters, (0.275)	Data load 2.573s / 10iters, (0.257319)
Learning rate = [0.009747869163339255, 0.009747869163339255]	Loss = 0.17161752 (ave = 0.33755143)

2023-07-05 14:05:32,447 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1130	Time 12.206s / 10iters, (1.221)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.775s / 10iters, (0.277)	Data load 0.079s / 10iters, (0.007922)
Learning rate = [0.00974561274115945, 0.00974561274115945]	Loss = 0.36989632 (ave = 0.35175719)

2023-07-05 14:05:44,695 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1140	Time 12.248s / 10iters, (1.225)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.335s / 10iters, (0.834)	Loss Time 2.719s / 10iters, (0.272)	Data load 0.075s / 10iters, (0.007548)
Learning rate = [0.009743356260929908, 0.009743356260929908]	Loss = 0.28158638 (ave = 0.26901752)

2023-07-05 14:05:57,032 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1150	Time 12.337s / 10iters, (1.234)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.879s / 10iters, (0.288)	Data load 0.086s / 10iters, (0.008630)
Learning rate = [0.009741099722634202, 0.009741099722634202]	Loss = 0.42655635 (ave = 0.25204557)

2023-07-05 14:06:09,368 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1160	Time 12.336s / 10iters, (1.234)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.838s / 10iters, (0.284)	Data load 0.097s / 10iters, (0.009730)
Learning rate = [0.009738843126255888, 0.009738843126255888]	Loss = 0.19842219 (ave = 0.25554467)

2023-07-05 14:06:21,531 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1170	Time 12.163s / 10iters, (1.216)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.083s / 10iters, (0.008253)
Learning rate = [0.009736586471778517, 0.009736586471778517]	Loss = 0.21527310 (ave = 0.25497915)

2023-07-05 14:06:33,725 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1180	Time 12.195s / 10iters, (1.219)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.092s / 10iters, (0.009207)
Learning rate = [0.009734329759185631, 0.009734329759185631]	Loss = 0.24843438 (ave = 0.26147988)

2023-07-05 14:06:45,923 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1190	Time 12.197s / 10iters, (1.220)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.080s / 10iters, (0.007971)
Learning rate = [0.009732072988460764, 0.009732072988460764]	Loss = 0.37547678 (ave = 0.28581308)

2023-07-05 14:06:58,149 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1200	Time 12.226s / 10iters, (1.223)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.795s / 10iters, (0.280)	Data load 0.078s / 10iters, (0.007838)
Learning rate = [0.009729816159587438, 0.009729816159587438]	Loss = 0.29805356 (ave = 0.36149971)

2023-07-05 14:07:10,392 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1210	Time 12.243s / 10iters, (1.224)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007557)
Learning rate = [0.009727559272549167, 0.009727559272549167]	Loss = 0.28803688 (ave = 0.29382258)

2023-07-05 14:07:22,682 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1220	Time 12.291s / 10iters, (1.229)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.078s / 10iters, (0.007753)
Learning rate = [0.009725302327329459, 0.009725302327329459]	Loss = 0.28758952 (ave = 0.26696408)

2023-07-05 14:07:34,976 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1230	Time 12.294s / 10iters, (1.229)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.082s / 10iters, (0.008196)
Learning rate = [0.009723045323911812, 0.009723045323911812]	Loss = 0.22619916 (ave = 0.29059012)

2023-07-05 14:07:47,241 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1240	Time 12.265s / 10iters, (1.226)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.077s / 10iters, (0.007692)
Learning rate = [0.00972078826227971, 0.00972078826227971]	Loss = 0.29707444 (ave = 0.24476828)

2023-07-05 14:07:59,537 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1250	Time 12.296s / 10iters, (1.230)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.245s / 10iters, (0.825)	Loss Time 2.866s / 10iters, (0.287)	Data load 0.082s / 10iters, (0.008187)
Learning rate = [0.009718531142416635, 0.009718531142416635]	Loss = 0.32905051 (ave = 0.23904356)

2023-07-05 14:08:11,886 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1260	Time 12.349s / 10iters, (1.235)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.317s / 10iters, (0.832)	Loss Time 2.857s / 10iters, (0.286)	Data load 0.077s / 10iters, (0.007723)
Learning rate = [0.009716273964306054, 0.009716273964306054]	Loss = 0.21707712 (ave = 0.22417526)

2023-07-05 14:08:24,250 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1270	Time 12.364s / 10iters, (1.236)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.894s / 10iters, (0.289)	Data load 0.077s / 10iters, (0.007726)
Learning rate = [0.009714016727931435, 0.009714016727931435]	Loss = 0.39023522 (ave = 0.29833725)

2023-07-05 14:08:36,546 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1280	Time 12.296s / 10iters, (1.230)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.186s / 10iters, (0.819)	Loss Time 2.911s / 10iters, (0.291)	Data load 0.089s / 10iters, (0.008890)
Learning rate = [0.009711759433276223, 0.009711759433276223]	Loss = 0.33557972 (ave = 0.27269534)

2023-07-05 14:08:48,823 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1290	Time 12.277s / 10iters, (1.228)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.084s / 10iters, (0.008393)
Learning rate = [0.009709502080323864, 0.009709502080323864]	Loss = 0.30796990 (ave = 0.24156400)

2023-07-05 14:09:01,108 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1300	Time 12.284s / 10iters, (1.228)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.186s / 10iters, (0.819)	Loss Time 2.902s / 10iters, (0.290)	Data load 0.098s / 10iters, (0.009764)
Learning rate = [0.009707244669057792, 0.009707244669057792]	Loss = 0.23690967 (ave = 0.25042746)

2023-07-05 14:09:13,385 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1310	Time 12.277s / 10iters, (1.228)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.856s / 10iters, (0.286)	Data load 0.084s / 10iters, (0.008428)
Learning rate = [0.009704987199461433, 0.009704987199461433]	Loss = 0.24291989 (ave = 0.23446680)

2023-07-05 14:09:25,680 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1320	Time 12.295s / 10iters, (1.229)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.861s / 10iters, (0.286)	Data load 0.080s / 10iters, (0.007988)
Learning rate = [0.009702729671518204, 0.009702729671518204]	Loss = 0.29298133 (ave = 0.24878906)

2023-07-05 14:09:38,158 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1330	Time 12.478s / 10iters, (1.248)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.385s / 10iters, (0.838)	Loss Time 2.901s / 10iters, (0.290)	Data load 0.078s / 10iters, (0.007800)
Learning rate = [0.00970047208521151, 0.00970047208521151]	Loss = 0.23039901 (ave = 0.25638472)

2023-07-05 14:09:50,652 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1340	Time 12.495s / 10iters, (1.249)	Forward Time 1.145s / 10iters, (0.115)	Backward Time 8.409s / 10iters, (0.841)	Loss Time 2.866s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007415)
Learning rate = [0.009698214440524749, 0.009698214440524749]	Loss = 0.17258060 (ave = 0.23392991)

2023-07-05 14:10:03,102 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1350	Time 12.450s / 10iters, (1.245)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.376s / 10iters, (0.838)	Loss Time 2.878s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007466)
Learning rate = [0.009695956737441313, 0.009695956737441313]	Loss = 0.44095996 (ave = 0.27180716)

2023-07-05 14:10:15,584 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1360	Time 12.482s / 10iters, (1.248)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.346s / 10iters, (0.835)	Loss Time 2.934s / 10iters, (0.293)	Data load 0.074s / 10iters, (0.007416)
Learning rate = [0.00969369897594458, 0.00969369897594458]	Loss = 0.28350830 (ave = 0.27435865)

2023-07-05 14:10:27,866 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1370	Time 12.282s / 10iters, (1.228)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.216s / 10iters, (0.822)	Loss Time 2.894s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007457)
Learning rate = [0.009691441156017921, 0.009691441156017921]	Loss = 0.39398026 (ave = 0.31876203)

2023-07-05 14:10:40,108 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1380	Time 12.242s / 10iters, (1.224)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.183s / 10iters, (0.818)	Loss Time 2.889s / 10iters, (0.289)	Data load 0.076s / 10iters, (0.007620)
Learning rate = [0.0096891832776447, 0.0096891832776447]	Loss = 0.17598949 (ave = 0.24346733)

2023-07-05 14:10:52,528 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1390	Time 12.419s / 10iters, (1.242)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.326s / 10iters, (0.833)	Loss Time 2.911s / 10iters, (0.291)	Data load 0.078s / 10iters, (0.007782)
Learning rate = [0.00968692534080827, 0.00968692534080827]	Loss = 0.34092173 (ave = 0.24761331)

2023-07-05 14:11:04,889 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1400	Time 12.361s / 10iters, (1.236)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.278s / 10iters, (0.828)	Loss Time 2.896s / 10iters, (0.290)	Data load 0.083s / 10iters, (0.008312)
Learning rate = [0.009684667345491973, 0.009684667345491973]	Loss = 0.17212327 (ave = 0.26261373)

2023-07-05 14:11:17,109 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1410	Time 12.221s / 10iters, (1.222)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.207s / 10iters, (0.821)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.079s / 10iters, (0.007948)
Learning rate = [0.009682409291679146, 0.009682409291679146]	Loss = 0.76496530 (ave = 0.31844340)

2023-07-05 14:11:29,444 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1420	Time 12.335s / 10iters, (1.234)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.900s / 10iters, (0.290)	Data load 0.090s / 10iters, (0.009023)
Learning rate = [0.009680151179353112, 0.009680151179353112]	Loss = 0.24365984 (ave = 0.30316601)

2023-07-05 14:11:41,862 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1430	Time 12.417s / 10iters, (1.242)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.928s / 10iters, (0.293)	Data load 0.093s / 10iters, (0.009272)
Learning rate = [0.00967789300849719, 0.00967789300849719]	Loss = 0.20289893 (ave = 0.29154811)

2023-07-05 14:11:54,386 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1440	Time 12.524s / 10iters, (1.252)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.385s / 10iters, (0.838)	Loss Time 2.957s / 10iters, (0.296)	Data load 0.077s / 10iters, (0.007716)
Learning rate = [0.00967563477909469, 0.00967563477909469]	Loss = 0.48063090 (ave = 0.38272768)

2023-07-05 14:12:06,744 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1450	Time 12.358s / 10iters, (1.236)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.897s / 10iters, (0.290)	Data load 0.095s / 10iters, (0.009513)
Learning rate = [0.009673376491128908, 0.009673376491128908]	Loss = 0.24547340 (ave = 0.32498504)

2023-07-05 14:12:19,006 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1460	Time 12.262s / 10iters, (1.226)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.225s / 10iters, (0.822)	Loss Time 2.875s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007356)
Learning rate = [0.00967111814458313, 0.00967111814458313]	Loss = 0.15508822 (ave = 0.35387748)

2023-07-05 14:12:31,209 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1470	Time 12.203s / 10iters, (1.220)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.170s / 10iters, (0.817)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.087s / 10iters, (0.008679)
Learning rate = [0.009668859739440643, 0.009668859739440643]	Loss = 0.56127125 (ave = 0.31058018)

2023-07-05 14:12:43,214 INFO    [trainer_contrastive.py, 272] Train Epoch: 3	Train Iteration: 1480	Time 12.005s / 10iters, (1.200)	Forward Time 1.081s / 10iters, (0.108)	Backward Time 8.105s / 10iters, (0.810)	Loss Time 2.743s / 10iters, (0.274)	Data load 0.075s / 10iters, (0.007530)
Learning rate = [0.009666601275684715, 0.009666601275684715]	Loss = 0.23945396 (ave = 0.27454039)

2023-07-05 14:12:58,044 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1490	Time 14.684s / 10iters, (1.468)	Forward Time 1.225s / 10iters, (0.122)	Backward Time 8.298s / 10iters, (0.830)	Loss Time 2.726s / 10iters, (0.273)	Data load 2.436s / 10iters, (0.243558)
Learning rate = [0.009664342753298609, 0.009664342753298609]	Loss = 0.27998647 (ave = 0.25155562)

2023-07-05 14:13:10,366 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1500	Time 12.323s / 10iters, (1.232)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.365s / 10iters, (0.837)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.081s / 10iters, (0.008058)
Learning rate = [0.009662084172265576, 0.009662084172265576]	Loss = 0.41758728 (ave = 0.31600468)

2023-07-05 14:13:22,620 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1510	Time 12.254s / 10iters, (1.225)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.093s / 10iters, (0.009269)
Learning rate = [0.009659825532568864, 0.009659825532568864]	Loss = 0.20415205 (ave = 0.29019048)

2023-07-05 14:13:34,849 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1520	Time 12.229s / 10iters, (1.223)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.282s / 10iters, (0.828)	Loss Time 2.745s / 10iters, (0.274)	Data load 0.091s / 10iters, (0.009107)
Learning rate = [0.009657566834191706, 0.009657566834191706]	Loss = 0.17207812 (ave = 0.23562707)

2023-07-05 14:13:47,039 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1530	Time 12.190s / 10iters, (1.219)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.731s / 10iters, (0.273)	Data load 0.075s / 10iters, (0.007506)
Learning rate = [0.009655308077117326, 0.009655308077117326]	Loss = 0.21935560 (ave = 0.20697765)

2023-07-05 14:13:59,296 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1540	Time 12.257s / 10iters, (1.226)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.760s / 10iters, (0.276)	Data load 0.099s / 10iters, (0.009946)
Learning rate = [0.009653049261328941, 0.009653049261328941]	Loss = 0.29086709 (ave = 0.27469769)

2023-07-05 14:14:11,614 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1550	Time 12.317s / 10iters, (1.232)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.815s / 10iters, (0.282)	Data load 0.083s / 10iters, (0.008329)
Learning rate = [0.00965079038680976, 0.00965079038680976]	Loss = 0.17085075 (ave = 0.26336526)

2023-07-05 14:14:23,895 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1560	Time 12.281s / 10iters, (1.228)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.265s / 10iters, (0.826)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007490)
Learning rate = [0.009648531453542981, 0.009648531453542981]	Loss = 0.21669194 (ave = 0.28161052)

2023-07-05 14:14:36,135 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1570	Time 12.241s / 10iters, (1.224)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007417)
Learning rate = [0.009646272461511791, 0.009646272461511791]	Loss = 0.24922661 (ave = 0.22940224)

2023-07-05 14:14:48,427 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1580	Time 12.292s / 10iters, (1.229)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.089s / 10iters, (0.008853)
Learning rate = [0.00964401341069937, 0.00964401341069937]	Loss = 0.14215529 (ave = 0.23829306)

2023-07-05 14:15:00,795 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1590	Time 12.368s / 10iters, (1.237)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.087s / 10iters, (0.008723)
Learning rate = [0.009641754301088892, 0.009641754301088892]	Loss = 0.18266726 (ave = 0.23443261)

2023-07-05 14:15:13,048 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1600	Time 12.253s / 10iters, (1.225)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.226s / 10iters, (0.823)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007489)
Learning rate = [0.009639495132663515, 0.009639495132663515]	Loss = 0.12289313 (ave = 0.22897952)

2023-07-05 14:15:25,275 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1610	Time 12.227s / 10iters, (1.223)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.210s / 10iters, (0.821)	Loss Time 2.835s / 10iters, (0.283)	Data load 0.078s / 10iters, (0.007848)
Learning rate = [0.009637235905406393, 0.009637235905406393]	Loss = 0.33693972 (ave = 0.26142530)

2023-07-05 14:15:37,493 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1620	Time 12.219s / 10iters, (1.222)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.199s / 10iters, (0.820)	Loss Time 2.835s / 10iters, (0.284)	Data load 0.083s / 10iters, (0.008302)
Learning rate = [0.009634976619300668, 0.009634976619300668]	Loss = 0.18138088 (ave = 0.20992341)

2023-07-05 14:15:49,706 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1630	Time 12.212s / 10iters, (1.221)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.187s / 10iters, (0.819)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.097s / 10iters, (0.009739)
Learning rate = [0.009632717274329473, 0.009632717274329473]	Loss = 0.21818638 (ave = 0.24515088)

2023-07-05 14:16:01,905 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1640	Time 12.199s / 10iters, (1.220)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007586)
Learning rate = [0.009630457870475935, 0.009630457870475935]	Loss = 0.12968977 (ave = 0.20019060)

2023-07-05 14:16:14,190 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1650	Time 12.285s / 10iters, (1.228)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.868s / 10iters, (0.287)	Data load 0.076s / 10iters, (0.007640)
Learning rate = [0.009628198407723167, 0.009628198407723167]	Loss = 0.30807951 (ave = 0.23618448)

2023-07-05 14:16:26,476 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1660	Time 12.287s / 10iters, (1.229)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.083s / 10iters, (0.008287)
Learning rate = [0.009625938886054276, 0.009625938886054276]	Loss = 0.15228288 (ave = 0.22204143)

2023-07-05 14:16:38,665 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1670	Time 12.189s / 10iters, (1.219)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.182s / 10iters, (0.818)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.083s / 10iters, (0.008306)
Learning rate = [0.009623679305452357, 0.009623679305452357]	Loss = 0.33755922 (ave = 0.30053774)

2023-07-05 14:16:50,874 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1680	Time 12.209s / 10iters, (1.221)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.210s / 10iters, (0.821)	Loss Time 2.833s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007421)
Learning rate = [0.009621419665900502, 0.009621419665900502]	Loss = 0.21041119 (ave = 0.24391280)

2023-07-05 14:17:03,126 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1690	Time 12.252s / 10iters, (1.225)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.209s / 10iters, (0.821)	Loss Time 2.865s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007420)
Learning rate = [0.009619159967381786, 0.009619159967381786]	Loss = 0.23895229 (ave = 0.20687873)

2023-07-05 14:17:15,395 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1700	Time 12.269s / 10iters, (1.227)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.891s / 10iters, (0.289)	Data load 0.074s / 10iters, (0.007395)
Learning rate = [0.009616900209879277, 0.009616900209879277]	Loss = 0.13944399 (ave = 0.31009624)

2023-07-05 14:17:27,695 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1710	Time 12.300s / 10iters, (1.230)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.878s / 10iters, (0.288)	Data load 0.085s / 10iters, (0.008485)
Learning rate = [0.009614640393376037, 0.009614640393376037]	Loss = 0.28778923 (ave = 0.31188995)

2023-07-05 14:17:39,958 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1720	Time 12.263s / 10iters, (1.226)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.888s / 10iters, (0.289)	Data load 0.077s / 10iters, (0.007653)
Learning rate = [0.009612380517855117, 0.009612380517855117]	Loss = 0.24035516 (ave = 0.26799703)

2023-07-05 14:17:52,258 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1730	Time 12.300s / 10iters, (1.230)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.880s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007386)
Learning rate = [0.009610120583299554, 0.009610120583299554]	Loss = 0.72954351 (ave = 0.32937272)

2023-07-05 14:18:04,649 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1740	Time 12.391s / 10iters, (1.239)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.317s / 10iters, (0.832)	Loss Time 2.890s / 10iters, (0.289)	Data load 0.083s / 10iters, (0.008349)
Learning rate = [0.009607860589692383, 0.009607860589692383]	Loss = 0.13379924 (ave = 0.31398551)

2023-07-05 14:18:16,886 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1750	Time 12.236s / 10iters, (1.224)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007422)
Learning rate = [0.009605600537016628, 0.009605600537016628]	Loss = 0.40137178 (ave = 0.39088690)

2023-07-05 14:18:29,217 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1760	Time 12.331s / 10iters, (1.233)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.904s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007476)
Learning rate = [0.009603340425255298, 0.009603340425255298]	Loss = 0.43819723 (ave = 0.37703133)

2023-07-05 14:18:41,422 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1770	Time 12.205s / 10iters, (1.220)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.178s / 10iters, (0.818)	Loss Time 2.865s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007392)
Learning rate = [0.009601080254391402, 0.009601080254391402]	Loss = 0.34580031 (ave = 0.36097143)

2023-07-05 14:18:53,546 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1780	Time 12.124s / 10iters, (1.212)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.131s / 10iters, (0.813)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007387)
Learning rate = [0.009598820024407926, 0.009598820024407926]	Loss = 0.21830079 (ave = 0.29059979)

2023-07-05 14:19:05,741 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1790	Time 12.196s / 10iters, (1.220)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.195s / 10iters, (0.820)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007400)
Learning rate = [0.009596559735287866, 0.009596559735287866]	Loss = 0.21533707 (ave = 0.35345600)

2023-07-05 14:19:17,941 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1800	Time 12.200s / 10iters, (1.220)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007396)
Learning rate = [0.009594299387014192, 0.009594299387014192]	Loss = 0.27263758 (ave = 0.40224656)

2023-07-05 14:19:30,145 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1810	Time 12.203s / 10iters, (1.220)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.165s / 10iters, (0.816)	Loss Time 2.875s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007444)
Learning rate = [0.009592038979569869, 0.009592038979569869]	Loss = 0.32254297 (ave = 0.34297630)

2023-07-05 14:19:42,297 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1820	Time 12.152s / 10iters, (1.215)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.149s / 10iters, (0.815)	Loss Time 2.820s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007536)
Learning rate = [0.009589778512937857, 0.009589778512937857]	Loss = 0.33992213 (ave = 0.32255467)

2023-07-05 14:19:54,413 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1830	Time 12.116s / 10iters, (1.212)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.116s / 10iters, (0.812)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007419)
Learning rate = [0.009587517987101103, 0.009587517987101103]	Loss = 0.46080998 (ave = 0.29980337)

2023-07-05 14:20:06,577 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1840	Time 12.164s / 10iters, (1.216)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.172s / 10iters, (0.817)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007388)
Learning rate = [0.009585257402042545, 0.009585257402042545]	Loss = 0.29376343 (ave = 0.30523727)

2023-07-05 14:20:18,622 INFO    [trainer_contrastive.py, 272] Train Epoch: 4	Train Iteration: 1850	Time 12.045s / 10iters, (1.205)	Forward Time 1.081s / 10iters, (0.108)	Backward Time 8.140s / 10iters, (0.814)	Loss Time 2.751s / 10iters, (0.275)	Data load 0.073s / 10iters, (0.007304)
Learning rate = [0.009582996757745111, 0.009582996757745111]	Loss = 0.46747705 (ave = 0.36928868)

2023-07-05 14:20:33,274 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 1860	Time 14.536s / 10iters, (1.454)	Forward Time 1.215s / 10iters, (0.121)	Backward Time 8.181s / 10iters, (0.818)	Loss Time 2.645s / 10iters, (0.265)	Data load 2.494s / 10iters, (0.249448)
Learning rate = [0.009580736054191723, 0.009580736054191723]	Loss = 0.21153882 (ave = 0.30103046)

2023-07-05 14:20:45,443 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 1870	Time 12.169s / 10iters, (1.217)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.323s / 10iters, (0.832)	Loss Time 2.669s / 10iters, (0.267)	Data load 0.075s / 10iters, (0.007508)
Learning rate = [0.009578475291365289, 0.009578475291365289]	Loss = 0.44240382 (ave = 0.29719635)

2023-07-05 14:20:57,609 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 1880	Time 12.166s / 10iters, (1.217)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.307s / 10iters, (0.831)	Loss Time 2.683s / 10iters, (0.268)	Data load 0.075s / 10iters, (0.007458)
Learning rate = [0.009576214469248712, 0.009576214469248712]	Loss = 0.30498019 (ave = 0.27130879)

2023-07-05 14:21:09,797 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 1890	Time 12.188s / 10iters, (1.219)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.328s / 10iters, (0.833)	Loss Time 2.683s / 10iters, (0.268)	Data load 0.084s / 10iters, (0.008352)
Learning rate = [0.00957395358782488, 0.00957395358782488]	Loss = 0.26308814 (ave = 0.25206650)

2023-07-05 14:21:21,938 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 1900	Time 12.141s / 10iters, (1.214)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.674s / 10iters, (0.267)	Data load 0.075s / 10iters, (0.007478)
Learning rate = [0.009571692647076677, 0.009571692647076677]	Loss = 0.28649420 (ave = 0.28629504)

2023-07-05 14:21:34,146 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 1910	Time 12.208s / 10iters, (1.221)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.288s / 10iters, (0.829)	Loss Time 2.751s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007492)
Learning rate = [0.009569431646986978, 0.009569431646986978]	Loss = 0.34596181 (ave = 0.26667801)

2023-07-05 14:21:46,436 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 1920	Time 12.290s / 10iters, (1.229)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.320s / 10iters, (0.832)	Loss Time 2.765s / 10iters, (0.276)	Data load 0.086s / 10iters, (0.008614)
Learning rate = [0.00956717058753864, 0.00956717058753864]	Loss = 0.30136621 (ave = 0.26677927)

2023-07-05 14:21:58,697 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 1930	Time 12.261s / 10iters, (1.226)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.743s / 10iters, (0.274)	Data load 0.087s / 10iters, (0.008702)
Learning rate = [0.00956490946871452, 0.00956490946871452]	Loss = 0.34139255 (ave = 0.28093450)

2023-07-05 14:22:10,992 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 1940	Time 12.295s / 10iters, (1.230)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.377s / 10iters, (0.838)	Loss Time 2.734s / 10iters, (0.273)	Data load 0.079s / 10iters, (0.007910)
Learning rate = [0.009562648290497463, 0.009562648290497463]	Loss = 0.28075701 (ave = 0.26934786)

2023-07-05 14:22:23,281 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 1950	Time 12.288s / 10iters, (1.229)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.361s / 10iters, (0.836)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.081s / 10iters, (0.008064)
Learning rate = [0.009560387052870302, 0.009560387052870302]	Loss = 0.55438542 (ave = 0.27069976)

2023-07-05 14:22:35,633 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 1960	Time 12.352s / 10iters, (1.235)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.390s / 10iters, (0.839)	Loss Time 2.758s / 10iters, (0.276)	Data load 0.079s / 10iters, (0.007922)
Learning rate = [0.009558125755815864, 0.009558125755815864]	Loss = 0.18521066 (ave = 0.24575724)

2023-07-05 14:22:47,802 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 1970	Time 12.170s / 10iters, (1.217)	Forward Time 1.182s / 10iters, (0.118)	Backward Time 8.230s / 10iters, (0.823)	Loss Time 2.665s / 10iters, (0.266)	Data load 0.092s / 10iters, (0.009213)
Learning rate = [0.009555864399316962, 0.009555864399316962]	Loss = 0.16422901 (ave = 0.31135247)

2023-07-05 14:23:00,039 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 1980	Time 12.236s / 10iters, (1.224)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.086s / 10iters, (0.008650)
Learning rate = [0.009553602983356403, 0.009553602983356403]	Loss = 0.18411995 (ave = 0.25637031)

2023-07-05 14:23:12,317 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 1990	Time 12.278s / 10iters, (1.228)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.328s / 10iters, (0.833)	Loss Time 2.762s / 10iters, (0.276)	Data load 0.084s / 10iters, (0.008362)
Learning rate = [0.009551341507916986, 0.009551341507916986]	Loss = 0.30768040 (ave = 0.22551527)

2023-07-05 14:23:24,636 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2000	Time 12.318s / 10iters, (1.232)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.295s / 10iters, (0.830)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.086s / 10iters, (0.008643)
Learning rate = [0.009549079972981494, 0.009549079972981494]	Loss = 0.27552822 (ave = 0.24922625)

2023-07-05 14:23:28,064 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 14:23:51,912 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 14:24:15,086 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 14:24:38,054 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 14:25:00,943 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 14:25:23,892 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 14:25:46,021 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 14:25:51,682 INFO    [base.py, 84] Performance 0.5938697415777189 -> 0.621844403488078
2023-07-05 14:25:57,082 INFO    [trainer_contrastive.py, 391] Test Time 146.922s, (2.332)	Loss 0.22712018

2023-07-05 14:25:57,083 INFO    [base.py, 33] Result for seg
2023-07-05 14:25:57,083 INFO    [base.py, 49] Mean IOU: 0.621844403488078

2023-07-05 14:25:57,084 INFO    [base.py, 50] Pixel ACC: 0.9293385806531977

2023-07-05 14:26:09,151 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2010	Time 164.515s / 10iters, (16.451)	Forward Time 1.148s / 10iters, (0.115)	Backward Time 8.124s / 10iters, (0.812)	Loss Time 2.706s / 10iters, (0.271)	Data load 152.536s / 10iters, (15.253633)
Learning rate = [0.009546818378532709, 0.009546818378532709]	Loss = 0.30364656 (ave = 0.25888807)

2023-07-05 14:26:21,301 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2020	Time 12.151s / 10iters, (1.215)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.077s / 10iters, (0.007696)
Learning rate = [0.009544556724553396, 0.009544556724553396]	Loss = 0.19600055 (ave = 0.25639957)

2023-07-05 14:26:33,684 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2030	Time 12.383s / 10iters, (1.238)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.378s / 10iters, (0.838)	Loss Time 2.803s / 10iters, (0.280)	Data load 0.085s / 10iters, (0.008507)
Learning rate = [0.009542295011026316, 0.009542295011026316]	Loss = 0.22976510 (ave = 0.24888765)

2023-07-05 14:26:45,745 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2040	Time 12.060s / 10iters, (1.206)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.144s / 10iters, (0.814)	Loss Time 2.743s / 10iters, (0.274)	Data load 0.075s / 10iters, (0.007507)
Learning rate = [0.009540033237934217, 0.009540033237934217]	Loss = 0.39796257 (ave = 0.28711170)

2023-07-05 14:26:57,837 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2050	Time 12.093s / 10iters, (1.209)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.149s / 10iters, (0.815)	Loss Time 2.766s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007558)
Learning rate = [0.009537771405259838, 0.009537771405259838]	Loss = 0.19024770 (ave = 0.24804885)

2023-07-05 14:27:09,972 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2060	Time 12.135s / 10iters, (1.213)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.725s / 10iters, (0.272)	Data load 0.081s / 10iters, (0.008066)
Learning rate = [0.00953550951298591, 0.00953550951298591]	Loss = 0.16035959 (ave = 0.22113424)

2023-07-05 14:27:22,157 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2070	Time 12.185s / 10iters, (1.218)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.765s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007582)
Learning rate = [0.009533247561095151, 0.009533247561095151]	Loss = 0.54952168 (ave = 0.26263358)

2023-07-05 14:27:34,483 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2080	Time 12.326s / 10iters, (1.233)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.323s / 10iters, (0.832)	Loss Time 2.808s / 10iters, (0.281)	Data load 0.081s / 10iters, (0.008072)
Learning rate = [0.009530985549570277, 0.009530985549570277]	Loss = 0.26599368 (ave = 0.29209015)

2023-07-05 14:27:46,660 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2090	Time 12.178s / 10iters, (1.218)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.205s / 10iters, (0.821)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.077s / 10iters, (0.007664)
Learning rate = [0.009528723478393985, 0.009528723478393985]	Loss = 0.12391245 (ave = 0.22482454)

2023-07-05 14:27:58,989 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2100	Time 12.328s / 10iters, (1.233)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.345s / 10iters, (0.834)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.097s / 10iters, (0.009658)
Learning rate = [0.009526461347548965, 0.009526461347548965]	Loss = 0.24486904 (ave = 0.26033535)

2023-07-05 14:28:11,216 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2110	Time 12.227s / 10iters, (1.223)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.766s / 10iters, (0.277)	Data load 0.101s / 10iters, (0.010105)
Learning rate = [0.009524199157017906, 0.009524199157017906]	Loss = 0.16065866 (ave = 0.29534436)

2023-07-05 14:28:23,339 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2120	Time 12.124s / 10iters, (1.212)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.148s / 10iters, (0.815)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.078s / 10iters, (0.007809)
Learning rate = [0.009521936906783475, 0.009521936906783475]	Loss = 0.22917096 (ave = 0.25861929)

2023-07-05 14:28:35,575 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2130	Time 12.235s / 10iters, (1.224)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.203s / 10iters, (0.820)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.106s / 10iters, (0.010595)
Learning rate = [0.009519674596828337, 0.009519674596828337]	Loss = 0.19402990 (ave = 0.24815881)

2023-07-05 14:28:47,846 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2140	Time 12.271s / 10iters, (1.227)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.235s / 10iters, (0.823)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.096s / 10iters, (0.009649)
Learning rate = [0.009517412227135143, 0.009517412227135143]	Loss = 0.19539434 (ave = 0.26915106)

2023-07-05 14:29:00,123 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2150	Time 12.277s / 10iters, (1.228)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007485)
Learning rate = [0.00951514979768654, 0.00951514979768654]	Loss = 0.26532742 (ave = 0.26646704)

2023-07-05 14:29:12,323 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2160	Time 12.200s / 10iters, (1.220)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.797s / 10iters, (0.280)	Data load 0.077s / 10iters, (0.007738)
Learning rate = [0.00951288730846516, 0.00951288730846516]	Loss = 0.27791888 (ave = 0.26840996)

2023-07-05 14:29:24,527 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2170	Time 12.204s / 10iters, (1.220)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.177s / 10iters, (0.818)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.091s / 10iters, (0.009125)
Learning rate = [0.00951062475945363, 0.00951062475945363]	Loss = 0.18927248 (ave = 0.22530289)

2023-07-05 14:29:36,729 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2180	Time 12.203s / 10iters, (1.220)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.204s / 10iters, (0.820)	Loss Time 2.805s / 10iters, (0.280)	Data load 0.085s / 10iters, (0.008463)
Learning rate = [0.00950836215063456, 0.00950836215063456]	Loss = 0.19332902 (ave = 0.25794226)

2023-07-05 14:29:48,941 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2190	Time 12.211s / 10iters, (1.221)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.084s / 10iters, (0.008440)
Learning rate = [0.009506099481990559, 0.009506099481990559]	Loss = 0.42892385 (ave = 0.22539739)

2023-07-05 14:30:01,147 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2200	Time 12.207s / 10iters, (1.221)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007553)
Learning rate = [0.00950383675350422, 0.00950383675350422]	Loss = 1.58969033 (ave = 0.38824333)

2023-07-05 14:30:13,309 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2210	Time 12.161s / 10iters, (1.216)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.150s / 10iters, (0.815)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007491)
Learning rate = [0.009501573965158132, 0.009501573965158132]	Loss = 0.25820979 (ave = 0.29634373)

2023-07-05 14:30:25,248 INFO    [trainer_contrastive.py, 272] Train Epoch: 5	Train Iteration: 2220	Time 11.939s / 10iters, (1.194)	Forward Time 1.074s / 10iters, (0.107)	Backward Time 8.070s / 10iters, (0.807)	Loss Time 2.723s / 10iters, (0.272)	Data load 0.073s / 10iters, (0.007272)
Learning rate = [0.00949931111693487, 0.00949931111693487]	Loss = 0.22397982 (ave = 0.24918271)

2023-07-05 14:30:39,952 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2230	Time 14.580s / 10iters, (1.458)	Forward Time 1.202s / 10iters, (0.120)	Backward Time 8.105s / 10iters, (0.811)	Loss Time 2.738s / 10iters, (0.274)	Data load 2.534s / 10iters, (0.253438)
Learning rate = [0.009497048208816996, 0.009497048208816996]	Loss = 0.12576632 (ave = 0.22772774)

2023-07-05 14:30:52,019 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2240	Time 12.067s / 10iters, (1.207)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.149s / 10iters, (0.815)	Loss Time 2.755s / 10iters, (0.275)	Data load 0.076s / 10iters, (0.007630)
Learning rate = [0.009494785240787073, 0.009494785240787073]	Loss = 0.24980101 (ave = 0.21173618)

2023-07-05 14:31:04,251 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2250	Time 12.232s / 10iters, (1.223)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.270s / 10iters, (0.827)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007499)
Learning rate = [0.009492522212827646, 0.009492522212827646]	Loss = 0.28067088 (ave = 0.24963360)

2023-07-05 14:31:16,482 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2260	Time 12.230s / 10iters, (1.223)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.281s / 10iters, (0.828)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.082s / 10iters, (0.008194)
Learning rate = [0.00949025912492125, 0.00949025912492125]	Loss = 0.25091943 (ave = 0.24459489)

2023-07-05 14:31:28,659 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2270	Time 12.177s / 10iters, (1.218)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.775s / 10iters, (0.278)	Data load 0.079s / 10iters, (0.007851)
Learning rate = [0.009487995977050414, 0.009487995977050414]	Loss = 0.22775862 (ave = 0.19792605)

2023-07-05 14:31:40,980 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2280	Time 12.320s / 10iters, (1.232)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.326s / 10iters, (0.833)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.084s / 10iters, (0.008397)
Learning rate = [0.009485732769197659, 0.009485732769197659]	Loss = 0.10741670 (ave = 0.20872477)

2023-07-05 14:31:53,104 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2290	Time 12.124s / 10iters, (1.212)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.176s / 10iters, (0.818)	Loss Time 2.756s / 10iters, (0.276)	Data load 0.076s / 10iters, (0.007621)
Learning rate = [0.009483469501345487, 0.009483469501345487]	Loss = 0.15818042 (ave = 0.22659864)

2023-07-05 14:32:05,533 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2300	Time 12.429s / 10iters, (1.243)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.419s / 10iters, (0.842)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.084s / 10iters, (0.008365)
Learning rate = [0.009481206173476402, 0.009481206173476402]	Loss = 0.30821708 (ave = 0.21616589)

2023-07-05 14:32:17,676 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2310	Time 12.143s / 10iters, (1.214)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007460)
Learning rate = [0.009478942785572889, 0.009478942785572889]	Loss = 0.14836575 (ave = 0.22762397)

2023-07-05 14:32:29,924 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2320	Time 12.248s / 10iters, (1.225)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.769s / 10iters, (0.277)	Data load 0.088s / 10iters, (0.008824)
Learning rate = [0.00947667933761743, 0.00947667933761743]	Loss = 0.26153719 (ave = 0.25249229)

2023-07-05 14:32:42,133 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2330	Time 12.208s / 10iters, (1.221)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.285s / 10iters, (0.829)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.074s / 10iters, (0.007378)
Learning rate = [0.009474415829592492, 0.009474415829592492]	Loss = 0.32913849 (ave = 0.23569631)

2023-07-05 14:32:54,501 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2340	Time 12.368s / 10iters, (1.237)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.338s / 10iters, (0.834)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.079s / 10iters, (0.007928)
Learning rate = [0.009472152261480534, 0.009472152261480534]	Loss = 0.17793326 (ave = 0.22093529)

2023-07-05 14:33:06,797 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2350	Time 12.297s / 10iters, (1.230)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007636)
Learning rate = [0.009469888633264008, 0.009469888633264008]	Loss = 0.27115366 (ave = 0.28604372)

2023-07-05 14:33:19,115 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2360	Time 12.318s / 10iters, (1.232)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.347s / 10iters, (0.835)	Loss Time 2.786s / 10iters, (0.279)	Data load 0.079s / 10iters, (0.007880)
Learning rate = [0.009467624944925352, 0.009467624944925352]	Loss = 0.30766168 (ave = 0.24034794)

2023-07-05 14:33:31,416 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2370	Time 12.301s / 10iters, (1.230)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.085s / 10iters, (0.008457)
Learning rate = [0.009465361196446996, 0.009465361196446996]	Loss = 0.29248595 (ave = 0.23194501)

2023-07-05 14:33:43,577 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2380	Time 12.160s / 10iters, (1.216)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.083s / 10iters, (0.008252)
Learning rate = [0.00946309738781136, 0.00946309738781136]	Loss = 0.22069138 (ave = 0.24975087)

2023-07-05 14:33:55,776 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2390	Time 12.200s / 10iters, (1.220)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.207s / 10iters, (0.821)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007597)
Learning rate = [0.009460833519000856, 0.009460833519000856]	Loss = 0.17723314 (ave = 0.22861222)

2023-07-05 14:34:07,970 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2400	Time 12.193s / 10iters, (1.219)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.176s / 10iters, (0.818)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007409)
Learning rate = [0.009458569589997882, 0.009458569589997882]	Loss = 0.25118285 (ave = 0.21317063)

2023-07-05 14:34:20,299 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2410	Time 12.329s / 10iters, (1.233)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.894s / 10iters, (0.289)	Data load 0.079s / 10iters, (0.007879)
Learning rate = [0.009456305600784832, 0.009456305600784832]	Loss = 0.33263251 (ave = 0.26722293)

2023-07-05 14:34:32,693 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2420	Time 12.394s / 10iters, (1.239)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.278s / 10iters, (0.828)	Loss Time 2.932s / 10iters, (0.293)	Data load 0.082s / 10iters, (0.008233)
Learning rate = [0.009454041551344083, 0.009454041551344083]	Loss = 0.20351800 (ave = 0.25464225)

2023-07-05 14:34:45,116 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2430	Time 12.423s / 10iters, (1.242)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.342s / 10iters, (0.834)	Loss Time 2.901s / 10iters, (0.290)	Data load 0.083s / 10iters, (0.008347)
Learning rate = [0.009451777441658009, 0.009451777441658009]	Loss = 0.26270038 (ave = 0.26776923)

2023-07-05 14:34:57,526 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2440	Time 12.410s / 10iters, (1.241)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.897s / 10iters, (0.290)	Data load 0.090s / 10iters, (0.008981)
Learning rate = [0.009449513271708971, 0.009449513271708971]	Loss = 0.35657823 (ave = 0.22894325)

2023-07-05 14:35:09,989 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2450	Time 12.463s / 10iters, (1.246)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.353s / 10iters, (0.835)	Loss Time 2.907s / 10iters, (0.291)	Data load 0.084s / 10iters, (0.008404)
Learning rate = [0.00944724904147932, 0.00944724904147932]	Loss = 0.16869745 (ave = 0.20336431)

2023-07-05 14:35:22,316 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2460	Time 12.327s / 10iters, (1.233)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.897s / 10iters, (0.290)	Data load 0.090s / 10iters, (0.008959)
Learning rate = [0.009444984750951395, 0.009444984750951395]	Loss = 0.14056173 (ave = 0.21642320)

2023-07-05 14:35:34,638 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2470	Time 12.322s / 10iters, (1.232)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.085s / 10iters, (0.008455)
Learning rate = [0.00944272040010753, 0.00944272040010753]	Loss = 0.19880061 (ave = 0.21039085)

2023-07-05 14:35:47,130 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2480	Time 12.492s / 10iters, (1.249)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.382s / 10iters, (0.838)	Loss Time 2.917s / 10iters, (0.292)	Data load 0.096s / 10iters, (0.009598)
Learning rate = [0.00944045598893005, 0.00944045598893005]	Loss = 0.16850148 (ave = 0.24548532)

2023-07-05 14:35:59,518 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2490	Time 12.387s / 10iters, (1.239)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.368s / 10iters, (0.837)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.096s / 10iters, (0.009624)
Learning rate = [0.00943819151740126, 0.00943819151740126]	Loss = 0.30313611 (ave = 0.20949242)

2023-07-05 14:36:11,953 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2500	Time 12.435s / 10iters, (1.244)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.334s / 10iters, (0.833)	Loss Time 2.907s / 10iters, (0.291)	Data load 0.077s / 10iters, (0.007709)
Learning rate = [0.009435926985503464, 0.009435926985503464]	Loss = 0.28123748 (ave = 0.29324714)

2023-07-05 14:36:24,329 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2510	Time 12.376s / 10iters, (1.238)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.312s / 10iters, (0.831)	Loss Time 2.880s / 10iters, (0.288)	Data load 0.082s / 10iters, (0.008213)
Learning rate = [0.009433662393218958, 0.009433662393218958]	Loss = 0.22295158 (ave = 0.24751975)

2023-07-05 14:36:36,749 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2520	Time 12.420s / 10iters, (1.242)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.307s / 10iters, (0.831)	Loss Time 2.922s / 10iters, (0.292)	Data load 0.084s / 10iters, (0.008415)
Learning rate = [0.00943139774053002, 0.00943139774053002]	Loss = 0.25992656 (ave = 0.33461929)

2023-07-05 14:36:49,078 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2530	Time 12.330s / 10iters, (1.233)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.077s / 10iters, (0.007747)
Learning rate = [0.009429133027418924, 0.009429133027418924]	Loss = 0.42681870 (ave = 0.32225424)

2023-07-05 14:37:01,399 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2540	Time 12.320s / 10iters, (1.232)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.323s / 10iters, (0.832)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.079s / 10iters, (0.007854)
Learning rate = [0.00942686825386793, 0.00942686825386793]	Loss = 0.30800530 (ave = 0.29570326)

2023-07-05 14:37:13,664 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2550	Time 12.265s / 10iters, (1.227)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.286s / 10iters, (0.829)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007580)
Learning rate = [0.009424603419859293, 0.009424603419859293]	Loss = 0.26565543 (ave = 0.25891325)

2023-07-05 14:37:25,988 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2560	Time 12.324s / 10iters, (1.232)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.078s / 10iters, (0.007788)
Learning rate = [0.009422338525375254, 0.009422338525375254]	Loss = 0.20009784 (ave = 0.27725331)

2023-07-05 14:37:38,167 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2570	Time 12.179s / 10iters, (1.218)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.208s / 10iters, (0.821)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.082s / 10iters, (0.008159)
Learning rate = [0.009420073570398048, 0.009420073570398048]	Loss = 0.23064177 (ave = 0.26396258)

2023-07-05 14:37:50,430 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2580	Time 12.263s / 10iters, (1.226)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.078s / 10iters, (0.007817)
Learning rate = [0.00941780855490989, 0.00941780855490989]	Loss = 0.12719601 (ave = 0.24823252)

2023-07-05 14:38:02,504 INFO    [trainer_contrastive.py, 272] Train Epoch: 6	Train Iteration: 2590	Time 12.073s / 10iters, (1.207)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.146s / 10iters, (0.815)	Loss Time 2.765s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007363)
Learning rate = [0.009415543478893, 0.009415543478893]	Loss = 0.27768105 (ave = 0.23698021)

2023-07-05 14:38:17,150 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2600	Time 14.508s / 10iters, (1.451)	Forward Time 1.325s / 10iters, (0.132)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.729s / 10iters, (0.273)	Data load 2.177s / 10iters, (0.217666)
Learning rate = [0.009413278342329577, 0.009413278342329577]	Loss = 0.19852585 (ave = 0.24078899)

2023-07-05 14:38:29,375 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2610	Time 12.225s / 10iters, (1.222)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.094s / 10iters, (0.009419)
Learning rate = [0.009411013145201815, 0.009411013145201815]	Loss = 0.32344723 (ave = 0.23490595)

2023-07-05 14:38:41,597 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2620	Time 12.222s / 10iters, (1.222)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.225s / 10iters, (0.823)	Loss Time 2.775s / 10iters, (0.278)	Data load 0.091s / 10iters, (0.009084)
Learning rate = [0.009408747887491896, 0.009408747887491896]	Loss = 0.25455812 (ave = 0.25294209)

2023-07-05 14:38:53,871 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2630	Time 12.274s / 10iters, (1.227)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.094s / 10iters, (0.009450)
Learning rate = [0.00940648256918199, 0.00940648256918199]	Loss = 0.21196519 (ave = 0.25226367)

2023-07-05 14:39:06,082 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2640	Time 12.211s / 10iters, (1.221)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.250s / 10iters, (0.825)	Loss Time 2.763s / 10iters, (0.276)	Data load 0.079s / 10iters, (0.007930)
Learning rate = [0.009404217190254263, 0.009404217190254263]	Loss = 0.23143670 (ave = 0.24527114)

2023-07-05 14:39:18,334 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2650	Time 12.252s / 10iters, (1.225)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.285s / 10iters, (0.829)	Loss Time 2.786s / 10iters, (0.279)	Data load 0.081s / 10iters, (0.008125)
Learning rate = [0.009401951750690868, 0.009401951750690868]	Loss = 0.30151972 (ave = 0.24011930)

2023-07-05 14:39:30,774 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2660	Time 12.440s / 10iters, (1.244)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.382s / 10iters, (0.838)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.085s / 10iters, (0.008475)
Learning rate = [0.009399686250473941, 0.009399686250473941]	Loss = 0.19650334 (ave = 0.22604992)

2023-07-05 14:39:43,089 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2670	Time 12.315s / 10iters, (1.231)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.278s / 10iters, (0.828)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.095s / 10iters, (0.009497)
Learning rate = [0.009397420689585621, 0.009397420689585621]	Loss = 0.20295398 (ave = 0.24904511)

2023-07-05 14:39:55,286 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2680	Time 12.197s / 10iters, (1.220)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.184s / 10iters, (0.818)	Loss Time 2.790s / 10iters, (0.279)	Data load 0.090s / 10iters, (0.009007)
Learning rate = [0.009395155068008027, 0.009395155068008027]	Loss = 0.24445501 (ave = 0.23805105)

2023-07-05 14:40:07,544 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2690	Time 12.258s / 10iters, (1.226)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.766s / 10iters, (0.277)	Data load 0.084s / 10iters, (0.008365)
Learning rate = [0.00939288938572327, 0.00939288938572327]	Loss = 0.29275575 (ave = 0.27238725)

2023-07-05 14:40:19,789 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2700	Time 12.245s / 10iters, (1.225)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.743s / 10iters, (0.274)	Data load 0.080s / 10iters, (0.008031)
Learning rate = [0.009390623642713458, 0.009390623642713458]	Loss = 0.21860646 (ave = 0.23670366)

2023-07-05 14:40:32,046 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2710	Time 12.256s / 10iters, (1.226)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.352s / 10iters, (0.835)	Loss Time 2.719s / 10iters, (0.272)	Data load 0.077s / 10iters, (0.007724)
Learning rate = [0.009388357838960677, 0.009388357838960677]	Loss = 0.19444796 (ave = 0.21370550)

2023-07-05 14:40:44,207 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2720	Time 12.161s / 10iters, (1.216)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.285s / 10iters, (0.829)	Loss Time 2.670s / 10iters, (0.267)	Data load 0.090s / 10iters, (0.008993)
Learning rate = [0.00938609197444701, 0.00938609197444701]	Loss = 0.28944036 (ave = 0.23989858)

2023-07-05 14:40:56,466 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2730	Time 12.259s / 10iters, (1.226)	Forward Time 1.162s / 10iters, (0.116)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.737s / 10iters, (0.274)	Data load 0.097s / 10iters, (0.009679)
Learning rate = [0.00938382604915453, 0.00938382604915453]	Loss = 0.15160583 (ave = 0.20974222)

2023-07-05 14:41:08,742 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2740	Time 12.276s / 10iters, (1.228)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.320s / 10iters, (0.832)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.083s / 10iters, (0.008303)
Learning rate = [0.0093815600630653, 0.0093815600630653]	Loss = 0.13835959 (ave = 0.21048392)

2023-07-05 14:41:21,053 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2750	Time 12.312s / 10iters, (1.231)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.789s / 10iters, (0.279)	Data load 0.111s / 10iters, (0.011088)
Learning rate = [0.009379294016161369, 0.009379294016161369]	Loss = 0.20915975 (ave = 0.26959276)

2023-07-05 14:41:33,547 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2760	Time 12.494s / 10iters, (1.249)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.433s / 10iters, (0.843)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.093s / 10iters, (0.009315)
Learning rate = [0.009377027908424781, 0.009377027908424781]	Loss = 0.20497301 (ave = 0.26230960)

2023-07-05 14:41:45,823 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2770	Time 12.276s / 10iters, (1.228)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.792s / 10iters, (0.279)	Data load 0.119s / 10iters, (0.011948)
Learning rate = [0.009374761739837567, 0.009374761739837567]	Loss = 0.24973035 (ave = 0.20445089)

2023-07-05 14:41:58,320 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2780	Time 12.497s / 10iters, (1.250)	Forward Time 1.137s / 10iters, (0.114)	Backward Time 8.420s / 10iters, (0.842)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.090s / 10iters, (0.009032)
Learning rate = [0.009372495510381747, 0.009372495510381747]	Loss = 0.20008411 (ave = 0.23684231)

2023-07-05 14:42:10,632 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2790	Time 12.313s / 10iters, (1.231)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.226s / 10iters, (0.823)	Loss Time 2.862s / 10iters, (0.286)	Data load 0.103s / 10iters, (0.010325)
Learning rate = [0.00937022922003933, 0.00937022922003933]	Loss = 0.24839476 (ave = 0.38928656)

2023-07-05 14:42:22,950 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2800	Time 12.318s / 10iters, (1.232)	Forward Time 1.153s / 10iters, (0.115)	Backward Time 8.253s / 10iters, (0.825)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.082s / 10iters, (0.008226)
Learning rate = [0.009367962868792322, 0.009367962868792322]	Loss = 0.48976627 (ave = 0.38568690)

2023-07-05 14:42:35,365 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2810	Time 12.415s / 10iters, (1.242)	Forward Time 1.145s / 10iters, (0.114)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.857s / 10iters, (0.286)	Data load 0.110s / 10iters, (0.010977)
Learning rate = [0.009365696456622712, 0.009365696456622712]	Loss = 0.31651843 (ave = 0.27588903)

2023-07-05 14:42:47,778 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2820	Time 12.413s / 10iters, (1.241)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.334s / 10iters, (0.833)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.092s / 10iters, (0.009249)
Learning rate = [0.00936342998351248, 0.00936342998351248]	Loss = 0.27475172 (ave = 0.27270026)

2023-07-05 14:43:00,418 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2830	Time 12.640s / 10iters, (1.264)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.525s / 10iters, (0.853)	Loss Time 2.905s / 10iters, (0.290)	Data load 0.083s / 10iters, (0.008291)
Learning rate = [0.009361163449443596, 0.009361163449443596]	Loss = 0.18918285 (ave = 0.26660714)

2023-07-05 14:43:12,575 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2840	Time 12.158s / 10iters, (1.216)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.158s / 10iters, (0.816)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007609)
Learning rate = [0.00935889685439802, 0.00935889685439802]	Loss = 0.35569617 (ave = 0.29265496)

2023-07-05 14:43:24,768 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2850	Time 12.193s / 10iters, (1.219)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.083s / 10iters, (0.008286)
Learning rate = [0.009356630198357705, 0.009356630198357705]	Loss = 0.60071748 (ave = 0.25934788)

2023-07-05 14:43:36,977 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2860	Time 12.209s / 10iters, (1.221)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.191s / 10iters, (0.819)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.083s / 10iters, (0.008335)
Learning rate = [0.009354363481304586, 0.009354363481304586]	Loss = 0.18642075 (ave = 0.27376093)

2023-07-05 14:43:49,220 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2870	Time 12.242s / 10iters, (1.224)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.230s / 10iters, (0.823)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007495)
Learning rate = [0.009352096703220597, 0.009352096703220597]	Loss = 0.25916719 (ave = 0.25507017)

2023-07-05 14:44:01,426 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2880	Time 12.206s / 10iters, (1.221)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.216s / 10iters, (0.822)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.080s / 10iters, (0.007951)
Learning rate = [0.009349829864087656, 0.009349829864087656]	Loss = 0.28163123 (ave = 0.22029486)

2023-07-05 14:44:13,544 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2890	Time 12.118s / 10iters, (1.212)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.164s / 10iters, (0.816)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007444)
Learning rate = [0.009347562963887673, 0.009347562963887673]	Loss = 0.22775953 (ave = 0.25332647)

2023-07-05 14:44:25,764 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2900	Time 12.220s / 10iters, (1.222)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.225s / 10iters, (0.823)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007569)
Learning rate = [0.009345296002602546, 0.009345296002602546]	Loss = 0.14933279 (ave = 0.24757504)

2023-07-05 14:44:38,093 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2910	Time 12.329s / 10iters, (1.233)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.298s / 10iters, (0.830)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007498)
Learning rate = [0.009343028980214163, 0.009343028980214163]	Loss = 0.21061905 (ave = 0.29829074)

2023-07-05 14:44:50,390 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2920	Time 12.297s / 10iters, (1.230)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.312s / 10iters, (0.831)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.083s / 10iters, (0.008346)
Learning rate = [0.009340761896704405, 0.009340761896704405]	Loss = 0.19817750 (ave = 0.19523539)

2023-07-05 14:45:02,640 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2930	Time 12.250s / 10iters, (1.225)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.098s / 10iters, (0.009806)
Learning rate = [0.009338494752055136, 0.009338494752055136]	Loss = 0.36137852 (ave = 0.27596172)

2023-07-05 14:45:15,002 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2940	Time 12.362s / 10iters, (1.236)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.329s / 10iters, (0.833)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007499)
Learning rate = [0.00933622754624822, 0.00933622754624822]	Loss = 0.25839236 (ave = 0.23132417)

2023-07-05 14:45:27,312 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2950	Time 12.311s / 10iters, (1.231)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.339s / 10iters, (0.834)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.087s / 10iters, (0.008683)
Learning rate = [0.009333960279265498, 0.009333960279265498]	Loss = 0.11544460 (ave = 0.21984948)

2023-07-05 14:45:39,409 INFO    [trainer_contrastive.py, 272] Train Epoch: 7	Train Iteration: 2960	Time 12.097s / 10iters, (1.210)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.167s / 10iters, (0.817)	Loss Time 2.763s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007510)
Learning rate = [0.009331692951088813, 0.009331692951088813]	Loss = 0.25072679 (ave = 0.22714505)

2023-07-05 14:45:53,857 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 2970	Time 14.308s / 10iters, (1.431)	Forward Time 1.254s / 10iters, (0.125)	Backward Time 8.204s / 10iters, (0.820)	Loss Time 2.726s / 10iters, (0.273)	Data load 2.124s / 10iters, (0.212414)
Learning rate = [0.00932942556169999, 0.00932942556169999]	Loss = 0.30036029 (ave = 0.25261056)

2023-07-05 14:46:05,974 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 2980	Time 12.117s / 10iters, (1.212)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.176s / 10iters, (0.818)	Loss Time 2.724s / 10iters, (0.272)	Data load 0.106s / 10iters, (0.010626)
Learning rate = [0.009327158111080843, 0.009327158111080843]	Loss = 0.21319579 (ave = 0.25227442)

2023-07-05 14:46:18,224 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 2990	Time 12.250s / 10iters, (1.225)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.750s / 10iters, (0.275)	Data load 0.084s / 10iters, (0.008389)
Learning rate = [0.009324890599213183, 0.009324890599213183]	Loss = 0.17962043 (ave = 0.22920735)

2023-07-05 14:46:30,441 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3000	Time 12.217s / 10iters, (1.222)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.747s / 10iters, (0.275)	Data load 0.082s / 10iters, (0.008177)
Learning rate = [0.009322623026078804, 0.009322623026078804]	Loss = 0.19413207 (ave = 0.28971674)

2023-07-05 14:46:33,747 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 14:46:57,840 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 14:47:21,434 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 14:47:44,684 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 14:48:07,865 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 14:48:31,098 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 14:48:53,996 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 14:48:59,940 INFO    [base.py, 84] Performance 0.621844403488078 -> 0.6258131230537759
2023-07-05 14:49:05,430 INFO    [trainer_contrastive.py, 391] Test Time 149.336s, (2.370)	Loss 0.21891652

2023-07-05 14:49:05,431 INFO    [base.py, 33] Result for seg
2023-07-05 14:49:05,431 INFO    [base.py, 49] Mean IOU: 0.6258131230537759

2023-07-05 14:49:05,432 INFO    [base.py, 50] Pixel ACC: 0.9326362906080948

2023-07-05 14:49:17,533 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3010	Time 167.092s / 10iters, (16.709)	Forward Time 1.181s / 10iters, (0.118)	Backward Time 8.132s / 10iters, (0.813)	Loss Time 2.705s / 10iters, (0.270)	Data load 155.075s / 10iters, (15.507516)
Learning rate = [0.009320355391659492, 0.009320355391659492]	Loss = 0.12353308 (ave = 0.25852426)

2023-07-05 14:49:29,646 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3020	Time 12.113s / 10iters, (1.211)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.146s / 10iters, (0.815)	Loss Time 2.754s / 10iters, (0.275)	Data load 0.097s / 10iters, (0.009664)
Learning rate = [0.009318087695937022, 0.009318087695937022]	Loss = 0.16652033 (ave = 0.24530636)

2023-07-05 14:49:41,710 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3030	Time 12.064s / 10iters, (1.206)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.150s / 10iters, (0.815)	Loss Time 2.735s / 10iters, (0.273)	Data load 0.087s / 10iters, (0.008728)
Learning rate = [0.009315819938893159, 0.009315819938893159]	Loss = 0.22447141 (ave = 0.29366040)

2023-07-05 14:49:53,928 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3040	Time 12.217s / 10iters, (1.222)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.096s / 10iters, (0.009619)
Learning rate = [0.00931355212050966, 0.00931355212050966]	Loss = 0.14565177 (ave = 0.24492932)

2023-07-05 14:50:06,067 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3050	Time 12.139s / 10iters, (1.214)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.172s / 10iters, (0.817)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.088s / 10iters, (0.008837)
Learning rate = [0.009311284240768268, 0.009311284240768268]	Loss = 0.18047775 (ave = 0.18327406)

2023-07-05 14:50:18,230 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3060	Time 12.163s / 10iters, (1.216)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.085s / 10iters, (0.008476)
Learning rate = [0.009309016299650717, 0.009309016299650717]	Loss = 0.22620888 (ave = 0.21626934)

2023-07-05 14:50:30,399 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3070	Time 12.169s / 10iters, (1.217)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.164s / 10iters, (0.816)	Loss Time 2.789s / 10iters, (0.279)	Data load 0.109s / 10iters, (0.010936)
Learning rate = [0.009306748297138727, 0.009306748297138727]	Loss = 0.18382037 (ave = 0.18594317)

2023-07-05 14:50:42,543 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3080	Time 12.144s / 10iters, (1.214)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.751s / 10iters, (0.275)	Data load 0.086s / 10iters, (0.008558)
Learning rate = [0.009304480233214018, 0.009304480233214018]	Loss = 0.16535263 (ave = 0.21722718)

2023-07-05 14:50:54,622 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3090	Time 12.079s / 10iters, (1.208)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.186s / 10iters, (0.819)	Loss Time 2.697s / 10iters, (0.270)	Data load 0.080s / 10iters, (0.008020)
Learning rate = [0.009302212107858289, 0.009302212107858289]	Loss = 0.20685835 (ave = 0.22622673)

2023-07-05 14:51:06,800 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3100	Time 12.177s / 10iters, (1.218)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.756s / 10iters, (0.276)	Data load 0.102s / 10iters, (0.010238)
Learning rate = [0.009299943921053233, 0.009299943921053233]	Loss = 0.30632785 (ave = 0.20308533)

2023-07-05 14:51:19,023 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3110	Time 12.223s / 10iters, (1.222)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.329s / 10iters, (0.833)	Loss Time 2.725s / 10iters, (0.272)	Data load 0.075s / 10iters, (0.007456)
Learning rate = [0.009297675672780531, 0.009297675672780531]	Loss = 0.17667912 (ave = 0.21077430)

2023-07-05 14:51:31,154 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3120	Time 12.131s / 10iters, (1.213)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.692s / 10iters, (0.269)	Data load 0.085s / 10iters, (0.008520)
Learning rate = [0.009295407363021856, 0.009295407363021856]	Loss = 0.24800940 (ave = 0.19489025)

2023-07-05 14:51:43,242 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3130	Time 12.088s / 10iters, (1.209)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.680s / 10iters, (0.268)	Data load 0.075s / 10iters, (0.007456)
Learning rate = [0.009293138991758869, 0.009293138991758869]	Loss = 0.18233092 (ave = 0.25276541)

2023-07-05 14:51:55,517 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3140	Time 12.275s / 10iters, (1.228)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.323s / 10iters, (0.832)	Loss Time 2.746s / 10iters, (0.275)	Data load 0.096s / 10iters, (0.009595)
Learning rate = [0.009290870558973222, 0.009290870558973222]	Loss = 0.42527971 (ave = 0.22967146)

2023-07-05 14:52:07,699 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3150	Time 12.182s / 10iters, (1.218)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.279s / 10iters, (0.828)	Loss Time 2.723s / 10iters, (0.272)	Data load 0.076s / 10iters, (0.007605)
Learning rate = [0.00928860206464655, 0.00928860206464655]	Loss = 0.12090170 (ave = 0.19164285)

2023-07-05 14:52:19,731 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3160	Time 12.032s / 10iters, (1.203)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.195s / 10iters, (0.819)	Loss Time 2.652s / 10iters, (0.265)	Data load 0.075s / 10iters, (0.007481)
Learning rate = [0.00928633350876049, 0.00928633350876049]	Loss = 0.22733061 (ave = 0.22235943)

2023-07-05 14:52:31,807 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3170	Time 12.076s / 10iters, (1.208)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.210s / 10iters, (0.821)	Loss Time 2.689s / 10iters, (0.269)	Data load 0.074s / 10iters, (0.007439)
Learning rate = [0.009284064891296656, 0.009284064891296656]	Loss = 0.15996060 (ave = 0.19226926)

2023-07-05 14:52:43,930 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3180	Time 12.123s / 10iters, (1.212)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.720s / 10iters, (0.272)	Data load 0.083s / 10iters, (0.008293)
Learning rate = [0.009281796212236659, 0.009281796212236659]	Loss = 0.15956563 (ave = 0.21818251)

2023-07-05 14:52:56,050 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3190	Time 12.119s / 10iters, (1.212)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.713s / 10iters, (0.271)	Data load 0.083s / 10iters, (0.008304)
Learning rate = [0.009279527471562098, 0.009279527471562098]	Loss = 0.17198208 (ave = 0.18191424)

2023-07-05 14:53:08,192 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3200	Time 12.143s / 10iters, (1.214)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.720s / 10iters, (0.272)	Data load 0.075s / 10iters, (0.007548)
Learning rate = [0.009277258669254558, 0.009277258669254558]	Loss = 0.20169410 (ave = 0.26339568)

2023-07-05 14:53:20,355 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3210	Time 12.163s / 10iters, (1.216)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.717s / 10iters, (0.272)	Data load 0.084s / 10iters, (0.008382)
Learning rate = [0.009274989805295621, 0.009274989805295621]	Loss = 0.26352701 (ave = 0.18543564)

2023-07-05 14:53:32,508 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3220	Time 12.153s / 10iters, (1.215)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.690s / 10iters, (0.269)	Data load 0.100s / 10iters, (0.009962)
Learning rate = [0.00927272087966685, 0.00927272087966685]	Loss = 0.22932258 (ave = 0.19985524)

2023-07-05 14:53:44,701 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3230	Time 12.193s / 10iters, (1.219)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.749s / 10iters, (0.275)	Data load 0.078s / 10iters, (0.007772)
Learning rate = [0.0092704518923498, 0.0092704518923498]	Loss = 0.30115360 (ave = 0.21906784)

2023-07-05 14:53:56,815 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3240	Time 12.114s / 10iters, (1.211)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.746s / 10iters, (0.275)	Data load 0.081s / 10iters, (0.008101)
Learning rate = [0.00926818284332602, 0.00926818284332602]	Loss = 0.12563375 (ave = 0.20070829)

2023-07-05 14:54:08,971 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3250	Time 12.156s / 10iters, (1.216)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.738s / 10iters, (0.274)	Data load 0.084s / 10iters, (0.008380)
Learning rate = [0.009265913732577047, 0.009265913732577047]	Loss = 0.14938788 (ave = 0.21930921)

2023-07-05 14:54:21,201 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3260	Time 12.230s / 10iters, (1.223)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.082s / 10iters, (0.008244)
Learning rate = [0.009263644560084402, 0.009263644560084402]	Loss = 0.21070339 (ave = 0.25441349)

2023-07-05 14:54:33,363 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3270	Time 12.162s / 10iters, (1.216)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.170s / 10iters, (0.817)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.083s / 10iters, (0.008317)
Learning rate = [0.009261375325829598, 0.009261375325829598]	Loss = 0.22381547 (ave = 0.22129373)

2023-07-05 14:54:45,629 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3280	Time 12.265s / 10iters, (1.227)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.226s / 10iters, (0.823)	Loss Time 2.852s / 10iters, (0.285)	Data load 0.086s / 10iters, (0.008579)
Learning rate = [0.009259106029794142, 0.009259106029794142]	Loss = 0.20191009 (ave = 0.19634477)

2023-07-05 14:54:57,893 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3290	Time 12.264s / 10iters, (1.226)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.235s / 10iters, (0.824)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.082s / 10iters, (0.008207)
Learning rate = [0.009256836671959527, 0.009256836671959527]	Loss = 0.50162727 (ave = 0.22906141)

2023-07-05 14:55:10,220 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3300	Time 12.327s / 10iters, (1.233)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.870s / 10iters, (0.287)	Data load 0.089s / 10iters, (0.008899)
Learning rate = [0.009254567252307234, 0.009254567252307234]	Loss = 0.18252078 (ave = 0.21811507)

2023-07-05 14:55:22,499 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3310	Time 12.278s / 10iters, (1.228)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.226s / 10iters, (0.823)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.082s / 10iters, (0.008153)
Learning rate = [0.009252297770818733, 0.009252297770818733]	Loss = 0.14951922 (ave = 0.20853943)

2023-07-05 14:55:34,687 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3320	Time 12.188s / 10iters, (1.219)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.189s / 10iters, (0.819)	Loss Time 2.820s / 10iters, (0.282)	Data load 0.077s / 10iters, (0.007661)
Learning rate = [0.009250028227475489, 0.009250028227475489]	Loss = 0.21425806 (ave = 0.24361403)

2023-07-05 14:55:47,048 INFO    [trainer_contrastive.py, 272] Train Epoch: 8	Train Iteration: 3330	Time 12.361s / 10iters, (1.236)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.345s / 10iters, (0.835)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.088s / 10iters, (0.008849)
Learning rate = [0.009247758622258951, 0.009247758622258951]	Loss = 0.14493704 (ave = 0.25197022)

2023-07-05 14:56:02,136 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3340	Time 14.942s / 10iters, (1.494)	Forward Time 1.325s / 10iters, (0.133)	Backward Time 8.350s / 10iters, (0.835)	Loss Time 2.767s / 10iters, (0.277)	Data load 2.500s / 10iters, (0.249988)
Learning rate = [0.009245488955150557, 0.009245488955150557]	Loss = 0.27403659 (ave = 0.24883045)

2023-07-05 14:56:14,456 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3350	Time 12.320s / 10iters, (1.232)	Forward Time 1.146s / 10iters, (0.115)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.082s / 10iters, (0.008200)
Learning rate = [0.009243219226131739, 0.009243219226131739]	Loss = 0.15708898 (ave = 0.25263876)

2023-07-05 14:56:26,787 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3360	Time 12.332s / 10iters, (1.233)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.085s / 10iters, (0.008487)
Learning rate = [0.009240949435183913, 0.009240949435183913]	Loss = 0.28984961 (ave = 0.26476357)

2023-07-05 14:56:39,311 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3370	Time 12.524s / 10iters, (1.252)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.455s / 10iters, (0.845)	Loss Time 2.878s / 10iters, (0.288)	Data load 0.076s / 10iters, (0.007581)
Learning rate = [0.009238679582288491, 0.009238679582288491]	Loss = 0.20562264 (ave = 0.28476522)

2023-07-05 14:56:51,643 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3380	Time 12.332s / 10iters, (1.233)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.334s / 10iters, (0.833)	Loss Time 2.795s / 10iters, (0.280)	Data load 0.078s / 10iters, (0.007764)
Learning rate = [0.009236409667426866, 0.009236409667426866]	Loss = 0.22248109 (ave = 0.19524962)

2023-07-05 14:57:03,904 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3390	Time 12.261s / 10iters, (1.226)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007448)
Learning rate = [0.009234139690580428, 0.009234139690580428]	Loss = 0.26347417 (ave = 0.22509279)

2023-07-05 14:57:16,309 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3400	Time 12.405s / 10iters, (1.240)	Forward Time 1.136s / 10iters, (0.114)	Backward Time 8.408s / 10iters, (0.841)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.077s / 10iters, (0.007726)
Learning rate = [0.009231869651730552, 0.009231869651730552]	Loss = 0.25151995 (ave = 0.23825111)

2023-07-05 14:57:28,560 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3410	Time 12.251s / 10iters, (1.225)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.751s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007474)
Learning rate = [0.009229599550858602, 0.009229599550858602]	Loss = 0.23260553 (ave = 0.25143337)

2023-07-05 14:57:40,979 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3420	Time 12.419s / 10iters, (1.242)	Forward Time 1.185s / 10iters, (0.119)	Backward Time 8.393s / 10iters, (0.839)	Loss Time 2.754s / 10iters, (0.275)	Data load 0.086s / 10iters, (0.008640)
Learning rate = [0.009227329387945933, 0.009227329387945933]	Loss = 0.17237395 (ave = 0.21654302)

2023-07-05 14:57:53,150 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3430	Time 12.171s / 10iters, (1.217)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.722s / 10iters, (0.272)	Data load 0.086s / 10iters, (0.008575)
Learning rate = [0.00922505916297389, 0.00922505916297389]	Loss = 0.29611209 (ave = 0.20662685)

2023-07-05 14:58:05,492 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3440	Time 12.342s / 10iters, (1.234)	Forward Time 1.150s / 10iters, (0.115)	Backward Time 8.369s / 10iters, (0.837)	Loss Time 2.740s / 10iters, (0.274)	Data load 0.082s / 10iters, (0.008231)
Learning rate = [0.009222788875923808, 0.009222788875923808]	Loss = 0.15461281 (ave = 0.22014928)

2023-07-05 14:58:17,723 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3450	Time 12.231s / 10iters, (1.223)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.272s / 10iters, (0.827)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.091s / 10iters, (0.009124)
Learning rate = [0.009220518526777006, 0.009220518526777006]	Loss = 0.19676036 (ave = 0.20050226)

2023-07-05 14:58:30,070 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3460	Time 12.347s / 10iters, (1.235)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.365s / 10iters, (0.836)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.088s / 10iters, (0.008796)
Learning rate = [0.009218248115514797, 0.009218248115514797]	Loss = 0.18727705 (ave = 0.22391158)

2023-07-05 14:58:42,340 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3470	Time 12.270s / 10iters, (1.227)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.282s / 10iters, (0.828)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.088s / 10iters, (0.008821)
Learning rate = [0.009215977642118484, 0.009215977642118484]	Loss = 0.17437737 (ave = 0.18665894)

2023-07-05 14:58:54,663 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3480	Time 12.324s / 10iters, (1.232)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.242s / 10iters, (0.824)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.112s / 10iters, (0.011179)
Learning rate = [0.009213707106569354, 0.009213707106569354]	Loss = 0.16064033 (ave = 0.22741598)

2023-07-05 14:59:07,007 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3490	Time 12.344s / 10iters, (1.234)	Forward Time 1.155s / 10iters, (0.116)	Backward Time 8.331s / 10iters, (0.833)	Loss Time 2.765s / 10iters, (0.277)	Data load 0.091s / 10iters, (0.009118)
Learning rate = [0.009211436508848687, 0.009211436508848687]	Loss = 0.44545615 (ave = 0.20961486)

2023-07-05 14:59:19,362 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3500	Time 12.355s / 10iters, (1.236)	Forward Time 1.145s / 10iters, (0.115)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.792s / 10iters, (0.279)	Data load 0.078s / 10iters, (0.007803)
Learning rate = [0.009209165848937755, 0.009209165848937755]	Loss = 0.17274325 (ave = 0.22185680)

2023-07-05 14:59:31,765 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3510	Time 12.402s / 10iters, (1.240)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.355s / 10iters, (0.835)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.094s / 10iters, (0.009426)
Learning rate = [0.009206895126817811, 0.009206895126817811]	Loss = 0.24772497 (ave = 0.19994943)

2023-07-05 14:59:44,173 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3520	Time 12.409s / 10iters, (1.241)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.330s / 10iters, (0.833)	Loss Time 2.877s / 10iters, (0.288)	Data load 0.080s / 10iters, (0.007970)
Learning rate = [0.009204624342470108, 0.009204624342470108]	Loss = 0.19027986 (ave = 0.20004218)

2023-07-05 14:59:56,564 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3530	Time 12.390s / 10iters, (1.239)	Forward Time 1.184s / 10iters, (0.118)	Backward Time 8.356s / 10iters, (0.836)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.081s / 10iters, (0.008082)
Learning rate = [0.009202353495875878, 0.009202353495875878]	Loss = 0.31306538 (ave = 0.24830202)

2023-07-05 15:00:08,829 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3540	Time 12.265s / 10iters, (1.227)	Forward Time 1.166s / 10iters, (0.117)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.723s / 10iters, (0.272)	Data load 0.104s / 10iters, (0.010404)
Learning rate = [0.009200082587016349, 0.009200082587016349]	Loss = 0.29628316 (ave = 0.22514978)

2023-07-05 15:00:20,999 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3550	Time 12.170s / 10iters, (1.217)	Forward Time 1.146s / 10iters, (0.115)	Backward Time 8.205s / 10iters, (0.820)	Loss Time 2.729s / 10iters, (0.273)	Data load 0.090s / 10iters, (0.008967)
Learning rate = [0.009197811615872733, 0.009197811615872733]	Loss = 0.18164128 (ave = 0.17973912)

2023-07-05 15:00:33,135 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3560	Time 12.136s / 10iters, (1.214)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.192s / 10iters, (0.819)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.079s / 10iters, (0.007941)
Learning rate = [0.009195540582426236, 0.009195540582426236]	Loss = 0.20751570 (ave = 0.24284256)

2023-07-05 15:00:45,387 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3570	Time 12.252s / 10iters, (1.225)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.272s / 10iters, (0.827)	Loss Time 2.785s / 10iters, (0.278)	Data load 0.085s / 10iters, (0.008526)
Learning rate = [0.009193269486658053, 0.009193269486658053]	Loss = 0.30531254 (ave = 0.20741197)

2023-07-05 15:00:57,513 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3580	Time 12.126s / 10iters, (1.213)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.155s / 10iters, (0.815)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.079s / 10iters, (0.007904)
Learning rate = [0.009190998328549362, 0.009190998328549362]	Loss = 0.24129896 (ave = 0.21921855)

2023-07-05 15:01:09,765 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3590	Time 12.252s / 10iters, (1.225)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.088s / 10iters, (0.008782)
Learning rate = [0.009188727108081336, 0.009188727108081336]	Loss = 0.18267328 (ave = 0.18288928)

2023-07-05 15:01:22,043 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3600	Time 12.278s / 10iters, (1.228)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.755s / 10iters, (0.276)	Data load 0.100s / 10iters, (0.010013)
Learning rate = [0.009186455825235139, 0.009186455825235139]	Loss = 0.19312616 (ave = 0.17904072)

2023-07-05 15:01:34,259 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3610	Time 12.216s / 10iters, (1.222)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.742s / 10iters, (0.274)	Data load 0.089s / 10iters, (0.008913)
Learning rate = [0.009184184479991916, 0.009184184479991916]	Loss = 0.21568264 (ave = 0.23263409)

2023-07-05 15:01:46,384 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3620	Time 12.125s / 10iters, (1.212)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.187s / 10iters, (0.819)	Loss Time 2.759s / 10iters, (0.276)	Data load 0.080s / 10iters, (0.007969)
Learning rate = [0.009181913072332808, 0.009181913072332808]	Loss = 0.27408755 (ave = 0.22839876)

2023-07-05 15:01:58,423 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3630	Time 12.039s / 10iters, (1.204)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.151s / 10iters, (0.815)	Loss Time 2.693s / 10iters, (0.269)	Data load 0.076s / 10iters, (0.007619)
Learning rate = [0.009179641602238943, 0.009179641602238943]	Loss = 0.38620836 (ave = 0.22913491)

2023-07-05 15:02:10,551 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3640	Time 12.128s / 10iters, (1.213)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.727s / 10iters, (0.273)	Data load 0.080s / 10iters, (0.007977)
Learning rate = [0.009177370069691437, 0.009177370069691437]	Loss = 0.34215191 (ave = 0.24070312)

2023-07-05 15:02:22,997 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3650	Time 12.446s / 10iters, (1.245)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.443s / 10iters, (0.844)	Loss Time 2.809s / 10iters, (0.281)	Data load 0.098s / 10iters, (0.009762)
Learning rate = [0.009175098474671397, 0.009175098474671397]	Loss = 0.22482936 (ave = 0.27121771)

2023-07-05 15:02:35,251 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3660	Time 12.255s / 10iters, (1.225)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.103s / 10iters, (0.010287)
Learning rate = [0.00917282681715992, 0.00917282681715992]	Loss = 0.21366839 (ave = 0.26807715)

2023-07-05 15:02:47,482 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3670	Time 12.231s / 10iters, (1.223)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.348s / 10iters, (0.835)	Loss Time 2.698s / 10iters, (0.270)	Data load 0.076s / 10iters, (0.007594)
Learning rate = [0.009170555097138086, 0.009170555097138086]	Loss = 0.34968990 (ave = 0.24738116)

2023-07-05 15:02:59,856 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3680	Time 12.374s / 10iters, (1.237)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.438s / 10iters, (0.844)	Loss Time 2.727s / 10iters, (0.273)	Data load 0.084s / 10iters, (0.008432)
Learning rate = [0.009168283314586972, 0.009168283314586972]	Loss = 0.21160521 (ave = 0.22583486)

2023-07-05 15:03:12,137 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3690	Time 12.280s / 10iters, (1.228)	Forward Time 1.139s / 10iters, (0.114)	Backward Time 8.337s / 10iters, (0.834)	Loss Time 2.712s / 10iters, (0.271)	Data load 0.091s / 10iters, (0.009149)
Learning rate = [0.009166011469487638, 0.009166011469487638]	Loss = 0.25088036 (ave = 0.30055224)

2023-07-05 15:03:24,185 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3700	Time 12.048s / 10iters, (1.205)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.678s / 10iters, (0.268)	Data load 0.074s / 10iters, (0.007396)
Learning rate = [0.009163739561821139, 0.009163739561821139]	Loss = 0.24071783 (ave = 0.20885139)

2023-07-05 15:03:36,149 INFO    [trainer_contrastive.py, 272] Train Epoch: 9	Train Iteration: 3710	Time 11.964s / 10iters, (1.196)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.131s / 10iters, (0.813)	Loss Time 2.677s / 10iters, (0.268)	Data load 0.076s / 10iters, (0.007590)
Learning rate = [0.00916146759156851, 0.00916146759156851]	Loss = 0.27758998 (ave = 0.23006756)

2023-07-05 15:03:51,336 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3720	Time 15.036s / 10iters, (1.504)	Forward Time 1.169s / 10iters, (0.117)	Backward Time 8.238s / 10iters, (0.824)	Loss Time 2.763s / 10iters, (0.276)	Data load 2.866s / 10iters, (0.286590)
Learning rate = [0.009159195558710786, 0.009159195558710786]	Loss = 0.14333567 (ave = 0.18827488)

2023-07-05 15:04:03,552 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3730	Time 12.217s / 10iters, (1.222)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.740s / 10iters, (0.274)	Data load 0.082s / 10iters, (0.008208)
Learning rate = [0.009156923463228982, 0.009156923463228982]	Loss = 0.20044866 (ave = 0.26015899)

2023-07-05 15:04:15,823 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3740	Time 12.271s / 10iters, (1.227)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.337s / 10iters, (0.834)	Loss Time 2.751s / 10iters, (0.275)	Data load 0.076s / 10iters, (0.007613)
Learning rate = [0.009154651305104108, 0.009154651305104108]	Loss = 0.13076743 (ave = 0.24935269)

2023-07-05 15:04:28,144 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3750	Time 12.320s / 10iters, (1.232)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.317s / 10iters, (0.832)	Loss Time 2.804s / 10iters, (0.280)	Data load 0.077s / 10iters, (0.007744)
Learning rate = [0.009152379084317158, 0.009152379084317158]	Loss = 0.17938875 (ave = 0.21674318)

2023-07-05 15:04:40,249 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3760	Time 12.105s / 10iters, (1.211)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.180s / 10iters, (0.818)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007489)
Learning rate = [0.009150106800849121, 0.009150106800849121]	Loss = 0.49838182 (ave = 0.23166991)

2023-07-05 15:04:52,444 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3770	Time 12.195s / 10iters, (1.220)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.745s / 10iters, (0.275)	Data load 0.076s / 10iters, (0.007631)
Learning rate = [0.009147834454680967, 0.009147834454680967]	Loss = 0.26139867 (ave = 0.20172868)

2023-07-05 15:05:04,574 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3780	Time 12.130s / 10iters, (1.213)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.158s / 10iters, (0.816)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.077s / 10iters, (0.007688)
Learning rate = [0.009145562045793665, 0.009145562045793665]	Loss = 0.14011583 (ave = 0.20216244)

2023-07-05 15:05:16,877 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3790	Time 12.303s / 10iters, (1.230)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.281s / 10iters, (0.828)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.088s / 10iters, (0.008786)
Learning rate = [0.009143289574168163, 0.009143289574168163]	Loss = 0.10828214 (ave = 0.22718177)

2023-07-05 15:05:29,020 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3800	Time 12.143s / 10iters, (1.214)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.189s / 10iters, (0.819)	Loss Time 2.775s / 10iters, (0.277)	Data load 0.084s / 10iters, (0.008403)
Learning rate = [0.009141017039785404, 0.009141017039785404]	Loss = 0.39096987 (ave = 0.27309496)

2023-07-05 15:05:41,245 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3810	Time 12.225s / 10iters, (1.223)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.080s / 10iters, (0.007974)
Learning rate = [0.009138744442626318, 0.009138744442626318]	Loss = 0.62995452 (ave = 0.29225688)

2023-07-05 15:05:53,453 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3820	Time 12.208s / 10iters, (1.221)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.195s / 10iters, (0.819)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007591)
Learning rate = [0.009136471782671825, 0.009136471782671825]	Loss = 0.23580232 (ave = 0.25158657)

2023-07-05 15:06:05,708 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3830	Time 12.255s / 10iters, (1.226)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.253s / 10iters, (0.825)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.077s / 10iters, (0.007667)
Learning rate = [0.009134199059902832, 0.009134199059902832]	Loss = 0.15218218 (ave = 0.23241464)

2023-07-05 15:06:17,989 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3840	Time 12.281s / 10iters, (1.228)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007440)
Learning rate = [0.009131926274300239, 0.009131926274300239]	Loss = 0.20669104 (ave = 0.27906613)

2023-07-05 15:06:30,254 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3850	Time 12.265s / 10iters, (1.227)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.083s / 10iters, (0.008290)
Learning rate = [0.009129653425844928, 0.009129653425844928]	Loss = 0.21016060 (ave = 0.27661029)

2023-07-05 15:06:42,349 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3860	Time 12.095s / 10iters, (1.209)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.145s / 10iters, (0.814)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007381)
Learning rate = [0.009127380514517778, 0.009127380514517778]	Loss = 0.17519334 (ave = 0.22857643)

2023-07-05 15:06:54,514 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3870	Time 12.165s / 10iters, (1.217)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.199s / 10iters, (0.820)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007443)
Learning rate = [0.00912510754029965, 0.00912510754029965]	Loss = 0.16052109 (ave = 0.21354570)

2023-07-05 15:07:06,693 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3880	Time 12.179s / 10iters, (1.218)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.189s / 10iters, (0.819)	Loss Time 2.808s / 10iters, (0.281)	Data load 0.085s / 10iters, (0.008494)
Learning rate = [0.009122834503171398, 0.009122834503171398]	Loss = 0.18528476 (ave = 0.24287945)

2023-07-05 15:07:18,818 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3890	Time 12.126s / 10iters, (1.213)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.161s / 10iters, (0.816)	Loss Time 2.785s / 10iters, (0.278)	Data load 0.088s / 10iters, (0.008811)
Learning rate = [0.009120561403113863, 0.009120561403113863]	Loss = 0.19362056 (ave = 0.23467737)

2023-07-05 15:07:31,047 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3900	Time 12.229s / 10iters, (1.223)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.084s / 10iters, (0.008368)
Learning rate = [0.009118288240107877, 0.009118288240107877]	Loss = 0.26350594 (ave = 0.19548271)

2023-07-05 15:07:43,146 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3910	Time 12.099s / 10iters, (1.210)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.157s / 10iters, (0.816)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.074s / 10iters, (0.007421)
Learning rate = [0.009116015014134254, 0.009116015014134254]	Loss = 0.12525581 (ave = 0.20524270)

2023-07-05 15:07:55,291 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3920	Time 12.145s / 10iters, (1.214)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.197s / 10iters, (0.820)	Loss Time 2.786s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007393)
Learning rate = [0.00911374172517381, 0.00911374172517381]	Loss = 0.26159617 (ave = 0.25290278)

2023-07-05 15:08:07,452 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3930	Time 12.161s / 10iters, (1.216)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.198s / 10iters, (0.820)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007511)
Learning rate = [0.009111468373207336, 0.009111468373207336]	Loss = 0.12922244 (ave = 0.18465287)

2023-07-05 15:08:19,585 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3940	Time 12.133s / 10iters, (1.213)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.168s / 10iters, (0.817)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007554)
Learning rate = [0.00910919495821562, 0.00910919495821562]	Loss = 0.15433274 (ave = 0.21369008)

2023-07-05 15:08:31,790 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3950	Time 12.205s / 10iters, (1.221)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.845s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007406)
Learning rate = [0.009106921480179438, 0.009106921480179438]	Loss = 0.19737042 (ave = 0.22432870)

2023-07-05 15:08:44,008 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3960	Time 12.218s / 10iters, (1.222)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.219s / 10iters, (0.822)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007600)
Learning rate = [0.00910464793907955, 0.00910464793907955]	Loss = 0.38530001 (ave = 0.23339298)

2023-07-05 15:08:56,183 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3970	Time 12.175s / 10iters, (1.218)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.168s / 10iters, (0.817)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007377)
Learning rate = [0.009102374334896711, 0.009102374334896711]	Loss = 0.18633121 (ave = 0.21620554)

2023-07-05 15:09:08,385 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3980	Time 12.202s / 10iters, (1.220)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.204s / 10iters, (0.820)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007466)
Learning rate = [0.009100100667611662, 0.009100100667611662]	Loss = 0.21821710 (ave = 0.28224682)

2023-07-05 15:09:20,468 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 3990	Time 12.083s / 10iters, (1.208)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.163s / 10iters, (0.816)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.077s / 10iters, (0.007715)
Learning rate = [0.009097826937205131, 0.009097826937205131]	Loss = 0.14979316 (ave = 0.26047740)

2023-07-05 15:09:32,664 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 4000	Time 12.196s / 10iters, (1.220)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.777s / 10iters, (0.278)	Data load 0.102s / 10iters, (0.010219)
Learning rate = [0.009095553143657835, 0.009095553143657835]	Loss = 0.28597662 (ave = 0.24321620)

2023-07-05 15:09:35,754 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 15:09:59,437 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 15:10:22,571 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 15:10:45,456 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 15:11:08,446 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 15:11:31,029 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 15:11:53,237 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 15:11:58,907 INFO    [base.py, 84] Performance 0.6258131230537759 -> 0.6497171948321523
2023-07-05 15:12:04,295 INFO    [trainer_contrastive.py, 391] Test Time 146.111s, (2.319)	Loss 0.19530791

2023-07-05 15:12:04,295 INFO    [base.py, 33] Result for seg
2023-07-05 15:12:04,295 INFO    [base.py, 49] Mean IOU: 0.6497171948321523

2023-07-05 15:12:04,296 INFO    [base.py, 50] Pixel ACC: 0.9411574317778014

2023-07-05 15:12:16,419 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 4010	Time 163.754s / 10iters, (16.375)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.171s / 10iters, (0.817)	Loss Time 2.730s / 10iters, (0.273)	Data load 151.727s / 10iters, (15.172653)
Learning rate = [0.009093279286950487, 0.009093279286950487]	Loss = 0.28087687 (ave = 0.23474829)

2023-07-05 15:12:28,466 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 4020	Time 12.047s / 10iters, (1.205)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.143s / 10iters, (0.814)	Loss Time 2.672s / 10iters, (0.267)	Data load 0.108s / 10iters, (0.010781)
Learning rate = [0.009091005367063778, 0.009091005367063778]	Loss = 0.14472598 (ave = 0.19763498)

2023-07-05 15:12:40,505 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 4030	Time 12.039s / 10iters, (1.204)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.162s / 10iters, (0.816)	Loss Time 2.694s / 10iters, (0.269)	Data load 0.085s / 10iters, (0.008467)
Learning rate = [0.009088731383978393, 0.009088731383978393]	Loss = 0.14366136 (ave = 0.21681464)

2023-07-05 15:12:52,754 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 4040	Time 12.249s / 10iters, (1.225)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.078s / 10iters, (0.007800)
Learning rate = [0.009086457337675009, 0.009086457337675009]	Loss = 0.16733283 (ave = 0.24636453)

2023-07-05 15:13:04,917 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 4050	Time 12.163s / 10iters, (1.216)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.750s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007545)
Learning rate = [0.009084183228134283, 0.009084183228134283]	Loss = 0.14719729 (ave = 0.22789511)

2023-07-05 15:13:17,093 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 4060	Time 12.176s / 10iters, (1.218)	Forward Time 1.083s / 10iters, (0.108)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.082s / 10iters, (0.008158)
Learning rate = [0.009081909055336871, 0.009081909055336871]	Loss = 0.23100916 (ave = 0.22100450)

2023-07-05 15:13:29,017 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 4070	Time 11.925s / 10iters, (1.192)	Forward Time 1.077s / 10iters, (0.108)	Backward Time 8.048s / 10iters, (0.805)	Loss Time 2.725s / 10iters, (0.272)	Data load 0.074s / 10iters, (0.007381)
Learning rate = [0.00907963481926341, 0.00907963481926341]	Loss = 0.18933760 (ave = 0.20449885)

2023-07-05 15:13:40,886 INFO    [trainer_contrastive.py, 272] Train Epoch: 10	Train Iteration: 4080	Time 11.869s / 10iters, (1.187)	Forward Time 1.068s / 10iters, (0.107)	Backward Time 8.045s / 10iters, (0.805)	Loss Time 2.679s / 10iters, (0.268)	Data load 0.076s / 10iters, (0.007610)
Learning rate = [0.009077360519894528, 0.009077360519894528]	Loss = 0.14038356 (ave = 0.19097111)

2023-07-05 15:13:55,693 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4090	Time 14.644s / 10iters, (1.464)	Forward Time 1.308s / 10iters, (0.131)	Backward Time 8.299s / 10iters, (0.830)	Loss Time 2.622s / 10iters, (0.262)	Data load 2.415s / 10iters, (0.241496)
Learning rate = [0.009075086157210843, 0.009075086157210843]	Loss = 0.21096312 (ave = 0.24627240)

2023-07-05 15:14:07,649 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4100	Time 11.956s / 10iters, (1.196)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.089s / 10iters, (0.809)	Loss Time 2.693s / 10iters, (0.269)	Data load 0.075s / 10iters, (0.007490)
Learning rate = [0.00907281173119296, 0.00907281173119296]	Loss = 0.20694090 (ave = 0.19370304)

2023-07-05 15:14:19,862 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4110	Time 12.213s / 10iters, (1.221)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.747s / 10iters, (0.275)	Data load 0.076s / 10iters, (0.007569)
Learning rate = [0.009070537241821474, 0.009070537241821474]	Loss = 0.24236275 (ave = 0.24102472)

2023-07-05 15:14:32,012 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4120	Time 12.150s / 10iters, (1.215)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.228s / 10iters, (0.823)	Loss Time 2.758s / 10iters, (0.276)	Data load 0.076s / 10iters, (0.007589)
Learning rate = [0.009068262689076966, 0.009068262689076966]	Loss = 0.15694778 (ave = 0.18520266)

2023-07-05 15:14:44,194 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4130	Time 12.182s / 10iters, (1.218)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007524)
Learning rate = [0.009065988072940009, 0.009065988072940009]	Loss = 0.14374138 (ave = 0.22279906)

2023-07-05 15:14:56,510 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4140	Time 12.317s / 10iters, (1.232)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.873s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007450)
Learning rate = [0.009063713393391163, 0.009063713393391163]	Loss = 0.30191660 (ave = 0.22943646)

2023-07-05 15:15:08,696 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4150	Time 12.185s / 10iters, (1.219)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.183s / 10iters, (0.818)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007512)
Learning rate = [0.009061438650410977, 0.009061438650410977]	Loss = 0.16479476 (ave = 0.22599137)

2023-07-05 15:15:20,917 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4160	Time 12.221s / 10iters, (1.222)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.225s / 10iters, (0.822)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007508)
Learning rate = [0.009059163843979987, 0.009059163843979987]	Loss = 0.18298666 (ave = 0.21877221)

2023-07-05 15:15:33,063 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4170	Time 12.146s / 10iters, (1.215)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.138s / 10iters, (0.814)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007585)
Learning rate = [0.009056888974078721, 0.009056888974078721]	Loss = 0.16616729 (ave = 0.22820473)

2023-07-05 15:15:45,313 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4180	Time 12.250s / 10iters, (1.225)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.215s / 10iters, (0.822)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007500)
Learning rate = [0.009054614040687694, 0.009054614040687694]	Loss = 0.18878336 (ave = 0.22904921)

2023-07-05 15:15:57,512 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4190	Time 12.199s / 10iters, (1.220)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.129s / 10iters, (0.813)	Loss Time 2.861s / 10iters, (0.286)	Data load 0.090s / 10iters, (0.009042)
Learning rate = [0.009052339043787406, 0.009052339043787406]	Loss = 0.18684098 (ave = 0.20951818)

2023-07-05 15:16:09,687 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4200	Time 12.175s / 10iters, (1.218)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.135s / 10iters, (0.814)	Loss Time 2.873s / 10iters, (0.287)	Data load 0.076s / 10iters, (0.007601)
Learning rate = [0.00905006398335835, 0.00905006398335835]	Loss = 0.24223864 (ave = 0.23451637)

2023-07-05 15:16:21,956 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4210	Time 12.269s / 10iters, (1.227)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.194s / 10iters, (0.819)	Loss Time 2.885s / 10iters, (0.288)	Data load 0.078s / 10iters, (0.007823)
Learning rate = [0.009047788859381007, 0.009047788859381007]	Loss = 0.21524741 (ave = 0.19732883)

2023-07-05 15:16:34,462 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4220	Time 12.506s / 10iters, (1.251)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.970s / 10iters, (0.297)	Data load 0.075s / 10iters, (0.007509)
Learning rate = [0.009045513671835845, 0.009045513671835845]	Loss = 0.20426458 (ave = 0.22593691)

2023-07-05 15:16:46,536 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4230	Time 12.074s / 10iters, (1.207)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.083s / 10iters, (0.808)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007530)
Learning rate = [0.009043238420703323, 0.009043238420703323]	Loss = 0.29288769 (ave = 0.20344162)

2023-07-05 15:16:58,790 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4240	Time 12.254s / 10iters, (1.225)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.226s / 10iters, (0.823)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007482)
Learning rate = [0.009040963105963886, 0.009040963105963886]	Loss = 0.11151984 (ave = 0.22203280)

2023-07-05 15:17:11,017 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4250	Time 12.227s / 10iters, (1.223)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.172s / 10iters, (0.817)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.089s / 10iters, (0.008921)
Learning rate = [0.009038687727597968, 0.009038687727597968]	Loss = 0.14774530 (ave = 0.16454917)

2023-07-05 15:17:23,239 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4260	Time 12.222s / 10iters, (1.222)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.177s / 10iters, (0.818)	Loss Time 2.875s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007517)
Learning rate = [0.009036412285585991, 0.009036412285585991]	Loss = 0.16923900 (ave = 0.22961713)

2023-07-05 15:17:35,488 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4270	Time 12.249s / 10iters, (1.225)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.861s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007458)
Learning rate = [0.009034136779908367, 0.009034136779908367]	Loss = 0.15708122 (ave = 0.19396380)

2023-07-05 15:17:47,595 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4280	Time 12.107s / 10iters, (1.211)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.094s / 10iters, (0.809)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007595)
Learning rate = [0.009031861210545496, 0.009031861210545496]	Loss = 0.39303401 (ave = 0.19720856)

2023-07-05 15:17:59,737 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4290	Time 12.142s / 10iters, (1.214)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.121s / 10iters, (0.812)	Loss Time 2.845s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007472)
Learning rate = [0.009029585577477768, 0.009029585577477768]	Loss = 0.33963636 (ave = 0.18411775)

2023-07-05 15:18:11,956 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4300	Time 12.219s / 10iters, (1.222)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.197s / 10iters, (0.820)	Loss Time 2.856s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007448)
Learning rate = [0.00902730988068556, 0.00902730988068556]	Loss = 0.13861801 (ave = 0.16642651)

2023-07-05 15:18:24,198 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4310	Time 12.242s / 10iters, (1.224)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.204s / 10iters, (0.820)	Loss Time 2.855s / 10iters, (0.286)	Data load 0.082s / 10iters, (0.008155)
Learning rate = [0.009025034120149232, 0.009025034120149232]	Loss = 0.19181709 (ave = 0.20720753)

2023-07-05 15:18:36,355 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4320	Time 12.157s / 10iters, (1.216)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.174s / 10iters, (0.817)	Loss Time 2.816s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007476)
Learning rate = [0.009022758295849144, 0.009022758295849144]	Loss = 0.17283791 (ave = 0.21042227)

2023-07-05 15:18:48,503 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4330	Time 12.148s / 10iters, (1.215)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.166s / 10iters, (0.817)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007432)
Learning rate = [0.009020482407765635, 0.009020482407765635]	Loss = 0.18205790 (ave = 0.19551067)

2023-07-05 15:19:00,676 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4340	Time 12.173s / 10iters, (1.217)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.169s / 10iters, (0.817)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007374)
Learning rate = [0.009018206455879035, 0.009018206455879035]	Loss = 0.26300871 (ave = 0.21116765)

2023-07-05 15:19:12,875 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4350	Time 12.198s / 10iters, (1.220)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.159s / 10iters, (0.816)	Loss Time 2.872s / 10iters, (0.287)	Data load 0.076s / 10iters, (0.007565)
Learning rate = [0.009015930440169666, 0.009015930440169666]	Loss = 0.15985499 (ave = 0.21268024)

2023-07-05 15:19:25,015 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4360	Time 12.141s / 10iters, (1.214)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.135s / 10iters, (0.814)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007532)
Learning rate = [0.009013654360617832, 0.009013654360617832]	Loss = 0.22747226 (ave = 0.20404403)

2023-07-05 15:19:37,214 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4370	Time 12.199s / 10iters, (1.220)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.172s / 10iters, (0.817)	Loss Time 2.857s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007483)
Learning rate = [0.009011378217203832, 0.009011378217203832]	Loss = 0.18432014 (ave = 0.19800420)

2023-07-05 15:19:49,396 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4380	Time 12.182s / 10iters, (1.218)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.163s / 10iters, (0.816)	Loss Time 2.848s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007466)
Learning rate = [0.009009102009907947, 0.009009102009907947]	Loss = 0.17634159 (ave = 0.18938605)

2023-07-05 15:20:01,573 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4390	Time 12.177s / 10iters, (1.218)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.143s / 10iters, (0.814)	Loss Time 2.855s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007580)
Learning rate = [0.009006825738710453, 0.009006825738710453]	Loss = 1.18547821 (ave = 0.27454628)

2023-07-05 15:20:13,832 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4400	Time 12.259s / 10iters, (1.226)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.184s / 10iters, (0.818)	Loss Time 2.906s / 10iters, (0.291)	Data load 0.075s / 10iters, (0.007459)
Learning rate = [0.009004549403591609, 0.009004549403591609]	Loss = 0.22949210 (ave = 0.23788545)

2023-07-05 15:20:26,051 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4410	Time 12.219s / 10iters, (1.222)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.186s / 10iters, (0.819)	Loss Time 2.862s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007486)
Learning rate = [0.009002273004531663, 0.009002273004531663]	Loss = 0.20628481 (ave = 0.22583378)

2023-07-05 15:20:38,240 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4420	Time 12.189s / 10iters, (1.219)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.131s / 10iters, (0.813)	Loss Time 2.891s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007478)
Learning rate = [0.008999996541510855, 0.008999996541510855]	Loss = 0.15720394 (ave = 0.20458142)

2023-07-05 15:20:50,442 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4430	Time 12.202s / 10iters, (1.220)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.151s / 10iters, (0.815)	Loss Time 2.875s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007479)
Learning rate = [0.00899772001450941, 0.00899772001450941]	Loss = 0.22114645 (ave = 0.24922544)

2023-07-05 15:21:02,537 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4440	Time 12.095s / 10iters, (1.209)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.108s / 10iters, (0.811)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.077s / 10iters, (0.007663)
Learning rate = [0.008995443423507542, 0.008995443423507542]	Loss = 0.19126396 (ave = 0.23972182)

2023-07-05 15:21:14,694 INFO    [trainer_contrastive.py, 272] Train Epoch: 11	Train Iteration: 4450	Time 12.157s / 10iters, (1.216)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007381)
Learning rate = [0.008993166768485454, 0.008993166768485454]	Loss = 0.27591756 (ave = 0.23886008)

2023-07-05 15:21:29,526 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4460	Time 14.689s / 10iters, (1.469)	Forward Time 1.254s / 10iters, (0.125)	Backward Time 8.305s / 10iters, (0.831)	Loss Time 2.805s / 10iters, (0.281)	Data load 2.324s / 10iters, (0.232420)
Learning rate = [0.008990890049423338, 0.008990890049423338]	Loss = 0.25064600 (ave = 0.21722363)

2023-07-05 15:21:41,747 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4470	Time 12.221s / 10iters, (1.222)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.195s / 10iters, (0.820)	Loss Time 2.848s / 10iters, (0.285)	Data load 0.081s / 10iters, (0.008058)
Learning rate = [0.008988613266301373, 0.008988613266301373]	Loss = 0.15747248 (ave = 0.19568516)

2023-07-05 15:21:54,057 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4480	Time 12.310s / 10iters, (1.231)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.877s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007494)
Learning rate = [0.008986336419099723, 0.008986336419099723]	Loss = 0.20351350 (ave = 0.20041800)

2023-07-05 15:22:06,262 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4490	Time 12.205s / 10iters, (1.220)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.156s / 10iters, (0.816)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.084s / 10iters, (0.008434)
Learning rate = [0.008984059507798547, 0.008984059507798547]	Loss = 0.22519356 (ave = 0.18478889)

2023-07-05 15:22:18,529 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4500	Time 12.267s / 10iters, (1.227)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.260s / 10iters, (0.826)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007492)
Learning rate = [0.00898178253237799, 0.00898178253237799]	Loss = 0.26955223 (ave = 0.20651577)

2023-07-05 15:22:30,820 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4510	Time 12.291s / 10iters, (1.229)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.287s / 10iters, (0.829)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.083s / 10iters, (0.008330)
Learning rate = [0.00897950549281818, 0.00897950549281818]	Loss = 0.15855393 (ave = 0.16101501)

2023-07-05 15:22:43,083 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4520	Time 12.264s / 10iters, (1.226)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007589)
Learning rate = [0.008977228389099243, 0.008977228389099243]	Loss = 0.17967336 (ave = 0.17316044)

2023-07-05 15:22:55,475 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4530	Time 12.391s / 10iters, (1.239)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.337s / 10iters, (0.834)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.079s / 10iters, (0.007936)
Learning rate = [0.008974951221201285, 0.008974951221201285]	Loss = 0.22039257 (ave = 0.21689438)

2023-07-05 15:23:07,715 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4540	Time 12.240s / 10iters, (1.224)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.194s / 10iters, (0.819)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.090s / 10iters, (0.009015)
Learning rate = [0.008972673989104401, 0.008972673989104401]	Loss = 0.20382670 (ave = 0.21259945)

2023-07-05 15:23:20,041 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4550	Time 12.326s / 10iters, (1.233)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.887s / 10iters, (0.289)	Data load 0.084s / 10iters, (0.008393)
Learning rate = [0.00897039669278868, 0.00897039669278868]	Loss = 0.21075401 (ave = 0.20133110)

2023-07-05 15:23:32,269 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4560	Time 12.228s / 10iters, (1.223)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.192s / 10iters, (0.819)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.083s / 10iters, (0.008312)
Learning rate = [0.008968119332234193, 0.008968119332234193]	Loss = 0.13339362 (ave = 0.24231420)

2023-07-05 15:23:44,563 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4570	Time 12.294s / 10iters, (1.229)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.242s / 10iters, (0.824)	Loss Time 2.885s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007533)
Learning rate = [0.008965841907421003, 0.008965841907421003]	Loss = 0.16727887 (ave = 0.24567056)

2023-07-05 15:23:56,874 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4580	Time 12.311s / 10iters, (1.231)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.889s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007465)
Learning rate = [0.00896356441832916, 0.00896356441832916]	Loss = 0.27551231 (ave = 0.19146635)

2023-07-05 15:24:09,177 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4590	Time 12.303s / 10iters, (1.230)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.232s / 10iters, (0.823)	Loss Time 2.896s / 10iters, (0.290)	Data load 0.076s / 10iters, (0.007590)
Learning rate = [0.008961286864938701, 0.008961286864938701]	Loss = 0.19185525 (ave = 0.21922281)

2023-07-05 15:24:21,465 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4600	Time 12.288s / 10iters, (1.229)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.879s / 10iters, (0.288)	Data load 0.076s / 10iters, (0.007570)
Learning rate = [0.008959009247229649, 0.008959009247229649]	Loss = 0.21161106 (ave = 0.24142239)

2023-07-05 15:24:33,757 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4610	Time 12.292s / 10iters, (1.229)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.225s / 10iters, (0.822)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.099s / 10iters, (0.009926)
Learning rate = [0.008956731565182025, 0.008956731565182025]	Loss = 0.14205416 (ave = 0.20121837)

2023-07-05 15:24:45,972 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4620	Time 12.215s / 10iters, (1.222)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.179s / 10iters, (0.818)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.083s / 10iters, (0.008284)
Learning rate = [0.008954453818775828, 0.008954453818775828]	Loss = 0.56839138 (ave = 0.25085934)

2023-07-05 15:24:58,184 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4630	Time 12.213s / 10iters, (1.221)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.177s / 10iters, (0.818)	Loss Time 2.865s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007501)
Learning rate = [0.008952176007991046, 0.008952176007991046]	Loss = 0.27394274 (ave = 0.21797601)

2023-07-05 15:25:10,597 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4640	Time 12.413s / 10iters, (1.241)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.371s / 10iters, (0.837)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.078s / 10iters, (0.007798)
Learning rate = [0.008949898132807662, 0.008949898132807662]	Loss = 0.40487838 (ave = 0.25771857)

2023-07-05 15:25:23,059 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4650	Time 12.462s / 10iters, (1.246)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.419s / 10iters, (0.842)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007579)
Learning rate = [0.00894762019320564, 0.00894762019320564]	Loss = 0.15845647 (ave = 0.24943075)

2023-07-05 15:25:35,461 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4660	Time 12.402s / 10iters, (1.240)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.379s / 10iters, (0.838)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.077s / 10iters, (0.007674)
Learning rate = [0.008945342189164937, 0.008945342189164937]	Loss = 0.17543823 (ave = 0.27489757)

2023-07-05 15:25:47,725 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4670	Time 12.265s / 10iters, (1.226)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.181s / 10iters, (0.818)	Loss Time 2.905s / 10iters, (0.290)	Data load 0.078s / 10iters, (0.007795)
Learning rate = [0.008943064120665494, 0.008943064120665494]	Loss = 0.19773521 (ave = 0.25021196)

2023-07-05 15:26:00,016 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4680	Time 12.290s / 10iters, (1.229)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.233s / 10iters, (0.823)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.083s / 10iters, (0.008285)
Learning rate = [0.008940785987687242, 0.008940785987687242]	Loss = 0.31564167 (ave = 0.21896675)

2023-07-05 15:26:12,290 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4690	Time 12.274s / 10iters, (1.227)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.166s / 10iters, (0.817)	Loss Time 2.909s / 10iters, (0.291)	Data load 0.080s / 10iters, (0.007958)
Learning rate = [0.008938507790210102, 0.008938507790210102]	Loss = 0.26673067 (ave = 0.21278637)

2023-07-05 15:26:24,616 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4700	Time 12.326s / 10iters, (1.233)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.865s / 10iters, (0.287)	Data load 0.088s / 10iters, (0.008770)
Learning rate = [0.00893622952821398, 0.00893622952821398]	Loss = 0.46795022 (ave = 0.22044582)

2023-07-05 15:26:37,011 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4710	Time 12.395s / 10iters, (1.239)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.364s / 10iters, (0.836)	Loss Time 2.848s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007491)
Learning rate = [0.008933951201678773, 0.008933951201678773]	Loss = 0.41160131 (ave = 0.28562898)

2023-07-05 15:26:49,244 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4720	Time 12.233s / 10iters, (1.223)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.197s / 10iters, (0.820)	Loss Time 2.870s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007480)
Learning rate = [0.008931672810584362, 0.008931672810584362]	Loss = 0.22422567 (ave = 0.20471798)

2023-07-05 15:27:01,550 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4730	Time 12.305s / 10iters, (1.231)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.906s / 10iters, (0.291)	Data load 0.086s / 10iters, (0.008603)
Learning rate = [0.008929394354910617, 0.008929394354910617]	Loss = 0.20841870 (ave = 0.24982561)

2023-07-05 15:27:13,801 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4740	Time 12.251s / 10iters, (1.225)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.192s / 10iters, (0.819)	Loss Time 2.879s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007487)
Learning rate = [0.008927115834637398, 0.008927115834637398]	Loss = 0.23378761 (ave = 0.21531687)

2023-07-05 15:27:26,019 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4750	Time 12.218s / 10iters, (1.222)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.182s / 10iters, (0.818)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007454)
Learning rate = [0.008924837249744558, 0.008924837249744558]	Loss = 0.15185770 (ave = 0.19953969)

2023-07-05 15:27:38,260 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4760	Time 12.241s / 10iters, (1.224)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.835s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007566)
Learning rate = [0.008922558600211924, 0.008922558600211924]	Loss = 0.18740723 (ave = 0.22880294)

2023-07-05 15:27:50,506 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4770	Time 12.246s / 10iters, (1.225)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.865s / 10iters, (0.286)	Data load 0.076s / 10iters, (0.007587)
Learning rate = [0.008920279886019325, 0.008920279886019325]	Loss = 0.20296015 (ave = 0.26497822)

2023-07-05 15:28:02,699 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4780	Time 12.193s / 10iters, (1.219)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.170s / 10iters, (0.817)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007525)
Learning rate = [0.008918001107146571, 0.008918001107146571]	Loss = 0.26473218 (ave = 0.31959199)

2023-07-05 15:28:14,959 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4790	Time 12.260s / 10iters, (1.226)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.852s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007545)
Learning rate = [0.008915722263573459, 0.008915722263573459]	Loss = 0.28489050 (ave = 0.23784436)

2023-07-05 15:28:27,207 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4800	Time 12.248s / 10iters, (1.225)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007531)
Learning rate = [0.008913443355279778, 0.008913443355279778]	Loss = 0.84311485 (ave = 0.44923261)

2023-07-05 15:28:39,256 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4810	Time 12.049s / 10iters, (1.205)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.130s / 10iters, (0.813)	Loss Time 2.749s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007454)
Learning rate = [0.008911164382245302, 0.008911164382245302]	Loss = 0.17813066 (ave = 0.30972257)

2023-07-05 15:28:51,200 INFO    [trainer_contrastive.py, 272] Train Epoch: 12	Train Iteration: 4820	Time 11.944s / 10iters, (1.194)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.076s / 10iters, (0.808)	Loss Time 2.714s / 10iters, (0.271)	Data load 0.073s / 10iters, (0.007328)
Learning rate = [0.008908885344449797, 0.008908885344449797]	Loss = 0.13621466 (ave = 0.22179853)

2023-07-05 15:29:06,257 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 4830	Time 14.899s / 10iters, (1.490)	Forward Time 1.149s / 10iters, (0.115)	Backward Time 8.208s / 10iters, (0.821)	Loss Time 2.727s / 10iters, (0.273)	Data load 2.815s / 10iters, (0.281516)
Learning rate = [0.00890660624187301, 0.00890660624187301]	Loss = 0.13589354 (ave = 0.25715429)

2023-07-05 15:29:18,489 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 4840	Time 12.232s / 10iters, (1.223)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.307s / 10iters, (0.831)	Loss Time 2.710s / 10iters, (0.271)	Data load 0.099s / 10iters, (0.009926)
Learning rate = [0.008904327074494681, 0.008904327074494681]	Loss = 0.18794358 (ave = 0.22542676)

2023-07-05 15:29:30,609 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 4850	Time 12.120s / 10iters, (1.212)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.209s / 10iters, (0.821)	Loss Time 2.715s / 10iters, (0.272)	Data load 0.075s / 10iters, (0.007530)
Learning rate = [0.00890204784229454, 0.00890204784229454]	Loss = 0.15833116 (ave = 0.18057083)

2023-07-05 15:29:42,889 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 4860	Time 12.280s / 10iters, (1.228)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.336s / 10iters, (0.834)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.076s / 10iters, (0.007623)
Learning rate = [0.008899768545252299, 0.008899768545252299]	Loss = 0.11947526 (ave = 0.23722203)

2023-07-05 15:29:55,156 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 4870	Time 12.267s / 10iters, (1.227)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.080s / 10iters, (0.007994)
Learning rate = [0.008897489183347658, 0.008897489183347658]	Loss = 0.23782611 (ave = 0.23712308)

2023-07-05 15:30:07,400 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 4880	Time 12.244s / 10iters, (1.224)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.288s / 10iters, (0.829)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007392)
Learning rate = [0.008895209756560312, 0.008895209756560312]	Loss = 0.25299582 (ave = 0.23332347)

2023-07-05 15:30:19,589 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 4890	Time 12.189s / 10iters, (1.219)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.205s / 10iters, (0.821)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.090s / 10iters, (0.008988)
Learning rate = [0.008892930264869937, 0.008892930264869937]	Loss = 0.31630698 (ave = 0.25817653)

2023-07-05 15:30:31,852 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 4900	Time 12.263s / 10iters, (1.226)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.255s / 10iters, (0.825)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007387)
Learning rate = [0.008890650708256198, 0.008890650708256198]	Loss = 0.21850954 (ave = 0.24985503)

2023-07-05 15:30:43,982 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 4910	Time 12.130s / 10iters, (1.213)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.170s / 10iters, (0.817)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007526)
Learning rate = [0.008888371086698751, 0.008888371086698751]	Loss = 0.39151630 (ave = 0.25364185)

2023-07-05 15:30:56,162 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 4920	Time 12.179s / 10iters, (1.218)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.077s / 10iters, (0.007730)
Learning rate = [0.008886091400177239, 0.008886091400177239]	Loss = 0.33718696 (ave = 0.25063233)

2023-07-05 15:31:08,380 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 4930	Time 12.218s / 10iters, (1.222)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.790s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007430)
Learning rate = [0.008883811648671289, 0.008883811648671289]	Loss = 0.09567352 (ave = 0.21247489)

2023-07-05 15:31:20,552 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 4940	Time 12.172s / 10iters, (1.217)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.785s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007431)
Learning rate = [0.008881531832160517, 0.008881531832160517]	Loss = 0.24691947 (ave = 0.29478609)

2023-07-05 15:31:32,668 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 4950	Time 12.117s / 10iters, (1.212)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.185s / 10iters, (0.818)	Loss Time 2.749s / 10iters, (0.275)	Data load 0.088s / 10iters, (0.008810)
Learning rate = [0.008879251950624532, 0.008879251950624532]	Loss = 0.24568395 (ave = 0.25657265)

2023-07-05 15:31:44,854 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 4960	Time 12.186s / 10iters, (1.219)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007460)
Learning rate = [0.008876972004042924, 0.008876972004042924]	Loss = 0.16532046 (ave = 0.26747900)

2023-07-05 15:31:56,983 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 4970	Time 12.129s / 10iters, (1.213)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.758s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007460)
Learning rate = [0.008874691992395276, 0.008874691992395276]	Loss = 0.22916532 (ave = 0.22131141)

2023-07-05 15:32:09,173 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 4980	Time 12.190s / 10iters, (1.219)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007506)
Learning rate = [0.008872411915661155, 0.008872411915661155]	Loss = 0.16135634 (ave = 0.19424455)

2023-07-05 15:32:21,303 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 4990	Time 12.131s / 10iters, (1.213)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.077s / 10iters, (0.007654)
Learning rate = [0.008870131773820119, 0.008870131773820119]	Loss = 0.21636765 (ave = 0.25923852)

2023-07-05 15:32:33,400 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5000	Time 12.097s / 10iters, (1.210)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.180s / 10iters, (0.818)	Loss Time 2.733s / 10iters, (0.273)	Data load 0.080s / 10iters, (0.008003)
Learning rate = [0.008867851566851707, 0.008867851566851707]	Loss = 0.19617647 (ave = 0.27928040)

2023-07-05 15:32:36,944 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 15:33:00,353 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 15:33:23,167 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 15:33:45,978 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 15:34:08,589 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 15:34:30,926 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 15:34:53,083 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 15:34:58,796 INFO    [base.py, 84] Performance 0.6497171948321523 -> 0.657797955505786
2023-07-05 15:35:02,906 INFO    [trainer_contrastive.py, 391] Test Time 145.218s, (2.305)	Loss 0.19820769

2023-07-05 15:35:02,908 INFO    [base.py, 33] Result for seg
2023-07-05 15:35:02,909 INFO    [base.py, 49] Mean IOU: 0.657797955505786

2023-07-05 15:35:02,910 INFO    [base.py, 50] Pixel ACC: 0.9391119888314488

2023-07-05 15:35:15,047 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5010	Time 161.647s / 10iters, (16.165)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.655s / 10iters, (0.265)	Data load 149.596s / 10iters, (14.959606)
Learning rate = [0.008865571294735457, 0.008865571294735457]	Loss = 1.15748453 (ave = 1.17017729)

2023-07-05 15:35:27,188 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5020	Time 12.141s / 10iters, (1.214)	Forward Time 1.082s / 10iters, (0.108)	Backward Time 8.297s / 10iters, (0.830)	Loss Time 2.686s / 10iters, (0.269)	Data load 0.075s / 10iters, (0.007494)
Learning rate = [0.008863290957450885, 0.008863290957450885]	Loss = 1.04084897 (ave = 1.06730142)

2023-07-05 15:35:39,271 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5030	Time 12.083s / 10iters, (1.208)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.236s / 10iters, (0.824)	Loss Time 2.662s / 10iters, (0.266)	Data load 0.085s / 10iters, (0.008535)
Learning rate = [0.008861010554977499, 0.008861010554977499]	Loss = 1.21855569 (ave = 1.03791410)

2023-07-05 15:35:51,207 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5040	Time 11.937s / 10iters, (1.194)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.125s / 10iters, (0.812)	Loss Time 2.628s / 10iters, (0.263)	Data load 0.075s / 10iters, (0.007507)
Learning rate = [0.008858730087294793, 0.008858730087294793]	Loss = 0.99939322 (ave = 0.99717832)

2023-07-05 15:36:03,270 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5050	Time 12.063s / 10iters, (1.206)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.207s / 10iters, (0.821)	Loss Time 2.693s / 10iters, (0.269)	Data load 0.075s / 10iters, (0.007502)
Learning rate = [0.008856449554382249, 0.008856449554382249]	Loss = 0.96945882 (ave = 1.01028767)

2023-07-05 15:36:15,463 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5060	Time 12.193s / 10iters, (1.219)	Forward Time 1.082s / 10iters, (0.108)	Backward Time 8.298s / 10iters, (0.830)	Loss Time 2.738s / 10iters, (0.274)	Data load 0.074s / 10iters, (0.007422)
Learning rate = [0.00885416895621934, 0.00885416895621934]	Loss = 0.91378886 (ave = 0.97072375)

2023-07-05 15:36:27,586 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5070	Time 12.123s / 10iters, (1.212)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.705s / 10iters, (0.270)	Data load 0.074s / 10iters, (0.007401)
Learning rate = [0.008851888292785522, 0.008851888292785522]	Loss = 0.92155331 (ave = 0.93740993)

2023-07-05 15:36:39,668 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5080	Time 12.082s / 10iters, (1.208)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.695s / 10iters, (0.269)	Data load 0.096s / 10iters, (0.009627)
Learning rate = [0.00884960756406024, 0.00884960756406024]	Loss = 0.87766689 (ave = 0.92305914)

2023-07-05 15:36:51,901 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5090	Time 12.233s / 10iters, (1.223)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.747s / 10iters, (0.275)	Data load 0.103s / 10iters, (0.010275)
Learning rate = [0.008847326770022928, 0.008847326770022928]	Loss = 0.86348391 (ave = 0.95590780)

2023-07-05 15:37:04,096 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5100	Time 12.195s / 10iters, (1.220)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.719s / 10iters, (0.272)	Data load 0.076s / 10iters, (0.007588)
Learning rate = [0.008845045910653005, 0.008845045910653005]	Loss = 1.20980167 (ave = 0.96375771)

2023-07-05 15:37:16,262 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5110	Time 12.166s / 10iters, (1.217)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.080s / 10iters, (0.007982)
Learning rate = [0.008842764985929882, 0.008842764985929882]	Loss = 0.86728030 (ave = 1.00172294)

2023-07-05 15:37:28,499 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5120	Time 12.237s / 10iters, (1.224)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.298s / 10iters, (0.830)	Loss Time 2.747s / 10iters, (0.275)	Data load 0.079s / 10iters, (0.007897)
Learning rate = [0.008840483995832954, 0.008840483995832954]	Loss = 0.85145211 (ave = 0.98869462)

2023-07-05 15:37:40,633 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5130	Time 12.135s / 10iters, (1.213)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.278s / 10iters, (0.828)	Loss Time 2.688s / 10iters, (0.269)	Data load 0.076s / 10iters, (0.007550)
Learning rate = [0.008838202940341603, 0.008838202940341603]	Loss = 1.00346482 (ave = 0.92425463)

2023-07-05 15:37:52,853 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5140	Time 12.220s / 10iters, (1.222)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.315s / 10iters, (0.832)	Loss Time 2.713s / 10iters, (0.271)	Data load 0.091s / 10iters, (0.009107)
Learning rate = [0.008835921819435202, 0.008835921819435202]	Loss = 0.92109907 (ave = 0.90965785)

2023-07-05 15:38:05,027 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5150	Time 12.174s / 10iters, (1.217)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.245s / 10iters, (0.825)	Loss Time 2.727s / 10iters, (0.273)	Data load 0.095s / 10iters, (0.009474)
Learning rate = [0.008833640633093108, 0.008833640633093108]	Loss = 0.97248667 (ave = 0.89579073)

2023-07-05 15:38:17,268 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5160	Time 12.241s / 10iters, (1.224)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.262s / 10iters, (0.826)	Loss Time 2.803s / 10iters, (0.280)	Data load 0.085s / 10iters, (0.008457)
Learning rate = [0.00883135938129467, 0.00883135938129467]	Loss = 0.97503674 (ave = 0.97193787)

2023-07-05 15:38:29,489 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5170	Time 12.220s / 10iters, (1.222)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007452)
Learning rate = [0.008829078064019218, 0.008829078064019218]	Loss = 1.05500281 (ave = 0.96309422)

2023-07-05 15:38:41,713 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5180	Time 12.225s / 10iters, (1.222)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.765s / 10iters, (0.277)	Data load 0.079s / 10iters, (0.007866)
Learning rate = [0.008826796681246078, 0.008826796681246078]	Loss = 1.07194507 (ave = 0.94670464)

2023-07-05 15:38:53,671 INFO    [trainer_contrastive.py, 272] Train Epoch: 13	Train Iteration: 5190	Time 11.958s / 10iters, (1.196)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.107s / 10iters, (0.811)	Loss Time 2.695s / 10iters, (0.269)	Data load 0.076s / 10iters, (0.007587)
Learning rate = [0.008824515232954555, 0.008824515232954555]	Loss = 0.89411664 (ave = 0.91067079)

2023-07-05 15:39:08,234 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5200	Time 14.373s / 10iters, (1.437)	Forward Time 1.235s / 10iters, (0.124)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.695s / 10iters, (0.270)	Data load 2.252s / 10iters, (0.225212)
Learning rate = [0.008822233719123948, 0.008822233719123948]	Loss = 0.93437040 (ave = 0.94916244)

2023-07-05 15:39:20,443 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5210	Time 12.210s / 10iters, (1.221)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.084s / 10iters, (0.008430)
Learning rate = [0.008819952139733538, 0.008819952139733538]	Loss = 0.97477829 (ave = 0.93156807)

2023-07-05 15:39:32,598 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5220	Time 12.155s / 10iters, (1.215)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.171s / 10iters, (0.817)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007507)
Learning rate = [0.008817670494762599, 0.008817670494762599]	Loss = 0.99153948 (ave = 0.96031877)

2023-07-05 15:39:44,885 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5230	Time 12.287s / 10iters, (1.229)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.077s / 10iters, (0.007657)
Learning rate = [0.008815388784190388, 0.008815388784190388]	Loss = 0.98114330 (ave = 0.92337747)

2023-07-05 15:39:57,165 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5240	Time 12.280s / 10iters, (1.228)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007489)
Learning rate = [0.008813107007996155, 0.008813107007996155]	Loss = 0.86752272 (ave = 0.91173878)

2023-07-05 15:40:09,401 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5250	Time 12.236s / 10iters, (1.224)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.085s / 10iters, (0.008528)
Learning rate = [0.00881082516615913, 0.00881082516615913]	Loss = 0.94447899 (ave = 0.95554616)

2023-07-05 15:40:21,670 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5260	Time 12.269s / 10iters, (1.227)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.204s / 10iters, (0.820)	Loss Time 2.896s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007524)
Learning rate = [0.008808543258658534, 0.008808543258658534]	Loss = 0.84979481 (ave = 0.89358727)

2023-07-05 15:40:34,159 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5270	Time 12.489s / 10iters, (1.249)	Forward Time 1.137s / 10iters, (0.114)	Backward Time 8.377s / 10iters, (0.838)	Loss Time 2.899s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007515)
Learning rate = [0.00880626128547358, 0.00880626128547358]	Loss = 1.08428764 (ave = 0.90221338)

2023-07-05 15:40:46,499 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5280	Time 12.340s / 10iters, (1.234)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.104s / 10iters, (0.010399)
Learning rate = [0.008803979246583458, 0.008803979246583458]	Loss = 0.97608596 (ave = 0.91912916)

2023-07-05 15:40:58,698 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5290	Time 12.199s / 10iters, (1.220)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.185s / 10iters, (0.819)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007489)
Learning rate = [0.008801697141967357, 0.008801697141967357]	Loss = 0.85870337 (ave = 0.91383964)

2023-07-05 15:41:11,016 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5300	Time 12.318s / 10iters, (1.232)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.253s / 10iters, (0.825)	Loss Time 2.898s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007488)
Learning rate = [0.008799414971604446, 0.008799414971604446]	Loss = 0.90275288 (ave = 0.93259140)

2023-07-05 15:41:23,297 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5310	Time 12.281s / 10iters, (1.228)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.238s / 10iters, (0.824)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.076s / 10iters, (0.007616)
Learning rate = [0.008797132735473886, 0.008797132735473886]	Loss = 0.96997905 (ave = 0.97880295)

2023-07-05 15:41:35,523 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5320	Time 12.226s / 10iters, (1.223)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.182s / 10iters, (0.818)	Loss Time 2.874s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007474)
Learning rate = [0.008794850433554815, 0.008794850433554815]	Loss = 0.89356601 (ave = 0.90612255)

2023-07-05 15:41:47,684 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5330	Time 12.161s / 10iters, (1.216)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.156s / 10iters, (0.816)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.079s / 10iters, (0.007905)
Learning rate = [0.008792568065826374, 0.008792568065826374]	Loss = 0.87833571 (ave = 0.98277453)

2023-07-05 15:41:59,837 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5340	Time 12.153s / 10iters, (1.215)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.197s / 10iters, (0.820)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.078s / 10iters, (0.007843)
Learning rate = [0.008790285632267681, 0.008790285632267681]	Loss = 0.96071470 (ave = 0.89983041)

2023-07-05 15:42:12,060 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5350	Time 12.223s / 10iters, (1.222)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.758s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007464)
Learning rate = [0.008788003132857844, 0.008788003132857844]	Loss = 0.93764770 (ave = 0.95626574)

2023-07-05 15:42:24,323 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5360	Time 12.263s / 10iters, (1.226)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.769s / 10iters, (0.277)	Data load 0.085s / 10iters, (0.008456)
Learning rate = [0.008785720567575957, 0.008785720567575957]	Loss = 0.90254033 (ave = 0.91703902)

2023-07-05 15:42:36,483 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5370	Time 12.160s / 10iters, (1.216)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.080s / 10iters, (0.008017)
Learning rate = [0.008783437936401102, 0.008783437936401102]	Loss = 0.87157840 (ave = 0.90589803)

2023-07-05 15:42:48,801 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5380	Time 12.318s / 10iters, (1.232)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.880s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007380)
Learning rate = [0.00878115523931235, 0.00878115523931235]	Loss = 0.97990936 (ave = 0.95301874)

2023-07-05 15:43:01,002 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5390	Time 12.201s / 10iters, (1.220)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.816s / 10iters, (0.282)	Data load 0.078s / 10iters, (0.007790)
Learning rate = [0.00877887247628876, 0.00877887247628876]	Loss = 0.99783540 (ave = 0.89936035)

2023-07-05 15:43:13,325 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5400	Time 12.323s / 10iters, (1.232)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.305s / 10iters, (0.831)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007396)
Learning rate = [0.008776589647309372, 0.008776589647309372]	Loss = 0.81981599 (ave = 0.92433546)

2023-07-05 15:43:25,579 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5410	Time 12.254s / 10iters, (1.225)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.852s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007390)
Learning rate = [0.008774306752353224, 0.008774306752353224]	Loss = 0.88988429 (ave = 0.91543299)

2023-07-05 15:43:37,759 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5420	Time 12.181s / 10iters, (1.218)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007442)
Learning rate = [0.00877202379139933, 0.00877202379139933]	Loss = 1.08550668 (ave = 0.96629657)

2023-07-05 15:43:50,007 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5430	Time 12.248s / 10iters, (1.225)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007482)
Learning rate = [0.008769740764426695, 0.008769740764426695]	Loss = 1.04576659 (ave = 0.94836091)

2023-07-05 15:44:02,250 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5440	Time 12.243s / 10iters, (1.224)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.816s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007382)
Learning rate = [0.008767457671414318, 0.008767457671414318]	Loss = 0.88465309 (ave = 0.92082040)

2023-07-05 15:44:14,496 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5450	Time 12.246s / 10iters, (1.225)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007402)
Learning rate = [0.008765174512341175, 0.008765174512341175]	Loss = 0.88958168 (ave = 0.90451608)

2023-07-05 15:44:26,745 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5460	Time 12.249s / 10iters, (1.225)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.270s / 10iters, (0.827)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007388)
Learning rate = [0.008762891287186237, 0.008762891287186237]	Loss = 0.88301712 (ave = 0.95850179)

2023-07-05 15:44:39,000 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5470	Time 12.255s / 10iters, (1.226)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.255s / 10iters, (0.825)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007511)
Learning rate = [0.008760607995928456, 0.008760607995928456]	Loss = 0.93544215 (ave = 0.88254603)

2023-07-05 15:44:51,291 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5480	Time 12.291s / 10iters, (1.229)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.275s / 10iters, (0.828)	Loss Time 2.850s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007487)
Learning rate = [0.008758324638546776, 0.008758324638546776]	Loss = 1.01997495 (ave = 0.92683725)

2023-07-05 15:45:03,415 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5490	Time 12.124s / 10iters, (1.212)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.175s / 10iters, (0.818)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007456)
Learning rate = [0.00875604121502013, 0.00875604121502013]	Loss = 0.75439084 (ave = 0.91050915)

2023-07-05 15:45:15,663 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5500	Time 12.247s / 10iters, (1.225)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007456)
Learning rate = [0.008753757725327427, 0.008753757725327427]	Loss = 0.75974208 (ave = 0.87713915)

2023-07-05 15:45:27,860 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5510	Time 12.197s / 10iters, (1.220)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.203s / 10iters, (0.820)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007476)
Learning rate = [0.008751474169447578, 0.008751474169447578]	Loss = 0.85779631 (ave = 0.96005820)

2023-07-05 15:45:40,132 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5520	Time 12.272s / 10iters, (1.227)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.255s / 10iters, (0.826)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007462)
Learning rate = [0.00874919054735947, 0.00874919054735947]	Loss = 1.15545046 (ave = 0.95488705)

2023-07-05 15:45:52,350 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5530	Time 12.218s / 10iters, (1.222)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.226s / 10iters, (0.823)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007499)
Learning rate = [0.008746906859041984, 0.008746906859041984]	Loss = 0.84670097 (ave = 0.90809303)

2023-07-05 15:46:04,628 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5540	Time 12.278s / 10iters, (1.228)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007443)
Learning rate = [0.008744623104473982, 0.008744623104473982]	Loss = 0.96727896 (ave = 0.87844816)

2023-07-05 15:46:16,920 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5550	Time 12.292s / 10iters, (1.229)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.835s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007478)
Learning rate = [0.00874233928363432, 0.00874233928363432]	Loss = 0.88559729 (ave = 0.91135151)

2023-07-05 15:46:28,935 INFO    [trainer_contrastive.py, 272] Train Epoch: 14	Train Iteration: 5560	Time 12.014s / 10iters, (1.201)	Forward Time 1.081s / 10iters, (0.108)	Backward Time 8.138s / 10iters, (0.814)	Loss Time 2.719s / 10iters, (0.272)	Data load 0.076s / 10iters, (0.007569)
Learning rate = [0.008740055396501833, 0.008740055396501833]	Loss = 0.85566157 (ave = 0.90390243)

2023-07-05 15:46:43,563 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5570	Time 14.495s / 10iters, (1.449)	Forward Time 1.227s / 10iters, (0.123)	Backward Time 8.365s / 10iters, (0.836)	Loss Time 2.741s / 10iters, (0.274)	Data load 2.162s / 10iters, (0.216183)
Learning rate = [0.008737771443055353, 0.008737771443055353]	Loss = 0.80152607 (ave = 0.87340376)

2023-07-05 15:46:55,747 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5580	Time 12.184s / 10iters, (1.218)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007574)
Learning rate = [0.008735487423273689, 0.008735487423273689]	Loss = 0.90082699 (ave = 0.87991585)

2023-07-05 15:47:07,921 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5590	Time 12.174s / 10iters, (1.217)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.217s / 10iters, (0.822)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007466)
Learning rate = [0.008733203337135646, 0.008733203337135646]	Loss = 0.80033058 (ave = 0.90883431)

2023-07-05 15:47:20,122 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5600	Time 12.200s / 10iters, (1.220)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.208s / 10iters, (0.821)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.084s / 10iters, (0.008369)
Learning rate = [0.008730919184620009, 0.008730919184620009]	Loss = 0.98586768 (ave = 0.93591684)

2023-07-05 15:47:32,284 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5610	Time 12.162s / 10iters, (1.216)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.785s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007549)
Learning rate = [0.008728634965705553, 0.008728634965705553]	Loss = 0.95770371 (ave = 0.91026443)

2023-07-05 15:47:44,471 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5620	Time 12.187s / 10iters, (1.219)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007452)
Learning rate = [0.00872635068037104, 0.00872635068037104]	Loss = 0.77567494 (ave = 0.91360797)

2023-07-05 15:47:56,745 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5630	Time 12.274s / 10iters, (1.227)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.082s / 10iters, (0.008161)
Learning rate = [0.008724066328595221, 0.008724066328595221]	Loss = 0.75844800 (ave = 0.86234334)

2023-07-05 15:48:09,031 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5640	Time 12.286s / 10iters, (1.229)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.083s / 10iters, (0.008276)
Learning rate = [0.008721781910356831, 0.008721781910356831]	Loss = 0.92176020 (ave = 0.92666060)

2023-07-05 15:48:21,221 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5650	Time 12.190s / 10iters, (1.219)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.194s / 10iters, (0.819)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007427)
Learning rate = [0.008719497425634593, 0.008719497425634593]	Loss = 1.00497222 (ave = 0.90060132)

2023-07-05 15:48:33,512 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5660	Time 12.291s / 10iters, (1.229)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.265s / 10iters, (0.827)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007527)
Learning rate = [0.008717212874407214, 0.008717212874407214]	Loss = 0.79650366 (ave = 0.98726768)

2023-07-05 15:48:45,767 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5670	Time 12.254s / 10iters, (1.225)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007464)
Learning rate = [0.008714928256653395, 0.008714928256653395]	Loss = 0.85056168 (ave = 0.90594075)

2023-07-05 15:48:57,996 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5680	Time 12.229s / 10iters, (1.223)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.076s / 10iters, (0.007556)
Learning rate = [0.00871264357235182, 0.00871264357235182]	Loss = 0.87620384 (ave = 0.89853134)

2023-07-05 15:49:10,315 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5690	Time 12.319s / 10iters, (1.232)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.894s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007490)
Learning rate = [0.008710358821481155, 0.008710358821481155]	Loss = 0.94984257 (ave = 0.92774406)

2023-07-05 15:49:22,619 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5700	Time 12.304s / 10iters, (1.230)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.923s / 10iters, (0.292)	Data load 0.075s / 10iters, (0.007458)
Learning rate = [0.008708074004020065, 0.008708074004020065]	Loss = 0.80450666 (ave = 0.86910313)

2023-07-05 15:49:34,876 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5710	Time 12.257s / 10iters, (1.226)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.204s / 10iters, (0.820)	Loss Time 2.889s / 10iters, (0.289)	Data load 0.074s / 10iters, (0.007400)
Learning rate = [0.00870578911994719, 0.00870578911994719]	Loss = 0.80486774 (ave = 0.95513096)

2023-07-05 15:49:47,298 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5720	Time 12.423s / 10iters, (1.242)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.327s / 10iters, (0.833)	Loss Time 2.924s / 10iters, (0.292)	Data load 0.075s / 10iters, (0.007464)
Learning rate = [0.008703504169241162, 0.008703504169241162]	Loss = 0.90261233 (ave = 0.91892306)

2023-07-05 15:49:59,722 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5730	Time 12.423s / 10iters, (1.242)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.314s / 10iters, (0.831)	Loss Time 2.925s / 10iters, (0.292)	Data load 0.074s / 10iters, (0.007413)
Learning rate = [0.0087012191518806, 0.0087012191518806]	Loss = 0.80347550 (ave = 0.88335850)

2023-07-05 15:50:11,950 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5740	Time 12.228s / 10iters, (1.223)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.232s / 10iters, (0.823)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007476)
Learning rate = [0.00869893406784411, 0.00869893406784411]	Loss = 0.74241096 (ave = 0.89782857)

2023-07-05 15:50:24,180 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5750	Time 12.231s / 10iters, (1.223)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007478)
Learning rate = [0.008696648917110287, 0.008696648917110287]	Loss = 0.83706504 (ave = 0.91781701)

2023-07-05 15:50:36,446 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5760	Time 12.266s / 10iters, (1.227)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.226s / 10iters, (0.823)	Loss Time 2.866s / 10iters, (0.287)	Data load 0.076s / 10iters, (0.007564)
Learning rate = [0.008694363699657703, 0.008694363699657703]	Loss = 0.82666582 (ave = 0.92191144)

2023-07-05 15:50:48,739 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5770	Time 12.293s / 10iters, (1.229)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.864s / 10iters, (0.286)	Data load 0.083s / 10iters, (0.008341)
Learning rate = [0.00869207841546493, 0.00869207841546493]	Loss = 0.92356479 (ave = 0.90137748)

2023-07-05 15:51:00,991 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5780	Time 12.252s / 10iters, (1.225)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007440)
Learning rate = [0.008689793064510523, 0.008689793064510523]	Loss = 0.94634628 (ave = 0.96826213)

2023-07-05 15:51:13,532 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5790	Time 12.540s / 10iters, (1.254)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.418s / 10iters, (0.842)	Loss Time 2.910s / 10iters, (0.291)	Data load 0.085s / 10iters, (0.008492)
Learning rate = [0.008687507646773016, 0.008687507646773016]	Loss = 0.87780225 (ave = 0.86252791)

2023-07-05 15:51:26,002 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5800	Time 12.470s / 10iters, (1.247)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.363s / 10iters, (0.836)	Loss Time 2.912s / 10iters, (0.291)	Data load 0.075s / 10iters, (0.007503)
Learning rate = [0.008685222162230938, 0.008685222162230938]	Loss = 0.96226275 (ave = 0.92668793)

2023-07-05 15:51:38,355 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5810	Time 12.353s / 10iters, (1.235)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.298s / 10iters, (0.830)	Loss Time 2.879s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007517)
Learning rate = [0.008682936610862804, 0.008682936610862804]	Loss = 1.03107953 (ave = 0.92508540)

2023-07-05 15:51:50,529 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5820	Time 12.174s / 10iters, (1.217)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.187s / 10iters, (0.819)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007550)
Learning rate = [0.00868065099264711, 0.00868065099264711]	Loss = 0.93903732 (ave = 0.86200516)

2023-07-05 15:52:02,847 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5830	Time 12.319s / 10iters, (1.232)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.077s / 10iters, (0.007662)
Learning rate = [0.008678365307562348, 0.008678365307562348]	Loss = 0.95756626 (ave = 0.97330593)

2023-07-05 15:52:14,961 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5840	Time 12.113s / 10iters, (1.211)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.195s / 10iters, (0.819)	Loss Time 2.743s / 10iters, (0.274)	Data load 0.075s / 10iters, (0.007476)
Learning rate = [0.00867607955558699, 0.00867607955558699]	Loss = 0.83352256 (ave = 0.89201511)

2023-07-05 15:52:27,125 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5850	Time 12.164s / 10iters, (1.216)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.738s / 10iters, (0.274)	Data load 0.081s / 10iters, (0.008106)
Learning rate = [0.008673793736699496, 0.008673793736699496]	Loss = 0.82831764 (ave = 0.96442331)

2023-07-05 15:52:39,326 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5860	Time 12.201s / 10iters, (1.220)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.755s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007461)
Learning rate = [0.008671507850878312, 0.008671507850878312]	Loss = 0.98700809 (ave = 0.91198792)

2023-07-05 15:52:51,559 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5870	Time 12.233s / 10iters, (1.223)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.086s / 10iters, (0.008606)
Learning rate = [0.008669221898101877, 0.008669221898101877]	Loss = 0.96528870 (ave = 0.90340806)

2023-07-05 15:53:03,669 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5880	Time 12.110s / 10iters, (1.211)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.163s / 10iters, (0.816)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007478)
Learning rate = [0.008666935878348608, 0.008666935878348608]	Loss = 0.90544772 (ave = 0.89861128)

2023-07-05 15:53:15,950 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5890	Time 12.281s / 10iters, (1.228)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.875s / 10iters, (0.288)	Data load 0.085s / 10iters, (0.008462)
Learning rate = [0.008664649791596911, 0.008664649791596911]	Loss = 0.85093451 (ave = 0.88797428)

2023-07-05 15:53:28,156 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5900	Time 12.205s / 10iters, (1.221)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.189s / 10iters, (0.819)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007596)
Learning rate = [0.008662363637825184, 0.008662363637825184]	Loss = 0.87981296 (ave = 0.88144692)

2023-07-05 15:53:40,368 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5910	Time 12.213s / 10iters, (1.221)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.852s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007486)
Learning rate = [0.008660077417011806, 0.008660077417011806]	Loss = 0.91584027 (ave = 0.92816581)

2023-07-05 15:53:52,621 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5920	Time 12.253s / 10iters, (1.225)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.833s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007475)
Learning rate = [0.008657791129135145, 0.008657791129135145]	Loss = 0.83500969 (ave = 0.89651682)

2023-07-05 15:54:04,643 INFO    [trainer_contrastive.py, 272] Train Epoch: 15	Train Iteration: 5930	Time 12.022s / 10iters, (1.202)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.145s / 10iters, (0.814)	Loss Time 2.720s / 10iters, (0.272)	Data load 0.076s / 10iters, (0.007633)
Learning rate = [0.008655504774173555, 0.008655504774173555]	Loss = 1.14791071 (ave = 0.90571076)

2023-07-05 15:54:19,617 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 5940	Time 14.850s / 10iters, (1.485)	Forward Time 1.184s / 10iters, (0.118)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.756s / 10iters, (0.276)	Data load 2.688s / 10iters, (0.268847)
Learning rate = [0.008653218352105377, 0.008653218352105377]	Loss = 0.87676674 (ave = 0.92129310)

2023-07-05 15:54:31,815 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 5950	Time 12.198s / 10iters, (1.220)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.188s / 10iters, (0.819)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007547)
Learning rate = [0.008650931862908941, 0.008650931862908941]	Loss = 0.86203736 (ave = 0.86697685)

2023-07-05 15:54:44,034 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 5960	Time 12.219s / 10iters, (1.222)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.195s / 10iters, (0.819)	Loss Time 2.848s / 10iters, (0.285)	Data load 0.077s / 10iters, (0.007747)
Learning rate = [0.008648645306562558, 0.008648645306562558]	Loss = 0.94641960 (ave = 0.97619960)

2023-07-05 15:54:56,300 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 5970	Time 12.265s / 10iters, (1.227)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.862s / 10iters, (0.286)	Data load 0.076s / 10iters, (0.007571)
Learning rate = [0.00864635868304453, 0.00864635868304453]	Loss = 0.87692153 (ave = 0.89933196)

2023-07-05 15:55:08,621 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 5980	Time 12.322s / 10iters, (1.232)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.077s / 10iters, (0.007708)
Learning rate = [0.008644071992333144, 0.008644071992333144]	Loss = 0.81941617 (ave = 0.84874615)

2023-07-05 15:55:20,831 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 5990	Time 12.210s / 10iters, (1.221)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.845s / 10iters, (0.284)	Data load 0.077s / 10iters, (0.007746)
Learning rate = [0.008641785234406675, 0.008641785234406675]	Loss = 0.91132200 (ave = 0.90683001)

2023-07-05 15:55:33,008 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6000	Time 12.176s / 10iters, (1.218)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.152s / 10iters, (0.815)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007565)
Learning rate = [0.008639498409243383, 0.008639498409243383]	Loss = 1.12778807 (ave = 0.89038903)

2023-07-05 15:55:37,874 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 15:56:01,621 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 15:56:24,656 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 15:56:47,891 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 15:57:11,058 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 15:57:33,926 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 15:57:56,413 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 15:58:02,169 INFO    [base.py, 84] Performance 0.657797955505786 -> 0.6719049180373877
2023-07-05 15:58:07,491 INFO    [trainer_contrastive.py, 391] Test Time 149.017s, (2.365)	Loss 0.17352847

2023-07-05 15:58:07,492 INFO    [base.py, 33] Result for seg
2023-07-05 15:58:07,492 INFO    [base.py, 49] Mean IOU: 0.6719049180373877

2023-07-05 15:58:07,493 INFO    [base.py, 50] Pixel ACC: 0.9455920686458482

2023-07-05 15:58:19,693 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6010	Time 166.685s / 10iters, (16.669)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.761s / 10iters, (0.276)	Data load 154.582s / 10iters, (15.458154)
Learning rate = [0.008637211516821517, 0.008637211516821517]	Loss = 0.93348837 (ave = 0.89392810)

2023-07-05 15:58:31,818 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6020	Time 12.125s / 10iters, (1.213)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.091s / 10iters, (0.009111)
Learning rate = [0.008634924557119308, 0.008634924557119308]	Loss = 0.91788530 (ave = 0.90352291)

2023-07-05 15:58:43,956 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6030	Time 12.138s / 10iters, (1.214)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.194s / 10iters, (0.819)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.082s / 10iters, (0.008236)
Learning rate = [0.008632637530114977, 0.008632637530114977]	Loss = 0.83347797 (ave = 0.89087674)

2023-07-05 15:58:56,099 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6040	Time 12.143s / 10iters, (1.214)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.175s / 10iters, (0.817)	Loss Time 2.789s / 10iters, (0.279)	Data load 0.087s / 10iters, (0.008710)
Learning rate = [0.008630350435786732, 0.008630350435786732]	Loss = 0.80630755 (ave = 0.89767280)

2023-07-05 15:59:08,158 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6050	Time 12.059s / 10iters, (1.206)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.148s / 10iters, (0.815)	Loss Time 2.750s / 10iters, (0.275)	Data load 0.076s / 10iters, (0.007593)
Learning rate = [0.008628063274112766, 0.008628063274112766]	Loss = 0.84081113 (ave = 0.84604027)

2023-07-05 15:59:20,284 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6060	Time 12.126s / 10iters, (1.213)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.169s / 10iters, (0.817)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.089s / 10iters, (0.008855)
Learning rate = [0.008625776045071257, 0.008625776045071257]	Loss = 0.84802306 (ave = 0.84787503)

2023-07-05 15:59:32,301 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6070	Time 12.017s / 10iters, (1.202)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.090s / 10iters, (0.809)	Loss Time 2.758s / 10iters, (0.276)	Data load 0.081s / 10iters, (0.008121)
Learning rate = [0.008623488748640376, 0.008623488748640376]	Loss = 0.82826585 (ave = 0.85379992)

2023-07-05 15:59:44,360 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6080	Time 12.059s / 10iters, (1.206)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.134s / 10iters, (0.813)	Loss Time 2.755s / 10iters, (0.275)	Data load 0.079s / 10iters, (0.007874)
Learning rate = [0.008621201384798272, 0.008621201384798272]	Loss = 0.80793029 (ave = 0.87281475)

2023-07-05 15:59:56,545 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6090	Time 12.185s / 10iters, (1.219)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.189s / 10iters, (0.819)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007436)
Learning rate = [0.008618913953523084, 0.008618913953523084]	Loss = 0.70523548 (ave = 0.89233075)

2023-07-05 16:00:08,707 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6100	Time 12.162s / 10iters, (1.216)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.192s / 10iters, (0.819)	Loss Time 2.797s / 10iters, (0.280)	Data load 0.077s / 10iters, (0.007715)
Learning rate = [0.00861662645479294, 0.00861662645479294]	Loss = 0.81018400 (ave = 0.89861145)

2023-07-05 16:00:20,921 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6110	Time 12.214s / 10iters, (1.221)	Forward Time 1.083s / 10iters, (0.108)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.094s / 10iters, (0.009445)
Learning rate = [0.008614338888585952, 0.008614338888585952]	Loss = 0.88388711 (ave = 0.89475091)

2023-07-05 16:00:33,037 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6120	Time 12.116s / 10iters, (1.212)	Forward Time 1.083s / 10iters, (0.108)	Backward Time 8.153s / 10iters, (0.815)	Loss Time 2.805s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007394)
Learning rate = [0.00861205125488022, 0.00861205125488022]	Loss = 0.81557107 (ave = 0.87024825)

2023-07-05 16:00:45,248 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6130	Time 12.211s / 10iters, (1.221)	Forward Time 1.083s / 10iters, (0.108)	Backward Time 8.235s / 10iters, (0.824)	Loss Time 2.816s / 10iters, (0.282)	Data load 0.077s / 10iters, (0.007720)
Learning rate = [0.008609763553653827, 0.008609763553653827]	Loss = 0.94429690 (ave = 0.88008484)

2023-07-05 16:00:57,371 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6140	Time 12.124s / 10iters, (1.212)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.153s / 10iters, (0.815)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007387)
Learning rate = [0.008607475784884841, 0.008607475784884841]	Loss = 0.74292642 (ave = 0.84573930)

2023-07-05 16:01:09,562 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6150	Time 12.191s / 10iters, (1.219)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.159s / 10iters, (0.816)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.083s / 10iters, (0.008307)
Learning rate = [0.008605187948551328, 0.008605187948551328]	Loss = 0.89316005 (ave = 0.89607540)

2023-07-05 16:01:21,745 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6160	Time 12.183s / 10iters, (1.218)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.174s / 10iters, (0.817)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.087s / 10iters, (0.008676)
Learning rate = [0.008602900044631328, 0.008602900044631328]	Loss = 0.83500588 (ave = 0.87411875)

2023-07-05 16:01:33,867 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6170	Time 12.122s / 10iters, (1.212)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.142s / 10iters, (0.814)	Loss Time 2.805s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007604)
Learning rate = [0.00860061207310287, 0.00860061207310287]	Loss = 0.85293519 (ave = 0.86873928)

2023-07-05 16:01:46,127 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6180	Time 12.260s / 10iters, (1.226)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.855s / 10iters, (0.285)	Data load 0.082s / 10iters, (0.008190)
Learning rate = [0.008598324033943974, 0.008598324033943974]	Loss = 0.94164860 (ave = 0.90280032)

2023-07-05 16:01:58,395 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6190	Time 12.267s / 10iters, (1.227)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.079s / 10iters, (0.007946)
Learning rate = [0.008596035927132643, 0.008596035927132643]	Loss = 0.92834985 (ave = 0.92694696)

2023-07-05 16:02:10,679 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6200	Time 12.284s / 10iters, (1.228)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.245s / 10iters, (0.824)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.080s / 10iters, (0.007979)
Learning rate = [0.008593747752646867, 0.008593747752646867]	Loss = 0.78198212 (ave = 0.89232348)

2023-07-05 16:02:22,939 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6210	Time 12.260s / 10iters, (1.226)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007485)
Learning rate = [0.00859145951046462, 0.00859145951046462]	Loss = 0.82806313 (ave = 0.87674456)

2023-07-05 16:02:35,232 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6220	Time 12.293s / 10iters, (1.229)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.076s / 10iters, (0.007593)
Learning rate = [0.008589171200563865, 0.008589171200563865]	Loss = 0.81782722 (ave = 0.85118217)

2023-07-05 16:02:47,525 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6230	Time 12.294s / 10iters, (1.229)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.092s / 10iters, (0.009173)
Learning rate = [0.008586882822922554, 0.008586882822922554]	Loss = 0.86404091 (ave = 0.90557168)

2023-07-05 16:02:59,833 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6240	Time 12.308s / 10iters, (1.231)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.884s / 10iters, (0.288)	Data load 0.078s / 10iters, (0.007820)
Learning rate = [0.008584594377518618, 0.008584594377518618]	Loss = 0.86033875 (ave = 0.94110633)

2023-07-05 16:03:12,119 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6250	Time 12.286s / 10iters, (1.229)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.085s / 10iters, (0.008491)
Learning rate = [0.00858230586432998, 0.00858230586432998]	Loss = 0.83250278 (ave = 0.92245667)

2023-07-05 16:03:24,424 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6260	Time 12.304s / 10iters, (1.230)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.868s / 10iters, (0.287)	Data load 0.084s / 10iters, (0.008448)
Learning rate = [0.008580017283334547, 0.008580017283334547]	Loss = 0.75228357 (ave = 0.85442980)

2023-07-05 16:03:36,719 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6270	Time 12.295s / 10iters, (1.230)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.080s / 10iters, (0.007973)
Learning rate = [0.008577728634510213, 0.008577728634510213]	Loss = 0.74888039 (ave = 0.88469578)

2023-07-05 16:03:49,043 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6280	Time 12.324s / 10iters, (1.232)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.086s / 10iters, (0.008629)
Learning rate = [0.00857543991783486, 0.00857543991783486]	Loss = 0.82631159 (ave = 0.88261907)

2023-07-05 16:04:01,429 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6290	Time 12.386s / 10iters, (1.239)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.894s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007526)
Learning rate = [0.008573151133286352, 0.008573151133286352]	Loss = 0.91608715 (ave = 0.90653038)

2023-07-05 16:04:13,805 INFO    [trainer_contrastive.py, 272] Train Epoch: 16	Train Iteration: 6300	Time 12.376s / 10iters, (1.238)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.379s / 10iters, (0.838)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.078s / 10iters, (0.007752)
Learning rate = [0.00857086228084254, 0.00857086228084254]	Loss = 0.91323990 (ave = 0.89088161)

2023-07-05 16:04:29,008 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6310	Time 15.046s / 10iters, (1.505)	Forward Time 1.400s / 10iters, (0.140)	Backward Time 8.470s / 10iters, (0.847)	Loss Time 2.662s / 10iters, (0.266)	Data load 2.514s / 10iters, (0.251398)
Learning rate = [0.008568573360481264, 0.008568573360481264]	Loss = 0.92382491 (ave = 0.93369006)

2023-07-05 16:04:41,349 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6320	Time 12.341s / 10iters, (1.234)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.372s / 10iters, (0.837)	Loss Time 2.775s / 10iters, (0.278)	Data load 0.076s / 10iters, (0.007627)
Learning rate = [0.008566284372180351, 0.008566284372180351]	Loss = 0.94441521 (ave = 0.86216580)

2023-07-05 16:04:53,808 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6330	Time 12.459s / 10iters, (1.246)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.419s / 10iters, (0.842)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007517)
Learning rate = [0.00856399531591761, 0.00856399531591761]	Loss = 0.84805918 (ave = 0.87785969)

2023-07-05 16:05:06,224 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6340	Time 12.416s / 10iters, (1.242)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.388s / 10iters, (0.839)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.082s / 10iters, (0.008182)
Learning rate = [0.00856170619167084, 0.00856170619167084]	Loss = 0.84691703 (ave = 0.85795819)

2023-07-05 16:05:18,518 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6350	Time 12.294s / 10iters, (1.229)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.081s / 10iters, (0.008094)
Learning rate = [0.008559416999417821, 0.008559416999417821]	Loss = 0.84300613 (ave = 0.86851634)

2023-07-05 16:05:30,965 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6360	Time 12.448s / 10iters, (1.245)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.378s / 10iters, (0.838)	Loss Time 2.890s / 10iters, (0.289)	Data load 0.077s / 10iters, (0.007691)
Learning rate = [0.008557127739136325, 0.008557127739136325]	Loss = 0.80089861 (ave = 0.91973172)

2023-07-05 16:05:43,255 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6370	Time 12.290s / 10iters, (1.229)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.084s / 10iters, (0.008362)
Learning rate = [0.008554838410804106, 0.008554838410804106]	Loss = 0.88233185 (ave = 0.89994560)

2023-07-05 16:05:55,606 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6380	Time 12.350s / 10iters, (1.235)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.877s / 10iters, (0.288)	Data load 0.084s / 10iters, (0.008384)
Learning rate = [0.008552549014398907, 0.008552549014398907]	Loss = 0.85119683 (ave = 0.89002128)

2023-07-05 16:06:07,908 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6390	Time 12.303s / 10iters, (1.230)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.225s / 10iters, (0.823)	Loss Time 2.889s / 10iters, (0.289)	Data load 0.095s / 10iters, (0.009458)
Learning rate = [0.008550259549898456, 0.008550259549898456]	Loss = 0.88970423 (ave = 0.87689036)

2023-07-05 16:06:20,190 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6400	Time 12.281s / 10iters, (1.228)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007545)
Learning rate = [0.008547970017280467, 0.008547970017280467]	Loss = 0.85849500 (ave = 0.87599471)

2023-07-05 16:06:32,464 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6410	Time 12.274s / 10iters, (1.227)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.816s / 10iters, (0.282)	Data load 0.083s / 10iters, (0.008297)
Learning rate = [0.008545680416522636, 0.008545680416522636]	Loss = 0.94366920 (ave = 0.91947933)

2023-07-05 16:06:44,887 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6420	Time 12.422s / 10iters, (1.242)	Forward Time 1.140s / 10iters, (0.114)	Backward Time 8.348s / 10iters, (0.835)	Loss Time 2.838s / 10iters, (0.284)	Data load 0.096s / 10iters, (0.009608)
Learning rate = [0.008543390747602655, 0.008543390747602655]	Loss = 0.69555253 (ave = 0.88205121)

2023-07-05 16:06:57,239 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6430	Time 12.352s / 10iters, (1.235)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007535)
Learning rate = [0.008541101010498193, 0.008541101010498193]	Loss = 0.78260899 (ave = 0.94826501)

2023-07-05 16:07:09,565 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6440	Time 12.326s / 10iters, (1.233)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.874s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007504)
Learning rate = [0.008538811205186908, 0.008538811205186908]	Loss = 0.87477410 (ave = 0.91604345)

2023-07-05 16:07:21,885 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6450	Time 12.320s / 10iters, (1.232)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.076s / 10iters, (0.007580)
Learning rate = [0.008536521331646445, 0.008536521331646445]	Loss = 0.88186026 (ave = 0.98621690)

2023-07-05 16:07:34,375 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6460	Time 12.490s / 10iters, (1.249)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.414s / 10iters, (0.841)	Loss Time 2.869s / 10iters, (0.287)	Data load 0.082s / 10iters, (0.008214)
Learning rate = [0.008534231389854431, 0.008534231389854431]	Loss = 0.90537167 (ave = 0.86508821)

2023-07-05 16:07:46,690 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6470	Time 12.315s / 10iters, (1.231)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.314s / 10iters, (0.831)	Loss Time 2.838s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007382)
Learning rate = [0.008531941379788487, 0.008531941379788487]	Loss = 0.81130397 (ave = 0.89808602)

2023-07-05 16:07:58,985 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6480	Time 12.295s / 10iters, (1.230)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007547)
Learning rate = [0.008529651301426213, 0.008529651301426213]	Loss = 0.83066779 (ave = 0.86553097)

2023-07-05 16:08:11,521 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6490	Time 12.536s / 10iters, (1.254)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.457s / 10iters, (0.846)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007400)
Learning rate = [0.008527361154745196, 0.008527361154745196]	Loss = 0.89467484 (ave = 0.94139987)

2023-07-05 16:08:23,836 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6500	Time 12.315s / 10iters, (1.232)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.255s / 10iters, (0.826)	Loss Time 2.857s / 10iters, (0.286)	Data load 0.102s / 10iters, (0.010201)
Learning rate = [0.00852507093972301, 0.00852507093972301]	Loss = 1.15973854 (ave = 0.92547878)

2023-07-05 16:08:36,063 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6510	Time 12.227s / 10iters, (1.223)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.820s / 10iters, (0.282)	Data load 0.109s / 10iters, (0.010862)
Learning rate = [0.008522780656337218, 0.008522780656337218]	Loss = 0.80350578 (ave = 0.85780351)

2023-07-05 16:08:48,478 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6520	Time 12.414s / 10iters, (1.241)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.336s / 10iters, (0.834)	Loss Time 2.878s / 10iters, (0.288)	Data load 0.076s / 10iters, (0.007613)
Learning rate = [0.008520490304565363, 0.008520490304565363]	Loss = 0.80818868 (ave = 0.86647304)

2023-07-05 16:09:00,719 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6530	Time 12.241s / 10iters, (1.224)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.235s / 10iters, (0.824)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.080s / 10iters, (0.007958)
Learning rate = [0.008518199884384976, 0.008518199884384976]	Loss = 0.84161508 (ave = 0.92572156)

2023-07-05 16:09:13,034 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6540	Time 12.315s / 10iters, (1.232)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.093s / 10iters, (0.009287)
Learning rate = [0.008515909395773577, 0.008515909395773577]	Loss = 0.85817200 (ave = 0.86281834)

2023-07-05 16:09:25,263 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6550	Time 12.229s / 10iters, (1.223)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.227s / 10iters, (0.823)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.083s / 10iters, (0.008319)
Learning rate = [0.008513618838708669, 0.008513618838708669]	Loss = 0.81396878 (ave = 0.88287009)

2023-07-05 16:09:37,561 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6560	Time 12.298s / 10iters, (1.230)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.862s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007434)
Learning rate = [0.00851132821316774, 0.00851132821316774]	Loss = 0.89909446 (ave = 0.90416285)

2023-07-05 16:09:49,869 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6570	Time 12.308s / 10iters, (1.231)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.230s / 10iters, (0.823)	Loss Time 2.878s / 10iters, (0.288)	Data load 0.092s / 10iters, (0.009248)
Learning rate = [0.008509037519128267, 0.008509037519128267]	Loss = 0.98755854 (ave = 0.89109842)

2023-07-05 16:10:02,338 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6580	Time 12.469s / 10iters, (1.247)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.364s / 10iters, (0.836)	Loss Time 2.920s / 10iters, (0.292)	Data load 0.081s / 10iters, (0.008074)
Learning rate = [0.008506746756567712, 0.008506746756567712]	Loss = 0.86324358 (ave = 0.92579941)

2023-07-05 16:10:14,799 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6590	Time 12.461s / 10iters, (1.246)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.930s / 10iters, (0.293)	Data load 0.086s / 10iters, (0.008626)
Learning rate = [0.00850445592546352, 0.00850445592546352]	Loss = 0.89712512 (ave = 0.86868352)

2023-07-05 16:10:27,192 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6600	Time 12.394s / 10iters, (1.239)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.292s / 10iters, (0.829)	Loss Time 2.912s / 10iters, (0.291)	Data load 0.084s / 10iters, (0.008393)
Learning rate = [0.008502165025793125, 0.008502165025793125]	Loss = 0.83516169 (ave = 0.86455626)

2023-07-05 16:10:39,614 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6610	Time 12.421s / 10iters, (1.242)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.931s / 10iters, (0.293)	Data load 0.074s / 10iters, (0.007416)
Learning rate = [0.008499874057533944, 0.008499874057533944]	Loss = 1.29735684 (ave = 0.91095599)

2023-07-05 16:10:51,927 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6620	Time 12.313s / 10iters, (1.231)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.232s / 10iters, (0.823)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.088s / 10iters, (0.008829)
Learning rate = [0.008497583020663384, 0.008497583020663384]	Loss = 0.76772094 (ave = 0.86476118)

2023-07-05 16:11:04,143 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6630	Time 12.217s / 10iters, (1.222)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.201s / 10iters, (0.820)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007408)
Learning rate = [0.008495291915158833, 0.008495291915158833]	Loss = 1.05137444 (ave = 0.87349278)

2023-07-05 16:11:16,586 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6640	Time 12.442s / 10iters, (1.244)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.371s / 10iters, (0.837)	Loss Time 2.893s / 10iters, (0.289)	Data load 0.074s / 10iters, (0.007418)
Learning rate = [0.008493000740997667, 0.008493000740997667]	Loss = 0.88169998 (ave = 0.91675482)

2023-07-05 16:11:28,929 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6650	Time 12.343s / 10iters, (1.234)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.903s / 10iters, (0.290)	Data load 0.082s / 10iters, (0.008232)
Learning rate = [0.008490709498157249, 0.008490709498157249]	Loss = 0.83310628 (ave = 0.89916791)

2023-07-05 16:11:41,164 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6660	Time 12.235s / 10iters, (1.224)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.195s / 10iters, (0.820)	Loss Time 2.877s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007378)
Learning rate = [0.008488418186614928, 0.008488418186614928]	Loss = 0.84534174 (ave = 0.88098654)

2023-07-05 16:11:53,118 INFO    [trainer_contrastive.py, 272] Train Epoch: 17	Train Iteration: 6670	Time 11.954s / 10iters, (1.195)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.057s / 10iters, (0.806)	Loss Time 2.734s / 10iters, (0.273)	Data load 0.074s / 10iters, (0.007374)
Learning rate = [0.008486126806348035, 0.008486126806348035]	Loss = 0.90970802 (ave = 0.84674098)

2023-07-05 16:12:08,248 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6680	Time 14.959s / 10iters, (1.496)	Forward Time 1.150s / 10iters, (0.115)	Backward Time 8.120s / 10iters, (0.812)	Loss Time 2.749s / 10iters, (0.275)	Data load 2.940s / 10iters, (0.294004)
Learning rate = [0.008483835357333889, 0.008483835357333889]	Loss = 0.76074880 (ave = 0.89102575)

2023-07-05 16:12:20,570 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6690	Time 12.322s / 10iters, (1.232)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.358s / 10iters, (0.836)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.084s / 10iters, (0.008361)
Learning rate = [0.008481543839549795, 0.008481543839549795]	Loss = 0.98712111 (ave = 0.84986726)

2023-07-05 16:12:32,872 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6700	Time 12.302s / 10iters, (1.230)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.764s / 10iters, (0.276)	Data load 0.110s / 10iters, (0.011027)
Learning rate = [0.008479252252973041, 0.008479252252973041]	Loss = 1.11708570 (ave = 0.91475138)

2023-07-05 16:12:45,221 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6710	Time 12.349s / 10iters, (1.235)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.373s / 10iters, (0.837)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007466)
Learning rate = [0.008476960597580909, 0.008476960597580909]	Loss = 0.79654872 (ave = 0.84585426)

2023-07-05 16:12:57,550 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6720	Time 12.329s / 10iters, (1.233)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.334s / 10iters, (0.833)	Loss Time 2.797s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007428)
Learning rate = [0.008474668873350657, 0.008474668873350657]	Loss = 0.80871701 (ave = 0.86996697)

2023-07-05 16:13:09,821 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6730	Time 12.271s / 10iters, (1.227)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.324s / 10iters, (0.832)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.090s / 10iters, (0.009003)
Learning rate = [0.00847237708025953, 0.00847237708025953]	Loss = 0.82553947 (ave = 0.85370454)

2023-07-05 16:13:22,217 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6740	Time 12.396s / 10iters, (1.240)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.370s / 10iters, (0.837)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.085s / 10iters, (0.008481)
Learning rate = [0.008470085218284766, 0.008470085218284766]	Loss = 0.80858523 (ave = 0.88146354)

2023-07-05 16:13:34,530 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6750	Time 12.313s / 10iters, (1.231)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.815s / 10iters, (0.282)	Data load 0.084s / 10iters, (0.008435)
Learning rate = [0.00846779328740358, 0.00846779328740358]	Loss = 0.87916577 (ave = 0.93159301)

2023-07-05 16:13:46,884 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6760	Time 12.354s / 10iters, (1.235)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.108s / 10iters, (0.010799)
Learning rate = [0.008465501287593177, 0.008465501287593177]	Loss = 1.01406550 (ave = 0.91920599)

2023-07-05 16:13:59,170 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6770	Time 12.285s / 10iters, (1.229)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.081s / 10iters, (0.008134)
Learning rate = [0.008463209218830748, 0.008463209218830748]	Loss = 0.84192419 (ave = 0.88484163)

2023-07-05 16:14:11,527 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6780	Time 12.358s / 10iters, (1.236)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.862s / 10iters, (0.286)	Data load 0.076s / 10iters, (0.007640)
Learning rate = [0.008460917081093467, 0.008460917081093467]	Loss = 0.88127685 (ave = 0.90241001)

2023-07-05 16:14:23,969 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6790	Time 12.442s / 10iters, (1.244)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.404s / 10iters, (0.840)	Loss Time 2.866s / 10iters, (0.287)	Data load 0.076s / 10iters, (0.007603)
Learning rate = [0.008458624874358497, 0.008458624874358497]	Loss = 0.88052285 (ave = 1.00641980)

2023-07-05 16:14:36,549 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6800	Time 12.580s / 10iters, (1.258)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.507s / 10iters, (0.851)	Loss Time 2.885s / 10iters, (0.288)	Data load 0.080s / 10iters, (0.007974)
Learning rate = [0.008456332598602982, 0.008456332598602982]	Loss = 1.50377727 (ave = 1.04881955)

2023-07-05 16:14:48,902 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6810	Time 12.354s / 10iters, (1.235)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.305s / 10iters, (0.831)	Loss Time 2.864s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007443)
Learning rate = [0.008454040253804055, 0.008454040253804055]	Loss = 0.99261969 (ave = 0.95236631)

2023-07-05 16:15:01,236 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6820	Time 12.334s / 10iters, (1.233)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.298s / 10iters, (0.830)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007443)
Learning rate = [0.008451747839938835, 0.008451747839938835]	Loss = 0.85288823 (ave = 0.89271526)

2023-07-05 16:15:13,724 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6830	Time 12.488s / 10iters, (1.249)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.382s / 10iters, (0.838)	Loss Time 2.892s / 10iters, (0.289)	Data load 0.107s / 10iters, (0.010662)
Learning rate = [0.008449455356984423, 0.008449455356984423]	Loss = 0.94721144 (ave = 0.89291131)

2023-07-05 16:15:26,219 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6840	Time 12.495s / 10iters, (1.249)	Forward Time 1.143s / 10iters, (0.114)	Backward Time 8.415s / 10iters, (0.842)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.106s / 10iters, (0.010605)
Learning rate = [0.008447162804917908, 0.008447162804917908]	Loss = 1.11824703 (ave = 0.90122614)

2023-07-05 16:15:38,604 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6850	Time 12.385s / 10iters, (1.238)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.353s / 10iters, (0.835)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007481)
Learning rate = [0.008444870183716367, 0.008444870183716367]	Loss = 0.88790876 (ave = 0.86861601)

2023-07-05 16:15:50,963 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6860	Time 12.359s / 10iters, (1.236)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.332s / 10iters, (0.833)	Loss Time 2.850s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007410)
Learning rate = [0.008442577493356855, 0.008442577493356855]	Loss = 0.81131977 (ave = 0.98176394)

2023-07-05 16:16:03,247 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6870	Time 12.285s / 10iters, (1.228)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.228s / 10iters, (0.823)	Loss Time 2.857s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007434)
Learning rate = [0.00844028473381642, 0.00844028473381642]	Loss = 0.94171649 (ave = 0.90294890)

2023-07-05 16:16:15,734 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6880	Time 12.486s / 10iters, (1.249)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.414s / 10iters, (0.841)	Loss Time 2.848s / 10iters, (0.285)	Data load 0.110s / 10iters, (0.010957)
Learning rate = [0.008437991905072093, 0.008437991905072093]	Loss = 1.14980304 (ave = 0.93202687)

2023-07-05 16:16:28,109 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6890	Time 12.375s / 10iters, (1.238)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.391s / 10iters, (0.839)	Loss Time 2.765s / 10iters, (0.277)	Data load 0.094s / 10iters, (0.009386)
Learning rate = [0.008435699007100889, 0.008435699007100889]	Loss = 0.81012607 (ave = 0.87752391)

2023-07-05 16:16:40,445 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6900	Time 12.336s / 10iters, (1.234)	Forward Time 1.136s / 10iters, (0.114)	Backward Time 8.364s / 10iters, (0.836)	Loss Time 2.729s / 10iters, (0.273)	Data load 0.107s / 10iters, (0.010711)
Learning rate = [0.00843340603987981, 0.00843340603987981]	Loss = 0.82942450 (ave = 0.83993723)

2023-07-05 16:16:52,794 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6910	Time 12.349s / 10iters, (1.235)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.403s / 10iters, (0.840)	Loss Time 2.747s / 10iters, (0.275)	Data load 0.079s / 10iters, (0.007907)
Learning rate = [0.008431113003385839, 0.008431113003385839]	Loss = 0.93691289 (ave = 0.84798476)

2023-07-05 16:17:05,362 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6920	Time 12.568s / 10iters, (1.257)	Forward Time 1.139s / 10iters, (0.114)	Backward Time 8.540s / 10iters, (0.854)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.102s / 10iters, (0.010166)
Learning rate = [0.008428819897595955, 0.008428819897595955]	Loss = 0.88523346 (ave = 0.90072083)

2023-07-05 16:17:17,731 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6930	Time 12.369s / 10iters, (1.237)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.362s / 10iters, (0.836)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.096s / 10iters, (0.009591)
Learning rate = [0.00842652672248711, 0.00842652672248711]	Loss = 0.82851899 (ave = 0.92107370)

2023-07-05 16:17:30,114 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6940	Time 12.383s / 10iters, (1.238)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.413s / 10iters, (0.841)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.081s / 10iters, (0.008090)
Learning rate = [0.00842423347803625, 0.00842423347803625]	Loss = 0.81346142 (ave = 0.95783116)

2023-07-05 16:17:42,474 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6950	Time 12.360s / 10iters, (1.236)	Forward Time 1.139s / 10iters, (0.114)	Backward Time 8.362s / 10iters, (0.836)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.092s / 10iters, (0.009161)
Learning rate = [0.0084219401642203, 0.0084219401642203]	Loss = 0.90766257 (ave = 0.89519265)

2023-07-05 16:17:54,801 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6960	Time 12.326s / 10iters, (1.233)	Forward Time 1.137s / 10iters, (0.114)	Backward Time 8.351s / 10iters, (0.835)	Loss Time 2.747s / 10iters, (0.275)	Data load 0.090s / 10iters, (0.009048)
Learning rate = [0.008419646781016176, 0.008419646781016176]	Loss = 0.77903533 (ave = 0.85598989)

2023-07-05 16:18:07,283 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6970	Time 12.482s / 10iters, (1.248)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.441s / 10iters, (0.844)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.103s / 10iters, (0.010302)
Learning rate = [0.00841735332840078, 0.00841735332840078]	Loss = 0.87746811 (ave = 0.86081969)

2023-07-05 16:18:19,718 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6980	Time 12.435s / 10iters, (1.243)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.442s / 10iters, (0.844)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.079s / 10iters, (0.007858)
Learning rate = [0.00841505980635099, 0.00841505980635099]	Loss = 0.87023836 (ave = 0.89310866)

2023-07-05 16:18:32,001 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 6990	Time 12.283s / 10iters, (1.228)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.322s / 10iters, (0.832)	Loss Time 2.742s / 10iters, (0.274)	Data load 0.097s / 10iters, (0.009712)
Learning rate = [0.00841276621484368, 0.00841276621484368]	Loss = 0.87799615 (ave = 0.82450216)

2023-07-05 16:18:44,341 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 7000	Time 12.340s / 10iters, (1.234)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.345s / 10iters, (0.835)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.090s / 10iters, (0.009019)
Learning rate = [0.008410472553855701, 0.008410472553855701]	Loss = 0.85190094 (ave = 0.86811919)

2023-07-05 16:18:47,404 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 16:19:11,158 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 16:19:34,300 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 16:19:57,477 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 16:20:20,364 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 16:20:42,975 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 16:21:05,224 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 16:21:10,942 INFO    [base.py, 84] Performance 0.6719049180373877 -> 0.6875013947062176
2023-07-05 16:21:16,428 INFO    [trainer_contrastive.py, 391] Test Time 146.436s, (2.324)	Loss 0.16683989

2023-07-05 16:21:16,429 INFO    [base.py, 33] Result for seg
2023-07-05 16:21:16,429 INFO    [base.py, 49] Mean IOU: 0.6875013947062176

2023-07-05 16:21:16,430 INFO    [base.py, 50] Pixel ACC: 0.948058083265102

2023-07-05 16:21:28,619 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 7010	Time 164.278s / 10iters, (16.428)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.238s / 10iters, (0.824)	Loss Time 2.738s / 10iters, (0.274)	Data load 152.171s / 10iters, (15.217145)
Learning rate = [0.008408178823363898, 0.008408178823363898]	Loss = 0.77814555 (ave = 0.84903638)

2023-07-05 16:21:40,734 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 7020	Time 12.114s / 10iters, (1.211)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.281s / 10iters, (0.828)	Loss Time 2.654s / 10iters, (0.265)	Data load 0.074s / 10iters, (0.007420)
Learning rate = [0.008405885023345092, 0.008405885023345092]	Loss = 0.80039120 (ave = 0.86951248)

2023-07-05 16:21:52,705 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 7030	Time 11.971s / 10iters, (1.197)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.132s / 10iters, (0.813)	Loss Time 2.642s / 10iters, (0.264)	Data load 0.110s / 10iters, (0.011048)
Learning rate = [0.008403591153776098, 0.008403591153776098]	Loss = 0.90731877 (ave = 0.84578220)

2023-07-05 16:22:04,561 INFO    [trainer_contrastive.py, 272] Train Epoch: 18	Train Iteration: 7040	Time 11.856s / 10iters, (1.186)	Forward Time 1.074s / 10iters, (0.107)	Backward Time 8.061s / 10iters, (0.806)	Loss Time 2.647s / 10iters, (0.265)	Data load 0.074s / 10iters, (0.007400)
Learning rate = [0.008401297214633709, 0.008401297214633709]	Loss = 0.83845842 (ave = 0.92277096)

2023-07-05 16:22:19,418 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7050	Time 14.648s / 10iters, (1.465)	Forward Time 1.159s / 10iters, (0.116)	Backward Time 8.134s / 10iters, (0.813)	Loss Time 2.741s / 10iters, (0.274)	Data load 2.615s / 10iters, (0.261501)
Learning rate = [0.008399003205894704, 0.008399003205894704]	Loss = 0.82813609 (ave = 0.83197580)

2023-07-05 16:22:31,540 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7060	Time 12.122s / 10iters, (1.212)	Forward Time 1.149s / 10iters, (0.115)	Backward Time 8.205s / 10iters, (0.821)	Loss Time 2.680s / 10iters, (0.268)	Data load 0.088s / 10iters, (0.008802)
Learning rate = [0.008396709127535856, 0.008396709127535856]	Loss = 0.88814658 (ave = 0.83759483)

2023-07-05 16:22:43,759 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7070	Time 12.219s / 10iters, (1.222)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.081s / 10iters, (0.008127)
Learning rate = [0.008394414979533908, 0.008394414979533908]	Loss = 0.94579905 (ave = 0.83682824)

2023-07-05 16:22:55,806 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7080	Time 12.047s / 10iters, (1.205)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.160s / 10iters, (0.816)	Loss Time 2.677s / 10iters, (0.268)	Data load 0.086s / 10iters, (0.008589)
Learning rate = [0.008392120761865603, 0.008392120761865603]	Loss = 0.79440784 (ave = 0.82770143)

2023-07-05 16:23:07,880 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7090	Time 12.074s / 10iters, (1.207)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.182s / 10iters, (0.818)	Loss Time 2.697s / 10iters, (0.270)	Data load 0.088s / 10iters, (0.008794)
Learning rate = [0.00838982647450766, 0.00838982647450766]	Loss = 0.83557057 (ave = 0.85991548)

2023-07-05 16:23:20,022 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7100	Time 12.142s / 10iters, (1.214)	Forward Time 1.085s / 10iters, (0.109)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007444)
Learning rate = [0.008387532117436787, 0.008387532117436787]	Loss = 0.76607287 (ave = 0.88800107)

2023-07-05 16:23:32,173 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7110	Time 12.150s / 10iters, (1.215)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.209s / 10iters, (0.821)	Loss Time 2.769s / 10iters, (0.277)	Data load 0.077s / 10iters, (0.007694)
Learning rate = [0.008385237690629675, 0.008385237690629675]	Loss = 0.73430848 (ave = 0.85294452)

2023-07-05 16:23:44,315 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7120	Time 12.142s / 10iters, (1.214)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.726s / 10iters, (0.273)	Data load 0.080s / 10iters, (0.007982)
Learning rate = [0.008382943194063004, 0.008382943194063004]	Loss = 0.95531714 (ave = 0.94023873)

2023-07-05 16:23:56,743 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7130	Time 12.428s / 10iters, (1.243)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.422s / 10iters, (0.842)	Loss Time 2.816s / 10iters, (0.282)	Data load 0.078s / 10iters, (0.007762)
Learning rate = [0.008380648627713433, 0.008380648627713433]	Loss = 0.79292929 (ave = 1.06158341)

2023-07-05 16:24:09,063 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7140	Time 12.320s / 10iters, (1.232)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.077s / 10iters, (0.007748)
Learning rate = [0.00837835399155761, 0.00837835399155761]	Loss = 0.86409628 (ave = 0.99192740)

2023-07-05 16:24:21,431 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7150	Time 12.368s / 10iters, (1.237)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.898s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007541)
Learning rate = [0.008376059285572168, 0.008376059285572168]	Loss = 0.85818785 (ave = 0.93620331)

2023-07-05 16:24:33,593 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7160	Time 12.162s / 10iters, (1.216)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.165s / 10iters, (0.817)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.079s / 10iters, (0.007941)
Learning rate = [0.008373764509733726, 0.008373764509733726]	Loss = 0.81424034 (ave = 0.89765381)

2023-07-05 16:24:45,773 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7170	Time 12.180s / 10iters, (1.218)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.219s / 10iters, (0.822)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007506)
Learning rate = [0.008371469664018884, 0.008371469664018884]	Loss = 0.86578864 (ave = 0.87806432)

2023-07-05 16:24:58,207 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7180	Time 12.434s / 10iters, (1.243)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.364s / 10iters, (0.836)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.081s / 10iters, (0.008071)
Learning rate = [0.008369174748404231, 0.008369174748404231]	Loss = 0.90163100 (ave = 0.94830905)

2023-07-05 16:25:10,476 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7190	Time 12.269s / 10iters, (1.227)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.245s / 10iters, (0.824)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.077s / 10iters, (0.007731)
Learning rate = [0.00836687976286634, 0.00836687976286634]	Loss = 0.88515711 (ave = 0.92605435)

2023-07-05 16:25:22,686 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7200	Time 12.210s / 10iters, (1.221)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.191s / 10iters, (0.819)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007443)
Learning rate = [0.008364584707381767, 0.008364584707381767]	Loss = 0.79279101 (ave = 0.89785286)

2023-07-05 16:25:34,919 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7210	Time 12.233s / 10iters, (1.223)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.077s / 10iters, (0.007732)
Learning rate = [0.008362289581927055, 0.008362289581927055]	Loss = 0.81269729 (ave = 0.95625258)

2023-07-05 16:25:47,098 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7220	Time 12.179s / 10iters, (1.218)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.174s / 10iters, (0.817)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.085s / 10iters, (0.008505)
Learning rate = [0.008359994386478735, 0.008359994386478735]	Loss = 0.97389472 (ave = 0.91192423)

2023-07-05 16:25:59,276 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7230	Time 12.178s / 10iters, (1.218)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.173s / 10iters, (0.817)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.084s / 10iters, (0.008440)
Learning rate = [0.008357699121013315, 0.008357699121013315]	Loss = 0.84565783 (ave = 0.88364238)

2023-07-05 16:26:11,485 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7240	Time 12.209s / 10iters, (1.221)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.205s / 10iters, (0.820)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007438)
Learning rate = [0.008355403785507295, 0.008355403785507295]	Loss = 1.06293166 (ave = 0.88407765)

2023-07-05 16:26:23,700 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7250	Time 12.216s / 10iters, (1.222)	Forward Time 1.085s / 10iters, (0.109)	Backward Time 8.195s / 10iters, (0.820)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.077s / 10iters, (0.007730)
Learning rate = [0.008353108379937156, 0.008353108379937156]	Loss = 1.01338720 (ave = 0.90743707)

2023-07-05 16:26:35,930 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7260	Time 12.230s / 10iters, (1.223)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.845s / 10iters, (0.285)	Data load 0.085s / 10iters, (0.008505)
Learning rate = [0.008350812904279368, 0.008350812904279368]	Loss = 1.02345788 (ave = 0.91558638)

2023-07-05 16:26:48,249 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7270	Time 12.319s / 10iters, (1.232)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.868s / 10iters, (0.287)	Data load 0.083s / 10iters, (0.008278)
Learning rate = [0.008348517358510379, 0.008348517358510379]	Loss = 0.72084677 (ave = 0.87164178)

2023-07-05 16:27:00,516 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7280	Time 12.267s / 10iters, (1.227)	Forward Time 1.085s / 10iters, (0.109)	Backward Time 8.250s / 10iters, (0.825)	Loss Time 2.855s / 10iters, (0.285)	Data load 0.077s / 10iters, (0.007668)
Learning rate = [0.00834622174260663, 0.00834622174260663]	Loss = 0.76171499 (ave = 0.91554364)

2023-07-05 16:27:12,816 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7290	Time 12.300s / 10iters, (1.230)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.255s / 10iters, (0.826)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007381)
Learning rate = [0.008343926056544541, 0.008343926056544541]	Loss = 0.85179847 (ave = 0.90408992)

2023-07-05 16:27:25,116 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7300	Time 12.300s / 10iters, (1.230)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.260s / 10iters, (0.826)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.078s / 10iters, (0.007815)
Learning rate = [0.008341630300300521, 0.008341630300300521]	Loss = 0.74716687 (ave = 0.84138041)

2023-07-05 16:27:37,366 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7310	Time 12.250s / 10iters, (1.225)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.865s / 10iters, (0.287)	Data load 0.076s / 10iters, (0.007640)
Learning rate = [0.008339334473850959, 0.008339334473850959]	Loss = 0.83100992 (ave = 0.85041437)

2023-07-05 16:27:49,561 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7320	Time 12.194s / 10iters, (1.219)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.184s / 10iters, (0.818)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007395)
Learning rate = [0.008337038577172235, 0.008337038577172235]	Loss = 0.89951634 (ave = 0.82440854)

2023-07-05 16:28:01,801 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7330	Time 12.241s / 10iters, (1.224)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.178s / 10iters, (0.818)	Loss Time 2.864s / 10iters, (0.286)	Data load 0.105s / 10iters, (0.010473)
Learning rate = [0.008334742610240706, 0.008334742610240706]	Loss = 0.75039625 (ave = 0.84503636)

2023-07-05 16:28:14,009 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7340	Time 12.208s / 10iters, (1.221)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.202s / 10iters, (0.820)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007396)
Learning rate = [0.008332446573032722, 0.008332446573032722]	Loss = 0.78077495 (ave = 0.84162173)

2023-07-05 16:28:26,251 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7350	Time 12.241s / 10iters, (1.224)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.203s / 10iters, (0.820)	Loss Time 2.875s / 10iters, (0.287)	Data load 0.077s / 10iters, (0.007654)
Learning rate = [0.008330150465524612, 0.008330150465524612]	Loss = 0.83217007 (ave = 0.85467284)

2023-07-05 16:28:38,537 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7360	Time 12.286s / 10iters, (1.229)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.870s / 10iters, (0.287)	Data load 0.085s / 10iters, (0.008456)
Learning rate = [0.008327854287692692, 0.008327854287692692]	Loss = 0.89598340 (ave = 0.89579849)

2023-07-05 16:28:50,827 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7370	Time 12.290s / 10iters, (1.229)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.872s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007444)
Learning rate = [0.008325558039513264, 0.008325558039513264]	Loss = 0.87210554 (ave = 0.91632646)

2023-07-05 16:29:03,060 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7380	Time 12.233s / 10iters, (1.223)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.216s / 10iters, (0.822)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.078s / 10iters, (0.007796)
Learning rate = [0.008323261720962613, 0.008323261720962613]	Loss = 0.89065284 (ave = 0.92349817)

2023-07-05 16:29:15,211 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7390	Time 12.151s / 10iters, (1.215)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.162s / 10iters, (0.816)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007385)
Learning rate = [0.008320965332017006, 0.008320965332017006]	Loss = 1.04051483 (ave = 0.91585479)

2023-07-05 16:29:27,449 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7400	Time 12.238s / 10iters, (1.224)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007507)
Learning rate = [0.0083186688726527, 0.0083186688726527]	Loss = 0.77297139 (ave = 0.91602333)

2023-07-05 16:29:39,459 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7410	Time 12.010s / 10iters, (1.201)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.126s / 10iters, (0.813)	Loss Time 2.724s / 10iters, (0.272)	Data load 0.074s / 10iters, (0.007397)
Learning rate = [0.008316372342845936, 0.008316372342845936]	Loss = 1.16452122 (ave = 0.92007143)

2023-07-05 16:29:51,452 INFO    [trainer_contrastive.py, 272] Train Epoch: 19	Train Iteration: 7420	Time 11.993s / 10iters, (1.199)	Forward Time 1.077s / 10iters, (0.108)	Backward Time 8.126s / 10iters, (0.813)	Loss Time 2.713s / 10iters, (0.271)	Data load 0.076s / 10iters, (0.007589)
Learning rate = [0.008314075742572936, 0.008314075742572936]	Loss = 0.90503222 (ave = 0.90805678)

2023-07-05 16:30:06,687 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7430	Time 15.090s / 10iters, (1.509)	Forward Time 1.157s / 10iters, (0.116)	Backward Time 8.285s / 10iters, (0.829)	Loss Time 2.794s / 10iters, (0.279)	Data load 2.853s / 10iters, (0.285320)
Learning rate = [0.008311779071809909, 0.008311779071809909]	Loss = 0.92845309 (ave = 0.92801225)

2023-07-05 16:30:18,838 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7440	Time 12.151s / 10iters, (1.215)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.217s / 10iters, (0.822)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007517)
Learning rate = [0.00830948233053305, 0.00830948233053305]	Loss = 0.83155185 (ave = 0.89746989)

2023-07-05 16:30:31,086 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7450	Time 12.248s / 10iters, (1.225)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.387s / 10iters, (0.839)	Loss Time 2.647s / 10iters, (0.265)	Data load 0.099s / 10iters, (0.009873)
Learning rate = [0.008307185518718537, 0.008307185518718537]	Loss = 0.77891058 (ave = 0.88820056)

2023-07-05 16:30:43,238 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7460	Time 12.152s / 10iters, (1.215)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.670s / 10iters, (0.267)	Data load 0.077s / 10iters, (0.007653)
Learning rate = [0.008304888636342529, 0.008304888636342529]	Loss = 0.80279946 (ave = 0.87280709)

2023-07-05 16:30:55,411 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7470	Time 12.173s / 10iters, (1.217)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.295s / 10iters, (0.829)	Loss Time 2.660s / 10iters, (0.266)	Data load 0.093s / 10iters, (0.009339)
Learning rate = [0.008302591683381176, 0.008302591683381176]	Loss = 0.68457389 (ave = 0.86342573)

2023-07-05 16:31:07,578 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7480	Time 12.167s / 10iters, (1.217)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.713s / 10iters, (0.271)	Data load 0.084s / 10iters, (0.008410)
Learning rate = [0.008300294659810614, 0.008300294659810614]	Loss = 0.87412095 (ave = 0.88019572)

2023-07-05 16:31:19,732 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7490	Time 12.155s / 10iters, (1.215)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.724s / 10iters, (0.272)	Data load 0.077s / 10iters, (0.007708)
Learning rate = [0.008297997565606953, 0.008297997565606953]	Loss = 0.83396590 (ave = 0.88250661)

2023-07-05 16:31:32,116 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7500	Time 12.384s / 10iters, (1.238)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.493s / 10iters, (0.849)	Loss Time 2.722s / 10iters, (0.272)	Data load 0.075s / 10iters, (0.007512)
Learning rate = [0.008295700400746295, 0.008295700400746295]	Loss = 0.91818154 (ave = 0.91708245)

2023-07-05 16:31:44,314 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7510	Time 12.198s / 10iters, (1.220)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.709s / 10iters, (0.271)	Data load 0.085s / 10iters, (0.008461)
Learning rate = [0.00829340316520473, 0.00829340316520473]	Loss = 0.94711792 (ave = 0.90117763)

2023-07-05 16:31:56,543 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7520	Time 12.229s / 10iters, (1.223)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.278s / 10iters, (0.828)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007491)
Learning rate = [0.008291105858958325, 0.008291105858958325]	Loss = 0.80982864 (ave = 0.88296050)

2023-07-05 16:32:08,789 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7530	Time 12.247s / 10iters, (1.225)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.253s / 10iters, (0.825)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007543)
Learning rate = [0.008288808481983137, 0.008288808481983137]	Loss = 0.90582871 (ave = 0.87890527)

2023-07-05 16:32:21,024 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7540	Time 12.235s / 10iters, (1.224)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.076s / 10iters, (0.007608)
Learning rate = [0.008286511034255203, 0.008286511034255203]	Loss = 0.82512033 (ave = 0.85737841)

2023-07-05 16:32:33,197 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7550	Time 12.173s / 10iters, (1.217)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.226s / 10iters, (0.823)	Loss Time 2.762s / 10iters, (0.276)	Data load 0.079s / 10iters, (0.007938)
Learning rate = [0.008284213515750547, 0.008284213515750547]	Loss = 0.98441839 (ave = 0.89229482)

2023-07-05 16:32:45,517 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7560	Time 12.320s / 10iters, (1.232)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.335s / 10iters, (0.833)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.090s / 10iters, (0.009021)
Learning rate = [0.008281915926445178, 0.008281915926445178]	Loss = 0.87704414 (ave = 0.84284670)

2023-07-05 16:32:57,693 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7570	Time 12.176s / 10iters, (1.218)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.209s / 10iters, (0.821)	Loss Time 2.792s / 10iters, (0.279)	Data load 0.076s / 10iters, (0.007561)
Learning rate = [0.008279618266315089, 0.008279618266315089]	Loss = 0.83049232 (ave = 0.87793328)

2023-07-05 16:33:09,905 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7580	Time 12.212s / 10iters, (1.221)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.079s / 10iters, (0.007901)
Learning rate = [0.008277320535336256, 0.008277320535336256]	Loss = 0.85495460 (ave = 0.93009105)

2023-07-05 16:33:22,167 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7590	Time 12.262s / 10iters, (1.226)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.287s / 10iters, (0.829)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.081s / 10iters, (0.008070)
Learning rate = [0.008275022733484641, 0.008275022733484641]	Loss = 0.80809569 (ave = 0.87432564)

2023-07-05 16:33:34,421 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7600	Time 12.255s / 10iters, (1.225)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.756s / 10iters, (0.276)	Data load 0.080s / 10iters, (0.008001)
Learning rate = [0.008272724860736191, 0.008272724860736191]	Loss = 0.79720086 (ave = 0.88059978)

2023-07-05 16:33:46,582 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7610	Time 12.160s / 10iters, (1.216)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.195s / 10iters, (0.820)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.106s / 10iters, (0.010574)
Learning rate = [0.008270426917066837, 0.008270426917066837]	Loss = 1.26023579 (ave = 0.95564206)

2023-07-05 16:33:58,777 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7620	Time 12.195s / 10iters, (1.220)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.084s / 10iters, (0.008415)
Learning rate = [0.008268128902452493, 0.008268128902452493]	Loss = 0.93255115 (ave = 0.86100402)

2023-07-05 16:34:10,974 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7630	Time 12.197s / 10iters, (1.220)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.077s / 10iters, (0.007676)
Learning rate = [0.008265830816869055, 0.008265830816869055]	Loss = 0.86901891 (ave = 0.84775612)

2023-07-05 16:34:23,219 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7640	Time 12.246s / 10iters, (1.225)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.275s / 10iters, (0.827)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.077s / 10iters, (0.007702)
Learning rate = [0.008263532660292412, 0.008263532660292412]	Loss = 0.89471942 (ave = 0.89289390)

2023-07-05 16:34:35,357 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7650	Time 12.138s / 10iters, (1.214)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.154s / 10iters, (0.815)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.086s / 10iters, (0.008610)
Learning rate = [0.008261234432698428, 0.008261234432698428]	Loss = 0.80829376 (ave = 0.83439403)

2023-07-05 16:34:47,612 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7660	Time 12.254s / 10iters, (1.225)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.805s / 10iters, (0.281)	Data load 0.079s / 10iters, (0.007867)
Learning rate = [0.008258936134062957, 0.008258936134062957]	Loss = 0.96977663 (ave = 0.89069869)

2023-07-05 16:34:59,916 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7670	Time 12.304s / 10iters, (1.230)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.091s / 10iters, (0.009088)
Learning rate = [0.008256637764361837, 0.008256637764361837]	Loss = 0.82541537 (ave = 0.83317773)

2023-07-05 16:35:12,254 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7680	Time 12.339s / 10iters, (1.234)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.083s / 10iters, (0.008315)
Learning rate = [0.008254339323570885, 0.008254339323570885]	Loss = 0.82537174 (ave = 0.84131637)

2023-07-05 16:35:24,503 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7690	Time 12.249s / 10iters, (1.225)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.091s / 10iters, (0.009126)
Learning rate = [0.00825204081166591, 0.00825204081166591]	Loss = 0.85786003 (ave = 0.87095392)

2023-07-05 16:35:36,646 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7700	Time 12.143s / 10iters, (1.214)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.168s / 10iters, (0.817)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.077s / 10iters, (0.007652)
Learning rate = [0.008249742228622702, 0.008249742228622702]	Loss = 0.81726027 (ave = 0.83904783)

2023-07-05 16:35:48,838 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7710	Time 12.192s / 10iters, (1.219)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.763s / 10iters, (0.276)	Data load 0.076s / 10iters, (0.007630)
Learning rate = [0.008247443574417028, 0.008247443574417028]	Loss = 0.88213873 (ave = 0.89804577)

2023-07-05 16:36:01,099 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7720	Time 12.261s / 10iters, (1.226)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.262s / 10iters, (0.826)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007496)
Learning rate = [0.008245144849024654, 0.008245144849024654]	Loss = 0.86041933 (ave = 0.93744935)

2023-07-05 16:36:13,462 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7730	Time 12.363s / 10iters, (1.236)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.077s / 10iters, (0.007693)
Learning rate = [0.008242846052421317, 0.008242846052421317]	Loss = 1.00161886 (ave = 0.94129324)

2023-07-05 16:36:25,835 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7740	Time 12.373s / 10iters, (1.237)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.865s / 10iters, (0.287)	Data load 0.086s / 10iters, (0.008583)
Learning rate = [0.008240547184582746, 0.008240547184582746]	Loss = 0.80406308 (ave = 0.85928454)

2023-07-05 16:36:38,282 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7750	Time 12.446s / 10iters, (1.245)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.357s / 10iters, (0.836)	Loss Time 2.895s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007536)
Learning rate = [0.00823824824548465, 0.00823824824548465]	Loss = 0.83462286 (ave = 0.84989727)

2023-07-05 16:36:50,542 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7760	Time 12.261s / 10iters, (1.226)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.199s / 10iters, (0.820)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.082s / 10iters, (0.008225)
Learning rate = [0.008235949235102728, 0.008235949235102728]	Loss = 0.83735335 (ave = 0.87177025)

2023-07-05 16:37:02,924 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7770	Time 12.382s / 10iters, (1.238)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.363s / 10iters, (0.836)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.079s / 10iters, (0.007867)
Learning rate = [0.008233650153412653, 0.008233650153412653]	Loss = 0.92610013 (ave = 0.89051848)

2023-07-05 16:37:15,079 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7780	Time 12.154s / 10iters, (1.215)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.185s / 10iters, (0.819)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007458)
Learning rate = [0.008231351000390092, 0.008231351000390092]	Loss = 0.78648430 (ave = 0.88371872)

2023-07-05 16:37:27,067 INFO    [trainer_contrastive.py, 272] Train Epoch: 20	Train Iteration: 7790	Time 11.989s / 10iters, (1.199)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.111s / 10iters, (0.811)	Loss Time 2.720s / 10iters, (0.272)	Data load 0.074s / 10iters, (0.007355)
Learning rate = [0.008229051776010689, 0.008229051776010689]	Loss = 0.75973928 (ave = 0.83721468)

2023-07-05 16:37:42,391 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7800	Time 15.146s / 10iters, (1.515)	Forward Time 1.353s / 10iters, (0.135)	Backward Time 8.407s / 10iters, (0.841)	Loss Time 2.787s / 10iters, (0.279)	Data load 2.598s / 10iters, (0.259765)
Learning rate = [0.00822675248025008, 0.00822675248025008]	Loss = 0.86744070 (ave = 0.87315379)

2023-07-05 16:37:54,831 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7810	Time 12.440s / 10iters, (1.244)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.379s / 10iters, (0.838)	Loss Time 2.855s / 10iters, (0.285)	Data load 0.091s / 10iters, (0.009076)
Learning rate = [0.008224453113083877, 0.008224453113083877]	Loss = 0.96148801 (ave = 0.86595638)

2023-07-05 16:38:07,046 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7820	Time 12.215s / 10iters, (1.222)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.099s / 10iters, (0.009883)
Learning rate = [0.008222153674487679, 0.008222153674487679]	Loss = 0.78525126 (ave = 0.81759353)

2023-07-05 16:38:19,321 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7830	Time 12.275s / 10iters, (1.228)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.816s / 10iters, (0.282)	Data load 0.087s / 10iters, (0.008674)
Learning rate = [0.008219854164437072, 0.008219854164437072]	Loss = 0.94465905 (ave = 0.88309896)

2023-07-05 16:38:31,638 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7840	Time 12.317s / 10iters, (1.232)	Forward Time 1.149s / 10iters, (0.115)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.848s / 10iters, (0.285)	Data load 0.091s / 10iters, (0.009113)
Learning rate = [0.008217554582907623, 0.008217554582907623]	Loss = 0.79436839 (ave = 0.86531527)

2023-07-05 16:38:44,079 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7850	Time 12.442s / 10iters, (1.244)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.329s / 10iters, (0.833)	Loss Time 2.928s / 10iters, (0.293)	Data load 0.081s / 10iters, (0.008070)
Learning rate = [0.008215254929874885, 0.008215254929874885]	Loss = 0.79043961 (ave = 0.86627626)

2023-07-05 16:38:56,351 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7860	Time 12.272s / 10iters, (1.227)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.253s / 10iters, (0.825)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.082s / 10iters, (0.008205)
Learning rate = [0.008212955205314391, 0.008212955205314391]	Loss = 0.86847091 (ave = 0.86162859)

2023-07-05 16:39:08,883 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7870	Time 12.532s / 10iters, (1.253)	Forward Time 1.158s / 10iters, (0.116)	Backward Time 8.421s / 10iters, (0.842)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.082s / 10iters, (0.008155)
Learning rate = [0.008210655409201663, 0.008210655409201663]	Loss = 0.78069675 (ave = 0.86629070)

2023-07-05 16:39:21,269 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7880	Time 12.385s / 10iters, (1.239)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.343s / 10iters, (0.834)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.076s / 10iters, (0.007593)
Learning rate = [0.008208355541512205, 0.008208355541512205]	Loss = 0.86449122 (ave = 0.88229083)

2023-07-05 16:39:33,686 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7890	Time 12.418s / 10iters, (1.242)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.329s / 10iters, (0.833)	Loss Time 2.893s / 10iters, (0.289)	Data load 0.086s / 10iters, (0.008576)
Learning rate = [0.008206055602221502, 0.008206055602221502]	Loss = 0.75184470 (ave = 0.86615015)

2023-07-05 16:39:46,011 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7900	Time 12.325s / 10iters, (1.232)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.275s / 10iters, (0.828)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.090s / 10iters, (0.008998)
Learning rate = [0.008203755591305028, 0.008203755591305028]	Loss = 0.98684746 (ave = 0.84324708)

2023-07-05 16:39:58,234 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7910	Time 12.223s / 10iters, (1.222)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.207s / 10iters, (0.821)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.079s / 10iters, (0.007931)
Learning rate = [0.008201455508738239, 0.008201455508738239]	Loss = 0.84358829 (ave = 0.82468619)

2023-07-05 16:40:10,564 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7920	Time 12.330s / 10iters, (1.233)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.299s / 10iters, (0.830)	Loss Time 2.845s / 10iters, (0.285)	Data load 0.077s / 10iters, (0.007703)
Learning rate = [0.008199155354496574, 0.008199155354496574]	Loss = 0.94181985 (ave = 0.88716449)

2023-07-05 16:40:22,832 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7930	Time 12.268s / 10iters, (1.227)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.088s / 10iters, (0.008782)
Learning rate = [0.008196855128555457, 0.008196855128555457]	Loss = 0.82841885 (ave = 0.87884494)

2023-07-05 16:40:35,031 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7940	Time 12.199s / 10iters, (1.220)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007508)
Learning rate = [0.008194554830890296, 0.008194554830890296]	Loss = 0.81180757 (ave = 0.82512869)

2023-07-05 16:40:47,242 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7950	Time 12.210s / 10iters, (1.221)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.180s / 10iters, (0.818)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007443)
Learning rate = [0.00819225446147648, 0.00819225446147648]	Loss = 0.82059681 (ave = 0.85641153)

2023-07-05 16:40:59,624 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7960	Time 12.383s / 10iters, (1.238)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.886s / 10iters, (0.289)	Data load 0.083s / 10iters, (0.008294)
Learning rate = [0.008189954020289386, 0.008189954020289386]	Loss = 0.91283369 (ave = 0.85279771)

2023-07-05 16:41:12,150 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7970	Time 12.525s / 10iters, (1.253)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.410s / 10iters, (0.841)	Loss Time 2.923s / 10iters, (0.292)	Data load 0.075s / 10iters, (0.007464)
Learning rate = [0.008187653507304373, 0.008187653507304373]	Loss = 0.85140675 (ave = 0.88154188)

2023-07-05 16:41:24,533 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7980	Time 12.383s / 10iters, (1.238)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.315s / 10iters, (0.831)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.089s / 10iters, (0.008922)
Learning rate = [0.008185352922496784, 0.008185352922496784]	Loss = 0.82275486 (ave = 0.86185711)

2023-07-05 16:41:36,918 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 7990	Time 12.385s / 10iters, (1.239)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.349s / 10iters, (0.835)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.078s / 10iters, (0.007764)
Learning rate = [0.008183052265841945, 0.008183052265841945]	Loss = 1.02573478 (ave = 0.90897815)

2023-07-05 16:41:49,259 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 8000	Time 12.341s / 10iters, (1.234)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.329s / 10iters, (0.833)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007486)
Learning rate = [0.008180751537315168, 0.008180751537315168]	Loss = 0.73501462 (ave = 0.83914028)

2023-07-05 16:41:52,703 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 16:42:17,151 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 16:42:40,239 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 16:43:03,362 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 16:43:26,535 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 16:43:49,498 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 16:44:12,032 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 16:44:17,844 INFO    [base.py, 84] Performance 0.6875013947062176 -> 0.6912862842038408
2023-07-05 16:44:22,129 INFO    [trainer_contrastive.py, 391] Test Time 148.433s, (2.356)	Loss 0.17009915

2023-07-05 16:44:22,130 INFO    [base.py, 33] Result for seg
2023-07-05 16:44:22,132 INFO    [base.py, 49] Mean IOU: 0.6912862842038408

2023-07-05 16:44:22,132 INFO    [base.py, 50] Pixel ACC: 0.947112922387326

2023-07-05 16:44:34,157 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 8010	Time 164.898s / 10iters, (16.490)	Forward Time 1.150s / 10iters, (0.115)	Backward Time 8.100s / 10iters, (0.810)	Loss Time 2.675s / 10iters, (0.268)	Data load 152.973s / 10iters, (15.297283)
Learning rate = [0.008178450736891748, 0.008178450736891748]	Loss = 0.95025599 (ave = 0.89237277)

2023-07-05 16:44:46,107 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 8020	Time 11.950s / 10iters, (1.195)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.122s / 10iters, (0.812)	Loss Time 2.628s / 10iters, (0.263)	Data load 0.097s / 10iters, (0.009747)
Learning rate = [0.00817614986454696, 0.00817614986454696]	Loss = 0.98658586 (ave = 0.85817764)

2023-07-05 16:44:58,066 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 8030	Time 11.959s / 10iters, (1.196)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.111s / 10iters, (0.811)	Loss Time 2.643s / 10iters, (0.264)	Data load 0.075s / 10iters, (0.007543)
Learning rate = [0.008173848920256068, 0.008173848920256068]	Loss = 0.81564432 (ave = 0.83706709)

2023-07-05 16:45:10,145 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 8040	Time 12.079s / 10iters, (1.208)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.216s / 10iters, (0.822)	Loss Time 2.679s / 10iters, (0.268)	Data load 0.091s / 10iters, (0.009139)
Learning rate = [0.008171547903994318, 0.008171547903994318]	Loss = 0.93096155 (ave = 0.85123379)

2023-07-05 16:45:22,146 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 8050	Time 12.001s / 10iters, (1.200)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.184s / 10iters, (0.818)	Loss Time 2.639s / 10iters, (0.264)	Data load 0.079s / 10iters, (0.007866)
Learning rate = [0.00816924681573694, 0.00816924681573694]	Loss = 0.87693197 (ave = 0.82953909)

2023-07-05 16:45:34,083 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 8060	Time 11.937s / 10iters, (1.194)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.108s / 10iters, (0.811)	Loss Time 2.652s / 10iters, (0.265)	Data load 0.083s / 10iters, (0.008277)
Learning rate = [0.008166945655459145, 0.008166945655459145]	Loss = 0.90769392 (ave = 0.86587880)

2023-07-05 16:45:46,131 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 8070	Time 12.048s / 10iters, (1.205)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.176s / 10iters, (0.818)	Loss Time 2.672s / 10iters, (0.267)	Data load 0.089s / 10iters, (0.008918)
Learning rate = [0.008164644423136132, 0.008164644423136132]	Loss = 0.93783116 (ave = 0.89699159)

2023-07-05 16:45:58,288 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 8080	Time 12.157s / 10iters, (1.216)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.674s / 10iters, (0.267)	Data load 0.088s / 10iters, (0.008839)
Learning rate = [0.008162343118743079, 0.008162343118743079]	Loss = 0.78576595 (ave = 0.88911926)

2023-07-05 16:46:10,321 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 8090	Time 12.033s / 10iters, (1.203)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.187s / 10iters, (0.819)	Loss Time 2.628s / 10iters, (0.263)	Data load 0.112s / 10iters, (0.011201)
Learning rate = [0.008160041742255151, 0.008160041742255151]	Loss = 0.76746219 (ave = 0.78557699)

2023-07-05 16:46:22,434 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 8100	Time 12.113s / 10iters, (1.211)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.685s / 10iters, (0.269)	Data load 0.074s / 10iters, (0.007427)
Learning rate = [0.0081577402936475, 0.0081577402936475]	Loss = 0.84783012 (ave = 0.84470448)

2023-07-05 16:46:34,457 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 8110	Time 12.023s / 10iters, (1.202)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.195s / 10iters, (0.820)	Loss Time 2.641s / 10iters, (0.264)	Data load 0.079s / 10iters, (0.007872)
Learning rate = [0.008155438772895252, 0.008155438772895252]	Loss = 0.76775515 (ave = 0.90117561)

2023-07-05 16:46:46,696 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 8120	Time 12.238s / 10iters, (1.224)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.366s / 10iters, (0.837)	Loss Time 2.683s / 10iters, (0.268)	Data load 0.076s / 10iters, (0.007605)
Learning rate = [0.008153137179973523, 0.008153137179973523]	Loss = 0.84403473 (ave = 0.90135120)

2023-07-05 16:46:58,914 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 8130	Time 12.219s / 10iters, (1.222)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.312s / 10iters, (0.831)	Loss Time 2.734s / 10iters, (0.273)	Data load 0.077s / 10iters, (0.007671)
Learning rate = [0.008150835514857416, 0.008150835514857416]	Loss = 0.89265281 (ave = 0.84810451)

2023-07-05 16:47:11,040 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 8140	Time 12.126s / 10iters, (1.213)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.704s / 10iters, (0.270)	Data load 0.084s / 10iters, (0.008434)
Learning rate = [0.00814853377752201, 0.00814853377752201]	Loss = 0.82008785 (ave = 0.83351954)

2023-07-05 16:47:23,069 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 8150	Time 12.029s / 10iters, (1.203)	Forward Time 1.083s / 10iters, (0.108)	Backward Time 8.158s / 10iters, (0.816)	Loss Time 2.714s / 10iters, (0.271)	Data load 0.073s / 10iters, (0.007345)
Learning rate = [0.00814623196794237, 0.00814623196794237]	Loss = 0.90163434 (ave = 0.89557180)

2023-07-05 16:47:35,030 INFO    [trainer_contrastive.py, 272] Train Epoch: 21	Train Iteration: 8160	Time 11.960s / 10iters, (1.196)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.116s / 10iters, (0.812)	Loss Time 2.691s / 10iters, (0.269)	Data load 0.073s / 10iters, (0.007316)
Learning rate = [0.008143930086093548, 0.008143930086093548]	Loss = 0.83620536 (ave = 0.84812049)

2023-07-05 16:47:50,273 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8170	Time 15.059s / 10iters, (1.506)	Forward Time 1.180s / 10iters, (0.118)	Backward Time 8.255s / 10iters, (0.826)	Loss Time 2.770s / 10iters, (0.277)	Data load 2.854s / 10iters, (0.285353)
Learning rate = [0.008141628131950575, 0.008141628131950575]	Loss = 0.78066230 (ave = 0.80139317)

2023-07-05 16:48:02,488 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8180	Time 12.215s / 10iters, (1.221)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.728s / 10iters, (0.273)	Data load 0.076s / 10iters, (0.007573)
Learning rate = [0.008139326105488467, 0.008139326105488467]	Loss = 0.73140109 (ave = 0.79254258)

2023-07-05 16:48:14,678 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8190	Time 12.190s / 10iters, (1.219)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.299s / 10iters, (0.830)	Loss Time 2.692s / 10iters, (0.269)	Data load 0.083s / 10iters, (0.008339)
Learning rate = [0.008137024006682227, 0.008137024006682227]	Loss = 1.01274335 (ave = 0.85856092)

2023-07-05 16:48:26,892 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8200	Time 12.214s / 10iters, (1.221)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.719s / 10iters, (0.272)	Data load 0.082s / 10iters, (0.008157)
Learning rate = [0.008134721835506838, 0.008134721835506838]	Loss = 0.74351001 (ave = 0.84953257)

2023-07-05 16:48:39,213 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8210	Time 12.321s / 10iters, (1.232)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.379s / 10iters, (0.838)	Loss Time 2.754s / 10iters, (0.275)	Data load 0.091s / 10iters, (0.009132)
Learning rate = [0.008132419591937265, 0.008132419591937265]	Loss = 0.87574869 (ave = 0.82849096)

2023-07-05 16:48:51,587 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8220	Time 12.375s / 10iters, (1.237)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.342s / 10iters, (0.834)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.084s / 10iters, (0.008357)
Learning rate = [0.00813011727594846, 0.00813011727594846]	Loss = 0.71571600 (ave = 0.81431332)

2023-07-05 16:49:03,938 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8230	Time 12.350s / 10iters, (1.235)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.887s / 10iters, (0.289)	Data load 0.077s / 10iters, (0.007675)
Learning rate = [0.008127814887515355, 0.008127814887515355]	Loss = 0.93136191 (ave = 0.85228233)

2023-07-05 16:49:16,300 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8240	Time 12.362s / 10iters, (1.236)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.881s / 10iters, (0.288)	Data load 0.094s / 10iters, (0.009366)
Learning rate = [0.00812551242661287, 0.00812551242661287]	Loss = 0.94916463 (ave = 0.84435269)

2023-07-05 16:49:28,642 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8250	Time 12.342s / 10iters, (1.234)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.089s / 10iters, (0.008895)
Learning rate = [0.008123209893215905, 0.008123209893215905]	Loss = 0.78793561 (ave = 0.79944145)

2023-07-05 16:49:40,975 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8260	Time 12.332s / 10iters, (1.233)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.260s / 10iters, (0.826)	Loss Time 2.874s / 10iters, (0.287)	Data load 0.086s / 10iters, (0.008551)
Learning rate = [0.008120907287299344, 0.008120907287299344]	Loss = 0.83851647 (ave = 0.82826381)

2023-07-05 16:49:53,414 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8270	Time 12.439s / 10iters, (1.244)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.881s / 10iters, (0.288)	Data load 0.109s / 10iters, (0.010928)
Learning rate = [0.008118604608838053, 0.008118604608838053]	Loss = 1.03135800 (ave = 0.86102511)

2023-07-05 16:50:05,709 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8280	Time 12.296s / 10iters, (1.230)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.877s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007527)
Learning rate = [0.008116301857806886, 0.008116301857806886]	Loss = 1.05965734 (ave = 0.93306388)

2023-07-05 16:50:17,964 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8290	Time 12.255s / 10iters, (1.226)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.198s / 10iters, (0.820)	Loss Time 2.895s / 10iters, (0.290)	Data load 0.073s / 10iters, (0.007334)
Learning rate = [0.008113999034180674, 0.008113999034180674]	Loss = 0.82575738 (ave = 0.89801191)

2023-07-05 16:50:30,172 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8300	Time 12.208s / 10iters, (1.221)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.233s / 10iters, (0.823)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007416)
Learning rate = [0.008111696137934239, 0.008111696137934239]	Loss = 0.84140521 (ave = 0.86824368)

2023-07-05 16:50:42,382 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8310	Time 12.210s / 10iters, (1.221)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.202s / 10iters, (0.820)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007394)
Learning rate = [0.008109393169042377, 0.008109393169042377]	Loss = 0.97555685 (ave = 0.88424433)

2023-07-05 16:50:54,605 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8320	Time 12.222s / 10iters, (1.222)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.201s / 10iters, (0.820)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007369)
Learning rate = [0.008107090127479875, 0.008107090127479875]	Loss = 0.95047104 (ave = 0.85777685)

2023-07-05 16:51:06,956 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8330	Time 12.351s / 10iters, (1.235)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.313s / 10iters, (0.831)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.082s / 10iters, (0.008201)
Learning rate = [0.0081047870132215, 0.0081047870132215]	Loss = 0.82309234 (ave = 0.82329398)

2023-07-05 16:51:19,187 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8340	Time 12.231s / 10iters, (1.223)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.262s / 10iters, (0.826)	Loss Time 2.808s / 10iters, (0.281)	Data load 0.073s / 10iters, (0.007330)
Learning rate = [0.008102483826242004, 0.008102483826242004]	Loss = 0.97584367 (ave = 0.83202187)

2023-07-05 16:51:31,388 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8350	Time 12.200s / 10iters, (1.220)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.785s / 10iters, (0.278)	Data load 0.087s / 10iters, (0.008661)
Learning rate = [0.008100180566516117, 0.008100180566516117]	Loss = 0.75746810 (ave = 0.86146477)

2023-07-05 16:51:43,581 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8360	Time 12.193s / 10iters, (1.219)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.207s / 10iters, (0.821)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007399)
Learning rate = [0.008097877234018563, 0.008097877234018563]	Loss = 0.84122854 (ave = 0.90827923)

2023-07-05 16:51:55,792 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8370	Time 12.211s / 10iters, (1.221)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007411)
Learning rate = [0.008095573828724037, 0.008095573828724037]	Loss = 0.79849070 (ave = 0.89077849)

2023-07-05 16:52:08,190 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8380	Time 12.398s / 10iters, (1.240)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.343s / 10iters, (0.834)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.084s / 10iters, (0.008415)
Learning rate = [0.008093270350607225, 0.008093270350607225]	Loss = 0.79990590 (ave = 0.87470152)

2023-07-05 16:52:20,587 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8390	Time 12.397s / 10iters, (1.240)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.322s / 10iters, (0.832)	Loss Time 2.881s / 10iters, (0.288)	Data load 0.084s / 10iters, (0.008421)
Learning rate = [0.008090966799642793, 0.008090966799642793]	Loss = 0.83986896 (ave = 0.83810959)

2023-07-05 16:52:32,817 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8400	Time 12.230s / 10iters, (1.223)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.209s / 10iters, (0.821)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.078s / 10iters, (0.007812)
Learning rate = [0.00808866317580539, 0.00808866317580539]	Loss = 0.79392338 (ave = 0.87683433)

2023-07-05 16:52:45,239 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8410	Time 12.421s / 10iters, (1.242)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.354s / 10iters, (0.835)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.089s / 10iters, (0.008886)
Learning rate = [0.008086359479069653, 0.008086359479069653]	Loss = 0.78017277 (ave = 0.84614406)

2023-07-05 16:52:57,512 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8420	Time 12.273s / 10iters, (1.227)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.088s / 10iters, (0.008794)
Learning rate = [0.008084055709410195, 0.008084055709410195]	Loss = 0.95653844 (ave = 0.80823746)

2023-07-05 16:53:10,085 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8430	Time 12.574s / 10iters, (1.257)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.510s / 10iters, (0.851)	Loss Time 2.861s / 10iters, (0.286)	Data load 0.078s / 10iters, (0.007807)
Learning rate = [0.008081751866801615, 0.008081751866801615]	Loss = 0.85142910 (ave = 0.84213796)

2023-07-05 16:53:22,311 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8440	Time 12.225s / 10iters, (1.223)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.085s / 10iters, (0.008525)
Learning rate = [0.0080794479512185, 0.0080794479512185]	Loss = 1.08441854 (ave = 0.86337900)

2023-07-05 16:53:34,568 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8450	Time 12.258s / 10iters, (1.226)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.106s / 10iters, (0.010600)
Learning rate = [0.00807714396263541, 0.00807714396263541]	Loss = 0.93096948 (ave = 0.85202367)

2023-07-05 16:53:46,851 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8460	Time 12.283s / 10iters, (1.228)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.235s / 10iters, (0.824)	Loss Time 2.855s / 10iters, (0.285)	Data load 0.096s / 10iters, (0.009588)
Learning rate = [0.0080748399010269, 0.0080748399010269]	Loss = 0.80370712 (ave = 0.83107203)

2023-07-05 16:53:59,196 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8470	Time 12.345s / 10iters, (1.235)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.082s / 10iters, (0.008222)
Learning rate = [0.008072535766367496, 0.008072535766367496]	Loss = 0.88840675 (ave = 0.84135014)

2023-07-05 16:54:11,498 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8480	Time 12.301s / 10iters, (1.230)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.864s / 10iters, (0.286)	Data load 0.078s / 10iters, (0.007812)
Learning rate = [0.008070231558631714, 0.008070231558631714]	Loss = 0.84416056 (ave = 0.82061535)

2023-07-05 16:54:23,830 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8490	Time 12.333s / 10iters, (1.233)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.878s / 10iters, (0.288)	Data load 0.081s / 10iters, (0.008060)
Learning rate = [0.008067927277794054, 0.008067927277794054]	Loss = 0.79546136 (ave = 0.82156197)

2023-07-05 16:54:36,158 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8500	Time 12.328s / 10iters, (1.233)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.900s / 10iters, (0.290)	Data load 0.084s / 10iters, (0.008417)
Learning rate = [0.008065622923828997, 0.008065622923828997]	Loss = 0.74746215 (ave = 0.82739832)

2023-07-05 16:54:48,545 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8510	Time 12.386s / 10iters, (1.239)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.304s / 10iters, (0.830)	Loss Time 2.890s / 10iters, (0.289)	Data load 0.088s / 10iters, (0.008788)
Learning rate = [0.008063318496711004, 0.008063318496711004]	Loss = 0.79486448 (ave = 0.84523053)

2023-07-05 16:55:00,794 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8520	Time 12.249s / 10iters, (1.225)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.865s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007445)
Learning rate = [0.008061013996414524, 0.008061013996414524]	Loss = 0.99933392 (ave = 0.86897286)

2023-07-05 16:55:12,734 INFO    [trainer_contrastive.py, 272] Train Epoch: 22	Train Iteration: 8530	Time 11.940s / 10iters, (1.194)	Forward Time 1.083s / 10iters, (0.108)	Backward Time 8.100s / 10iters, (0.810)	Loss Time 2.683s / 10iters, (0.268)	Data load 0.073s / 10iters, (0.007341)
Learning rate = [0.008058709422913988, 0.008058709422913988]	Loss = 0.81919062 (ave = 0.85741565)

2023-07-05 16:55:27,917 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8540	Time 14.998s / 10iters, (1.500)	Forward Time 1.297s / 10iters, (0.130)	Backward Time 8.334s / 10iters, (0.833)	Loss Time 2.760s / 10iters, (0.276)	Data load 2.608s / 10iters, (0.260813)
Learning rate = [0.008056404776183806, 0.008056404776183806]	Loss = 0.94658077 (ave = 0.88571306)

2023-07-05 16:55:40,277 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8550	Time 12.360s / 10iters, (1.236)	Forward Time 1.147s / 10iters, (0.115)	Backward Time 8.315s / 10iters, (0.831)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.090s / 10iters, (0.009025)
Learning rate = [0.008054100056198376, 0.008054100056198376]	Loss = 0.84514195 (ave = 0.83853164)

2023-07-05 16:55:52,699 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8560	Time 12.422s / 10iters, (1.242)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.394s / 10iters, (0.839)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.080s / 10iters, (0.008018)
Learning rate = [0.008051795262932072, 0.008051795262932072]	Loss = 0.76563239 (ave = 0.91266196)

2023-07-05 16:56:05,071 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8570	Time 12.372s / 10iters, (1.237)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.329s / 10iters, (0.833)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.087s / 10iters, (0.008710)
Learning rate = [0.00804949039635926, 0.00804949039635926]	Loss = 0.74161541 (ave = 0.84850897)

2023-07-05 16:56:17,497 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8580	Time 12.426s / 10iters, (1.243)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.387s / 10iters, (0.839)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.080s / 10iters, (0.007991)
Learning rate = [0.008047185456454286, 0.008047185456454286]	Loss = 1.00817537 (ave = 0.93256981)

2023-07-05 16:56:29,873 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8590	Time 12.376s / 10iters, (1.238)	Forward Time 1.143s / 10iters, (0.114)	Backward Time 8.323s / 10iters, (0.832)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.080s / 10iters, (0.007994)
Learning rate = [0.00804488044319147, 0.00804488044319147]	Loss = 0.86881095 (ave = 0.90590374)

2023-07-05 16:56:42,052 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8600	Time 12.178s / 10iters, (1.218)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.181s / 10iters, (0.818)	Loss Time 2.789s / 10iters, (0.279)	Data load 0.091s / 10iters, (0.009073)
Learning rate = [0.008042575356545128, 0.008042575356545128]	Loss = 0.89225847 (ave = 0.90135387)

2023-07-05 16:56:54,323 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8610	Time 12.271s / 10iters, (1.227)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.092s / 10iters, (0.009210)
Learning rate = [0.00804027019648955, 0.00804027019648955]	Loss = 0.94896889 (ave = 0.87261729)

2023-07-05 16:57:06,589 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8620	Time 12.266s / 10iters, (1.227)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.281s / 10iters, (0.828)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007603)
Learning rate = [0.008037964962999015, 0.008037964962999015]	Loss = 0.90950418 (ave = 0.92912048)

2023-07-05 16:57:18,786 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8630	Time 12.197s / 10iters, (1.220)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.204s / 10iters, (0.820)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.080s / 10iters, (0.007998)
Learning rate = [0.008035659656047777, 0.008035659656047777]	Loss = 0.76814854 (ave = 0.87079284)

2023-07-05 16:57:31,060 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8640	Time 12.275s / 10iters, (1.227)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.282s / 10iters, (0.828)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.083s / 10iters, (0.008333)
Learning rate = [0.008033354275610078, 0.008033354275610078]	Loss = 0.99254459 (ave = 0.82066774)

2023-07-05 16:57:43,412 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8650	Time 12.352s / 10iters, (1.235)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.344s / 10iters, (0.834)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007622)
Learning rate = [0.008031048821660143, 0.008031048821660143]	Loss = 0.87073129 (ave = 0.87415670)

2023-07-05 16:57:55,885 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8660	Time 12.472s / 10iters, (1.247)	Forward Time 1.145s / 10iters, (0.114)	Backward Time 8.384s / 10iters, (0.838)	Loss Time 2.864s / 10iters, (0.286)	Data load 0.079s / 10iters, (0.007915)
Learning rate = [0.008028743294172181, 0.008028743294172181]	Loss = 0.82338607 (ave = 0.88141482)

2023-07-05 16:58:08,271 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8670	Time 12.386s / 10iters, (1.239)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.333s / 10iters, (0.833)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007494)
Learning rate = [0.008026437693120376, 0.008026437693120376]	Loss = 0.96685505 (ave = 0.90866488)

2023-07-05 16:58:20,595 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8680	Time 12.324s / 10iters, (1.232)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.253s / 10iters, (0.825)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.083s / 10iters, (0.008328)
Learning rate = [0.008024132018478906, 0.008024132018478906]	Loss = 0.75064749 (ave = 0.81415269)

2023-07-05 16:58:32,879 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8690	Time 12.285s / 10iters, (1.228)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.250s / 10iters, (0.825)	Loss Time 2.855s / 10iters, (0.285)	Data load 0.078s / 10iters, (0.007834)
Learning rate = [0.00802182627022192, 0.00802182627022192]	Loss = 0.74040461 (ave = 0.83346264)

2023-07-05 16:58:45,229 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8700	Time 12.350s / 10iters, (1.235)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.878s / 10iters, (0.288)	Data load 0.087s / 10iters, (0.008697)
Learning rate = [0.008019520448323561, 0.008019520448323561]	Loss = 0.82357949 (ave = 0.79031439)

2023-07-05 16:58:57,567 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8710	Time 12.337s / 10iters, (1.234)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.298s / 10iters, (0.830)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.094s / 10iters, (0.009442)
Learning rate = [0.008017214552757944, 0.008017214552757944]	Loss = 0.95260876 (ave = 0.89315680)

2023-07-05 16:59:10,147 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8720	Time 12.581s / 10iters, (1.258)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.426s / 10iters, (0.843)	Loss Time 2.943s / 10iters, (0.294)	Data load 0.084s / 10iters, (0.008436)
Learning rate = [0.008014908583499174, 0.008014908583499174]	Loss = 0.88909471 (ave = 0.88335083)

2023-07-05 16:59:22,495 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8730	Time 12.348s / 10iters, (1.235)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.085s / 10iters, (0.008488)
Learning rate = [0.008012602540521338, 0.008012602540521338]	Loss = 0.72015101 (ave = 0.82280863)

2023-07-05 16:59:34,850 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8740	Time 12.354s / 10iters, (1.235)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.314s / 10iters, (0.831)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.082s / 10iters, (0.008190)
Learning rate = [0.008010296423798502, 0.008010296423798502]	Loss = 0.79165870 (ave = 0.80156425)

2023-07-05 16:59:47,137 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8750	Time 12.287s / 10iters, (1.229)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.227s / 10iters, (0.823)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.087s / 10iters, (0.008682)
Learning rate = [0.008007990233304714, 0.008007990233304714]	Loss = 0.88611692 (ave = 0.89383311)

2023-07-05 16:59:59,491 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8760	Time 12.355s / 10iters, (1.235)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.903s / 10iters, (0.290)	Data load 0.078s / 10iters, (0.007850)
Learning rate = [0.008005683969014011, 0.008005683969014011]	Loss = 0.86959469 (ave = 0.85088533)

2023-07-05 17:00:11,847 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8770	Time 12.355s / 10iters, (1.236)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.285s / 10iters, (0.829)	Loss Time 2.874s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007514)
Learning rate = [0.008003377630900407, 0.008003377630900407]	Loss = 0.96160728 (ave = 0.87845254)

2023-07-05 17:00:24,195 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8780	Time 12.348s / 10iters, (1.235)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.309s / 10iters, (0.831)	Loss Time 2.852s / 10iters, (0.285)	Data load 0.084s / 10iters, (0.008412)
Learning rate = [0.008001071218937903, 0.008001071218937903]	Loss = 0.96446246 (ave = 0.83015225)

2023-07-05 17:00:36,685 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8790	Time 12.490s / 10iters, (1.249)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.453s / 10iters, (0.845)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.084s / 10iters, (0.008365)
Learning rate = [0.007998764733100475, 0.007998764733100475]	Loss = 0.84098458 (ave = 0.85879887)

2023-07-05 17:00:49,142 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8800	Time 12.457s / 10iters, (1.246)	Forward Time 1.139s / 10iters, (0.114)	Backward Time 8.449s / 10iters, (0.845)	Loss Time 2.786s / 10iters, (0.279)	Data load 0.082s / 10iters, (0.008220)
Learning rate = [0.007996458173362085, 0.007996458173362085]	Loss = 0.85947770 (ave = 0.88043448)

2023-07-05 17:01:01,524 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8810	Time 12.382s / 10iters, (1.238)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.365s / 10iters, (0.836)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.084s / 10iters, (0.008352)
Learning rate = [0.007994151539696686, 0.007994151539696686]	Loss = 0.81569254 (ave = 0.88637949)

2023-07-05 17:01:13,808 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8820	Time 12.285s / 10iters, (1.228)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007592)
Learning rate = [0.0079918448320782, 0.0079918448320782]	Loss = 0.94135797 (ave = 0.85939098)

2023-07-05 17:01:26,091 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8830	Time 12.282s / 10iters, (1.228)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.077s / 10iters, (0.007710)
Learning rate = [0.007989538050480537, 0.007989538050480537]	Loss = 0.78746319 (ave = 0.90998794)

2023-07-05 17:01:38,468 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8840	Time 12.377s / 10iters, (1.238)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.330s / 10iters, (0.833)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.087s / 10iters, (0.008658)
Learning rate = [0.007987231194877596, 0.007987231194877596]	Loss = 0.94963849 (ave = 0.92099717)

2023-07-05 17:01:50,895 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8850	Time 12.427s / 10iters, (1.243)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.362s / 10iters, (0.836)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.085s / 10iters, (0.008526)
Learning rate = [0.007984924265243247, 0.007984924265243247]	Loss = 0.79824382 (ave = 0.86687304)

2023-07-05 17:02:03,406 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8860	Time 12.511s / 10iters, (1.251)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.389s / 10iters, (0.839)	Loss Time 2.915s / 10iters, (0.291)	Data load 0.080s / 10iters, (0.007992)
Learning rate = [0.00798261726155135, 0.00798261726155135]	Loss = 0.89332330 (ave = 0.89712899)

2023-07-05 17:02:15,643 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8870	Time 12.237s / 10iters, (1.224)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.081s / 10iters, (0.008117)
Learning rate = [0.007980310183775744, 0.007980310183775744]	Loss = 0.77016884 (ave = 0.88780904)

2023-07-05 17:02:27,988 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8880	Time 12.345s / 10iters, (1.235)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.292s / 10iters, (0.829)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.084s / 10iters, (0.008390)
Learning rate = [0.00797800303189025, 0.00797800303189025]	Loss = 0.80877405 (ave = 0.87263390)

2023-07-05 17:02:40,192 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8890	Time 12.204s / 10iters, (1.220)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.250s / 10iters, (0.825)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007451)
Learning rate = [0.007975695805868675, 0.007975695805868675]	Loss = 0.79840118 (ave = 0.85791777)

2023-07-05 17:02:52,225 INFO    [trainer_contrastive.py, 272] Train Epoch: 23	Train Iteration: 8900	Time 12.033s / 10iters, (1.203)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.149s / 10iters, (0.815)	Loss Time 2.710s / 10iters, (0.271)	Data load 0.078s / 10iters, (0.007811)
Learning rate = [0.007973388505684806, 0.007973388505684806]	Loss = 0.97573185 (ave = 0.79992458)

2023-07-05 17:03:07,340 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 8910	Time 14.955s / 10iters, (1.495)	Forward Time 1.301s / 10iters, (0.130)	Backward Time 8.361s / 10iters, (0.836)	Loss Time 2.736s / 10iters, (0.274)	Data load 2.556s / 10iters, (0.255636)
Learning rate = [0.00797108113131241, 0.00797108113131241]	Loss = 1.50176430 (ave = 0.91425863)

2023-07-05 17:03:19,554 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 8920	Time 12.214s / 10iters, (1.221)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.270s / 10iters, (0.827)	Loss Time 2.733s / 10iters, (0.273)	Data load 0.078s / 10iters, (0.007786)
Learning rate = [0.007968773682725243, 0.007968773682725243]	Loss = 1.01685286 (ave = 0.85769900)

2023-07-05 17:03:31,960 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 8930	Time 12.405s / 10iters, (1.241)	Forward Time 1.138s / 10iters, (0.114)	Backward Time 8.425s / 10iters, (0.842)	Loss Time 2.744s / 10iters, (0.274)	Data load 0.098s / 10iters, (0.009795)
Learning rate = [0.007966466159897037, 0.007966466159897037]	Loss = 0.77025259 (ave = 0.88115981)

2023-07-05 17:03:44,318 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 8940	Time 12.359s / 10iters, (1.236)	Forward Time 1.137s / 10iters, (0.114)	Backward Time 8.357s / 10iters, (0.836)	Loss Time 2.785s / 10iters, (0.278)	Data load 0.079s / 10iters, (0.007863)
Learning rate = [0.007964158562801506, 0.007964158562801506]	Loss = 0.90495938 (ave = 0.86824390)

2023-07-05 17:03:56,535 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 8950	Time 12.217s / 10iters, (1.222)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.281s / 10iters, (0.828)	Loss Time 2.758s / 10iters, (0.276)	Data load 0.082s / 10iters, (0.008168)
Learning rate = [0.007961850891412351, 0.007961850891412351]	Loss = 0.86987299 (ave = 0.83537121)

2023-07-05 17:04:08,737 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 8960	Time 12.202s / 10iters, (1.220)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.081s / 10iters, (0.008089)
Learning rate = [0.00795954314570325, 0.00795954314570325]	Loss = 0.68609864 (ave = 0.84980767)

2023-07-05 17:04:21,066 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 8970	Time 12.328s / 10iters, (1.233)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.319s / 10iters, (0.832)	Loss Time 2.833s / 10iters, (0.283)	Data load 0.084s / 10iters, (0.008388)
Learning rate = [0.00795723532564787, 0.00795723532564787]	Loss = 0.90692091 (ave = 0.88603306)

2023-07-05 17:04:33,450 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 8980	Time 12.385s / 10iters, (1.238)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.348s / 10iters, (0.835)	Loss Time 2.855s / 10iters, (0.285)	Data load 0.079s / 10iters, (0.007939)
Learning rate = [0.007954927431219852, 0.007954927431219852]	Loss = 0.72329032 (ave = 0.82631718)

2023-07-05 17:04:45,819 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 8990	Time 12.368s / 10iters, (1.237)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.323s / 10iters, (0.832)	Loss Time 2.833s / 10iters, (0.283)	Data load 0.091s / 10iters, (0.009082)
Learning rate = [0.007952619462392823, 0.007952619462392823]	Loss = 0.82887948 (ave = 0.83758351)

2023-07-05 17:04:58,215 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9000	Time 12.397s / 10iters, (1.240)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.909s / 10iters, (0.291)	Data load 0.075s / 10iters, (0.007502)
Learning rate = [0.007950311419140396, 0.007950311419140396]	Loss = 0.88130969 (ave = 0.88039860)

2023-07-05 17:05:02,986 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 17:05:26,841 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 17:05:50,232 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 17:06:13,494 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 17:06:36,753 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 17:06:59,662 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 17:07:22,192 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 17:07:27,966 INFO    [base.py, 84] Performance 0.6912862842038408 -> 0.7105715709605773
2023-07-05 17:07:33,515 INFO    [trainer_contrastive.py, 391] Test Time 149.573s, (2.374)	Loss 0.15929674

2023-07-05 17:07:33,516 INFO    [base.py, 33] Result for seg
2023-07-05 17:07:33,517 INFO    [base.py, 49] Mean IOU: 0.7105715709605773

2023-07-05 17:07:33,517 INFO    [base.py, 50] Pixel ACC: 0.9489951548839491

2023-07-05 17:07:45,591 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9010	Time 167.375s / 10iters, (16.738)	Forward Time 1.161s / 10iters, (0.116)	Backward Time 8.182s / 10iters, (0.818)	Loss Time 2.641s / 10iters, (0.264)	Data load 155.391s / 10iters, (15.539096)
Learning rate = [0.007948003301436161, 0.007948003301436161]	Loss = 0.77546191 (ave = 0.86323653)

2023-07-05 17:07:57,460 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9020	Time 11.869s / 10iters, (1.187)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.098s / 10iters, (0.810)	Loss Time 2.590s / 10iters, (0.259)	Data load 0.075s / 10iters, (0.007464)
Learning rate = [0.00794569510925369, 0.00794569510925369]	Loss = 0.91255486 (ave = 0.82227944)

2023-07-05 17:08:09,351 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9030	Time 11.891s / 10iters, (1.189)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.090s / 10iters, (0.809)	Loss Time 2.628s / 10iters, (0.263)	Data load 0.078s / 10iters, (0.007822)
Learning rate = [0.00794338684256654, 0.00794338684256654]	Loss = 0.82869208 (ave = 0.87523670)

2023-07-05 17:08:21,415 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9040	Time 12.064s / 10iters, (1.206)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.688s / 10iters, (0.269)	Data load 0.092s / 10iters, (0.009158)
Learning rate = [0.007941078501348245, 0.007941078501348245]	Loss = 0.80492026 (ave = 0.85985691)

2023-07-05 17:08:33,670 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9050	Time 12.256s / 10iters, (1.226)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.281s / 10iters, (0.828)	Loss Time 2.777s / 10iters, (0.278)	Data load 0.079s / 10iters, (0.007895)
Learning rate = [0.007938770085572332, 0.007938770085572332]	Loss = 1.13951266 (ave = 0.88138220)

2023-07-05 17:08:45,936 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9060	Time 12.265s / 10iters, (1.227)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.255s / 10iters, (0.826)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.084s / 10iters, (0.008378)
Learning rate = [0.007936461595212297, 0.007936461595212297]	Loss = 0.87209165 (ave = 0.90905979)

2023-07-05 17:08:58,132 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9070	Time 12.196s / 10iters, (1.220)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.219s / 10iters, (0.822)	Loss Time 2.786s / 10iters, (0.279)	Data load 0.082s / 10iters, (0.008170)
Learning rate = [0.007934153030241625, 0.007934153030241625]	Loss = 0.79468119 (ave = 0.87722724)

2023-07-05 17:09:10,377 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9080	Time 12.245s / 10iters, (1.224)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.101s / 10iters, (0.010057)
Learning rate = [0.007931844390633783, 0.007931844390633783]	Loss = 0.75852919 (ave = 0.85241638)

2023-07-05 17:09:22,649 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9090	Time 12.272s / 10iters, (1.227)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.243s / 10iters, (0.824)	Loss Time 2.848s / 10iters, (0.285)	Data load 0.078s / 10iters, (0.007823)
Learning rate = [0.007929535676362218, 0.007929535676362218]	Loss = 1.15556085 (ave = 0.93574179)

2023-07-05 17:09:34,866 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9100	Time 12.217s / 10iters, (1.222)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.077s / 10iters, (0.007726)
Learning rate = [0.007927226887400359, 0.007927226887400359]	Loss = 0.88107419 (ave = 0.86680815)

2023-07-05 17:09:47,058 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9110	Time 12.192s / 10iters, (1.219)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.157s / 10iters, (0.816)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007536)
Learning rate = [0.007924918023721618, 0.007924918023721618]	Loss = 0.83398795 (ave = 0.88077987)

2023-07-05 17:09:59,176 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9120	Time 12.118s / 10iters, (1.212)	Forward Time 1.084s / 10iters, (0.108)	Backward Time 8.161s / 10iters, (0.816)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.073s / 10iters, (0.007339)
Learning rate = [0.007922609085299388, 0.007922609085299388]	Loss = 0.83729821 (ave = 0.84371749)

2023-07-05 17:10:11,338 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9130	Time 12.162s / 10iters, (1.216)	Forward Time 1.084s / 10iters, (0.108)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007444)
Learning rate = [0.007920300072107048, 0.007920300072107048]	Loss = 0.81526142 (ave = 0.80771679)

2023-07-05 17:10:23,462 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9140	Time 12.124s / 10iters, (1.212)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.146s / 10iters, (0.815)	Loss Time 2.818s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007357)
Learning rate = [0.00791799098411795, 0.00791799098411795]	Loss = 0.74620855 (ave = 0.78842917)

2023-07-05 17:10:35,655 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9150	Time 12.193s / 10iters, (1.219)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.192s / 10iters, (0.819)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007416)
Learning rate = [0.007915681821305438, 0.007915681821305438]	Loss = 0.86805409 (ave = 0.84287333)

2023-07-05 17:10:47,927 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9160	Time 12.272s / 10iters, (1.227)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007486)
Learning rate = [0.007913372583642829, 0.007913372583642829]	Loss = 0.86127841 (ave = 0.79227870)

2023-07-05 17:11:00,174 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9170	Time 12.248s / 10iters, (1.225)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.865s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007399)
Learning rate = [0.00791106327110343, 0.00791106327110343]	Loss = 0.79379678 (ave = 0.80797455)

2023-07-05 17:11:12,508 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9180	Time 12.333s / 10iters, (1.233)	Forward Time 1.084s / 10iters, (0.108)	Backward Time 8.345s / 10iters, (0.835)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007443)
Learning rate = [0.007908753883660522, 0.007908753883660522]	Loss = 0.77809513 (ave = 0.82683076)

2023-07-05 17:11:24,797 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9190	Time 12.289s / 10iters, (1.229)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.873s / 10iters, (0.287)	Data load 0.082s / 10iters, (0.008229)
Learning rate = [0.007906444421287375, 0.007906444421287375]	Loss = 0.71786493 (ave = 0.82158338)

2023-07-05 17:11:37,093 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9200	Time 12.296s / 10iters, (1.230)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.081s / 10iters, (0.008051)
Learning rate = [0.007904134883957234, 0.007904134883957234]	Loss = 0.81583458 (ave = 0.82534012)

2023-07-05 17:11:49,307 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9210	Time 12.214s / 10iters, (1.221)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.180s / 10iters, (0.818)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007567)
Learning rate = [0.00790182527164333, 0.00790182527164333]	Loss = 0.85521245 (ave = 0.84312134)

2023-07-05 17:12:01,593 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9220	Time 12.286s / 10iters, (1.229)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.223s / 10iters, (0.822)	Loss Time 2.877s / 10iters, (0.288)	Data load 0.090s / 10iters, (0.009010)
Learning rate = [0.007899515584318877, 0.007899515584318877]	Loss = 0.77549827 (ave = 0.85633424)

2023-07-05 17:12:13,929 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9230	Time 12.335s / 10iters, (1.234)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.298s / 10iters, (0.830)	Loss Time 2.868s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007427)
Learning rate = [0.007897205821957068, 0.007897205821957068]	Loss = 1.09403050 (ave = 0.90776713)

2023-07-05 17:12:26,106 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9240	Time 12.177s / 10iters, (1.218)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.809s / 10iters, (0.281)	Data load 0.087s / 10iters, (0.008660)
Learning rate = [0.007894895984531077, 0.007894895984531077]	Loss = 0.80182564 (ave = 0.85520073)

2023-07-05 17:12:38,448 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9250	Time 12.343s / 10iters, (1.234)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.329s / 10iters, (0.833)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.079s / 10iters, (0.007915)
Learning rate = [0.00789258607201406, 0.00789258607201406]	Loss = 0.80327207 (ave = 0.85968465)

2023-07-05 17:12:50,681 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9260	Time 12.233s / 10iters, (1.223)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.086s / 10iters, (0.008596)
Learning rate = [0.007890276084379156, 0.007890276084379156]	Loss = 0.82001078 (ave = 0.85670475)

2023-07-05 17:13:02,837 INFO    [trainer_contrastive.py, 272] Train Epoch: 24	Train Iteration: 9270	Time 12.155s / 10iters, (1.216)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.755s / 10iters, (0.275)	Data load 0.074s / 10iters, (0.007365)
Learning rate = [0.007887966021599488, 0.007887966021599488]	Loss = 0.89742202 (ave = 0.89198673)

2023-07-05 17:13:18,373 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9280	Time 15.326s / 10iters, (1.533)	Forward Time 1.275s / 10iters, (0.127)	Backward Time 8.437s / 10iters, (0.844)	Loss Time 2.778s / 10iters, (0.278)	Data load 2.836s / 10iters, (0.283645)
Learning rate = [0.007885655883648155, 0.007885655883648155]	Loss = 0.92104584 (ave = 0.82880765)

2023-07-05 17:13:30,647 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9290	Time 12.274s / 10iters, (1.227)	Forward Time 1.208s / 10iters, (0.121)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.673s / 10iters, (0.267)	Data load 0.077s / 10iters, (0.007654)
Learning rate = [0.00788334567049824, 0.00788334567049824]	Loss = 0.97113740 (ave = 0.84796547)

2023-07-05 17:13:43,098 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9300	Time 12.451s / 10iters, (1.245)	Forward Time 1.155s / 10iters, (0.116)	Backward Time 8.424s / 10iters, (0.842)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.088s / 10iters, (0.008829)
Learning rate = [0.007881035382122812, 0.007881035382122812]	Loss = 0.81194419 (ave = 0.80968477)

2023-07-05 17:13:55,594 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9310	Time 12.496s / 10iters, (1.250)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.435s / 10iters, (0.843)	Loss Time 2.861s / 10iters, (0.286)	Data load 0.077s / 10iters, (0.007738)
Learning rate = [0.007878725018494914, 0.007878725018494914]	Loss = 0.77676547 (ave = 0.77830213)

2023-07-05 17:14:08,121 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9320	Time 12.527s / 10iters, (1.253)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.453s / 10iters, (0.845)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007456)
Learning rate = [0.007876414579587576, 0.007876414579587576]	Loss = 0.76751053 (ave = 0.83546235)

2023-07-05 17:14:20,413 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9330	Time 12.291s / 10iters, (1.229)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.278s / 10iters, (0.828)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007606)
Learning rate = [0.007874104065373807, 0.007874104065373807]	Loss = 0.74913746 (ave = 0.81454418)

2023-07-05 17:14:32,783 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9340	Time 12.370s / 10iters, (1.237)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.351s / 10iters, (0.835)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.083s / 10iters, (0.008348)
Learning rate = [0.007871793475826599, 0.007871793475826599]	Loss = 0.81692576 (ave = 0.93775975)

2023-07-05 17:14:45,117 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9350	Time 12.334s / 10iters, (1.233)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.848s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007429)
Learning rate = [0.007869482810918923, 0.007869482810918923]	Loss = 0.94810545 (ave = 0.89556141)

2023-07-05 17:14:57,508 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9360	Time 12.391s / 10iters, (1.239)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.337s / 10iters, (0.834)	Loss Time 2.870s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007518)
Learning rate = [0.007867172070623735, 0.007867172070623735]	Loss = 0.83112705 (ave = 0.82222122)

2023-07-05 17:15:09,769 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9370	Time 12.261s / 10iters, (1.226)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007451)
Learning rate = [0.00786486125491397, 0.00786486125491397]	Loss = 0.81754887 (ave = 0.88901929)

2023-07-05 17:15:22,162 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9380	Time 12.392s / 10iters, (1.239)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.348s / 10iters, (0.835)	Loss Time 2.861s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007426)
Learning rate = [0.007862550363762546, 0.007862550363762546]	Loss = 0.76406348 (ave = 0.87788438)

2023-07-05 17:15:34,401 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9390	Time 12.239s / 10iters, (1.224)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.223s / 10iters, (0.822)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.083s / 10iters, (0.008314)
Learning rate = [0.007860239397142362, 0.007860239397142362]	Loss = 0.96843958 (ave = 0.85333004)

2023-07-05 17:15:46,761 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9400	Time 12.361s / 10iters, (1.236)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.872s / 10iters, (0.287)	Data load 0.091s / 10iters, (0.009101)
Learning rate = [0.007857928355026297, 0.007857928355026297]	Loss = 0.78621089 (ave = 0.94108110)

2023-07-05 17:15:59,160 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9410	Time 12.399s / 10iters, (1.240)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.329s / 10iters, (0.833)	Loss Time 2.868s / 10iters, (0.287)	Data load 0.100s / 10iters, (0.010024)
Learning rate = [0.00785561723738721, 0.00785561723738721]	Loss = 0.87011898 (ave = 0.88511752)

2023-07-05 17:16:11,503 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9420	Time 12.342s / 10iters, (1.234)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.297s / 10iters, (0.830)	Loss Time 2.874s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007448)
Learning rate = [0.007853306044197948, 0.007853306044197948]	Loss = 0.71233547 (ave = 0.83512121)

2023-07-05 17:16:23,838 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9430	Time 12.335s / 10iters, (1.233)	Forward Time 1.139s / 10iters, (0.114)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.805s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007431)
Learning rate = [0.007850994775431332, 0.007850994775431332]	Loss = 0.68136966 (ave = 0.79206699)

2023-07-05 17:16:36,198 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9440	Time 12.360s / 10iters, (1.236)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.292s / 10iters, (0.829)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.076s / 10iters, (0.007620)
Learning rate = [0.007848683431060169, 0.007848683431060169]	Loss = 0.98071980 (ave = 0.87500125)

2023-07-05 17:16:48,451 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9450	Time 12.253s / 10iters, (1.225)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.243s / 10iters, (0.824)	Loss Time 2.815s / 10iters, (0.281)	Data load 0.082s / 10iters, (0.008245)
Learning rate = [0.007846372011057248, 0.007846372011057248]	Loss = 0.84848285 (ave = 0.79205012)

2023-07-05 17:17:00,836 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9460	Time 12.385s / 10iters, (1.238)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.307s / 10iters, (0.831)	Loss Time 2.869s / 10iters, (0.287)	Data load 0.096s / 10iters, (0.009634)
Learning rate = [0.007844060515395332, 0.007844060515395332]	Loss = 0.87927973 (ave = 0.91838704)

2023-07-05 17:17:13,145 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9470	Time 12.309s / 10iters, (1.231)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.855s / 10iters, (0.286)	Data load 0.094s / 10iters, (0.009393)
Learning rate = [0.007841748944047176, 0.007841748944047176]	Loss = 0.76234061 (ave = 0.80218359)

2023-07-05 17:17:25,621 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9480	Time 12.476s / 10iters, (1.248)	Forward Time 1.152s / 10iters, (0.115)	Backward Time 8.366s / 10iters, (0.837)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007539)
Learning rate = [0.007839437296985505, 0.007839437296985505]	Loss = 0.80788904 (ave = 0.85691149)

2023-07-05 17:17:38,240 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9490	Time 12.618s / 10iters, (1.262)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.487s / 10iters, (0.849)	Loss Time 2.928s / 10iters, (0.293)	Data load 0.076s / 10iters, (0.007591)
Learning rate = [0.007837125574183033, 0.007837125574183033]	Loss = 0.93945444 (ave = 0.86335894)

2023-07-05 17:17:50,656 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9500	Time 12.416s / 10iters, (1.242)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.299s / 10iters, (0.830)	Loss Time 2.919s / 10iters, (0.292)	Data load 0.089s / 10iters, (0.008940)
Learning rate = [0.007834813775612456, 0.007834813775612456]	Loss = 0.93516278 (ave = 0.84115433)

2023-07-05 17:18:03,058 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9510	Time 12.403s / 10iters, (1.240)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.322s / 10iters, (0.832)	Loss Time 2.852s / 10iters, (0.285)	Data load 0.112s / 10iters, (0.011176)
Learning rate = [0.007832501901246444, 0.007832501901246444]	Loss = 0.92215443 (ave = 0.85572585)

2023-07-05 17:18:15,323 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9520	Time 12.265s / 10iters, (1.226)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007419)
Learning rate = [0.007830189951057654, 0.007830189951057654]	Loss = 0.88543993 (ave = 0.82456706)

2023-07-05 17:18:27,678 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9530	Time 12.355s / 10iters, (1.236)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.313s / 10iters, (0.831)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.079s / 10iters, (0.007902)
Learning rate = [0.007827877925018722, 0.007827877925018722]	Loss = 0.85872555 (ave = 0.78913277)

2023-07-05 17:18:39,977 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9540	Time 12.298s / 10iters, (1.230)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.092s / 10iters, (0.009225)
Learning rate = [0.007825565823102268, 0.007825565823102268]	Loss = 0.74582756 (ave = 0.83322484)

2023-07-05 17:18:52,329 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9550	Time 12.353s / 10iters, (1.235)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.091s / 10iters, (0.009083)
Learning rate = [0.007823253645280888, 0.007823253645280888]	Loss = 0.83423108 (ave = 0.89077884)

2023-07-05 17:19:04,795 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9560	Time 12.466s / 10iters, (1.247)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.429s / 10iters, (0.843)	Loss Time 2.862s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007481)
Learning rate = [0.007820941391527166, 0.007820941391527166]	Loss = 0.83118969 (ave = 0.86415612)

2023-07-05 17:19:17,069 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9570	Time 12.274s / 10iters, (1.227)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007540)
Learning rate = [0.007818629061813657, 0.007818629061813657]	Loss = 0.82027560 (ave = 0.78471011)

2023-07-05 17:19:29,411 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9580	Time 12.342s / 10iters, (1.234)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.265s / 10iters, (0.827)	Loss Time 2.885s / 10iters, (0.288)	Data load 0.085s / 10iters, (0.008544)
Learning rate = [0.007816316656112907, 0.007816316656112907]	Loss = 0.93615663 (ave = 0.93480002)

2023-07-05 17:19:41,678 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9590	Time 12.268s / 10iters, (1.227)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007472)
Learning rate = [0.00781400417439744, 0.00781400417439744]	Loss = 0.82427382 (ave = 0.87404537)

2023-07-05 17:19:53,894 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9600	Time 12.216s / 10iters, (1.222)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.176s / 10iters, (0.818)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.079s / 10iters, (0.007899)
Learning rate = [0.0078116916166397566, 0.0078116916166397566]	Loss = 0.88872409 (ave = 0.84140132)

2023-07-05 17:20:06,188 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9610	Time 12.294s / 10iters, (1.229)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.228s / 10iters, (0.823)	Loss Time 2.848s / 10iters, (0.285)	Data load 0.099s / 10iters, (0.009875)
Learning rate = [0.007809378982812345, 0.007809378982812345]	Loss = 0.78614682 (ave = 0.85629402)

2023-07-05 17:20:18,442 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9620	Time 12.254s / 10iters, (1.225)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.086s / 10iters, (0.008577)
Learning rate = [0.0078070662728876705, 0.0078070662728876705]	Loss = 0.83333468 (ave = 0.82272744)

2023-07-05 17:20:30,616 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9630	Time 12.174s / 10iters, (1.217)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.189s / 10iters, (0.819)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007435)
Learning rate = [0.007804753486838181, 0.007804753486838181]	Loss = 0.93406940 (ave = 0.89229441)

2023-07-05 17:20:42,736 INFO    [trainer_contrastive.py, 272] Train Epoch: 25	Train Iteration: 9640	Time 12.120s / 10iters, (1.212)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.178s / 10iters, (0.818)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007483)
Learning rate = [0.0078024406246363035, 0.0078024406246363035]	Loss = 0.81176293 (ave = 0.82118897)

2023-07-05 17:20:57,925 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9650	Time 15.003s / 10iters, (1.500)	Forward Time 1.277s / 10iters, (0.128)	Backward Time 8.333s / 10iters, (0.833)	Loss Time 2.707s / 10iters, (0.271)	Data load 2.685s / 10iters, (0.268473)
Learning rate = [0.007800127686254446, 0.007800127686254446]	Loss = 0.78300285 (ave = 0.89202328)

2023-07-05 17:21:10,178 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9660	Time 12.252s / 10iters, (1.225)	Forward Time 1.155s / 10iters, (0.116)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.725s / 10iters, (0.272)	Data load 0.077s / 10iters, (0.007675)
Learning rate = [0.007797814671665, 0.007797814671665]	Loss = 0.86686587 (ave = 0.90621980)

2023-07-05 17:21:22,373 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9670	Time 12.196s / 10iters, (1.220)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007628)
Learning rate = [0.007795501580840337, 0.007795501580840337]	Loss = 0.95367265 (ave = 0.87765599)

2023-07-05 17:21:34,631 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9680	Time 12.257s / 10iters, (1.226)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.084s / 10iters, (0.008384)
Learning rate = [0.007793188413752805, 0.007793188413752805]	Loss = 0.82390141 (ave = 0.83240955)

2023-07-05 17:21:46,956 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9690	Time 12.325s / 10iters, (1.233)	Forward Time 1.151s / 10iters, (0.115)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.777s / 10iters, (0.278)	Data load 0.106s / 10iters, (0.010596)
Learning rate = [0.007790875170374741, 0.007790875170374741]	Loss = 0.79637218 (ave = 0.85789533)

2023-07-05 17:21:59,508 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9700	Time 12.552s / 10iters, (1.255)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.447s / 10iters, (0.845)	Loss Time 2.899s / 10iters, (0.290)	Data load 0.086s / 10iters, (0.008592)
Learning rate = [0.007788561850678458, 0.007788561850678458]	Loss = 0.92709076 (ave = 0.80709562)

2023-07-05 17:22:11,886 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9710	Time 12.378s / 10iters, (1.238)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.134s / 10iters, (0.013410)
Learning rate = [0.007786248454636247, 0.007786248454636247]	Loss = 0.73614669 (ave = 0.80648758)

2023-07-05 17:22:24,309 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9720	Time 12.423s / 10iters, (1.242)	Forward Time 1.145s / 10iters, (0.114)	Backward Time 8.409s / 10iters, (0.841)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.090s / 10iters, (0.008971)
Learning rate = [0.007783934982220384, 0.007783934982220384]	Loss = 0.81571889 (ave = 0.79495354)

2023-07-05 17:22:36,736 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9730	Time 12.426s / 10iters, (1.243)	Forward Time 1.153s / 10iters, (0.115)	Backward Time 8.405s / 10iters, (0.841)	Loss Time 2.766s / 10iters, (0.277)	Data load 0.102s / 10iters, (0.010202)
Learning rate = [0.007781621433403127, 0.007781621433403127]	Loss = 0.90115696 (ave = 0.88475262)

2023-07-05 17:22:49,216 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9740	Time 12.481s / 10iters, (1.248)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.401s / 10iters, (0.840)	Loss Time 2.845s / 10iters, (0.285)	Data load 0.108s / 10iters, (0.010839)
Learning rate = [0.007779307808156709, 0.007779307808156709]	Loss = 0.85080117 (ave = 0.83186346)

2023-07-05 17:23:01,605 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9750	Time 12.389s / 10iters, (1.239)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.372s / 10iters, (0.837)	Loss Time 2.789s / 10iters, (0.279)	Data load 0.097s / 10iters, (0.009668)
Learning rate = [0.007776994106453351, 0.007776994106453351]	Loss = 0.86140823 (ave = 0.84320422)

2023-07-05 17:23:13,988 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9760	Time 12.383s / 10iters, (1.238)	Forward Time 1.147s / 10iters, (0.115)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.082s / 10iters, (0.008237)
Learning rate = [0.007774680328265248, 0.007774680328265248]	Loss = 0.80505252 (ave = 0.82988126)

2023-07-05 17:23:26,538 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9770	Time 12.550s / 10iters, (1.255)	Forward Time 1.150s / 10iters, (0.115)	Backward Time 8.463s / 10iters, (0.846)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.104s / 10iters, (0.010426)
Learning rate = [0.007772366473564579, 0.007772366473564579]	Loss = 0.84147310 (ave = 0.85273697)

2023-07-05 17:23:39,013 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9780	Time 12.475s / 10iters, (1.248)	Forward Time 1.136s / 10iters, (0.114)	Backward Time 8.405s / 10iters, (0.840)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.094s / 10iters, (0.009388)
Learning rate = [0.007770052542323506, 0.007770052542323506]	Loss = 0.79278803 (ave = 0.83256503)

2023-07-05 17:23:51,399 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9790	Time 12.386s / 10iters, (1.239)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.388s / 10iters, (0.839)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007448)
Learning rate = [0.007767738534514166, 0.007767738534514166]	Loss = 0.86622792 (ave = 0.84282584)

2023-07-05 17:24:03,820 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9800	Time 12.421s / 10iters, (1.242)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.345s / 10iters, (0.834)	Loss Time 2.877s / 10iters, (0.288)	Data load 0.100s / 10iters, (0.010043)
Learning rate = [0.00776542445010868, 0.00776542445010868]	Loss = 0.90736622 (ave = 0.89558533)

2023-07-05 17:24:16,242 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9810	Time 12.422s / 10iters, (1.242)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.319s / 10iters, (0.832)	Loss Time 2.890s / 10iters, (0.289)	Data load 0.092s / 10iters, (0.009209)
Learning rate = [0.00776311028907915, 0.00776311028907915]	Loss = 1.04645550 (ave = 0.83792470)

2023-07-05 17:24:28,638 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9820	Time 12.395s / 10iters, (1.240)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.889s / 10iters, (0.289)	Data load 0.084s / 10iters, (0.008421)
Learning rate = [0.007760796051397657, 0.007760796051397657]	Loss = 0.93557286 (ave = 0.84100443)

2023-07-05 17:24:41,253 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9830	Time 12.616s / 10iters, (1.262)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.507s / 10iters, (0.851)	Loss Time 2.922s / 10iters, (0.292)	Data load 0.074s / 10iters, (0.007419)
Learning rate = [0.007758481737036265, 0.007758481737036265]	Loss = 0.84323049 (ave = 0.82262344)

2023-07-05 17:24:53,745 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9840	Time 12.492s / 10iters, (1.249)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.382s / 10iters, (0.838)	Loss Time 2.921s / 10iters, (0.292)	Data load 0.088s / 10iters, (0.008819)
Learning rate = [0.007756167345967014, 0.007756167345967014]	Loss = 0.76106375 (ave = 0.84687778)

2023-07-05 17:25:06,236 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9850	Time 12.491s / 10iters, (1.249)	Forward Time 1.150s / 10iters, (0.115)	Backward Time 8.364s / 10iters, (0.836)	Loss Time 2.895s / 10iters, (0.290)	Data load 0.082s / 10iters, (0.008211)
Learning rate = [0.0077538528781619315, 0.0077538528781619315]	Loss = 0.89763129 (ave = 0.82859893)

2023-07-05 17:25:18,579 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9860	Time 12.343s / 10iters, (1.234)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.861s / 10iters, (0.286)	Data load 0.080s / 10iters, (0.007952)
Learning rate = [0.0077515383335930175, 0.0077515383335930175]	Loss = 0.78250605 (ave = 0.79482757)

2023-07-05 17:25:31,191 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9870	Time 12.612s / 10iters, (1.261)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.515s / 10iters, (0.852)	Loss Time 2.907s / 10iters, (0.291)	Data load 0.087s / 10iters, (0.008667)
Learning rate = [0.00774922371223226, 0.00774922371223226]	Loss = 0.75514281 (ave = 0.82037567)

2023-07-05 17:25:43,638 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9880	Time 12.447s / 10iters, (1.245)	Forward Time 1.142s / 10iters, (0.114)	Backward Time 8.338s / 10iters, (0.834)	Loss Time 2.879s / 10iters, (0.288)	Data load 0.087s / 10iters, (0.008686)
Learning rate = [0.007746909014051621, 0.007746909014051621]	Loss = 0.84654772 (ave = 0.81362075)

2023-07-05 17:25:56,165 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9890	Time 12.527s / 10iters, (1.253)	Forward Time 1.145s / 10iters, (0.114)	Backward Time 8.432s / 10iters, (0.843)	Loss Time 2.870s / 10iters, (0.287)	Data load 0.080s / 10iters, (0.007989)
Learning rate = [0.007744594239023046, 0.007744594239023046]	Loss = 0.75748605 (ave = 0.83283372)

2023-07-05 17:26:08,718 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9900	Time 12.553s / 10iters, (1.255)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.461s / 10iters, (0.846)	Loss Time 2.884s / 10iters, (0.288)	Data load 0.085s / 10iters, (0.008456)
Learning rate = [0.007742279387118463, 0.007742279387118463]	Loss = 0.87104201 (ave = 0.90655325)

2023-07-05 17:26:21,192 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9910	Time 12.474s / 10iters, (1.247)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.359s / 10iters, (0.836)	Loss Time 2.917s / 10iters, (0.292)	Data load 0.086s / 10iters, (0.008612)
Learning rate = [0.0077399644583097775, 0.0077399644583097775]	Loss = 0.84674168 (ave = 0.82986956)

2023-07-05 17:26:33,841 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9920	Time 12.649s / 10iters, (1.265)	Forward Time 1.163s / 10iters, (0.116)	Backward Time 8.495s / 10iters, (0.849)	Loss Time 2.905s / 10iters, (0.290)	Data load 0.086s / 10iters, (0.008636)
Learning rate = [0.007737649452568875, 0.007737649452568875]	Loss = 0.83602262 (ave = 0.81865777)

2023-07-05 17:26:46,448 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9930	Time 12.607s / 10iters, (1.261)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.441s / 10iters, (0.844)	Loss Time 2.967s / 10iters, (0.297)	Data load 0.078s / 10iters, (0.007829)
Learning rate = [0.007735334369867623, 0.007735334369867623]	Loss = 0.68624789 (ave = 0.82504917)

2023-07-05 17:26:59,039 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9940	Time 12.591s / 10iters, (1.259)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.527s / 10iters, (0.853)	Loss Time 2.884s / 10iters, (0.288)	Data load 0.080s / 10iters, (0.008035)
Learning rate = [0.00773301921017787, 0.00773301921017787]	Loss = 0.76889783 (ave = 0.81854012)

2023-07-05 17:27:11,659 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9950	Time 12.620s / 10iters, (1.262)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.499s / 10iters, (0.850)	Loss Time 2.916s / 10iters, (0.292)	Data load 0.086s / 10iters, (0.008590)
Learning rate = [0.007730703973471443, 0.007730703973471443]	Loss = 0.77212840 (ave = 0.81042662)

2023-07-05 17:27:24,168 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9960	Time 12.509s / 10iters, (1.251)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.409s / 10iters, (0.841)	Loss Time 2.910s / 10iters, (0.291)	Data load 0.098s / 10iters, (0.009765)
Learning rate = [0.007728388659720149, 0.007728388659720149]	Loss = 1.56473708 (ave = 0.88324142)

2023-07-05 17:27:36,554 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9970	Time 12.386s / 10iters, (1.239)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.855s / 10iters, (0.286)	Data load 0.105s / 10iters, (0.010460)
Learning rate = [0.007726073268895777, 0.007726073268895777]	Loss = 0.78807795 (ave = 0.81727337)

2023-07-05 17:27:48,984 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9980	Time 12.430s / 10iters, (1.243)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.362s / 10iters, (0.836)	Loss Time 2.885s / 10iters, (0.288)	Data load 0.078s / 10iters, (0.007804)
Learning rate = [0.007723757800970096, 0.007723757800970096]	Loss = 0.81037366 (ave = 0.85517235)

2023-07-05 17:28:01,440 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 9990	Time 12.456s / 10iters, (1.246)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.372s / 10iters, (0.837)	Loss Time 2.900s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007526)
Learning rate = [0.007721442255914855, 0.007721442255914855]	Loss = 0.84662664 (ave = 0.88864852)

2023-07-05 17:28:13,789 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 10000	Time 12.349s / 10iters, (1.235)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.285s / 10iters, (0.829)	Loss Time 2.877s / 10iters, (0.288)	Data load 0.090s / 10iters, (0.008996)
Learning rate = [0.007719126633701781, 0.007719126633701781]	Loss = 0.82108474 (ave = 0.85969937)

2023-07-05 17:28:17,689 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 17:28:42,458 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 17:29:05,917 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 17:29:29,633 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 17:29:53,077 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 17:30:16,132 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 17:30:38,765 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 17:30:47,634 INFO    [trainer_contrastive.py, 391] Test Time 150.732s, (2.393)	Loss 0.16864409

2023-07-05 17:30:47,635 INFO    [base.py, 33] Result for seg
2023-07-05 17:30:47,636 INFO    [base.py, 49] Mean IOU: 0.6961638532118856

2023-07-05 17:30:47,636 INFO    [base.py, 50] Pixel ACC: 0.946390144157715

2023-07-05 17:30:59,551 INFO    [trainer_contrastive.py, 272] Train Epoch: 26	Train Iteration: 10010	Time 165.762s / 10iters, (16.576)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.030s / 10iters, (0.803)	Loss Time 2.678s / 10iters, (0.268)	Data load 153.943s / 10iters, (15.394263)
Learning rate = [0.007716810934302587, 0.007716810934302587]	Loss = 0.88611352 (ave = 0.86096654)

2023-07-05 17:31:14,261 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10020	Time 14.519s / 10iters, (1.452)	Forward Time 1.184s / 10iters, (0.118)	Backward Time 8.101s / 10iters, (0.810)	Loss Time 2.652s / 10iters, (0.265)	Data load 2.581s / 10iters, (0.258090)
Learning rate = [0.007714495157688959, 0.007714495157688959]	Loss = 0.79838496 (ave = 0.81305531)

2023-07-05 17:31:26,462 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10030	Time 12.202s / 10iters, (1.220)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.701s / 10iters, (0.270)	Data load 0.095s / 10iters, (0.009470)
Learning rate = [0.007712179303832568, 0.007712179303832568]	Loss = 0.91463977 (ave = 0.84047223)

2023-07-05 17:31:38,707 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10040	Time 12.245s / 10iters, (1.224)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.085s / 10iters, (0.008511)
Learning rate = [0.007709863372705065, 0.007709863372705065]	Loss = 0.83001673 (ave = 0.84118927)

2023-07-05 17:31:50,874 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10050	Time 12.167s / 10iters, (1.217)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.227s / 10iters, (0.823)	Loss Time 2.735s / 10iters, (0.273)	Data load 0.077s / 10iters, (0.007670)
Learning rate = [0.007707547364278076, 0.007707547364278076]	Loss = 0.77190566 (ave = 0.84727956)

2023-07-05 17:32:03,117 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10060	Time 12.243s / 10iters, (1.224)	Forward Time 1.157s / 10iters, (0.116)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.086s / 10iters, (0.008603)
Learning rate = [0.007705231278523216, 0.007705231278523216]	Loss = 0.84434175 (ave = 0.81785514)

2023-07-05 17:32:15,304 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10070	Time 12.187s / 10iters, (1.219)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.742s / 10iters, (0.274)	Data load 0.091s / 10iters, (0.009132)
Learning rate = [0.007702915115412072, 0.007702915115412072]	Loss = 0.84329611 (ave = 0.79653237)

2023-07-05 17:32:27,480 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10080	Time 12.175s / 10iters, (1.218)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.673s / 10iters, (0.267)	Data load 0.095s / 10iters, (0.009463)
Learning rate = [0.007700598874916214, 0.007700598874916214]	Loss = 0.76320046 (ave = 0.84457107)

2023-07-05 17:32:39,608 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10090	Time 12.128s / 10iters, (1.213)	Forward Time 1.161s / 10iters, (0.116)	Backward Time 8.236s / 10iters, (0.824)	Loss Time 2.655s / 10iters, (0.265)	Data load 0.075s / 10iters, (0.007521)
Learning rate = [0.007698282557007195, 0.007698282557007195]	Loss = 0.80010945 (ave = 0.78521355)

2023-07-05 17:32:51,752 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10100	Time 12.145s / 10iters, (1.214)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.292s / 10iters, (0.829)	Loss Time 2.663s / 10iters, (0.266)	Data load 0.079s / 10iters, (0.007855)
Learning rate = [0.007695966161656542, 0.007695966161656542]	Loss = 0.83619064 (ave = 0.84009141)

2023-07-05 17:33:04,097 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10110	Time 12.345s / 10iters, (1.234)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.428s / 10iters, (0.843)	Loss Time 2.735s / 10iters, (0.273)	Data load 0.076s / 10iters, (0.007643)
Learning rate = [0.007693649688835766, 0.007693649688835766]	Loss = 0.78753865 (ave = 0.84826872)

2023-07-05 17:33:16,435 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10120	Time 12.338s / 10iters, (1.234)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.337s / 10iters, (0.834)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.089s / 10iters, (0.008925)
Learning rate = [0.007691333138516359, 0.007691333138516359]	Loss = 0.69494802 (ave = 0.78867834)

2023-07-05 17:33:28,672 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10130	Time 12.236s / 10iters, (1.224)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007442)
Learning rate = [0.0076890165106697885, 0.0076890165106697885]	Loss = 0.80596471 (ave = 0.80835632)

2023-07-05 17:33:40,998 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10140	Time 12.327s / 10iters, (1.233)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.084s / 10iters, (0.008376)
Learning rate = [0.007686699805267507, 0.007686699805267507]	Loss = 0.79237992 (ave = 0.83508337)

2023-07-05 17:33:53,328 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10150	Time 12.329s / 10iters, (1.233)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.275s / 10iters, (0.828)	Loss Time 2.852s / 10iters, (0.285)	Data load 0.091s / 10iters, (0.009112)
Learning rate = [0.007684383022280944, 0.007684383022280944]	Loss = 0.79577708 (ave = 0.78844302)

2023-07-05 17:34:05,644 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10160	Time 12.316s / 10iters, (1.232)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.098s / 10iters, (0.009766)
Learning rate = [0.007682066161681508, 0.007682066161681508]	Loss = 0.79149348 (ave = 0.80964440)

2023-07-05 17:34:18,066 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10170	Time 12.422s / 10iters, (1.242)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.388s / 10iters, (0.839)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.089s / 10iters, (0.008882)
Learning rate = [0.007679749223440592, 0.007679749223440592]	Loss = 0.92709714 (ave = 0.83167040)

2023-07-05 17:34:30,350 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10180	Time 12.285s / 10iters, (1.228)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.088s / 10iters, (0.008769)
Learning rate = [0.007677432207529562, 0.007677432207529562]	Loss = 0.97298235 (ave = 0.84846023)

2023-07-05 17:34:42,689 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10190	Time 12.339s / 10iters, (1.234)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.862s / 10iters, (0.286)	Data load 0.085s / 10iters, (0.008514)
Learning rate = [0.007675115113919769, 0.007675115113919769]	Loss = 0.88232756 (ave = 0.85123340)

2023-07-05 17:34:55,018 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10200	Time 12.329s / 10iters, (1.233)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.833s / 10iters, (0.283)	Data load 0.094s / 10iters, (0.009433)
Learning rate = [0.007672797942582544, 0.007672797942582544]	Loss = 0.89683676 (ave = 0.87219692)

2023-07-05 17:35:07,323 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10210	Time 12.305s / 10iters, (1.231)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.082s / 10iters, (0.008198)
Learning rate = [0.0076704806934891935, 0.0076704806934891935]	Loss = 0.76655579 (ave = 0.84832006)

2023-07-05 17:35:19,592 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10220	Time 12.268s / 10iters, (1.227)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.077s / 10iters, (0.007661)
Learning rate = [0.0076681633666110085, 0.0076681633666110085]	Loss = 0.72769278 (ave = 0.81443256)

2023-07-05 17:35:32,042 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10230	Time 12.450s / 10iters, (1.245)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.358s / 10iters, (0.836)	Loss Time 2.874s / 10iters, (0.287)	Data load 0.093s / 10iters, (0.009311)
Learning rate = [0.007665845961919257, 0.007665845961919257]	Loss = 0.82738101 (ave = 0.79280529)

2023-07-05 17:35:44,381 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10240	Time 12.339s / 10iters, (1.234)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.307s / 10iters, (0.831)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007437)
Learning rate = [0.007663528479385185, 0.007663528479385185]	Loss = 0.78148526 (ave = 0.81335099)

2023-07-05 17:35:56,673 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10250	Time 12.292s / 10iters, (1.229)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.275s / 10iters, (0.827)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.079s / 10iters, (0.007919)
Learning rate = [0.0076612109189800265, 0.0076612109189800265]	Loss = 0.90807700 (ave = 0.83574140)

2023-07-05 17:36:08,928 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10260	Time 12.255s / 10iters, (1.226)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007359)
Learning rate = [0.007658893280674982, 0.007658893280674982]	Loss = 0.88490468 (ave = 0.79970860)

2023-07-05 17:36:21,305 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10270	Time 12.377s / 10iters, (1.238)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.376s / 10iters, (0.838)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007626)
Learning rate = [0.007656575564441243, 0.007656575564441243]	Loss = 0.80629092 (ave = 0.82425475)

2023-07-05 17:36:33,549 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10280	Time 12.245s / 10iters, (1.224)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.734s / 10iters, (0.273)	Data load 0.103s / 10iters, (0.010275)
Learning rate = [0.007654257770249979, 0.007654257770249979]	Loss = 0.94026613 (ave = 0.85586313)

2023-07-05 17:36:45,846 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10290	Time 12.296s / 10iters, (1.230)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.366s / 10iters, (0.837)	Loss Time 2.732s / 10iters, (0.273)	Data load 0.098s / 10iters, (0.009822)
Learning rate = [0.007651939898072331, 0.007651939898072331]	Loss = 0.94109714 (ave = 0.85578449)

2023-07-05 17:36:58,115 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10300	Time 12.269s / 10iters, (1.227)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.323s / 10iters, (0.832)	Loss Time 2.738s / 10iters, (0.274)	Data load 0.098s / 10iters, (0.009777)
Learning rate = [0.007649621947879429, 0.007649621947879429]	Loss = 0.78123492 (ave = 0.83436888)

2023-07-05 17:37:10,305 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10310	Time 12.190s / 10iters, (1.219)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.097s / 10iters, (0.009651)
Learning rate = [0.00764730391964238, 0.00764730391964238]	Loss = 0.78375274 (ave = 0.90171106)

2023-07-05 17:37:22,592 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10320	Time 12.287s / 10iters, (1.229)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.325s / 10iters, (0.832)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.092s / 10iters, (0.009209)
Learning rate = [0.007644985813332266, 0.007644985813332266]	Loss = 0.95994085 (ave = 0.90124713)

2023-07-05 17:37:34,864 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10330	Time 12.271s / 10iters, (1.227)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.322s / 10iters, (0.832)	Loss Time 2.769s / 10iters, (0.277)	Data load 0.077s / 10iters, (0.007743)
Learning rate = [0.007642667628920156, 0.007642667628920156]	Loss = 0.80759978 (ave = 0.82267712)

2023-07-05 17:37:47,162 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10340	Time 12.299s / 10iters, (1.230)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.795s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007532)
Learning rate = [0.0076403493663770895, 0.0076403493663770895]	Loss = 0.92910981 (ave = 0.84533048)

2023-07-05 17:37:59,329 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10350	Time 12.167s / 10iters, (1.217)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.077s / 10iters, (0.007738)
Learning rate = [0.007638031025674096, 0.007638031025674096]	Loss = 0.79674524 (ave = 0.86535711)

2023-07-05 17:38:11,766 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10360	Time 12.436s / 10iters, (1.244)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.436s / 10iters, (0.844)	Loss Time 2.803s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007402)
Learning rate = [0.007635712606782175, 0.007635712606782175]	Loss = 0.95524418 (ave = 0.82930990)

2023-07-05 17:38:24,128 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10370	Time 12.363s / 10iters, (1.236)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.090s / 10iters, (0.009021)
Learning rate = [0.007633394109672311, 0.007633394109672311]	Loss = 0.72193277 (ave = 0.84768347)

2023-07-05 17:38:36,204 INFO    [trainer_contrastive.py, 272] Train Epoch: 27	Train Iteration: 10380	Time 12.076s / 10iters, (1.208)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.143s / 10iters, (0.814)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.074s / 10iters, (0.007390)
Learning rate = [0.007631075534315467, 0.007631075534315467]	Loss = 0.76681030 (ave = 0.86408088)

2023-07-05 17:38:51,161 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10390	Time 14.762s / 10iters, (1.476)	Forward Time 1.207s / 10iters, (0.121)	Backward Time 8.158s / 10iters, (0.816)	Loss Time 2.708s / 10iters, (0.271)	Data load 2.689s / 10iters, (0.268944)
Learning rate = [0.007628756880682585, 0.007628756880682585]	Loss = 0.84129649 (ave = 0.94029645)

2023-07-05 17:39:03,380 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10400	Time 12.219s / 10iters, (1.222)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.692s / 10iters, (0.269)	Data load 0.089s / 10iters, (0.008876)
Learning rate = [0.0076264381487445845, 0.0076264381487445845]	Loss = 0.90759945 (ave = 0.82893665)

2023-07-05 17:39:15,682 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10410	Time 12.301s / 10iters, (1.230)	Forward Time 1.147s / 10iters, (0.115)	Backward Time 8.334s / 10iters, (0.833)	Loss Time 2.709s / 10iters, (0.271)	Data load 0.111s / 10iters, (0.011064)
Learning rate = [0.007624119338472369, 0.007624119338472369]	Loss = 0.79656225 (ave = 0.82215502)

2023-07-05 17:39:28,023 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10420	Time 12.342s / 10iters, (1.234)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.094s / 10iters, (0.009411)
Learning rate = [0.007621800449836814, 0.007621800449836814]	Loss = 0.79578298 (ave = 0.87100008)

2023-07-05 17:39:40,408 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10430	Time 12.385s / 10iters, (1.238)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.361s / 10iters, (0.836)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007525)
Learning rate = [0.007619481482808783, 0.007619481482808783]	Loss = 0.84690094 (ave = 0.84128945)

2023-07-05 17:39:52,779 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10440	Time 12.370s / 10iters, (1.237)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.357s / 10iters, (0.836)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007602)
Learning rate = [0.007617162437359113, 0.007617162437359113]	Loss = 0.83374888 (ave = 0.82046148)

2023-07-05 17:40:05,020 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10450	Time 12.241s / 10iters, (1.224)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.735s / 10iters, (0.274)	Data load 0.086s / 10iters, (0.008596)
Learning rate = [0.0076148433134586215, 0.0076148433134586215]	Loss = 0.83609676 (ave = 0.83464123)

2023-07-05 17:40:17,433 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10460	Time 12.414s / 10iters, (1.241)	Forward Time 1.139s / 10iters, (0.114)	Backward Time 8.417s / 10iters, (0.842)	Loss Time 2.762s / 10iters, (0.276)	Data load 0.095s / 10iters, (0.009549)
Learning rate = [0.007612524111078107, 0.007612524111078107]	Loss = 0.78764677 (ave = 0.87095237)

2023-07-05 17:40:29,793 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10470	Time 12.359s / 10iters, (1.236)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.345s / 10iters, (0.835)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.095s / 10iters, (0.009539)
Learning rate = [0.007610204830188344, 0.007610204830188344]	Loss = 0.95056510 (ave = 0.82902332)

2023-07-05 17:40:42,256 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10480	Time 12.464s / 10iters, (1.246)	Forward Time 1.189s / 10iters, (0.119)	Backward Time 8.442s / 10iters, (0.844)	Loss Time 2.752s / 10iters, (0.275)	Data load 0.080s / 10iters, (0.007950)
Learning rate = [0.007607885470760089, 0.007607885470760089]	Loss = 1.06185102 (ave = 0.90026996)

2023-07-05 17:40:54,598 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10490	Time 12.342s / 10iters, (1.234)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.387s / 10iters, (0.839)	Loss Time 2.749s / 10iters, (0.275)	Data load 0.083s / 10iters, (0.008331)
Learning rate = [0.007605566032764078, 0.007605566032764078]	Loss = 0.85518861 (ave = 0.79315238)

2023-07-05 17:41:06,962 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10500	Time 12.365s / 10iters, (1.236)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.400s / 10iters, (0.840)	Loss Time 2.747s / 10iters, (0.275)	Data load 0.092s / 10iters, (0.009185)
Learning rate = [0.007603246516171023, 0.007603246516171023]	Loss = 0.85358667 (ave = 0.87626771)

2023-07-05 17:41:19,311 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10510	Time 12.349s / 10iters, (1.235)	Forward Time 1.136s / 10iters, (0.114)	Backward Time 8.383s / 10iters, (0.838)	Loss Time 2.747s / 10iters, (0.275)	Data load 0.082s / 10iters, (0.008237)
Learning rate = [0.007600926920951619, 0.007600926920951619]	Loss = 0.72029990 (ave = 0.84962482)

2023-07-05 17:41:31,696 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10520	Time 12.384s / 10iters, (1.238)	Forward Time 1.138s / 10iters, (0.114)	Backward Time 8.379s / 10iters, (0.838)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.086s / 10iters, (0.008615)
Learning rate = [0.007598607247076536, 0.007598607247076536]	Loss = 0.80435097 (ave = 0.81650433)

2023-07-05 17:41:44,126 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10530	Time 12.431s / 10iters, (1.243)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.404s / 10iters, (0.840)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007577)
Learning rate = [0.007596287494516426, 0.007596287494516426]	Loss = 0.87521702 (ave = 0.87369154)

2023-07-05 17:41:56,475 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10540	Time 12.349s / 10iters, (1.235)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.081s / 10iters, (0.008112)
Learning rate = [0.007593967663241921, 0.007593967663241921]	Loss = 0.86246943 (ave = 0.83447461)

2023-07-05 17:42:08,835 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10550	Time 12.359s / 10iters, (1.236)	Forward Time 1.148s / 10iters, (0.115)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.087s / 10iters, (0.008653)
Learning rate = [0.007591647753223629, 0.007591647753223629]	Loss = 0.87827075 (ave = 0.85953183)

2023-07-05 17:42:21,140 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10560	Time 12.306s / 10iters, (1.231)	Forward Time 1.138s / 10iters, (0.114)	Backward Time 8.228s / 10iters, (0.823)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.086s / 10iters, (0.008601)
Learning rate = [0.00758932776443214, 0.00758932776443214]	Loss = 0.84205055 (ave = 0.83887674)

2023-07-05 17:42:33,640 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10570	Time 12.500s / 10iters, (1.250)	Forward Time 1.141s / 10iters, (0.114)	Backward Time 8.361s / 10iters, (0.836)	Loss Time 2.904s / 10iters, (0.290)	Data load 0.095s / 10iters, (0.009479)
Learning rate = [0.007587007696838021, 0.007587007696838021]	Loss = 0.72908437 (ave = 0.86816151)

2023-07-05 17:42:46,089 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10580	Time 12.449s / 10iters, (1.245)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.388s / 10iters, (0.839)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.086s / 10iters, (0.008618)
Learning rate = [0.007584687550411817, 0.007584687550411817]	Loss = 0.88621247 (ave = 0.85481486)

2023-07-05 17:42:58,392 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10590	Time 12.302s / 10iters, (1.230)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.329s / 10iters, (0.833)	Loss Time 2.786s / 10iters, (0.279)	Data load 0.077s / 10iters, (0.007654)
Learning rate = [0.007582367325124056, 0.007582367325124056]	Loss = 0.77064204 (ave = 0.81862346)

2023-07-05 17:43:10,761 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10600	Time 12.369s / 10iters, (1.237)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.391s / 10iters, (0.839)	Loss Time 2.765s / 10iters, (0.276)	Data load 0.093s / 10iters, (0.009286)
Learning rate = [0.00758004702094524, 0.00758004702094524]	Loss = 0.83392990 (ave = 0.80541616)

2023-07-05 17:43:23,119 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10610	Time 12.358s / 10iters, (1.236)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.435s / 10iters, (0.844)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.075s / 10iters, (0.007517)
Learning rate = [0.007577726637845854, 0.007577726637845854]	Loss = 0.72303516 (ave = 0.77843834)

2023-07-05 17:43:35,449 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10620	Time 12.330s / 10iters, (1.233)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.372s / 10iters, (0.837)	Loss Time 2.750s / 10iters, (0.275)	Data load 0.083s / 10iters, (0.008282)
Learning rate = [0.007575406175796361, 0.007575406175796361]	Loss = 0.70142591 (ave = 0.78916836)

2023-07-05 17:43:47,830 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10630	Time 12.382s / 10iters, (1.238)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.342s / 10iters, (0.834)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007522)
Learning rate = [0.007573085634767201, 0.007573085634767201]	Loss = 0.83935249 (ave = 0.82912948)

2023-07-05 17:44:00,152 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10640	Time 12.322s / 10iters, (1.232)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.102s / 10iters, (0.010150)
Learning rate = [0.007570765014728793, 0.007570765014728793]	Loss = 0.78719729 (ave = 0.80514046)

2023-07-05 17:44:12,654 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10650	Time 12.502s / 10iters, (1.250)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.489s / 10iters, (0.849)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.084s / 10iters, (0.008384)
Learning rate = [0.00756844431565154, 0.00756844431565154]	Loss = 0.90283000 (ave = 0.83511735)

2023-07-05 17:44:24,876 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10660	Time 12.222s / 10iters, (1.222)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.747s / 10iters, (0.275)	Data load 0.083s / 10iters, (0.008269)
Learning rate = [0.007566123537505814, 0.007566123537505814]	Loss = 0.85320097 (ave = 0.82904829)

2023-07-05 17:44:37,082 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10670	Time 12.206s / 10iters, (1.221)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.732s / 10iters, (0.273)	Data load 0.075s / 10iters, (0.007481)
Learning rate = [0.0075638026802619775, 0.0075638026802619775]	Loss = 0.92612326 (ave = 0.87308467)

2023-07-05 17:44:49,309 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10680	Time 12.228s / 10iters, (1.223)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.757s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007378)
Learning rate = [0.007561481743890363, 0.007561481743890363]	Loss = 0.89261144 (ave = 0.86715986)

2023-07-05 17:45:01,621 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10690	Time 12.312s / 10iters, (1.231)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.376s / 10iters, (0.838)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007456)
Learning rate = [0.007559160728361283, 0.007559160728361283]	Loss = 0.97530842 (ave = 0.92824509)

2023-07-05 17:45:14,036 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10700	Time 12.415s / 10iters, (1.241)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.446s / 10iters, (0.845)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.077s / 10iters, (0.007698)
Learning rate = [0.007556839633645033, 0.007556839633645033]	Loss = 0.74518383 (ave = 0.84951800)

2023-07-05 17:45:26,321 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10710	Time 12.285s / 10iters, (1.228)	Forward Time 1.172s / 10iters, (0.117)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.716s / 10iters, (0.272)	Data load 0.101s / 10iters, (0.010117)
Learning rate = [0.007554518459711884, 0.007554518459711884]	Loss = 0.77730983 (ave = 0.82521692)

2023-07-05 17:45:38,747 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10720	Time 12.426s / 10iters, (1.243)	Forward Time 1.157s / 10iters, (0.116)	Backward Time 8.412s / 10iters, (0.841)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.086s / 10iters, (0.008606)
Learning rate = [0.007552197206532083, 0.007552197206532083]	Loss = 0.88832313 (ave = 0.84398279)

2023-07-05 17:45:51,020 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10730	Time 12.273s / 10iters, (1.227)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.336s / 10iters, (0.834)	Loss Time 2.710s / 10iters, (0.271)	Data load 0.094s / 10iters, (0.009402)
Learning rate = [0.007549875874075865, 0.007549875874075865]	Loss = 0.87103927 (ave = 0.86621297)

2023-07-05 17:46:03,413 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10740	Time 12.393s / 10iters, (1.239)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.386s / 10iters, (0.839)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.095s / 10iters, (0.009543)
Learning rate = [0.007547554462313432, 0.007547554462313432]	Loss = 0.70246053 (ave = 0.83974257)

2023-07-05 17:46:15,669 INFO    [trainer_contrastive.py, 272] Train Epoch: 28	Train Iteration: 10750	Time 12.256s / 10iters, (1.226)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.292s / 10iters, (0.829)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.078s / 10iters, (0.007773)
Learning rate = [0.007545232971214973, 0.007545232971214973]	Loss = 0.82245982 (ave = 0.79885905)

2023-07-05 17:46:30,621 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10760	Time 14.791s / 10iters, (1.479)	Forward Time 1.235s / 10iters, (0.123)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.725s / 10iters, (0.273)	Data load 2.616s / 10iters, (0.261589)
Learning rate = [0.0075429114007506525, 0.0075429114007506525]	Loss = 0.97377777 (ave = 1.03716446)

2023-07-05 17:46:42,935 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10770	Time 12.314s / 10iters, (1.231)	Forward Time 1.216s / 10iters, (0.122)	Backward Time 8.305s / 10iters, (0.830)	Loss Time 2.709s / 10iters, (0.271)	Data load 0.084s / 10iters, (0.008406)
Learning rate = [0.007540589750890612, 0.007540589750890612]	Loss = 0.80635971 (ave = 0.92329494)

2023-07-05 17:46:55,164 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10780	Time 12.228s / 10iters, (1.223)	Forward Time 1.140s / 10iters, (0.114)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007523)
Learning rate = [0.007538268021604976, 0.007538268021604976]	Loss = 0.98602319 (ave = 0.86385462)

2023-07-05 17:47:07,480 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10790	Time 12.316s / 10iters, (1.232)	Forward Time 1.149s / 10iters, (0.115)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.809s / 10iters, (0.281)	Data load 0.112s / 10iters, (0.011208)
Learning rate = [0.007535946212863844, 0.007535946212863844]	Loss = 0.95628214 (ave = 0.87050297)

2023-07-05 17:47:19,954 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10800	Time 12.474s / 10iters, (1.247)	Forward Time 1.144s / 10iters, (0.114)	Backward Time 8.441s / 10iters, (0.844)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.087s / 10iters, (0.008655)
Learning rate = [0.007533624324637292, 0.007533624324637292]	Loss = 0.82186997 (ave = 0.85405645)

2023-07-05 17:47:32,270 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10810	Time 12.316s / 10iters, (1.232)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.343s / 10iters, (0.834)	Loss Time 2.762s / 10iters, (0.276)	Data load 0.092s / 10iters, (0.009185)
Learning rate = [0.007531302356895383, 0.007531302356895383]	Loss = 0.92845559 (ave = 0.84550434)

2023-07-05 17:47:44,556 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10820	Time 12.286s / 10iters, (1.229)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.785s / 10iters, (0.279)	Data load 0.081s / 10iters, (0.008143)
Learning rate = [0.007528980309608147, 0.007528980309608147]	Loss = 0.75481313 (ave = 0.86853465)

2023-07-05 17:47:56,932 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10830	Time 12.376s / 10iters, (1.238)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.347s / 10iters, (0.835)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007580)
Learning rate = [0.007526658182745603, 0.007526658182745603]	Loss = 0.79934800 (ave = 0.85012402)

2023-07-05 17:48:09,315 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10840	Time 12.383s / 10iters, (1.238)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.360s / 10iters, (0.836)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007513)
Learning rate = [0.007524335976277741, 0.007524335976277741]	Loss = 1.00367355 (ave = 0.83604205)

2023-07-05 17:48:21,665 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10850	Time 12.350s / 10iters, (1.235)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.326s / 10iters, (0.833)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.082s / 10iters, (0.008247)
Learning rate = [0.0075220136901745305, 0.0075220136901745305]	Loss = 0.75272477 (ave = 0.79416143)

2023-07-05 17:48:33,967 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10860	Time 12.302s / 10iters, (1.230)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.286s / 10iters, (0.829)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.083s / 10iters, (0.008274)
Learning rate = [0.007519691324405926, 0.007519691324405926]	Loss = 0.72507519 (ave = 0.84844133)

2023-07-05 17:48:46,319 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10870	Time 12.353s / 10iters, (1.235)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.306s / 10iters, (0.831)	Loss Time 2.866s / 10iters, (0.287)	Data load 0.077s / 10iters, (0.007712)
Learning rate = [0.0075173688789418516, 0.0075173688789418516]	Loss = 0.81235212 (ave = 0.86349247)

2023-07-05 17:48:58,829 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10880	Time 12.509s / 10iters, (1.251)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.388s / 10iters, (0.839)	Loss Time 2.909s / 10iters, (0.291)	Data load 0.079s / 10iters, (0.007860)
Learning rate = [0.007515046353752214, 0.007515046353752214]	Loss = 0.96596372 (ave = 0.83487745)

2023-07-05 17:49:11,326 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10890	Time 12.497s / 10iters, (1.250)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.368s / 10iters, (0.837)	Loss Time 2.937s / 10iters, (0.294)	Data load 0.088s / 10iters, (0.008788)
Learning rate = [0.007512723748806899, 0.007512723748806899]	Loss = 0.95025021 (ave = 0.88167207)

2023-07-05 17:49:23,784 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10900	Time 12.458s / 10iters, (1.246)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.382s / 10iters, (0.838)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.085s / 10iters, (0.008550)
Learning rate = [0.007510401064075766, 0.007510401064075766]	Loss = 0.80530971 (ave = 0.87515745)

2023-07-05 17:49:36,189 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10910	Time 12.405s / 10iters, (1.241)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.901s / 10iters, (0.290)	Data load 0.076s / 10iters, (0.007585)
Learning rate = [0.00750807829952866, 0.00750807829952866]	Loss = 0.78927493 (ave = 0.82349250)

2023-07-05 17:49:48,831 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10920	Time 12.642s / 10iters, (1.264)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.497s / 10iters, (0.850)	Loss Time 2.955s / 10iters, (0.295)	Data load 0.078s / 10iters, (0.007791)
Learning rate = [0.007505755455135398, 0.007505755455135398]	Loss = 0.83361250 (ave = 0.84276285)

2023-07-05 17:50:01,321 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10930	Time 12.490s / 10iters, (1.249)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.374s / 10iters, (0.837)	Loss Time 2.930s / 10iters, (0.293)	Data load 0.086s / 10iters, (0.008592)
Learning rate = [0.007503432530865776, 0.007503432530865776]	Loss = 0.91015983 (ave = 0.83021734)

2023-07-05 17:50:13,853 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10940	Time 12.533s / 10iters, (1.253)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.424s / 10iters, (0.842)	Loss Time 2.916s / 10iters, (0.292)	Data load 0.084s / 10iters, (0.008421)
Learning rate = [0.007501109526689573, 0.007501109526689573]	Loss = 0.82956743 (ave = 0.85112882)

2023-07-05 17:50:26,300 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10950	Time 12.447s / 10iters, (1.245)	Forward Time 1.157s / 10iters, (0.116)	Backward Time 8.346s / 10iters, (0.835)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.090s / 10iters, (0.008961)
Learning rate = [0.007498786442576539, 0.007498786442576539]	Loss = 0.82322794 (ave = 0.84472048)

2023-07-05 17:50:38,748 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10960	Time 12.448s / 10iters, (1.245)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.341s / 10iters, (0.834)	Loss Time 2.889s / 10iters, (0.289)	Data load 0.101s / 10iters, (0.010069)
Learning rate = [0.007496463278496408, 0.007496463278496408]	Loss = 0.80023491 (ave = 0.79439527)

2023-07-05 17:50:51,107 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10970	Time 12.359s / 10iters, (1.236)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.353s / 10iters, (0.835)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.078s / 10iters, (0.007811)
Learning rate = [0.007494140034418891, 0.007494140034418891]	Loss = 0.87834728 (ave = 0.88104375)

2023-07-05 17:51:03,658 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10980	Time 12.551s / 10iters, (1.255)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.530s / 10iters, (0.853)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.103s / 10iters, (0.010293)
Learning rate = [0.007491816710313673, 0.007491816710313673]	Loss = 0.80324036 (ave = 0.84910794)

2023-07-05 17:51:16,005 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 10990	Time 12.347s / 10iters, (1.235)	Forward Time 1.155s / 10iters, (0.116)	Backward Time 8.391s / 10iters, (0.839)	Loss Time 2.702s / 10iters, (0.270)	Data load 0.099s / 10iters, (0.009853)
Learning rate = [0.007489493306150423, 0.007489493306150423]	Loss = 0.93777847 (ave = 0.84239308)

2023-07-05 17:51:28,274 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 11000	Time 12.268s / 10iters, (1.227)	Forward Time 1.168s / 10iters, (0.117)	Backward Time 8.250s / 10iters, (0.825)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.098s / 10iters, (0.009824)
Learning rate = [0.007487169821898785, 0.007487169821898785]	Loss = 0.94935262 (ave = 0.82963176)

2023-07-05 17:51:32,795 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 17:51:56,665 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 17:52:19,990 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 17:52:43,392 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 17:53:06,764 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 17:53:30,026 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 17:53:53,072 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 17:54:01,951 INFO    [trainer_contrastive.py, 391] Test Time 150.546s, (2.390)	Loss 0.18091078

2023-07-05 17:54:01,952 INFO    [base.py, 33] Result for seg
2023-07-05 17:54:01,954 INFO    [base.py, 49] Mean IOU: 0.6780696231108709

2023-07-05 17:54:01,955 INFO    [base.py, 50] Pixel ACC: 0.944506880057028

2023-07-05 17:54:14,151 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 11010	Time 165.877s / 10iters, (16.588)	Forward Time 1.211s / 10iters, (0.121)	Backward Time 8.168s / 10iters, (0.817)	Loss Time 2.694s / 10iters, (0.269)	Data load 153.804s / 10iters, (15.380358)
Learning rate = [0.007484846257528377, 0.007484846257528377]	Loss = 1.30830193 (ave = 0.90499055)

2023-07-05 17:54:26,360 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 11020	Time 12.209s / 10iters, (1.221)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.692s / 10iters, (0.269)	Data load 0.095s / 10iters, (0.009499)
Learning rate = [0.0074825226130088044, 0.0074825226130088044]	Loss = 0.86506039 (ave = 0.82738001)

2023-07-05 17:54:38,491 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 11030	Time 12.131s / 10iters, (1.213)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.684s / 10iters, (0.268)	Data load 0.085s / 10iters, (0.008454)
Learning rate = [0.007480198888309642, 0.007480198888309642]	Loss = 0.90895551 (ave = 0.82283934)

2023-07-05 17:54:50,642 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 11040	Time 12.151s / 10iters, (1.215)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.197s / 10iters, (0.820)	Loss Time 2.763s / 10iters, (0.276)	Data load 0.091s / 10iters, (0.009095)
Learning rate = [0.007477875083400448, 0.007477875083400448]	Loss = 0.82797909 (ave = 0.86590137)

2023-07-05 17:55:02,797 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 11050	Time 12.155s / 10iters, (1.215)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.166s / 10iters, (0.817)	Loss Time 2.766s / 10iters, (0.277)	Data load 0.095s / 10iters, (0.009511)
Learning rate = [0.007475551198250757, 0.007475551198250757]	Loss = 0.80455208 (ave = 0.85821365)

2023-07-05 17:55:14,957 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 11060	Time 12.160s / 10iters, (1.216)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.174s / 10iters, (0.817)	Loss Time 2.785s / 10iters, (0.278)	Data load 0.093s / 10iters, (0.009295)
Learning rate = [0.007473227232830076, 0.007473227232830076]	Loss = 0.78937668 (ave = 0.81104913)

2023-07-05 17:55:27,096 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 11070	Time 12.139s / 10iters, (1.214)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.177s / 10iters, (0.818)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.080s / 10iters, (0.007967)
Learning rate = [0.007470903187107901, 0.007470903187107901]	Loss = 0.86412996 (ave = 0.81752339)

2023-07-05 17:55:39,283 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 11080	Time 12.187s / 10iters, (1.219)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.756s / 10iters, (0.276)	Data load 0.079s / 10iters, (0.007855)
Learning rate = [0.007468579061053696, 0.007468579061053696]	Loss = 0.82416600 (ave = 0.83049446)

2023-07-05 17:55:51,524 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 11090	Time 12.241s / 10iters, (1.224)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.286s / 10iters, (0.829)	Loss Time 2.795s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007415)
Learning rate = [0.007466254854636906, 0.007466254854636906]	Loss = 0.67039222 (ave = 0.81143109)

2023-07-05 17:56:03,558 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 11100	Time 12.034s / 10iters, (1.203)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.125s / 10iters, (0.812)	Loss Time 2.735s / 10iters, (0.274)	Data load 0.084s / 10iters, (0.008443)
Learning rate = [0.007463930567826956, 0.007463930567826956]	Loss = 0.76215172 (ave = 0.81620953)

2023-07-05 17:56:15,843 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 11110	Time 12.285s / 10iters, (1.228)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.852s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007386)
Learning rate = [0.007461606200593249, 0.007461606200593249]	Loss = 0.93746364 (ave = 0.81794804)

2023-07-05 17:56:27,856 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 11120	Time 12.013s / 10iters, (1.201)	Forward Time 1.077s / 10iters, (0.108)	Backward Time 8.106s / 10iters, (0.811)	Loss Time 2.750s / 10iters, (0.275)	Data load 0.080s / 10iters, (0.008008)
Learning rate = [0.007459281752905158, 0.007459281752905158]	Loss = 0.93312901 (ave = 0.80957630)

2023-07-05 17:56:39,889 INFO    [trainer_contrastive.py, 272] Train Epoch: 29	Train Iteration: 11130	Time 12.033s / 10iters, (1.203)	Forward Time 1.081s / 10iters, (0.108)	Backward Time 8.138s / 10iters, (0.814)	Loss Time 2.740s / 10iters, (0.274)	Data load 0.073s / 10iters, (0.007349)
Learning rate = [0.007456957224732046, 0.007456957224732046]	Loss = 0.74605209 (ave = 0.80615305)

2023-07-05 17:56:55,297 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11140	Time 15.194s / 10iters, (1.519)	Forward Time 1.169s / 10iters, (0.117)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.790s / 10iters, (0.279)	Data load 2.917s / 10iters, (0.291722)
Learning rate = [0.007454632616043241, 0.007454632616043241]	Loss = 0.84204340 (ave = 0.80090366)

2023-07-05 17:57:07,618 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11150	Time 12.321s / 10iters, (1.232)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.370s / 10iters, (0.837)	Loss Time 2.754s / 10iters, (0.275)	Data load 0.088s / 10iters, (0.008820)
Learning rate = [0.007452307926808061, 0.007452307926808061]	Loss = 0.71838653 (ave = 0.78055289)

2023-07-05 17:57:19,965 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11160	Time 12.347s / 10iters, (1.235)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.400s / 10iters, (0.840)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.088s / 10iters, (0.008767)
Learning rate = [0.007449983156995791, 0.007449983156995791]	Loss = 0.86172324 (ave = 0.84304724)

2023-07-05 17:57:32,281 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11170	Time 12.316s / 10iters, (1.232)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.351s / 10iters, (0.835)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.086s / 10iters, (0.008577)
Learning rate = [0.007447658306575701, 0.007447658306575701]	Loss = 0.93836600 (ave = 0.86458856)

2023-07-05 17:57:44,784 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11180	Time 12.503s / 10iters, (1.250)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.448s / 10iters, (0.845)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.102s / 10iters, (0.010190)
Learning rate = [0.007445333375517035, 0.007445333375517035]	Loss = 0.81410307 (ave = 0.79773414)

2023-07-05 17:57:57,061 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11190	Time 12.278s / 10iters, (1.228)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.330s / 10iters, (0.833)	Loss Time 2.754s / 10iters, (0.275)	Data load 0.083s / 10iters, (0.008284)
Learning rate = [0.007443008363789015, 0.007443008363789015]	Loss = 0.74346375 (ave = 0.76692669)

2023-07-05 17:58:09,424 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11200	Time 12.363s / 10iters, (1.236)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.380s / 10iters, (0.838)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.100s / 10iters, (0.009984)
Learning rate = [0.007440683271360841, 0.007440683271360841]	Loss = 0.81950116 (ave = 0.82341030)

2023-07-05 17:58:21,711 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11210	Time 12.287s / 10iters, (1.229)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.101s / 10iters, (0.010084)
Learning rate = [0.007438358098201691, 0.007438358098201691]	Loss = 0.85472089 (ave = 0.81646618)

2023-07-05 17:58:34,017 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11220	Time 12.306s / 10iters, (1.231)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.815s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007596)
Learning rate = [0.007436032844280719, 0.007436032844280719]	Loss = 0.86767650 (ave = 0.83602094)

2023-07-05 17:58:46,388 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11230	Time 12.371s / 10iters, (1.237)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.324s / 10iters, (0.832)	Loss Time 2.862s / 10iters, (0.286)	Data load 0.078s / 10iters, (0.007820)
Learning rate = [0.00743370750956706, 0.00743370750956706]	Loss = 0.87193841 (ave = 0.84676377)

2023-07-05 17:58:58,876 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11240	Time 12.488s / 10iters, (1.249)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.421s / 10iters, (0.842)	Loss Time 2.884s / 10iters, (0.288)	Data load 0.080s / 10iters, (0.008037)
Learning rate = [0.007431382094029822, 0.007431382094029822]	Loss = 0.81859148 (ave = 0.83974434)

2023-07-05 17:59:11,230 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11250	Time 12.354s / 10iters, (1.235)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.347s / 10iters, (0.835)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.081s / 10iters, (0.008144)
Learning rate = [0.007429056597638093, 0.007429056597638093]	Loss = 0.72000194 (ave = 0.79244096)

2023-07-05 17:59:23,682 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11260	Time 12.452s / 10iters, (1.245)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.424s / 10iters, (0.842)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.084s / 10iters, (0.008426)
Learning rate = [0.007426731020360939, 0.007426731020360939]	Loss = 0.79809594 (ave = 0.78736788)

2023-07-05 17:59:35,964 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11270	Time 12.283s / 10iters, (1.228)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.325s / 10iters, (0.832)	Loss Time 2.754s / 10iters, (0.275)	Data load 0.076s / 10iters, (0.007597)
Learning rate = [0.007424405362167401, 0.007424405362167401]	Loss = 1.01517856 (ave = 0.86127971)

2023-07-05 17:59:48,134 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11280	Time 12.170s / 10iters, (1.217)	Forward Time 1.177s / 10iters, (0.118)	Backward Time 8.189s / 10iters, (0.819)	Loss Time 2.711s / 10iters, (0.271)	Data load 0.092s / 10iters, (0.009163)
Learning rate = [0.007422079623026498, 0.007422079623026498]	Loss = 0.77638829 (ave = 0.82115933)

2023-07-05 18:00:00,496 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11290	Time 12.362s / 10iters, (1.236)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.391s / 10iters, (0.839)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.080s / 10iters, (0.007952)
Learning rate = [0.00741975380290723, 0.00741975380290723]	Loss = 1.05485857 (ave = 0.83030293)

2023-07-05 18:00:12,916 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11300	Time 12.421s / 10iters, (1.242)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.419s / 10iters, (0.842)	Loss Time 2.797s / 10iters, (0.280)	Data load 0.091s / 10iters, (0.009117)
Learning rate = [0.007417427901778566, 0.007417427901778566]	Loss = 1.12522137 (ave = 0.86325803)

2023-07-05 18:00:25,316 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11310	Time 12.400s / 10iters, (1.240)	Forward Time 1.137s / 10iters, (0.114)	Backward Time 8.358s / 10iters, (0.836)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.095s / 10iters, (0.009495)
Learning rate = [0.0074151019196094636, 0.0074151019196094636]	Loss = 0.93218839 (ave = 0.85532354)

2023-07-05 18:00:37,832 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11320	Time 12.516s / 10iters, (1.252)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.524s / 10iters, (0.852)	Loss Time 2.797s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007640)
Learning rate = [0.007412775856368848, 0.007412775856368848]	Loss = 0.79071015 (ave = 0.80785140)

2023-07-05 18:00:50,259 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11330	Time 12.428s / 10iters, (1.243)	Forward Time 1.160s / 10iters, (0.116)	Backward Time 8.409s / 10iters, (0.841)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.091s / 10iters, (0.009081)
Learning rate = [0.007410449712025626, 0.007410449712025626]	Loss = 0.75874156 (ave = 0.83316817)

2023-07-05 18:01:02,871 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11340	Time 12.611s / 10iters, (1.261)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.565s / 10iters, (0.856)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.091s / 10iters, (0.009061)
Learning rate = [0.007408123486548683, 0.007408123486548683]	Loss = 0.78860313 (ave = 0.82960824)

2023-07-05 18:01:15,253 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11350	Time 12.382s / 10iters, (1.238)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.405s / 10iters, (0.841)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007517)
Learning rate = [0.007405797179906878, 0.007405797179906878]	Loss = 0.62484050 (ave = 0.78480978)

2023-07-05 18:01:27,588 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11360	Time 12.335s / 10iters, (1.233)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.341s / 10iters, (0.834)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.085s / 10iters, (0.008509)
Learning rate = [0.007403470792069048, 0.007403470792069048]	Loss = 1.00647080 (ave = 0.82915422)

2023-07-05 18:01:39,871 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11370	Time 12.283s / 10iters, (1.228)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.307s / 10iters, (0.831)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.077s / 10iters, (0.007658)
Learning rate = [0.007401144323004009, 0.007401144323004009]	Loss = 0.76758534 (ave = 0.76389725)

2023-07-05 18:01:52,292 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11380	Time 12.421s / 10iters, (1.242)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.358s / 10iters, (0.836)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.102s / 10iters, (0.010244)
Learning rate = [0.007398817772680552, 0.007398817772680552]	Loss = 0.94304466 (ave = 0.82345573)

2023-07-05 18:02:04,638 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11390	Time 12.346s / 10iters, (1.235)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.332s / 10iters, (0.833)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.086s / 10iters, (0.008622)
Learning rate = [0.0073964911410674475, 0.0073964911410674475]	Loss = 0.73282361 (ave = 0.76741495)

2023-07-05 18:02:17,030 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11400	Time 12.391s / 10iters, (1.239)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.418s / 10iters, (0.842)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.081s / 10iters, (0.008086)
Learning rate = [0.007394164428133441, 0.007394164428133441]	Loss = 0.76152074 (ave = 0.81582474)

2023-07-05 18:02:29,266 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11410	Time 12.237s / 10iters, (1.224)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.325s / 10iters, (0.832)	Loss Time 2.689s / 10iters, (0.269)	Data load 0.092s / 10iters, (0.009240)
Learning rate = [0.007391837633847256, 0.007391837633847256]	Loss = 0.81344479 (ave = 0.78130640)

2023-07-05 18:02:41,570 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11420	Time 12.304s / 10iters, (1.230)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.413s / 10iters, (0.841)	Loss Time 2.676s / 10iters, (0.268)	Data load 0.081s / 10iters, (0.008101)
Learning rate = [0.007389510758177593, 0.007389510758177593]	Loss = 0.72629851 (ave = 0.73272558)

2023-07-05 18:02:53,824 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11430	Time 12.254s / 10iters, (1.225)	Forward Time 1.139s / 10iters, (0.114)	Backward Time 8.359s / 10iters, (0.836)	Loss Time 2.669s / 10iters, (0.267)	Data load 0.086s / 10iters, (0.008606)
Learning rate = [0.007387183801093128, 0.007387183801093128]	Loss = 1.08210278 (ave = 0.79662604)

2023-07-05 18:03:06,104 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11440	Time 12.280s / 10iters, (1.228)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.398s / 10iters, (0.840)	Loss Time 2.693s / 10iters, (0.269)	Data load 0.076s / 10iters, (0.007624)
Learning rate = [0.007384856762562517, 0.007384856762562517]	Loss = 0.83466136 (ave = 0.81278189)

2023-07-05 18:03:18,479 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11450	Time 12.375s / 10iters, (1.238)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.397s / 10iters, (0.840)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.101s / 10iters, (0.010126)
Learning rate = [0.007382529642554392, 0.007382529642554392]	Loss = 0.83328617 (ave = 0.86451666)

2023-07-05 18:03:30,932 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11460	Time 12.453s / 10iters, (1.245)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.456s / 10iters, (0.846)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.097s / 10iters, (0.009732)
Learning rate = [0.007380202441037357, 0.007380202441037357]	Loss = 0.84463954 (ave = 0.80724267)

2023-07-05 18:03:43,367 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11470	Time 12.435s / 10iters, (1.243)	Forward Time 1.148s / 10iters, (0.115)	Backward Time 8.395s / 10iters, (0.840)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.078s / 10iters, (0.007847)
Learning rate = [0.007377875157980002, 0.007377875157980002]	Loss = 0.77403486 (ave = 0.85101515)

2023-07-05 18:03:55,803 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11480	Time 12.437s / 10iters, (1.244)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.333s / 10iters, (0.833)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.124s / 10iters, (0.012437)
Learning rate = [0.0073755477933508855, 0.0073755477933508855]	Loss = 0.79470336 (ave = 0.84504314)

2023-07-05 18:04:08,091 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11490	Time 12.288s / 10iters, (1.229)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.805s / 10iters, (0.281)	Data load 0.089s / 10iters, (0.008862)
Learning rate = [0.007373220347118546, 0.007373220347118546]	Loss = 0.84425056 (ave = 0.83625426)

2023-07-05 18:04:20,128 INFO    [trainer_contrastive.py, 272] Train Epoch: 30	Train Iteration: 11500	Time 12.037s / 10iters, (1.204)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.156s / 10iters, (0.816)	Loss Time 2.728s / 10iters, (0.273)	Data load 0.072s / 10iters, (0.007242)
Learning rate = [0.007370892819251505, 0.007370892819251505]	Loss = 0.82407391 (ave = 0.82963166)

2023-07-05 18:04:34,912 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11510	Time 14.603s / 10iters, (1.460)	Forward Time 1.241s / 10iters, (0.124)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.659s / 10iters, (0.266)	Data load 2.483s / 10iters, (0.248271)
Learning rate = [0.007368565209718247, 0.007368565209718247]	Loss = 0.77545542 (ave = 0.86308333)

2023-07-05 18:04:47,247 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11520	Time 12.335s / 10iters, (1.233)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.364s / 10iters, (0.836)	Loss Time 2.797s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007527)
Learning rate = [0.007366237518487246, 0.007366237518487246]	Loss = 0.96466303 (ave = 0.84577753)

2023-07-05 18:04:59,508 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11530	Time 12.261s / 10iters, (1.226)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.297s / 10iters, (0.830)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007457)
Learning rate = [0.007363909745526947, 0.007363909745526947]	Loss = 0.77702719 (ave = 0.84762721)

2023-07-05 18:05:11,996 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11540	Time 12.487s / 10iters, (1.249)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.466s / 10iters, (0.847)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007471)
Learning rate = [0.007361581890805771, 0.007361581890805771]	Loss = 0.82841384 (ave = 0.83475423)

2023-07-05 18:05:24,446 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11550	Time 12.450s / 10iters, (1.245)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.440s / 10iters, (0.844)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007425)
Learning rate = [0.007359253954292119, 0.007359253954292119]	Loss = 0.92050540 (ave = 0.85074832)

2023-07-05 18:05:36,888 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11560	Time 12.442s / 10iters, (1.244)	Forward Time 1.140s / 10iters, (0.114)	Backward Time 8.440s / 10iters, (0.844)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007435)
Learning rate = [0.007356925935954367, 0.007356925935954367]	Loss = 0.72375989 (ave = 0.77786936)

2023-07-05 18:05:49,480 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11570	Time 12.592s / 10iters, (1.259)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.544s / 10iters, (0.854)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.078s / 10iters, (0.007837)
Learning rate = [0.007354597835760867, 0.007354597835760867]	Loss = 0.76043248 (ave = 0.78194254)

2023-07-05 18:06:02,049 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11580	Time 12.569s / 10iters, (1.257)	Forward Time 1.137s / 10iters, (0.114)	Backward Time 8.501s / 10iters, (0.850)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.089s / 10iters, (0.008930)
Learning rate = [0.00735226965367995, 0.00735226965367995]	Loss = 0.75219023 (ave = 0.80450723)

2023-07-05 18:06:14,577 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11590	Time 12.528s / 10iters, (1.253)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.560s / 10iters, (0.856)	Loss Time 2.786s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007473)
Learning rate = [0.007349941389679921, 0.007349941389679921]	Loss = 0.75718188 (ave = 0.82208772)

2023-07-05 18:06:26,866 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11600	Time 12.288s / 10iters, (1.229)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.345s / 10iters, (0.834)	Loss Time 2.757s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007428)
Learning rate = [0.007347613043729061, 0.007347613043729061]	Loss = 0.76094049 (ave = 0.84305695)

2023-07-05 18:06:39,053 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11610	Time 12.187s / 10iters, (1.219)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.262s / 10iters, (0.826)	Loss Time 2.707s / 10iters, (0.271)	Data load 0.087s / 10iters, (0.008730)
Learning rate = [0.007345284615795631, 0.007345284615795631]	Loss = 0.84388256 (ave = 0.87313628)

2023-07-05 18:06:51,291 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11620	Time 12.238s / 10iters, (1.224)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.721s / 10iters, (0.272)	Data load 0.096s / 10iters, (0.009629)
Learning rate = [0.007342956105847865, 0.007342956105847865]	Loss = 0.88046497 (ave = 0.86740581)

2023-07-05 18:07:03,561 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11630	Time 12.270s / 10iters, (1.227)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.315s / 10iters, (0.831)	Loss Time 2.751s / 10iters, (0.275)	Data load 0.077s / 10iters, (0.007679)
Learning rate = [0.007340627513853976, 0.007340627513853976]	Loss = 0.99599618 (ave = 0.86484742)

2023-07-05 18:07:15,878 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11640	Time 12.317s / 10iters, (1.232)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.833s / 10iters, (0.283)	Data load 0.083s / 10iters, (0.008335)
Learning rate = [0.007338298839782153, 0.007338298839782153]	Loss = 0.88077956 (ave = 0.89994700)

2023-07-05 18:07:28,217 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11650	Time 12.339s / 10iters, (1.234)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.855s / 10iters, (0.285)	Data load 0.094s / 10iters, (0.009410)
Learning rate = [0.007335970083600559, 0.007335970083600559]	Loss = 0.82995629 (ave = 0.82990215)

2023-07-05 18:07:40,477 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11660	Time 12.260s / 10iters, (1.226)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.805s / 10iters, (0.281)	Data load 0.088s / 10iters, (0.008788)
Learning rate = [0.0073336412452773385, 0.0073336412452773385]	Loss = 0.86406195 (ave = 0.82201626)

2023-07-05 18:07:52,790 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11670	Time 12.313s / 10iters, (1.231)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.087s / 10iters, (0.008685)
Learning rate = [0.007331312324780606, 0.007331312324780606]	Loss = 0.82414562 (ave = 0.80894212)

2023-07-05 18:08:05,085 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11680	Time 12.295s / 10iters, (1.230)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.079s / 10iters, (0.007925)
Learning rate = [0.0073289833220784575, 0.0073289833220784575]	Loss = 0.72201502 (ave = 0.83182966)

2023-07-05 18:08:17,421 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11690	Time 12.336s / 10iters, (1.234)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.085s / 10iters, (0.008483)
Learning rate = [0.007326654237138964, 0.007326654237138964]	Loss = 0.81028539 (ave = 0.86210029)

2023-07-05 18:08:29,716 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11700	Time 12.295s / 10iters, (1.229)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.090s / 10iters, (0.009043)
Learning rate = [0.00732432506993017, 0.00732432506993017]	Loss = 0.81452328 (ave = 0.81552720)

2023-07-05 18:08:41,965 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11710	Time 12.250s / 10iters, (1.225)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.086s / 10iters, (0.008627)
Learning rate = [0.007321995820420101, 0.007321995820420101]	Loss = 0.79627007 (ave = 0.79846988)

2023-07-05 18:08:54,171 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11720	Time 12.206s / 10iters, (1.221)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.080s / 10iters, (0.008009)
Learning rate = [0.007319666488576756, 0.007319666488576756]	Loss = 0.58821183 (ave = 0.81324521)

2023-07-05 18:09:06,379 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11730	Time 12.208s / 10iters, (1.221)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.270s / 10iters, (0.827)	Loss Time 2.766s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007535)
Learning rate = [0.007317337074368109, 0.007317337074368109]	Loss = 0.75092047 (ave = 0.81339660)

2023-07-05 18:09:18,636 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11740	Time 12.257s / 10iters, (1.226)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007436)
Learning rate = [0.007315007577762114, 0.007315007577762114]	Loss = 0.81605899 (ave = 0.83341269)

2023-07-05 18:09:30,969 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11750	Time 12.333s / 10iters, (1.233)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.890s / 10iters, (0.289)	Data load 0.074s / 10iters, (0.007404)
Learning rate = [0.007312677998726697, 0.007312677998726697]	Loss = 0.84995413 (ave = 0.88787551)

2023-07-05 18:09:43,321 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11760	Time 12.352s / 10iters, (1.235)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.297s / 10iters, (0.830)	Loss Time 2.874s / 10iters, (0.287)	Data load 0.081s / 10iters, (0.008149)
Learning rate = [0.007310348337229763, 0.007310348337229763]	Loss = 0.99722612 (ave = 0.84225752)

2023-07-05 18:09:55,647 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11770	Time 12.327s / 10iters, (1.233)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.243s / 10iters, (0.824)	Loss Time 2.884s / 10iters, (0.288)	Data load 0.090s / 10iters, (0.009014)
Learning rate = [0.007308018593239193, 0.007308018593239193]	Loss = 0.84576190 (ave = 0.79150078)

2023-07-05 18:10:08,094 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11780	Time 12.447s / 10iters, (1.245)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.420s / 10iters, (0.842)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.088s / 10iters, (0.008817)
Learning rate = [0.007305688766722841, 0.007305688766722841]	Loss = 0.75745076 (ave = 0.84680924)

2023-07-05 18:10:20,501 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11790	Time 12.406s / 10iters, (1.241)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.288s / 10iters, (0.829)	Loss Time 2.908s / 10iters, (0.291)	Data load 0.088s / 10iters, (0.008799)
Learning rate = [0.007303358857648544, 0.007303358857648544]	Loss = 0.88370645 (ave = 0.83730173)

2023-07-05 18:10:32,869 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11800	Time 12.368s / 10iters, (1.237)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.307s / 10iters, (0.831)	Loss Time 2.878s / 10iters, (0.288)	Data load 0.080s / 10iters, (0.007985)
Learning rate = [0.007301028865984105, 0.007301028865984105]	Loss = 0.79670715 (ave = 0.91202490)

2023-07-05 18:10:45,200 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11810	Time 12.331s / 10iters, (1.233)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.253s / 10iters, (0.825)	Loss Time 2.910s / 10iters, (0.291)	Data load 0.076s / 10iters, (0.007566)
Learning rate = [0.007298698791697311, 0.007298698791697311]	Loss = 0.92815280 (ave = 0.86539742)

2023-07-05 18:10:57,517 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11820	Time 12.317s / 10iters, (1.232)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.078s / 10iters, (0.007755)
Learning rate = [0.007296368634755926, 0.007296368634755926]	Loss = 0.79277813 (ave = 0.82773591)

2023-07-05 18:11:09,715 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11830	Time 12.198s / 10iters, (1.220)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.083s / 10iters, (0.008295)
Learning rate = [0.00729403839512768, 0.00729403839512768]	Loss = 0.81524563 (ave = 0.80400429)

2023-07-05 18:11:21,955 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11840	Time 12.241s / 10iters, (1.224)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.755s / 10iters, (0.275)	Data load 0.074s / 10iters, (0.007438)
Learning rate = [0.0072917080727802905, 0.0072917080727802905]	Loss = 0.72690815 (ave = 0.84140636)

2023-07-05 18:11:34,182 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11850	Time 12.226s / 10iters, (1.223)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.786s / 10iters, (0.279)	Data load 0.081s / 10iters, (0.008124)
Learning rate = [0.007289377667681444, 0.007289377667681444]	Loss = 0.84261185 (ave = 0.77162488)

2023-07-05 18:11:46,366 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11860	Time 12.185s / 10iters, (1.218)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.730s / 10iters, (0.273)	Data load 0.078s / 10iters, (0.007834)
Learning rate = [0.007287047179798804, 0.007287047179798804]	Loss = 0.85186255 (ave = 0.81474001)

2023-07-05 18:11:58,357 INFO    [trainer_contrastive.py, 272] Train Epoch: 31	Train Iteration: 11870	Time 11.991s / 10iters, (1.199)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.129s / 10iters, (0.813)	Loss Time 2.705s / 10iters, (0.271)	Data load 0.076s / 10iters, (0.007625)
Learning rate = [0.007284716609100013, 0.007284716609100013]	Loss = 0.75637561 (ave = 0.81356687)

2023-07-05 18:12:13,460 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 11880	Time 14.947s / 10iters, (1.495)	Forward Time 1.154s / 10iters, (0.115)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.708s / 10iters, (0.271)	Data load 2.867s / 10iters, (0.286746)
Learning rate = [0.007282385955552685, 0.007282385955552685]	Loss = 0.77763367 (ave = 0.83809575)

2023-07-05 18:12:25,522 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 11890	Time 12.062s / 10iters, (1.206)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.180s / 10iters, (0.818)	Loss Time 2.686s / 10iters, (0.269)	Data load 0.094s / 10iters, (0.009433)
Learning rate = [0.007280055219124413, 0.007280055219124413]	Loss = 0.64308727 (ave = 0.80158536)

2023-07-05 18:12:37,572 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 11900	Time 12.050s / 10iters, (1.205)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.197s / 10iters, (0.820)	Loss Time 2.678s / 10iters, (0.268)	Data load 0.076s / 10iters, (0.007618)
Learning rate = [0.007277724399782764, 0.007277724399782764]	Loss = 0.71514958 (ave = 0.73347442)

2023-07-05 18:12:49,871 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 11910	Time 12.300s / 10iters, (1.230)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.378s / 10iters, (0.838)	Loss Time 2.727s / 10iters, (0.273)	Data load 0.079s / 10iters, (0.007909)
Learning rate = [0.007275393497495282, 0.007275393497495282]	Loss = 0.80298722 (ave = 0.75331750)

2023-07-05 18:13:01,992 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 11920	Time 12.121s / 10iters, (1.212)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.676s / 10iters, (0.268)	Data load 0.082s / 10iters, (0.008232)
Learning rate = [0.007273062512229485, 0.007273062512229485]	Loss = 0.80379510 (ave = 0.82745396)

2023-07-05 18:13:14,116 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 11930	Time 12.124s / 10iters, (1.212)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.706s / 10iters, (0.271)	Data load 0.080s / 10iters, (0.008050)
Learning rate = [0.007270731443952869, 0.007270731443952869]	Loss = 0.76358438 (ave = 0.80578411)

2023-07-05 18:13:26,407 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 11940	Time 12.291s / 10iters, (1.229)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.343s / 10iters, (0.834)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.078s / 10iters, (0.007843)
Learning rate = [0.007268400292632903, 0.007268400292632903]	Loss = 0.77300894 (ave = 0.80092544)

2023-07-05 18:13:38,584 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 11950	Time 12.177s / 10iters, (1.218)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.243s / 10iters, (0.824)	Loss Time 2.759s / 10iters, (0.276)	Data load 0.078s / 10iters, (0.007751)
Learning rate = [0.007266069058237035, 0.007266069058237035]	Loss = 0.79155350 (ave = 0.81364522)

2023-07-05 18:13:50,723 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 11960	Time 12.139s / 10iters, (1.214)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.757s / 10iters, (0.276)	Data load 0.078s / 10iters, (0.007797)
Learning rate = [0.007263737740732685, 0.007263737740732685]	Loss = 0.83321989 (ave = 0.80429758)

2023-07-05 18:14:02,943 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 11970	Time 12.220s / 10iters, (1.222)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007518)
Learning rate = [0.007261406340087252, 0.007261406340087252]	Loss = 0.77110541 (ave = 0.81090429)

2023-07-05 18:14:15,121 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 11980	Time 12.178s / 10iters, (1.218)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.077s / 10iters, (0.007730)
Learning rate = [0.007259074856268109, 0.007259074856268109]	Loss = 0.75139034 (ave = 0.74710038)

2023-07-05 18:14:27,291 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 11990	Time 12.170s / 10iters, (1.217)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.152s / 10iters, (0.815)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.084s / 10iters, (0.008355)
Learning rate = [0.007256743289242603, 0.007256743289242603]	Loss = 0.85273552 (ave = 0.83309703)

2023-07-05 18:14:39,502 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12000	Time 12.211s / 10iters, (1.221)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.096s / 10iters, (0.009609)
Learning rate = [0.00725441163897806, 0.00725441163897806]	Loss = 0.62133849 (ave = 0.75508317)

2023-07-05 18:14:42,765 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 18:15:06,372 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 18:15:29,514 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 18:15:52,777 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 18:16:15,914 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 18:16:39,019 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 18:17:01,834 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 18:17:07,688 INFO    [base.py, 84] Performance 0.7105715709605773 -> 0.7227532946373106
2023-07-05 18:17:13,500 INFO    [trainer_contrastive.py, 391] Test Time 147.985s, (2.349)	Loss 0.14704177

2023-07-05 18:17:13,500 INFO    [base.py, 33] Result for seg
2023-07-05 18:17:13,501 INFO    [base.py, 49] Mean IOU: 0.7227532946373106

2023-07-05 18:17:13,502 INFO    [base.py, 50] Pixel ACC: 0.9545543056111707

2023-07-05 18:17:25,631 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12010	Time 166.129s / 10iters, (16.613)	Forward Time 1.160s / 10iters, (0.116)	Backward Time 8.173s / 10iters, (0.817)	Loss Time 2.691s / 10iters, (0.269)	Data load 154.105s / 10iters, (15.410456)
Learning rate = [0.007252079905441778, 0.007252079905441778]	Loss = 0.72918749 (ave = 0.79583823)

2023-07-05 18:17:37,661 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12020	Time 12.030s / 10iters, (1.203)	Forward Time 1.157s / 10iters, (0.116)	Backward Time 8.169s / 10iters, (0.817)	Loss Time 2.628s / 10iters, (0.263)	Data load 0.076s / 10iters, (0.007631)
Learning rate = [0.007249748088601031, 0.007249748088601031]	Loss = 0.91476417 (ave = 0.77304022)

2023-07-05 18:17:49,689 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12030	Time 12.028s / 10iters, (1.203)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.129s / 10iters, (0.813)	Loss Time 2.693s / 10iters, (0.269)	Data load 0.085s / 10iters, (0.008542)
Learning rate = [0.007247416188423073, 0.007247416188423073]	Loss = 0.86970770 (ave = 0.81130148)

2023-07-05 18:18:01,777 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12040	Time 12.088s / 10iters, (1.209)	Forward Time 1.135s / 10iters, (0.114)	Backward Time 8.165s / 10iters, (0.817)	Loss Time 2.679s / 10iters, (0.268)	Data load 0.108s / 10iters, (0.010836)
Learning rate = [0.007245084204875126, 0.007245084204875126]	Loss = 0.81402582 (ave = 0.83194833)

2023-07-05 18:18:13,878 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12050	Time 12.100s / 10iters, (1.210)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.181s / 10iters, (0.818)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007537)
Learning rate = [0.007242752137924393, 0.007242752137924393]	Loss = 0.85307586 (ave = 0.85579481)

2023-07-05 18:18:26,038 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12060	Time 12.160s / 10iters, (1.216)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.195s / 10iters, (0.819)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.078s / 10iters, (0.007817)
Learning rate = [0.007240419987538052, 0.007240419987538052]	Loss = 0.73982012 (ave = 0.89676553)

2023-07-05 18:18:38,191 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12070	Time 12.154s / 10iters, (1.215)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.199s / 10iters, (0.820)	Loss Time 2.765s / 10iters, (0.277)	Data load 0.082s / 10iters, (0.008176)
Learning rate = [0.007238087753683251, 0.007238087753683251]	Loss = 0.76934814 (ave = 0.83512146)

2023-07-05 18:18:50,367 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12080	Time 12.175s / 10iters, (1.218)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.764s / 10iters, (0.276)	Data load 0.078s / 10iters, (0.007818)
Learning rate = [0.007235755436327122, 0.007235755436327122]	Loss = 0.86378878 (ave = 0.83258162)

2023-07-05 18:19:02,586 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12090	Time 12.219s / 10iters, (1.222)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.270s / 10iters, (0.827)	Loss Time 2.766s / 10iters, (0.277)	Data load 0.088s / 10iters, (0.008832)
Learning rate = [0.007233423035436765, 0.007233423035436765]	Loss = 0.83503878 (ave = 0.87822052)

2023-07-05 18:19:14,831 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12100	Time 12.245s / 10iters, (1.225)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.097s / 10iters, (0.009678)
Learning rate = [0.007231090550979256, 0.007231090550979256]	Loss = 0.85006601 (ave = 0.89712086)

2023-07-05 18:19:26,975 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12110	Time 12.144s / 10iters, (1.214)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.757s / 10iters, (0.276)	Data load 0.089s / 10iters, (0.008914)
Learning rate = [0.007228757982921651, 0.007228757982921651]	Loss = 0.78124589 (ave = 0.83397100)

2023-07-05 18:19:39,146 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12120	Time 12.171s / 10iters, (1.217)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.210s / 10iters, (0.821)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007491)
Learning rate = [0.007226425331230978, 0.007226425331230978]	Loss = 0.77523440 (ave = 0.84277852)

2023-07-05 18:19:51,447 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12130	Time 12.301s / 10iters, (1.230)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.305s / 10iters, (0.831)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.077s / 10iters, (0.007733)
Learning rate = [0.007224092595874238, 0.007224092595874238]	Loss = 0.77404070 (ave = 0.83786728)

2023-07-05 18:20:03,721 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12140	Time 12.274s / 10iters, (1.227)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.102s / 10iters, (0.010247)
Learning rate = [0.007221759776818412, 0.007221759776818412]	Loss = 0.74286842 (ave = 0.83668971)

2023-07-05 18:20:16,075 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12150	Time 12.354s / 10iters, (1.235)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.315s / 10iters, (0.832)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.085s / 10iters, (0.008482)
Learning rate = [0.0072194268740304515, 0.0072194268740304515]	Loss = 0.86315608 (ave = 0.85932870)

2023-07-05 18:20:28,389 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12160	Time 12.314s / 10iters, (1.231)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.285s / 10iters, (0.828)	Loss Time 2.820s / 10iters, (0.282)	Data load 0.082s / 10iters, (0.008211)
Learning rate = [0.007217093887477286, 0.007217093887477286]	Loss = 0.90786314 (ave = 0.82756550)

2023-07-05 18:20:40,564 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12170	Time 12.174s / 10iters, (1.217)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.081s / 10iters, (0.008072)
Learning rate = [0.007214760817125819, 0.007214760817125819]	Loss = 0.73306668 (ave = 0.83396226)

2023-07-05 18:20:53,023 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12180	Time 12.459s / 10iters, (1.246)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.403s / 10iters, (0.840)	Loss Time 2.856s / 10iters, (0.286)	Data load 0.076s / 10iters, (0.007565)
Learning rate = [0.00721242766294293, 0.00721242766294293]	Loss = 0.97835457 (ave = 0.84913788)

2023-07-05 18:21:05,558 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12190	Time 12.536s / 10iters, (1.254)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.384s / 10iters, (0.838)	Loss Time 2.931s / 10iters, (0.293)	Data load 0.095s / 10iters, (0.009527)
Learning rate = [0.007210094424895472, 0.007210094424895472]	Loss = 0.79925823 (ave = 0.90772516)

2023-07-05 18:21:17,885 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12200	Time 12.327s / 10iters, (1.233)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.242s / 10iters, (0.824)	Loss Time 2.884s / 10iters, (0.288)	Data load 0.089s / 10iters, (0.008911)
Learning rate = [0.007207761102950275, 0.007207761102950275]	Loss = 0.72157246 (ave = 0.82328094)

2023-07-05 18:21:30,254 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12210	Time 12.368s / 10iters, (1.237)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.909s / 10iters, (0.291)	Data load 0.086s / 10iters, (0.008649)
Learning rate = [0.007205427697074139, 0.007205427697074139]	Loss = 0.74611831 (ave = 0.83386703)

2023-07-05 18:21:42,709 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12220	Time 12.456s / 10iters, (1.246)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.351s / 10iters, (0.835)	Loss Time 2.915s / 10iters, (0.291)	Data load 0.076s / 10iters, (0.007603)
Learning rate = [0.007203094207233849, 0.007203094207233849]	Loss = 0.82698858 (ave = 0.79344094)

2023-07-05 18:21:54,814 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12230	Time 12.104s / 10iters, (1.210)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.132s / 10iters, (0.813)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.078s / 10iters, (0.007815)
Learning rate = [0.007200760633396152, 0.007200760633396152]	Loss = 0.85457474 (ave = 0.80425222)

2023-07-05 18:22:06,735 INFO    [trainer_contrastive.py, 272] Train Epoch: 32	Train Iteration: 12240	Time 11.921s / 10iters, (1.192)	Forward Time 1.082s / 10iters, (0.108)	Backward Time 8.069s / 10iters, (0.807)	Loss Time 2.697s / 10iters, (0.270)	Data load 0.073s / 10iters, (0.007299)
Learning rate = [0.00719842697552778, 0.00719842697552778]	Loss = 0.70837075 (ave = 0.80749787)

2023-07-05 18:22:21,765 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12250	Time 14.856s / 10iters, (1.486)	Forward Time 1.274s / 10iters, (0.127)	Backward Time 8.285s / 10iters, (0.829)	Loss Time 2.770s / 10iters, (0.277)	Data load 2.526s / 10iters, (0.252642)
Learning rate = [0.007196093233595434, 0.007196093233595434]	Loss = 0.79873246 (ave = 0.80571750)

2023-07-05 18:22:34,126 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12260	Time 12.361s / 10iters, (1.236)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.378s / 10iters, (0.838)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.092s / 10iters, (0.009181)
Learning rate = [0.007193759407565793, 0.007193759407565793]	Loss = 0.81044042 (ave = 0.83389124)

2023-07-05 18:22:46,391 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12270	Time 12.265s / 10iters, (1.226)	Forward Time 1.153s / 10iters, (0.115)	Backward Time 8.305s / 10iters, (0.831)	Loss Time 2.693s / 10iters, (0.269)	Data load 0.113s / 10iters, (0.011259)
Learning rate = [0.00719142549740551, 0.00719142549740551]	Loss = 0.73335558 (ave = 0.78213580)

2023-07-05 18:22:58,868 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12280	Time 12.478s / 10iters, (1.248)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.497s / 10iters, (0.850)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.083s / 10iters, (0.008308)
Learning rate = [0.007189091503081213, 0.007189091503081213]	Loss = 0.93981749 (ave = 0.83792740)

2023-07-05 18:23:11,056 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12290	Time 12.187s / 10iters, (1.219)	Forward Time 1.208s / 10iters, (0.121)	Backward Time 8.232s / 10iters, (0.823)	Loss Time 2.671s / 10iters, (0.267)	Data load 0.076s / 10iters, (0.007609)
Learning rate = [0.007186757424559502, 0.007186757424559502]	Loss = 0.88029224 (ave = 0.80753489)

2023-07-05 18:23:23,496 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12300	Time 12.440s / 10iters, (1.244)	Forward Time 1.146s / 10iters, (0.115)	Backward Time 8.380s / 10iters, (0.838)	Loss Time 2.818s / 10iters, (0.282)	Data load 0.096s / 10iters, (0.009648)
Learning rate = [0.007184423261806957, 0.007184423261806957]	Loss = 0.74723536 (ave = 0.81090965)

2023-07-05 18:23:35,632 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12310	Time 12.136s / 10iters, (1.214)	Forward Time 1.166s / 10iters, (0.117)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.662s / 10iters, (0.266)	Data load 0.094s / 10iters, (0.009369)
Learning rate = [0.007182089014790127, 0.007182089014790127]	Loss = 0.92702258 (ave = 0.79331515)

2023-07-05 18:23:48,054 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12320	Time 12.422s / 10iters, (1.242)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.445s / 10iters, (0.845)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.093s / 10iters, (0.009250)
Learning rate = [0.0071797546834755374, 0.0071797546834755374]	Loss = 0.77302718 (ave = 0.86638367)

2023-07-05 18:24:00,328 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12330	Time 12.274s / 10iters, (1.227)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.374s / 10iters, (0.837)	Loss Time 2.679s / 10iters, (0.268)	Data load 0.087s / 10iters, (0.008726)
Learning rate = [0.007177420267829693, 0.007177420267829693]	Loss = 0.88155657 (ave = 0.77862674)

2023-07-05 18:24:12,643 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12340	Time 12.315s / 10iters, (1.232)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.371s / 10iters, (0.837)	Loss Time 2.738s / 10iters, (0.274)	Data load 0.089s / 10iters, (0.008852)
Learning rate = [0.007175085767819064, 0.007175085767819064]	Loss = 0.89861971 (ave = 0.82604454)

2023-07-05 18:24:24,963 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12350	Time 12.320s / 10iters, (1.232)	Forward Time 1.144s / 10iters, (0.114)	Backward Time 8.354s / 10iters, (0.835)	Loss Time 2.745s / 10iters, (0.274)	Data load 0.077s / 10iters, (0.007703)
Learning rate = [0.007172751183410105, 0.007172751183410105]	Loss = 0.82389146 (ave = 0.84293001)

2023-07-05 18:24:37,179 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12360	Time 12.215s / 10iters, (1.222)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.676s / 10iters, (0.268)	Data load 0.102s / 10iters, (0.010176)
Learning rate = [0.007170416514569238, 0.007170416514569238]	Loss = 0.82549882 (ave = 0.76489038)

2023-07-05 18:24:49,585 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12370	Time 12.406s / 10iters, (1.241)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.441s / 10iters, (0.844)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.078s / 10iters, (0.007798)
Learning rate = [0.0071680817612628615, 0.0071680817612628615]	Loss = 0.86971724 (ave = 0.79351344)

2023-07-05 18:25:01,839 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12380	Time 12.254s / 10iters, (1.225)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.325s / 10iters, (0.833)	Loss Time 2.732s / 10iters, (0.273)	Data load 0.085s / 10iters, (0.008452)
Learning rate = [0.007165746923457351, 0.007165746923457351]	Loss = 0.81383032 (ave = 0.84085656)

2023-07-05 18:25:14,063 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12390	Time 12.224s / 10iters, (1.222)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.076s / 10iters, (0.007578)
Learning rate = [0.00716341200111905, 0.00716341200111905]	Loss = 0.79311240 (ave = 0.82226300)

2023-07-05 18:25:26,250 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12400	Time 12.187s / 10iters, (1.219)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.756s / 10iters, (0.276)	Data load 0.081s / 10iters, (0.008109)
Learning rate = [0.007161076994214287, 0.007161076994214287]	Loss = 0.71976459 (ave = 0.78405346)

2023-07-05 18:25:38,435 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12410	Time 12.185s / 10iters, (1.218)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.763s / 10iters, (0.276)	Data load 0.087s / 10iters, (0.008732)
Learning rate = [0.007158741902709355, 0.007158741902709355]	Loss = 0.81699091 (ave = 0.83236064)

2023-07-05 18:25:50,634 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12420	Time 12.200s / 10iters, (1.220)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.735s / 10iters, (0.273)	Data load 0.074s / 10iters, (0.007372)
Learning rate = [0.007156406726570522, 0.007156406726570522]	Loss = 1.18127716 (ave = 0.85723509)

2023-07-05 18:26:02,801 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12430	Time 12.167s / 10iters, (1.217)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.227s / 10iters, (0.823)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.084s / 10iters, (0.008445)
Learning rate = [0.007154071465764041, 0.007154071465764041]	Loss = 0.87233555 (ave = 0.87079217)

2023-07-05 18:26:15,022 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12440	Time 12.221s / 10iters, (1.222)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.085s / 10iters, (0.008511)
Learning rate = [0.0071517361202561225, 0.0071517361202561225]	Loss = 0.78258181 (ave = 0.82831386)

2023-07-05 18:26:27,403 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12450	Time 12.381s / 10iters, (1.238)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.403s / 10iters, (0.840)	Loss Time 2.792s / 10iters, (0.279)	Data load 0.084s / 10iters, (0.008380)
Learning rate = [0.007149400690012967, 0.007149400690012967]	Loss = 0.80117083 (ave = 0.86347862)

2023-07-05 18:26:39,769 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12460	Time 12.366s / 10iters, (1.237)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.368s / 10iters, (0.837)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.078s / 10iters, (0.007792)
Learning rate = [0.007147065175000741, 0.007147065175000741]	Loss = 0.95391357 (ave = 0.89750284)

2023-07-05 18:26:52,097 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12470	Time 12.327s / 10iters, (1.233)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.260s / 10iters, (0.826)	Loss Time 2.869s / 10iters, (0.287)	Data load 0.086s / 10iters, (0.008573)
Learning rate = [0.007144729575185583, 0.007144729575185583]	Loss = 0.76201034 (ave = 0.78822954)

2023-07-05 18:27:04,329 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12480	Time 12.233s / 10iters, (1.223)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.203s / 10iters, (0.820)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.090s / 10iters, (0.008979)
Learning rate = [0.007142393890533615, 0.007142393890533615]	Loss = 0.81277359 (ave = 0.85661753)

2023-07-05 18:27:16,669 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12490	Time 12.340s / 10iters, (1.234)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.299s / 10iters, (0.830)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.079s / 10iters, (0.007874)
Learning rate = [0.007140058121010925, 0.007140058121010925]	Loss = 0.83993208 (ave = 0.84943740)

2023-07-05 18:27:29,001 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12500	Time 12.332s / 10iters, (1.233)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.079s / 10iters, (0.007935)
Learning rate = [0.007137722266583576, 0.007137722266583576]	Loss = 1.13430560 (ave = 0.84400563)

2023-07-05 18:27:41,235 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12510	Time 12.234s / 10iters, (1.223)	Forward Time 1.137s / 10iters, (0.114)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.711s / 10iters, (0.271)	Data load 0.078s / 10iters, (0.007820)
Learning rate = [0.007135386327217611, 0.007135386327217611]	Loss = 0.89011455 (ave = 0.81610879)

2023-07-05 18:27:53,548 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12520	Time 12.312s / 10iters, (1.231)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.323s / 10iters, (0.832)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.087s / 10iters, (0.008739)
Learning rate = [0.007133050302879037, 0.007133050302879037]	Loss = 0.82246840 (ave = 0.83278246)

2023-07-05 18:28:05,964 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12530	Time 12.416s / 10iters, (1.242)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.349s / 10iters, (0.835)	Loss Time 2.865s / 10iters, (0.287)	Data load 0.080s / 10iters, (0.007964)
Learning rate = [0.007130714193533847, 0.007130714193533847]	Loss = 0.71393746 (ave = 0.81436538)

2023-07-05 18:28:18,224 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12540	Time 12.260s / 10iters, (1.226)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.078s / 10iters, (0.007833)
Learning rate = [0.007128377999147997, 0.007128377999147997]	Loss = 0.81383884 (ave = 0.83394870)

2023-07-05 18:28:30,591 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12550	Time 12.367s / 10iters, (1.237)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.334s / 10iters, (0.833)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.097s / 10iters, (0.009674)
Learning rate = [0.007126041719687424, 0.007126041719687424]	Loss = 0.76386786 (ave = 0.77259406)

2023-07-05 18:28:42,945 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12560	Time 12.354s / 10iters, (1.235)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.312s / 10iters, (0.831)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.083s / 10iters, (0.008290)
Learning rate = [0.007123705355118037, 0.007123705355118037]	Loss = 0.82837057 (ave = 0.84409214)

2023-07-05 18:28:55,158 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12570	Time 12.214s / 10iters, (1.221)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.233s / 10iters, (0.823)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007496)
Learning rate = [0.007121368905405718, 0.007121368905405718]	Loss = 0.81373394 (ave = 0.77200351)

2023-07-05 18:29:07,473 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12580	Time 12.315s / 10iters, (1.231)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.299s / 10iters, (0.830)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.082s / 10iters, (0.008181)
Learning rate = [0.007119032370516322, 0.007119032370516322]	Loss = 0.82140768 (ave = 0.90326283)

2023-07-05 18:29:19,789 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12590	Time 12.316s / 10iters, (1.232)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.325s / 10iters, (0.832)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.087s / 10iters, (0.008701)
Learning rate = [0.007116695750415684, 0.007116695750415684]	Loss = 0.75563860 (ave = 0.79137667)

2023-07-05 18:29:31,981 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12600	Time 12.193s / 10iters, (1.219)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.209s / 10iters, (0.821)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.079s / 10iters, (0.007904)
Learning rate = [0.007114359045069602, 0.007114359045069602]	Loss = 0.76987743 (ave = 0.81210896)

2023-07-05 18:29:44,038 INFO    [trainer_contrastive.py, 272] Train Epoch: 33	Train Iteration: 12610	Time 12.057s / 10iters, (1.206)	Forward Time 1.081s / 10iters, (0.108)	Backward Time 8.157s / 10iters, (0.816)	Loss Time 2.742s / 10iters, (0.274)	Data load 0.076s / 10iters, (0.007638)
Learning rate = [0.007112022254443859, 0.007112022254443859]	Loss = 0.83187115 (ave = 0.82469643)

2023-07-05 18:29:59,026 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12620	Time 14.800s / 10iters, (1.480)	Forward Time 1.300s / 10iters, (0.130)	Backward Time 8.320s / 10iters, (0.832)	Loss Time 2.656s / 10iters, (0.266)	Data load 2.523s / 10iters, (0.252316)
Learning rate = [0.007109685378504205, 0.007109685378504205]	Loss = 0.92882168 (ave = 0.83152651)

2023-07-05 18:30:11,377 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12630	Time 12.351s / 10iters, (1.235)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.415s / 10iters, (0.841)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.094s / 10iters, (0.009363)
Learning rate = [0.007107348417216365, 0.007107348417216365]	Loss = 0.76412988 (ave = 0.77309834)

2023-07-05 18:30:23,680 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12640	Time 12.303s / 10iters, (1.230)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.335s / 10iters, (0.834)	Loss Time 2.765s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007525)
Learning rate = [0.007105011370546039, 0.007105011370546039]	Loss = 0.86955887 (ave = 0.80909157)

2023-07-05 18:30:35,873 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12650	Time 12.193s / 10iters, (1.219)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.272s / 10iters, (0.827)	Loss Time 2.755s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007511)
Learning rate = [0.007102674238458899, 0.007102674238458899]	Loss = 0.85298878 (ave = 0.78574855)

2023-07-05 18:30:48,127 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12660	Time 12.255s / 10iters, (1.225)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.245s / 10iters, (0.825)	Loss Time 2.835s / 10iters, (0.283)	Data load 0.080s / 10iters, (0.008046)
Learning rate = [0.007100337020920592, 0.007100337020920592]	Loss = 0.75935441 (ave = 0.80436714)

2023-07-05 18:31:00,495 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12670	Time 12.367s / 10iters, (1.237)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.324s / 10iters, (0.832)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.086s / 10iters, (0.008643)
Learning rate = [0.007097999717896739, 0.007097999717896739]	Loss = 0.92636585 (ave = 0.82002098)

2023-07-05 18:31:12,819 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12680	Time 12.324s / 10iters, (1.232)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.282s / 10iters, (0.828)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.077s / 10iters, (0.007658)
Learning rate = [0.007095662329352932, 0.007095662329352932]	Loss = 0.70900762 (ave = 0.79718999)

2023-07-05 18:31:25,030 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12690	Time 12.211s / 10iters, (1.221)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.216s / 10iters, (0.822)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.096s / 10iters, (0.009582)
Learning rate = [0.00709332485525474, 0.00709332485525474]	Loss = 0.72349679 (ave = 0.77918549)

2023-07-05 18:31:37,417 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12700	Time 12.388s / 10iters, (1.239)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.347s / 10iters, (0.835)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.095s / 10iters, (0.009520)
Learning rate = [0.007090987295567703, 0.007090987295567703]	Loss = 0.74013478 (ave = 0.97223127)

2023-07-05 18:31:49,703 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12710	Time 12.285s / 10iters, (1.229)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.079s / 10iters, (0.007937)
Learning rate = [0.007088649650257334, 0.007088649650257334]	Loss = 0.76285702 (ave = 0.78613042)

2023-07-05 18:32:02,080 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12720	Time 12.377s / 10iters, (1.238)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.083s / 10iters, (0.008265)
Learning rate = [0.007086311919289124, 0.007086311919289124]	Loss = 0.81135988 (ave = 0.76795002)

2023-07-05 18:32:14,420 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12730	Time 12.340s / 10iters, (1.234)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.095s / 10iters, (0.009514)
Learning rate = [0.00708397410262853, 0.00708397410262853]	Loss = 0.79216957 (ave = 0.83171839)

2023-07-05 18:32:26,966 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12740	Time 12.547s / 10iters, (1.255)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.453s / 10iters, (0.845)	Loss Time 2.892s / 10iters, (0.289)	Data load 0.080s / 10iters, (0.007997)
Learning rate = [0.007081636200240989, 0.007081636200240989]	Loss = 0.95149267 (ave = 0.85981690)

2023-07-05 18:32:39,269 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12750	Time 12.303s / 10iters, (1.230)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.091s / 10iters, (0.009101)
Learning rate = [0.00707929821209191, 0.00707929821209191]	Loss = 0.91966975 (ave = 0.83663077)

2023-07-05 18:32:51,654 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12760	Time 12.385s / 10iters, (1.239)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.304s / 10iters, (0.830)	Loss Time 2.884s / 10iters, (0.288)	Data load 0.079s / 10iters, (0.007903)
Learning rate = [0.007076960138146672, 0.007076960138146672]	Loss = 0.91200233 (ave = 0.85273820)

2023-07-05 18:33:03,968 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12770	Time 12.313s / 10iters, (1.231)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.848s / 10iters, (0.285)	Data load 0.084s / 10iters, (0.008354)
Learning rate = [0.007074621978370631, 0.007074621978370631]	Loss = 0.76882041 (ave = 0.80739491)

2023-07-05 18:33:16,242 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12780	Time 12.274s / 10iters, (1.227)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.083s / 10iters, (0.008255)
Learning rate = [0.007072283732729116, 0.007072283732729116]	Loss = 0.93578964 (ave = 0.83900670)

2023-07-05 18:33:28,528 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12790	Time 12.286s / 10iters, (1.229)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.079s / 10iters, (0.007920)
Learning rate = [0.007069945401187423, 0.007069945401187423]	Loss = 0.92637527 (ave = 0.91378474)

2023-07-05 18:33:40,740 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12800	Time 12.212s / 10iters, (1.221)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.085s / 10iters, (0.008453)
Learning rate = [0.007067606983710832, 0.007067606983710832]	Loss = 0.75796539 (ave = 0.81558263)

2023-07-05 18:33:53,080 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12810	Time 12.340s / 10iters, (1.234)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.886s / 10iters, (0.289)	Data load 0.074s / 10iters, (0.007450)
Learning rate = [0.00706526848026459, 0.00706526848026459]	Loss = 1.01272094 (ave = 0.86752586)

2023-07-05 18:34:05,259 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12820	Time 12.179s / 10iters, (1.218)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.157s / 10iters, (0.816)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.088s / 10iters, (0.008785)
Learning rate = [0.007062929890813914, 0.007062929890813914]	Loss = 0.83596218 (ave = 0.82499297)

2023-07-05 18:34:17,521 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12830	Time 12.262s / 10iters, (1.226)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.083s / 10iters, (0.008335)
Learning rate = [0.007060591215324001, 0.007060591215324001]	Loss = 0.83178622 (ave = 0.76985098)

2023-07-05 18:34:29,836 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12840	Time 12.315s / 10iters, (1.232)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.865s / 10iters, (0.287)	Data load 0.076s / 10iters, (0.007576)
Learning rate = [0.007058252453760017, 0.007058252453760017]	Loss = 0.85930324 (ave = 0.85691442)

2023-07-05 18:34:42,153 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12850	Time 12.316s / 10iters, (1.232)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.873s / 10iters, (0.287)	Data load 0.090s / 10iters, (0.009050)
Learning rate = [0.007055913606087102, 0.007055913606087102]	Loss = 0.84555095 (ave = 0.84981281)

2023-07-05 18:34:54,412 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12860	Time 12.259s / 10iters, (1.226)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.850s / 10iters, (0.285)	Data load 0.081s / 10iters, (0.008074)
Learning rate = [0.0070535746722703695, 0.0070535746722703695]	Loss = 0.87161016 (ave = 0.85549259)

2023-07-05 18:35:06,818 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12870	Time 12.406s / 10iters, (1.241)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.328s / 10iters, (0.833)	Loss Time 2.906s / 10iters, (0.291)	Data load 0.074s / 10iters, (0.007426)
Learning rate = [0.0070512356522749045, 0.0070512356522749045]	Loss = 0.75000215 (ave = 0.83850239)

2023-07-05 18:35:19,252 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12880	Time 12.434s / 10iters, (1.243)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.320s / 10iters, (0.832)	Loss Time 2.906s / 10iters, (0.291)	Data load 0.082s / 10iters, (0.008192)
Learning rate = [0.007048896546065767, 0.007048896546065767]	Loss = 1.19130957 (ave = 0.85912949)

2023-07-05 18:35:31,657 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12890	Time 12.405s / 10iters, (1.241)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.345s / 10iters, (0.834)	Loss Time 2.862s / 10iters, (0.286)	Data load 0.088s / 10iters, (0.008788)
Learning rate = [0.0070465573536079885, 0.0070465573536079885]	Loss = 1.06097257 (ave = 0.85438099)

2023-07-05 18:35:44,024 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12900	Time 12.366s / 10iters, (1.237)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.288s / 10iters, (0.829)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.089s / 10iters, (0.008937)
Learning rate = [0.007044218074866574, 0.007044218074866574]	Loss = 1.27923298 (ave = 0.89995226)

2023-07-05 18:35:56,471 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12910	Time 12.447s / 10iters, (1.245)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.351s / 10iters, (0.835)	Loss Time 2.899s / 10iters, (0.290)	Data load 0.076s / 10iters, (0.007641)
Learning rate = [0.007041878709806503, 0.007041878709806503]	Loss = 0.78017414 (ave = 0.84702459)

2023-07-05 18:36:08,888 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12920	Time 12.417s / 10iters, (1.242)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.332s / 10iters, (0.833)	Loss Time 2.887s / 10iters, (0.289)	Data load 0.079s / 10iters, (0.007944)
Learning rate = [0.007039539258392721, 0.007039539258392721]	Loss = 0.85380208 (ave = 0.91258629)

2023-07-05 18:36:21,181 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12930	Time 12.293s / 10iters, (1.229)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.082s / 10iters, (0.008204)
Learning rate = [0.007037199720590157, 0.007037199720590157]	Loss = 0.97260404 (ave = 0.82307033)

2023-07-05 18:36:33,464 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12940	Time 12.283s / 10iters, (1.228)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.087s / 10iters, (0.008739)
Learning rate = [0.007034860096363706, 0.007034860096363706]	Loss = 0.72969413 (ave = 0.80686544)

2023-07-05 18:36:45,741 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12950	Time 12.277s / 10iters, (1.228)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.088s / 10iters, (0.008833)
Learning rate = [0.007032520385678233, 0.007032520385678233]	Loss = 0.81666487 (ave = 0.82492770)

2023-07-05 18:36:58,121 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12960	Time 12.380s / 10iters, (1.238)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.344s / 10iters, (0.834)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.098s / 10iters, (0.009758)
Learning rate = [0.0070301805884985845, 0.0070301805884985845]	Loss = 0.82704735 (ave = 0.79689025)

2023-07-05 18:37:10,354 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12970	Time 12.234s / 10iters, (1.223)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.737s / 10iters, (0.274)	Data load 0.093s / 10iters, (0.009280)
Learning rate = [0.007027840704789574, 0.007027840704789574]	Loss = 0.82434320 (ave = 0.80563704)

2023-07-05 18:37:22,744 INFO    [trainer_contrastive.py, 272] Train Epoch: 34	Train Iteration: 12980	Time 12.389s / 10iters, (1.239)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.408s / 10iters, (0.841)	Loss Time 2.792s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007372)
Learning rate = [0.007025500734515986, 0.007025500734515986]	Loss = 0.76185572 (ave = 0.79651605)

2023-07-05 18:37:38,380 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 12990	Time 15.467s / 10iters, (1.547)	Forward Time 1.211s / 10iters, (0.121)	Backward Time 8.423s / 10iters, (0.842)	Loss Time 2.778s / 10iters, (0.278)	Data load 3.055s / 10iters, (0.305522)
Learning rate = [0.007023160677642584, 0.007023160677642584]	Loss = 0.69358027 (ave = 0.80333084)

2023-07-05 18:37:50,688 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13000	Time 12.308s / 10iters, (1.231)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.331s / 10iters, (0.833)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.094s / 10iters, (0.009448)
Learning rate = [0.007020820534134097, 0.007020820534134097]	Loss = 0.77023101 (ave = 0.78413888)

2023-07-05 18:37:53,620 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 18:38:17,873 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 18:38:41,094 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 18:39:04,376 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 18:39:27,548 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 18:39:50,593 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 18:40:13,190 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 18:40:18,952 INFO    [base.py, 84] Performance 0.7227532946373106 -> 0.727582636251853
2023-07-05 18:40:24,874 INFO    [trainer_contrastive.py, 391] Test Time 148.101s, (2.351)	Loss 0.14479926

2023-07-05 18:40:24,874 INFO    [base.py, 33] Result for seg
2023-07-05 18:40:24,875 INFO    [base.py, 49] Mean IOU: 0.727582636251853

2023-07-05 18:40:24,875 INFO    [base.py, 50] Pixel ACC: 0.9545638179602723

2023-07-05 18:40:37,120 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13010	Time 166.432s / 10iters, (16.643)	Forward Time 1.158s / 10iters, (0.116)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.744s / 10iters, (0.274)	Data load 154.272s / 10iters, (15.427241)
Learning rate = [0.007018480303955231, 0.007018480303955231]	Loss = 0.74148583 (ave = 0.73099186)

2023-07-05 18:40:49,349 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13020	Time 12.229s / 10iters, (1.223)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.079s / 10iters, (0.007944)
Learning rate = [0.007016139987070664, 0.007016139987070664]	Loss = 0.79598379 (ave = 0.80868337)

2023-07-05 18:41:01,491 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13030	Time 12.142s / 10iters, (1.214)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.173s / 10iters, (0.817)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.084s / 10iters, (0.008437)
Learning rate = [0.007013799583445045, 0.007013799583445045]	Loss = 0.70778906 (ave = 0.80995534)

2023-07-05 18:41:13,671 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13040	Time 12.179s / 10iters, (1.218)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.205s / 10iters, (0.821)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.086s / 10iters, (0.008569)
Learning rate = [0.007011459093042998, 0.007011459093042998]	Loss = 0.91962421 (ave = 0.85852033)

2023-07-05 18:41:25,663 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13050	Time 11.993s / 10iters, (1.199)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.095s / 10iters, (0.809)	Loss Time 2.720s / 10iters, (0.272)	Data load 0.075s / 10iters, (0.007468)
Learning rate = [0.007009118515829116, 0.007009118515829116]	Loss = 0.67389268 (ave = 0.81836385)

2023-07-05 18:41:37,898 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13060	Time 12.235s / 10iters, (1.223)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.095s / 10iters, (0.009499)
Learning rate = [0.007006777851767966, 0.007006777851767966]	Loss = 0.77383858 (ave = 0.81125037)

2023-07-05 18:41:50,138 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13070	Time 12.240s / 10iters, (1.224)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.279s / 10iters, (0.828)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007483)
Learning rate = [0.00700443710082409, 0.00700443710082409]	Loss = 1.03129435 (ave = 0.84476366)

2023-07-05 18:42:02,390 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13080	Time 12.253s / 10iters, (1.225)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.074s / 10iters, (0.007437)
Learning rate = [0.007002096262961998, 0.007002096262961998]	Loss = 0.73692435 (ave = 0.84112191)

2023-07-05 18:42:14,680 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13090	Time 12.290s / 10iters, (1.229)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.085s / 10iters, (0.008453)
Learning rate = [0.006999755338146175, 0.006999755338146175]	Loss = 0.75675696 (ave = 0.82286121)

2023-07-05 18:42:26,884 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13100	Time 12.204s / 10iters, (1.220)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.088s / 10iters, (0.008761)
Learning rate = [0.006997414326341079, 0.006997414326341079]	Loss = 0.72639185 (ave = 0.82735371)

2023-07-05 18:42:39,137 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13110	Time 12.253s / 10iters, (1.225)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.262s / 10iters, (0.826)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.088s / 10iters, (0.008774)
Learning rate = [0.006995073227511134, 0.006995073227511134]	Loss = 0.81556469 (ave = 0.79791666)

2023-07-05 18:42:51,432 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13120	Time 12.296s / 10iters, (1.230)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.255s / 10iters, (0.825)	Loss Time 2.875s / 10iters, (0.288)	Data load 0.076s / 10iters, (0.007634)
Learning rate = [0.0069927320416207465, 0.0069927320416207465]	Loss = 0.84017861 (ave = 0.86891148)

2023-07-05 18:43:03,668 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13130	Time 12.235s / 10iters, (1.224)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.188s / 10iters, (0.819)	Loss Time 2.862s / 10iters, (0.286)	Data load 0.081s / 10iters, (0.008125)
Learning rate = [0.006990390768634287, 0.006990390768634287]	Loss = 0.69257045 (ave = 0.77590272)

2023-07-05 18:43:16,052 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13140	Time 12.384s / 10iters, (1.238)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.907s / 10iters, (0.291)	Data load 0.075s / 10iters, (0.007546)
Learning rate = [0.006988049408516102, 0.006988049408516102]	Loss = 0.83470458 (ave = 0.84856560)

2023-07-05 18:43:28,294 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13150	Time 12.243s / 10iters, (1.224)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.205s / 10iters, (0.821)	Loss Time 2.852s / 10iters, (0.285)	Data load 0.078s / 10iters, (0.007756)
Learning rate = [0.006985707961230508, 0.006985707961230508]	Loss = 0.95436168 (ave = 0.81335270)

2023-07-05 18:43:40,651 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13160	Time 12.357s / 10iters, (1.236)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.288s / 10iters, (0.829)	Loss Time 2.901s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007529)
Learning rate = [0.006983366426741796, 0.006983366426741796]	Loss = 0.77439010 (ave = 0.75840210)

2023-07-05 18:43:53,093 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13170	Time 12.441s / 10iters, (1.244)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.347s / 10iters, (0.835)	Loss Time 2.915s / 10iters, (0.291)	Data load 0.086s / 10iters, (0.008633)
Learning rate = [0.006981024805014227, 0.006981024805014227]	Loss = 0.91168475 (ave = 0.78778287)

2023-07-05 18:44:05,334 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13180	Time 12.241s / 10iters, (1.224)	Forward Time 1.136s / 10iters, (0.114)	Backward Time 8.192s / 10iters, (0.819)	Loss Time 2.835s / 10iters, (0.284)	Data load 0.078s / 10iters, (0.007758)
Learning rate = [0.006978683096012034, 0.006978683096012034]	Loss = 0.79215074 (ave = 0.77246655)

2023-07-05 18:44:17,702 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13190	Time 12.368s / 10iters, (1.237)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.897s / 10iters, (0.290)	Data load 0.085s / 10iters, (0.008538)
Learning rate = [0.006976341299699422, 0.006976341299699422]	Loss = 0.80610180 (ave = 0.82660923)

2023-07-05 18:44:30,007 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13200	Time 12.305s / 10iters, (1.231)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.093s / 10iters, (0.009300)
Learning rate = [0.006973999416040572, 0.006973999416040572]	Loss = 0.92083538 (ave = 0.81266723)

2023-07-05 18:44:42,278 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13210	Time 12.270s / 10iters, (1.227)	Forward Time 1.139s / 10iters, (0.114)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.792s / 10iters, (0.279)	Data load 0.078s / 10iters, (0.007763)
Learning rate = [0.006971657444999631, 0.006971657444999631]	Loss = 0.78142339 (ave = 0.81011737)

2023-07-05 18:44:54,522 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13220	Time 12.244s / 10iters, (1.224)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.790s / 10iters, (0.279)	Data load 0.078s / 10iters, (0.007756)
Learning rate = [0.006969315386540719, 0.006969315386540719]	Loss = 0.77714634 (ave = 0.80535583)

2023-07-05 18:45:06,776 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13230	Time 12.254s / 10iters, (1.225)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.235s / 10iters, (0.823)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007563)
Learning rate = [0.0069669732406279355, 0.0069669732406279355]	Loss = 0.72554123 (ave = 0.76380242)

2023-07-05 18:45:19,211 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13240	Time 12.435s / 10iters, (1.244)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.328s / 10iters, (0.833)	Loss Time 2.889s / 10iters, (0.289)	Data load 0.097s / 10iters, (0.009685)
Learning rate = [0.006964631007225337, 0.006964631007225337]	Loss = 0.82041365 (ave = 0.79043556)

2023-07-05 18:45:31,650 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13250	Time 12.439s / 10iters, (1.244)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.362s / 10iters, (0.836)	Loss Time 2.880s / 10iters, (0.288)	Data load 0.089s / 10iters, (0.008874)
Learning rate = [0.006962288686296968, 0.006962288686296968]	Loss = 0.85771650 (ave = 0.84263269)

2023-07-05 18:45:43,883 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13260	Time 12.233s / 10iters, (1.223)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.250s / 10iters, (0.825)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007471)
Learning rate = [0.006959946277806834, 0.006959946277806834]	Loss = 0.94861120 (ave = 0.84109610)

2023-07-05 18:45:56,184 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13270	Time 12.300s / 10iters, (1.230)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.835s / 10iters, (0.284)	Data load 0.099s / 10iters, (0.009883)
Learning rate = [0.006957603781718914, 0.006957603781718914]	Loss = 0.74323088 (ave = 0.82477790)

2023-07-05 18:46:08,443 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13280	Time 12.259s / 10iters, (1.226)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007431)
Learning rate = [0.006955261197997165, 0.006955261197997165]	Loss = 0.82603186 (ave = 0.91587194)

2023-07-05 18:46:20,820 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13290	Time 12.377s / 10iters, (1.238)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.426s / 10iters, (0.843)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.078s / 10iters, (0.007750)
Learning rate = [0.006952918526605506, 0.006952918526605506]	Loss = 1.00085545 (ave = 0.90829038)

2023-07-05 18:46:33,020 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13300	Time 12.200s / 10iters, (1.220)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.750s / 10iters, (0.275)	Data load 0.082s / 10iters, (0.008187)
Learning rate = [0.006950575767507834, 0.006950575767507834]	Loss = 0.86280811 (ave = 0.93178059)

2023-07-05 18:46:45,358 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13310	Time 12.337s / 10iters, (1.234)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.346s / 10iters, (0.835)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.087s / 10iters, (0.008661)
Learning rate = [0.006948232920668019, 0.006948232920668019]	Loss = 0.85090584 (ave = 0.92560022)

2023-07-05 18:46:57,599 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13320	Time 12.241s / 10iters, (1.224)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.262s / 10iters, (0.826)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.087s / 10iters, (0.008731)
Learning rate = [0.006945889986049895, 0.006945889986049895]	Loss = 0.74764150 (ave = 0.93859258)

2023-07-05 18:47:09,966 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13330	Time 12.367s / 10iters, (1.237)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.299s / 10iters, (0.830)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.088s / 10iters, (0.008763)
Learning rate = [0.006943546963617275, 0.006943546963617275]	Loss = 0.81926298 (ave = 0.89995695)

2023-07-05 18:47:22,237 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13340	Time 12.270s / 10iters, (1.227)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.079s / 10iters, (0.007949)
Learning rate = [0.006941203853333941, 0.006941203853333941]	Loss = 0.86724299 (ave = 0.85595192)

2023-07-05 18:47:34,270 INFO    [trainer_contrastive.py, 272] Train Epoch: 35	Train Iteration: 13350	Time 12.033s / 10iters, (1.203)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.152s / 10iters, (0.815)	Loss Time 2.717s / 10iters, (0.272)	Data load 0.074s / 10iters, (0.007352)
Learning rate = [0.006938860655163643, 0.006938860655163643]	Loss = 0.77492654 (ave = 0.81844131)

2023-07-05 18:47:49,537 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13360	Time 15.056s / 10iters, (1.506)	Forward Time 1.148s / 10iters, (0.115)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.730s / 10iters, (0.273)	Data load 2.919s / 10iters, (0.291856)
Learning rate = [0.00693651736907011, 0.00693651736907011]	Loss = 0.70856333 (ave = 0.88621475)

2023-07-05 18:48:01,683 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13370	Time 12.146s / 10iters, (1.215)	Forward Time 1.164s / 10iters, (0.116)	Backward Time 8.208s / 10iters, (0.821)	Loss Time 2.683s / 10iters, (0.268)	Data load 0.091s / 10iters, (0.009144)
Learning rate = [0.006934173995017036, 0.006934173995017036]	Loss = 0.76382148 (ave = 0.93471782)

2023-07-05 18:48:14,015 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13380	Time 12.331s / 10iters, (1.233)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.096s / 10iters, (0.009637)
Learning rate = [0.006931830532968086, 0.006931830532968086]	Loss = 0.84315264 (ave = 0.91763321)

2023-07-05 18:48:26,331 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13390	Time 12.316s / 10iters, (1.232)	Forward Time 1.142s / 10iters, (0.114)	Backward Time 8.337s / 10iters, (0.834)	Loss Time 2.749s / 10iters, (0.275)	Data load 0.088s / 10iters, (0.008780)
Learning rate = [0.006929486982886906, 0.006929486982886906]	Loss = 0.87012208 (ave = 0.84261804)

2023-07-05 18:48:38,616 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13400	Time 12.285s / 10iters, (1.228)	Forward Time 1.144s / 10iters, (0.114)	Backward Time 8.278s / 10iters, (0.828)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007499)
Learning rate = [0.006927143344737097, 0.006927143344737097]	Loss = 0.90262675 (ave = 0.83781235)

2023-07-05 18:48:50,921 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13410	Time 12.306s / 10iters, (1.231)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.319s / 10iters, (0.832)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.092s / 10iters, (0.009221)
Learning rate = [0.006924799618482246, 0.006924799618482246]	Loss = 0.88187957 (ave = 0.77172511)

2023-07-05 18:49:03,208 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13420	Time 12.286s / 10iters, (1.229)	Forward Time 1.137s / 10iters, (0.114)	Backward Time 8.270s / 10iters, (0.827)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.079s / 10iters, (0.007906)
Learning rate = [0.006922455804085904, 0.006922455804085904]	Loss = 0.82125586 (ave = 0.80890694)

2023-07-05 18:49:15,636 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13430	Time 12.429s / 10iters, (1.243)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.388s / 10iters, (0.839)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.088s / 10iters, (0.008825)
Learning rate = [0.006920111901511595, 0.006920111901511595]	Loss = 0.87665147 (ave = 0.80734732)

2023-07-05 18:49:28,081 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13440	Time 12.445s / 10iters, (1.244)	Forward Time 1.143s / 10iters, (0.114)	Backward Time 8.408s / 10iters, (0.841)	Loss Time 2.818s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007493)
Learning rate = [0.006917767910722814, 0.006917767910722814]	Loss = 0.93006754 (ave = 0.82204436)

2023-07-05 18:49:40,354 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13450	Time 12.273s / 10iters, (1.227)	Forward Time 1.148s / 10iters, (0.115)	Backward Time 8.326s / 10iters, (0.833)	Loss Time 2.723s / 10iters, (0.272)	Data load 0.075s / 10iters, (0.007532)
Learning rate = [0.0069154238316830275, 0.0069154238316830275]	Loss = 0.75863916 (ave = 0.81590201)

2023-07-05 18:49:52,602 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13460	Time 12.248s / 10iters, (1.225)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.729s / 10iters, (0.273)	Data load 0.106s / 10iters, (0.010558)
Learning rate = [0.00691307966435567, 0.00691307966435567]	Loss = 1.02318871 (ave = 0.87580130)

2023-07-05 18:50:04,906 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13470	Time 12.304s / 10iters, (1.230)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.084s / 10iters, (0.008395)
Learning rate = [0.006910735408704155, 0.006910735408704155]	Loss = 1.02648997 (ave = 0.83293585)

2023-07-05 18:50:17,322 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13480	Time 12.417s / 10iters, (1.242)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.397s / 10iters, (0.840)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007580)
Learning rate = [0.006908391064691857, 0.006908391064691857]	Loss = 0.79629970 (ave = 0.81745800)

2023-07-05 18:50:29,888 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13490	Time 12.566s / 10iters, (1.257)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.458s / 10iters, (0.846)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.113s / 10iters, (0.011300)
Learning rate = [0.0069060466322821285, 0.0069060466322821285]	Loss = 0.89070082 (ave = 0.78801292)

2023-07-05 18:50:42,527 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13500	Time 12.638s / 10iters, (1.264)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.583s / 10iters, (0.858)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.084s / 10iters, (0.008392)
Learning rate = [0.006903702111438289, 0.006903702111438289]	Loss = 0.74009371 (ave = 0.78885624)

2023-07-05 18:50:54,890 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13510	Time 12.364s / 10iters, (1.236)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.326s / 10iters, (0.833)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.079s / 10iters, (0.007941)
Learning rate = [0.006901357502123632, 0.006901357502123632]	Loss = 0.85799360 (ave = 0.78975849)

2023-07-05 18:51:07,384 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13520	Time 12.494s / 10iters, (1.249)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.496s / 10iters, (0.850)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.084s / 10iters, (0.008434)
Learning rate = [0.006899012804301421, 0.006899012804301421]	Loss = 0.82570994 (ave = 0.80595238)

2023-07-05 18:51:19,611 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13530	Time 12.227s / 10iters, (1.223)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.720s / 10iters, (0.272)	Data load 0.091s / 10iters, (0.009054)
Learning rate = [0.0068966680179348904, 0.0068966680179348904]	Loss = 0.79063869 (ave = 0.80993196)

2023-07-05 18:51:31,924 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13540	Time 12.313s / 10iters, (1.231)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.424s / 10iters, (0.842)	Loss Time 2.693s / 10iters, (0.269)	Data load 0.089s / 10iters, (0.008881)
Learning rate = [0.006894323142987242, 0.006894323142987242]	Loss = 0.81943381 (ave = 0.81518061)

2023-07-05 18:51:44,220 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13550	Time 12.295s / 10iters, (1.230)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.377s / 10iters, (0.838)	Loss Time 2.710s / 10iters, (0.271)	Data load 0.074s / 10iters, (0.007442)
Learning rate = [0.006891978179421656, 0.006891978179421656]	Loss = 0.82534319 (ave = 0.85360357)

2023-07-05 18:51:56,518 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13560	Time 12.298s / 10iters, (1.230)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.356s / 10iters, (0.836)	Loss Time 2.737s / 10iters, (0.274)	Data load 0.097s / 10iters, (0.009696)
Learning rate = [0.006889633127201274, 0.006889633127201274]	Loss = 0.76336402 (ave = 0.85173369)

2023-07-05 18:52:08,697 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13570	Time 12.180s / 10iters, (1.218)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.341s / 10iters, (0.834)	Loss Time 2.634s / 10iters, (0.263)	Data load 0.074s / 10iters, (0.007440)
Learning rate = [0.006887287986289217, 0.006887287986289217]	Loss = 0.89898729 (ave = 0.78236713)

2023-07-05 18:52:20,946 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13580	Time 12.249s / 10iters, (1.225)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.339s / 10iters, (0.834)	Loss Time 2.721s / 10iters, (0.272)	Data load 0.085s / 10iters, (0.008511)
Learning rate = [0.00688494275664857, 0.00688494275664857]	Loss = 0.80401164 (ave = 0.77867469)

2023-07-05 18:52:33,230 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13590	Time 12.284s / 10iters, (1.228)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.099s / 10iters, (0.009863)
Learning rate = [0.006882597438242392, 0.006882597438242392]	Loss = 0.79921746 (ave = 0.77256560)

2023-07-05 18:52:45,536 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13600	Time 12.306s / 10iters, (1.231)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.082s / 10iters, (0.008212)
Learning rate = [0.006880252031033713, 0.006880252031033713]	Loss = 0.72959316 (ave = 0.91322362)

2023-07-05 18:52:57,782 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13610	Time 12.246s / 10iters, (1.225)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.764s / 10iters, (0.276)	Data load 0.117s / 10iters, (0.011734)
Learning rate = [0.006877906534985532, 0.006877906534985532]	Loss = 0.83151078 (ave = 0.81967427)

2023-07-05 18:53:10,253 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13620	Time 12.471s / 10iters, (1.247)	Forward Time 1.179s / 10iters, (0.118)	Backward Time 8.481s / 10iters, (0.848)	Loss Time 2.723s / 10iters, (0.272)	Data load 0.087s / 10iters, (0.008729)
Learning rate = [0.006875560950060819, 0.006875560950060819]	Loss = 0.77789861 (ave = 0.85591792)

2023-07-05 18:53:22,703 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13630	Time 12.451s / 10iters, (1.245)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.437s / 10iters, (0.844)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.092s / 10iters, (0.009212)
Learning rate = [0.006873215276222517, 0.006873215276222517]	Loss = 0.78454208 (ave = 0.79706097)

2023-07-05 18:53:35,185 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13640	Time 12.481s / 10iters, (1.248)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.464s / 10iters, (0.846)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.118s / 10iters, (0.011817)
Learning rate = [0.006870869513433534, 0.006870869513433534]	Loss = 0.94281268 (ave = 0.82163934)

2023-07-05 18:53:47,358 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13650	Time 12.173s / 10iters, (1.217)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.207s / 10iters, (0.821)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007447)
Learning rate = [0.006868523661656753, 0.006868523661656753]	Loss = 0.79450667 (ave = 0.80083829)

2023-07-05 18:53:59,797 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13660	Time 12.439s / 10iters, (1.244)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.432s / 10iters, (0.843)	Loss Time 2.790s / 10iters, (0.279)	Data load 0.085s / 10iters, (0.008459)
Learning rate = [0.006866177720855027, 0.006866177720855027]	Loss = 0.70026320 (ave = 0.79148681)

2023-07-05 18:54:12,110 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13670	Time 12.313s / 10iters, (1.231)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.357s / 10iters, (0.836)	Loss Time 2.758s / 10iters, (0.276)	Data load 0.082s / 10iters, (0.008224)
Learning rate = [0.006863831690991176, 0.006863831690991176]	Loss = 0.83284962 (ave = 0.82251646)

2023-07-05 18:54:24,388 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13680	Time 12.278s / 10iters, (1.228)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.315s / 10iters, (0.831)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.090s / 10iters, (0.009010)
Learning rate = [0.006861485572027997, 0.006861485572027997]	Loss = 0.68269825 (ave = 0.78427425)

2023-07-05 18:54:36,734 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13690	Time 12.346s / 10iters, (1.235)	Forward Time 1.142s / 10iters, (0.114)	Backward Time 8.329s / 10iters, (0.833)	Loss Time 2.765s / 10iters, (0.276)	Data load 0.110s / 10iters, (0.010960)
Learning rate = [0.006859139363928249, 0.006859139363928249]	Loss = 0.84117949 (ave = 0.84923546)

2023-07-05 18:54:49,029 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13700	Time 12.295s / 10iters, (1.229)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.309s / 10iters, (0.831)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007417)
Learning rate = [0.006856793066654666, 0.006856793066654666]	Loss = 0.80014503 (ave = 0.76279107)

2023-07-05 18:55:01,323 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13710	Time 12.294s / 10iters, (1.229)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.804s / 10iters, (0.280)	Data load 0.105s / 10iters, (0.010472)
Learning rate = [0.006854446680169954, 0.006854446680169954]	Loss = 0.71790338 (ave = 0.77394505)

2023-07-05 18:55:13,325 INFO    [trainer_contrastive.py, 272] Train Epoch: 36	Train Iteration: 13720	Time 12.002s / 10iters, (1.200)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.132s / 10iters, (0.813)	Loss Time 2.707s / 10iters, (0.271)	Data load 0.082s / 10iters, (0.008229)
Learning rate = [0.006852100204436785, 0.006852100204436785]	Loss = 0.87248588 (ave = 0.78986148)

2023-07-05 18:55:28,365 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13730	Time 14.887s / 10iters, (1.489)	Forward Time 1.231s / 10iters, (0.123)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.659s / 10iters, (0.266)	Data load 2.734s / 10iters, (0.273391)
Learning rate = [0.006849753639417805, 0.006849753639417805]	Loss = 0.70939195 (ave = 0.75768986)

2023-07-05 18:55:40,778 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13740	Time 12.413s / 10iters, (1.241)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.475s / 10iters, (0.848)	Loss Time 2.727s / 10iters, (0.273)	Data load 0.076s / 10iters, (0.007628)
Learning rate = [0.0068474069850756256, 0.0068474069850756256]	Loss = 0.71859604 (ave = 0.79022595)

2023-07-05 18:55:53,248 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13750	Time 12.470s / 10iters, (1.247)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.553s / 10iters, (0.855)	Loss Time 2.712s / 10iters, (0.271)	Data load 0.083s / 10iters, (0.008289)
Learning rate = [0.006845060241372832, 0.006845060241372832]	Loss = 0.80700666 (ave = 0.83025020)

2023-07-05 18:56:05,572 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13760	Time 12.324s / 10iters, (1.232)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.403s / 10iters, (0.840)	Loss Time 2.723s / 10iters, (0.272)	Data load 0.077s / 10iters, (0.007668)
Learning rate = [0.006842713408271981, 0.006842713408271981]	Loss = 0.76201868 (ave = 0.77712876)

2023-07-05 18:56:17,894 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13770	Time 12.322s / 10iters, (1.232)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.362s / 10iters, (0.836)	Loss Time 2.756s / 10iters, (0.276)	Data load 0.083s / 10iters, (0.008345)
Learning rate = [0.006840366485735592, 0.006840366485735592]	Loss = 0.77177727 (ave = 0.80815324)

2023-07-05 18:56:30,221 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13780	Time 12.328s / 10iters, (1.233)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.344s / 10iters, (0.834)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007510)
Learning rate = [0.006838019473726163, 0.006838019473726163]	Loss = 0.74552482 (ave = 0.77157266)

2023-07-05 18:56:42,600 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13790	Time 12.378s / 10iters, (1.238)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.343s / 10iters, (0.834)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.084s / 10iters, (0.008428)
Learning rate = [0.006835672372206158, 0.006835672372206158]	Loss = 0.86152077 (ave = 0.76784917)

2023-07-05 18:56:54,863 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13800	Time 12.263s / 10iters, (1.226)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.253s / 10iters, (0.825)	Loss Time 2.803s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007572)
Learning rate = [0.006833325181138011, 0.006833325181138011]	Loss = 0.89082891 (ave = 0.84326788)

2023-07-05 18:57:07,254 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13810	Time 12.391s / 10iters, (1.239)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.405s / 10iters, (0.841)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.087s / 10iters, (0.008668)
Learning rate = [0.006830977900484127, 0.006830977900484127]	Loss = 0.79844981 (ave = 0.83000715)

2023-07-05 18:57:19,446 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13820	Time 12.192s / 10iters, (1.219)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007619)
Learning rate = [0.006828630530206877, 0.006828630530206877]	Loss = 0.64424098 (ave = 0.77467421)

2023-07-05 18:57:31,969 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13830	Time 12.523s / 10iters, (1.252)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.436s / 10iters, (0.844)	Loss Time 2.904s / 10iters, (0.290)	Data load 0.080s / 10iters, (0.008005)
Learning rate = [0.006826283070268608, 0.006826283070268608]	Loss = 1.04485846 (ave = 0.81256043)

2023-07-05 18:57:44,606 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13840	Time 12.637s / 10iters, (1.264)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.544s / 10iters, (0.854)	Loss Time 2.904s / 10iters, (0.290)	Data load 0.081s / 10iters, (0.008072)
Learning rate = [0.006823935520631633, 0.006823935520631633]	Loss = 0.75270402 (ave = 0.81124734)

2023-07-05 18:57:56,956 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13850	Time 12.350s / 10iters, (1.235)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.312s / 10iters, (0.831)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007459)
Learning rate = [0.0068215878812582335, 0.0068215878812582335]	Loss = 0.75167942 (ave = 0.82072825)

2023-07-05 18:58:09,389 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13860	Time 12.432s / 10iters, (1.243)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.363s / 10iters, (0.836)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.089s / 10iters, (0.008916)
Learning rate = [0.006819240152110665, 0.006819240152110665]	Loss = 0.73744351 (ave = 0.83368432)

2023-07-05 18:58:21,802 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13870	Time 12.413s / 10iters, (1.241)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.344s / 10iters, (0.834)	Loss Time 2.862s / 10iters, (0.286)	Data load 0.083s / 10iters, (0.008266)
Learning rate = [0.0068168923331511505, 0.0068168923331511505]	Loss = 0.85445601 (ave = 0.80379150)

2023-07-05 18:58:34,249 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13880	Time 12.447s / 10iters, (1.245)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.402s / 10iters, (0.840)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007426)
Learning rate = [0.006814544424341877, 0.006814544424341877]	Loss = 0.76347226 (ave = 0.79302418)

2023-07-05 18:58:46,676 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13890	Time 12.427s / 10iters, (1.243)	Forward Time 1.135s / 10iters, (0.114)	Backward Time 8.361s / 10iters, (0.836)	Loss Time 2.852s / 10iters, (0.285)	Data load 0.079s / 10iters, (0.007869)
Learning rate = [0.006812196425645014, 0.006812196425645014]	Loss = 0.81908321 (ave = 0.79592354)

2023-07-05 18:58:59,151 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13900	Time 12.474s / 10iters, (1.247)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.360s / 10iters, (0.836)	Loss Time 2.912s / 10iters, (0.291)	Data load 0.077s / 10iters, (0.007719)
Learning rate = [0.0068098483370226896, 0.0068098483370226896]	Loss = 0.74647707 (ave = 0.78721563)

2023-07-05 18:59:11,659 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13910	Time 12.508s / 10iters, (1.251)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.439s / 10iters, (0.844)	Loss Time 2.897s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007518)
Learning rate = [0.006807500158437003, 0.006807500158437003]	Loss = 0.85283482 (ave = 0.81931881)

2023-07-05 18:59:23,994 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13920	Time 12.335s / 10iters, (1.233)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.850s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007441)
Learning rate = [0.006805151889850029, 0.006805151889850029]	Loss = 0.75215876 (ave = 0.81736010)

2023-07-05 18:59:36,381 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13930	Time 12.387s / 10iters, (1.239)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.326s / 10iters, (0.833)	Loss Time 2.894s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007457)
Learning rate = [0.006802803531223806, 0.006802803531223806]	Loss = 0.84570134 (ave = 0.86588321)

2023-07-05 18:59:48,830 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13940	Time 12.450s / 10iters, (1.245)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.389s / 10iters, (0.839)	Loss Time 2.887s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007465)
Learning rate = [0.006800455082520342, 0.006800455082520342]	Loss = 0.71660250 (ave = 0.82315745)

2023-07-05 19:00:01,250 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13950	Time 12.419s / 10iters, (1.242)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.349s / 10iters, (0.835)	Loss Time 2.900s / 10iters, (0.290)	Data load 0.082s / 10iters, (0.008150)
Learning rate = [0.006798106543701616, 0.006798106543701616]	Loss = 0.78333771 (ave = 0.80020233)

2023-07-05 19:00:13,651 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13960	Time 12.401s / 10iters, (1.240)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.278s / 10iters, (0.828)	Loss Time 2.947s / 10iters, (0.295)	Data load 0.077s / 10iters, (0.007748)
Learning rate = [0.006795757914729576, 0.006795757914729576]	Loss = 0.76146615 (ave = 0.81022732)

2023-07-05 19:00:26,062 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13970	Time 12.412s / 10iters, (1.241)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.922s / 10iters, (0.292)	Data load 0.078s / 10iters, (0.007843)
Learning rate = [0.0067934091955661425, 0.0067934091955661425]	Loss = 0.76594150 (ave = 0.84290072)

2023-07-05 19:00:38,457 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13980	Time 12.395s / 10iters, (1.240)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.327s / 10iters, (0.833)	Loss Time 2.893s / 10iters, (0.289)	Data load 0.078s / 10iters, (0.007799)
Learning rate = [0.006791060386173201, 0.006791060386173201]	Loss = 0.82410872 (ave = 0.82798941)

2023-07-05 19:00:50,799 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 13990	Time 12.342s / 10iters, (1.234)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007411)
Learning rate = [0.006788711486512606, 0.006788711486512606]	Loss = 0.74971890 (ave = 0.81132913)

2023-07-05 19:01:03,153 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 14000	Time 12.354s / 10iters, (1.235)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.278s / 10iters, (0.828)	Loss Time 2.903s / 10iters, (0.290)	Data load 0.081s / 10iters, (0.008144)
Learning rate = [0.006786362496546184, 0.006786362496546184]	Loss = 0.77967781 (ave = 0.79485754)

2023-07-05 19:01:06,935 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 19:01:30,786 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 19:01:54,005 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 19:02:17,333 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 19:02:40,508 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 19:03:03,513 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 19:03:26,301 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 19:03:34,990 INFO    [trainer_contrastive.py, 391] Test Time 148.856s, (2.363)	Loss 0.15480991

2023-07-05 19:03:34,991 INFO    [base.py, 33] Result for seg
2023-07-05 19:03:34,992 INFO    [base.py, 49] Mean IOU: 0.7114339417568599

2023-07-05 19:03:34,993 INFO    [base.py, 50] Pixel ACC: 0.95138182213903

2023-07-05 19:03:47,225 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 14010	Time 164.072s / 10iters, (16.407)	Forward Time 1.170s / 10iters, (0.117)	Backward Time 8.238s / 10iters, (0.824)	Loss Time 2.731s / 10iters, (0.273)	Data load 151.933s / 10iters, (15.193313)
Learning rate = [0.006784013416235728, 0.006784013416235728]	Loss = 0.98618817 (ave = 0.80375140)

2023-07-05 19:03:59,394 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 14020	Time 12.168s / 10iters, (1.217)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.705s / 10iters, (0.270)	Data load 0.075s / 10iters, (0.007461)
Learning rate = [0.006781664245543003, 0.006781664245543003]	Loss = 0.95068216 (ave = 0.89334008)

2023-07-05 19:04:11,746 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 14030	Time 12.353s / 10iters, (1.235)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.441s / 10iters, (0.844)	Loss Time 2.716s / 10iters, (0.272)	Data load 0.075s / 10iters, (0.007452)
Learning rate = [0.006779314984429743, 0.006779314984429743]	Loss = 0.87199759 (ave = 0.80229914)

2023-07-05 19:04:24,031 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 14040	Time 12.285s / 10iters, (1.228)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.397s / 10iters, (0.840)	Loss Time 2.683s / 10iters, (0.268)	Data load 0.074s / 10iters, (0.007423)
Learning rate = [0.006776965632857646, 0.006776965632857646]	Loss = 0.69270968 (ave = 0.82152632)

2023-07-05 19:04:36,105 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 14050	Time 12.074s / 10iters, (1.207)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.186s / 10iters, (0.819)	Loss Time 2.687s / 10iters, (0.269)	Data load 0.104s / 10iters, (0.010368)
Learning rate = [0.006774616190788385, 0.006774616190788385]	Loss = 0.93033171 (ave = 0.83415237)

2023-07-05 19:04:48,197 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 14060	Time 12.092s / 10iters, (1.209)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.685s / 10iters, (0.268)	Data load 0.076s / 10iters, (0.007646)
Learning rate = [0.006772266658183601, 0.006772266658183601]	Loss = 0.83389008 (ave = 0.79681117)

2023-07-05 19:05:00,358 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 14070	Time 12.160s / 10iters, (1.216)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.691s / 10iters, (0.269)	Data load 0.098s / 10iters, (0.009755)
Learning rate = [0.006769917035004899, 0.006769917035004899]	Loss = 0.72224444 (ave = 0.77878516)

2023-07-05 19:05:12,554 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 14080	Time 12.196s / 10iters, (1.220)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.255s / 10iters, (0.825)	Loss Time 2.733s / 10iters, (0.273)	Data load 0.092s / 10iters, (0.009171)
Learning rate = [0.0067675673212138614, 0.0067675673212138614]	Loss = 0.76038361 (ave = 0.80441517)

2023-07-05 19:05:24,440 INFO    [trainer_contrastive.py, 272] Train Epoch: 37	Train Iteration: 14090	Time 11.886s / 10iters, (1.189)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.066s / 10iters, (0.807)	Loss Time 2.659s / 10iters, (0.266)	Data load 0.074s / 10iters, (0.007448)
Learning rate = [0.006765217516772028, 0.006765217516772028]	Loss = 0.73482913 (ave = 0.73564825)

2023-07-05 19:05:39,198 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14100	Time 14.592s / 10iters, (1.459)	Forward Time 1.293s / 10iters, (0.129)	Backward Time 8.130s / 10iters, (0.813)	Loss Time 2.583s / 10iters, (0.258)	Data load 2.586s / 10iters, (0.258587)
Learning rate = [0.0067628676216409216, 0.0067628676216409216]	Loss = 0.73900062 (ave = 0.82921041)

2023-07-05 19:05:51,479 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14110	Time 12.281s / 10iters, (1.228)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.803s / 10iters, (0.280)	Data load 0.088s / 10iters, (0.008796)
Learning rate = [0.0067605176357820205, 0.0067605176357820205]	Loss = 0.78955698 (ave = 0.79633541)

2023-07-05 19:06:03,789 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14120	Time 12.310s / 10iters, (1.231)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.315s / 10iters, (0.831)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007439)
Learning rate = [0.006758167559156781, 0.006758167559156781]	Loss = 0.71118951 (ave = 0.85275719)

2023-07-05 19:06:16,173 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14130	Time 12.384s / 10iters, (1.238)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.361s / 10iters, (0.836)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.087s / 10iters, (0.008686)
Learning rate = [0.0067558173917266215, 0.0067558173917266215]	Loss = 0.73868597 (ave = 0.79762594)

2023-07-05 19:06:28,510 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14140	Time 12.337s / 10iters, (1.234)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.083s / 10iters, (0.008285)
Learning rate = [0.006753467133452936, 0.006753467133452936]	Loss = 0.66017014 (ave = 0.81058013)

2023-07-05 19:06:40,915 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14150	Time 12.404s / 10iters, (1.240)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.333s / 10iters, (0.833)	Loss Time 2.868s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007541)
Learning rate = [0.00675111678429708, 0.00675111678429708]	Loss = 0.77762538 (ave = 0.79839098)

2023-07-05 19:06:53,256 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14160	Time 12.341s / 10iters, (1.234)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.091s / 10iters, (0.009066)
Learning rate = [0.006748766344220384, 0.006748766344220384]	Loss = 0.86109304 (ave = 0.79489980)

2023-07-05 19:07:05,732 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14170	Time 12.476s / 10iters, (1.248)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.391s / 10iters, (0.839)	Loss Time 2.869s / 10iters, (0.287)	Data load 0.108s / 10iters, (0.010811)
Learning rate = [0.00674641581318414, 0.00674641581318414]	Loss = 0.75362438 (ave = 0.82037860)

2023-07-05 19:07:18,144 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14180	Time 12.412s / 10iters, (1.241)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.348s / 10iters, (0.835)	Loss Time 2.893s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007518)
Learning rate = [0.006744065191149617, 0.006744065191149617]	Loss = 0.80538833 (ave = 0.81733775)

2023-07-05 19:07:30,494 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14190	Time 12.350s / 10iters, (1.235)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.875s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007503)
Learning rate = [0.006741714478078045, 0.006741714478078045]	Loss = 0.72825831 (ave = 0.82401083)

2023-07-05 19:07:42,801 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14200	Time 12.307s / 10iters, (1.231)	Forward Time 1.149s / 10iters, (0.115)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.096s / 10iters, (0.009617)
Learning rate = [0.0067393636739306265, 0.0067393636739306265]	Loss = 0.81389838 (ave = 0.76371043)

2023-07-05 19:07:55,039 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14210	Time 12.238s / 10iters, (1.224)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.758s / 10iters, (0.276)	Data load 0.100s / 10iters, (0.010046)
Learning rate = [0.006737012778668532, 0.006737012778668532]	Loss = 0.89726371 (ave = 0.79430065)

2023-07-05 19:08:07,325 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14220	Time 12.286s / 10iters, (1.229)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007514)
Learning rate = [0.0067346617922529, 0.0067346617922529]	Loss = 0.83589953 (ave = 0.79748139)

2023-07-05 19:08:19,592 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14230	Time 12.267s / 10iters, (1.227)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.797s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007441)
Learning rate = [0.006732310714644835, 0.006732310714644835]	Loss = 0.86931396 (ave = 0.81837152)

2023-07-05 19:08:31,918 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14240	Time 12.326s / 10iters, (1.233)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.326s / 10iters, (0.833)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.089s / 10iters, (0.008909)
Learning rate = [0.006729959545805415, 0.006729959545805415]	Loss = 0.69278860 (ave = 0.75726085)

2023-07-05 19:08:44,262 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14250	Time 12.344s / 10iters, (1.234)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.334s / 10iters, (0.833)	Loss Time 2.785s / 10iters, (0.279)	Data load 0.109s / 10iters, (0.010874)
Learning rate = [0.006727608285695681, 0.006727608285695681]	Loss = 1.00548482 (ave = 0.78499437)

2023-07-05 19:08:56,573 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14260	Time 12.312s / 10iters, (1.231)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007507)
Learning rate = [0.006725256934276645, 0.006725256934276645]	Loss = 1.03526008 (ave = 0.80474864)

2023-07-05 19:09:08,830 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14270	Time 12.257s / 10iters, (1.226)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.081s / 10iters, (0.008138)
Learning rate = [0.006722905491509289, 0.006722905491509289]	Loss = 0.91785902 (ave = 0.81658625)

2023-07-05 19:09:21,151 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14280	Time 12.321s / 10iters, (1.232)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.297s / 10iters, (0.830)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007414)
Learning rate = [0.006720553957354557, 0.006720553957354557]	Loss = 0.79067248 (ave = 0.82832339)

2023-07-05 19:09:33,536 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14290	Time 12.385s / 10iters, (1.238)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.337s / 10iters, (0.834)	Loss Time 2.872s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007454)
Learning rate = [0.006718202331773368, 0.006718202331773368]	Loss = 0.82483554 (ave = 0.79725181)

2023-07-05 19:09:45,834 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14300	Time 12.297s / 10iters, (1.230)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.078s / 10iters, (0.007765)
Learning rate = [0.006715850614726605, 0.006715850614726605]	Loss = 0.67588979 (ave = 0.76774690)

2023-07-05 19:09:58,283 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14310	Time 12.449s / 10iters, (1.245)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.421s / 10iters, (0.842)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007414)
Learning rate = [0.006713498806175119, 0.006713498806175119]	Loss = 0.76023644 (ave = 0.76885669)

2023-07-05 19:10:10,695 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14320	Time 12.412s / 10iters, (1.241)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.375s / 10iters, (0.838)	Loss Time 2.848s / 10iters, (0.285)	Data load 0.094s / 10iters, (0.009372)
Learning rate = [0.006711146906079732, 0.006711146906079732]	Loss = 0.70572227 (ave = 0.76220722)

2023-07-05 19:10:23,071 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14330	Time 12.376s / 10iters, (1.238)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.336s / 10iters, (0.834)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.094s / 10iters, (0.009367)
Learning rate = [0.006708794914401231, 0.006708794914401231]	Loss = 0.82477438 (ave = 0.79507799)

2023-07-05 19:10:35,438 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14340	Time 12.368s / 10iters, (1.237)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.334s / 10iters, (0.833)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.081s / 10iters, (0.008140)
Learning rate = [0.006706442831100371, 0.006706442831100371]	Loss = 0.93688995 (ave = 0.84406946)

2023-07-05 19:10:47,810 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14350	Time 12.371s / 10iters, (1.237)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.087s / 10iters, (0.008719)
Learning rate = [0.006704090656137878, 0.006704090656137878]	Loss = 0.88246369 (ave = 0.79798241)

2023-07-05 19:11:00,250 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14360	Time 12.441s / 10iters, (1.244)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.371s / 10iters, (0.837)	Loss Time 2.898s / 10iters, (0.290)	Data load 0.074s / 10iters, (0.007447)
Learning rate = [0.006701738389474441, 0.006701738389474441]	Loss = 0.85407782 (ave = 0.81969569)

2023-07-05 19:11:12,644 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14370	Time 12.393s / 10iters, (1.239)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.357s / 10iters, (0.836)	Loss Time 2.866s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007519)
Learning rate = [0.006699386031070722, 0.006699386031070722]	Loss = 0.73278689 (ave = 0.72638707)

2023-07-05 19:11:25,080 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14380	Time 12.436s / 10iters, (1.244)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.354s / 10iters, (0.835)	Loss Time 2.877s / 10iters, (0.288)	Data load 0.096s / 10iters, (0.009597)
Learning rate = [0.0066970335808873484, 0.0066970335808873484]	Loss = 0.90195167 (ave = 0.79084928)

2023-07-05 19:11:37,451 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14390	Time 12.371s / 10iters, (1.237)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.326s / 10iters, (0.833)	Loss Time 2.866s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007499)
Learning rate = [0.006694681038884911, 0.006694681038884911]	Loss = 0.96647632 (ave = 0.79717934)

2023-07-05 19:11:49,847 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14400	Time 12.396s / 10iters, (1.240)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.356s / 10iters, (0.836)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007505)
Learning rate = [0.00669232840502398, 0.00669232840502398]	Loss = 0.72171336 (ave = 0.75161849)

2023-07-05 19:12:02,298 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14410	Time 12.450s / 10iters, (1.245)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.414s / 10iters, (0.841)	Loss Time 2.865s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007392)
Learning rate = [0.006689975679265078, 0.006689975679265078]	Loss = 1.06484270 (ave = 0.80051483)

2023-07-05 19:12:14,666 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14420	Time 12.369s / 10iters, (1.237)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.317s / 10iters, (0.832)	Loss Time 2.866s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007459)
Learning rate = [0.006687622861568706, 0.006687622861568706]	Loss = 0.86634189 (ave = 0.79686528)

2023-07-05 19:12:27,073 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14430	Time 12.406s / 10iters, (1.241)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.361s / 10iters, (0.836)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.084s / 10iters, (0.008433)
Learning rate = [0.0066852699518953305, 0.0066852699518953305]	Loss = 0.82721597 (ave = 0.79187863)

2023-07-05 19:12:39,432 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14440	Time 12.359s / 10iters, (1.236)	Forward Time 1.153s / 10iters, (0.115)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.838s / 10iters, (0.284)	Data load 0.078s / 10iters, (0.007768)
Learning rate = [0.0066829169502053845, 0.0066829169502053845]	Loss = 0.81461066 (ave = 0.83248560)

2023-07-05 19:12:51,774 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14450	Time 12.342s / 10iters, (1.234)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.086s / 10iters, (0.008644)
Learning rate = [0.006680563856459266, 0.006680563856459266]	Loss = 0.72747934 (ave = 0.77063107)

2023-07-05 19:13:03,911 INFO    [trainer_contrastive.py, 272] Train Epoch: 38	Train Iteration: 14460	Time 12.137s / 10iters, (1.214)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.204s / 10iters, (0.820)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.073s / 10iters, (0.007343)
Learning rate = [0.006678210670617346, 0.006678210670617346]	Loss = 0.65070975 (ave = 0.70598822)

2023-07-05 19:13:19,048 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14470	Time 14.963s / 10iters, (1.496)	Forward Time 1.184s / 10iters, (0.118)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.754s / 10iters, (0.275)	Data load 2.784s / 10iters, (0.278432)
Learning rate = [0.006675857392639958, 0.006675857392639958]	Loss = 0.94768631 (ave = 0.80822212)

2023-07-05 19:13:31,281 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14480	Time 12.233s / 10iters, (1.223)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.077s / 10iters, (0.007669)
Learning rate = [0.006673504022487408, 0.006673504022487408]	Loss = 0.87398255 (ave = 0.84515075)

2023-07-05 19:13:43,504 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14490	Time 12.223s / 10iters, (1.222)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.217s / 10iters, (0.822)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007519)
Learning rate = [0.00667115056011996, 0.00667115056011996]	Loss = 0.85329539 (ave = 0.83228214)

2023-07-05 19:13:55,759 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14500	Time 12.256s / 10iters, (1.226)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.838s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007498)
Learning rate = [0.006668797005497856, 0.006668797005497856]	Loss = 0.76626199 (ave = 0.79733453)

2023-07-05 19:14:08,024 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14510	Time 12.265s / 10iters, (1.227)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007457)
Learning rate = [0.0066664433585813, 0.0066664433585813]	Loss = 0.78140533 (ave = 0.85815306)

2023-07-05 19:14:20,467 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14520	Time 12.443s / 10iters, (1.244)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.382s / 10iters, (0.838)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007447)
Learning rate = [0.0066640896193304626, 0.0066640896193304626]	Loss = 0.76579368 (ave = 0.81597675)

2023-07-05 19:14:32,880 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14530	Time 12.413s / 10iters, (1.241)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.338s / 10iters, (0.834)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007448)
Learning rate = [0.006661735787705484, 0.006661735787705484]	Loss = 0.76860487 (ave = 0.81699000)

2023-07-05 19:14:45,162 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14540	Time 12.282s / 10iters, (1.228)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.279s / 10iters, (0.828)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007454)
Learning rate = [0.006659381863666471, 0.006659381863666471]	Loss = 0.82014465 (ave = 0.80977634)

2023-07-05 19:14:57,329 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14550	Time 12.167s / 10iters, (1.217)	Forward Time 1.085s / 10iters, (0.109)	Backward Time 8.207s / 10iters, (0.821)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007464)
Learning rate = [0.006657027847173494, 0.006657027847173494]	Loss = 0.97679436 (ave = 0.82074904)

2023-07-05 19:15:09,588 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14560	Time 12.259s / 10iters, (1.226)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.080s / 10iters, (0.007986)
Learning rate = [0.006654673738186598, 0.006654673738186598]	Loss = 0.79332030 (ave = 0.83015248)

2023-07-05 19:15:21,865 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14570	Time 12.277s / 10iters, (1.228)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.275s / 10iters, (0.828)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007419)
Learning rate = [0.006652319536665784, 0.006652319536665784]	Loss = 0.79610759 (ave = 0.81607957)

2023-07-05 19:15:34,043 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14580	Time 12.178s / 10iters, (1.218)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.233s / 10iters, (0.823)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007371)
Learning rate = [0.006649965242571033, 0.006649965242571033]	Loss = 0.74222827 (ave = 0.77219641)

2023-07-05 19:15:46,133 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14590	Time 12.090s / 10iters, (1.209)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.128s / 10iters, (0.813)	Loss Time 2.786s / 10iters, (0.279)	Data load 0.084s / 10iters, (0.008369)
Learning rate = [0.006647610855862282, 0.006647610855862282]	Loss = 0.96767354 (ave = 0.80304074)

2023-07-05 19:15:58,376 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14600	Time 12.243s / 10iters, (1.224)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.233s / 10iters, (0.823)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007447)
Learning rate = [0.006645256376499439, 0.006645256376499439]	Loss = 0.82181245 (ave = 0.80001958)

2023-07-05 19:16:10,542 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14610	Time 12.166s / 10iters, (1.217)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.077s / 10iters, (0.007736)
Learning rate = [0.00664290180444238, 0.00664290180444238]	Loss = 0.76658481 (ave = 0.77626050)

2023-07-05 19:16:22,758 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14620	Time 12.216s / 10iters, (1.222)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.818s / 10iters, (0.282)	Data load 0.077s / 10iters, (0.007693)
Learning rate = [0.00664054713965095, 0.00664054713965095]	Loss = 0.73723960 (ave = 0.78135335)

2023-07-05 19:16:34,944 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14630	Time 12.186s / 10iters, (1.219)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.260s / 10iters, (0.826)	Loss Time 2.757s / 10iters, (0.276)	Data load 0.077s / 10iters, (0.007709)
Learning rate = [0.0066381923820849524, 0.0066381923820849524]	Loss = 0.78513432 (ave = 0.77328395)

2023-07-05 19:16:47,038 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14640	Time 12.094s / 10iters, (1.209)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.156s / 10iters, (0.816)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.078s / 10iters, (0.007783)
Learning rate = [0.006635837531704166, 0.006635837531704166]	Loss = 0.80767483 (ave = 0.83242759)

2023-07-05 19:16:59,282 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14650	Time 12.244s / 10iters, (1.224)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.242s / 10iters, (0.824)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007421)
Learning rate = [0.006633482588468332, 0.006633482588468332]	Loss = 0.83139229 (ave = 0.83407637)

2023-07-05 19:17:11,523 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14660	Time 12.241s / 10iters, (1.224)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.245s / 10iters, (0.824)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007400)
Learning rate = [0.0066311275523371575, 0.0066311275523371575]	Loss = 0.83058465 (ave = 0.83527432)

2023-07-05 19:17:23,715 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14670	Time 12.192s / 10iters, (1.219)	Forward Time 1.085s / 10iters, (0.109)	Backward Time 8.176s / 10iters, (0.818)	Loss Time 2.833s / 10iters, (0.283)	Data load 0.098s / 10iters, (0.009794)
Learning rate = [0.00662877242327032, 0.00662877242327032]	Loss = 0.86074716 (ave = 0.80530541)

2023-07-05 19:17:35,929 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14680	Time 12.214s / 10iters, (1.221)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.192s / 10iters, (0.819)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007493)
Learning rate = [0.006626417201227458, 0.006626417201227458]	Loss = 0.77834004 (ave = 0.80559195)

2023-07-05 19:17:48,243 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14690	Time 12.314s / 10iters, (1.231)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.907s / 10iters, (0.291)	Data load 0.074s / 10iters, (0.007414)
Learning rate = [0.006624061886168184, 0.006624061886168184]	Loss = 0.77144682 (ave = 0.81196936)

2023-07-05 19:18:00,410 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14700	Time 12.166s / 10iters, (1.217)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.153s / 10iters, (0.815)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007431)
Learning rate = [0.006621706478052071, 0.006621706478052071]	Loss = 0.80918890 (ave = 0.80524407)

2023-07-05 19:18:12,634 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14710	Time 12.224s / 10iters, (1.222)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.186s / 10iters, (0.819)	Loss Time 2.868s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007402)
Learning rate = [0.00661935097683866, 0.00661935097683866]	Loss = 0.74831939 (ave = 0.77399306)

2023-07-05 19:18:24,905 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14720	Time 12.271s / 10iters, (1.227)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.865s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007424)
Learning rate = [0.00661699538248746, 0.00661699538248746]	Loss = 0.70486885 (ave = 0.75535123)

2023-07-05 19:18:37,219 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14730	Time 12.314s / 10iters, (1.231)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.080s / 10iters, (0.008039)
Learning rate = [0.006614639694957941, 0.006614639694957941]	Loss = 1.23060906 (ave = 0.83412915)

2023-07-05 19:18:49,520 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14740	Time 12.301s / 10iters, (1.230)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.907s / 10iters, (0.291)	Data load 0.075s / 10iters, (0.007524)
Learning rate = [0.006612283914209549, 0.006612283914209549]	Loss = 0.65586025 (ave = 0.81631048)

2023-07-05 19:19:01,712 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14750	Time 12.192s / 10iters, (1.219)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.180s / 10iters, (0.818)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.078s / 10iters, (0.007825)
Learning rate = [0.0066099280402016885, 0.0066099280402016885]	Loss = 0.79408383 (ave = 0.75385982)

2023-07-05 19:19:13,866 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14760	Time 12.155s / 10iters, (1.215)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.172s / 10iters, (0.817)	Loss Time 2.809s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007474)
Learning rate = [0.006607572072893731, 0.006607572072893731]	Loss = 0.79842675 (ave = 0.80740815)

2023-07-05 19:19:26,027 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14770	Time 12.160s / 10iters, (1.216)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.215s / 10iters, (0.822)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.078s / 10iters, (0.007752)
Learning rate = [0.006605216012245016, 0.006605216012245016]	Loss = 0.81310099 (ave = 0.81085653)

2023-07-05 19:19:38,098 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14780	Time 12.072s / 10iters, (1.207)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.154s / 10iters, (0.815)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.078s / 10iters, (0.007787)
Learning rate = [0.006602859858214852, 0.006602859858214852]	Loss = 0.74594426 (ave = 0.80762975)

2023-07-05 19:19:50,255 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14790	Time 12.157s / 10iters, (1.216)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007505)
Learning rate = [0.0066005036107625046, 0.0066005036107625046]	Loss = 0.82134527 (ave = 0.75400786)

2023-07-05 19:20:02,467 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14800	Time 12.212s / 10iters, (1.221)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.217s / 10iters, (0.822)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.089s / 10iters, (0.008911)
Learning rate = [0.006598147269847218, 0.006598147269847218]	Loss = 0.77765656 (ave = 0.77281355)

2023-07-05 19:20:14,674 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14810	Time 12.207s / 10iters, (1.221)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.242s / 10iters, (0.824)	Loss Time 2.785s / 10iters, (0.279)	Data load 0.084s / 10iters, (0.008368)
Learning rate = [0.006595790835428189, 0.006595790835428189]	Loss = 0.86590463 (ave = 0.80527006)

2023-07-05 19:20:27,125 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14820	Time 12.451s / 10iters, (1.245)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.395s / 10iters, (0.840)	Loss Time 2.856s / 10iters, (0.286)	Data load 0.078s / 10iters, (0.007810)
Learning rate = [0.006593434307464593, 0.006593434307464593]	Loss = 0.62824273 (ave = 0.76633019)

2023-07-05 19:20:39,356 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14830	Time 12.231s / 10iters, (1.223)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.077s / 10iters, (0.007726)
Learning rate = [0.006591077685915561, 0.006591077685915561]	Loss = 0.81632352 (ave = 0.82436292)

2023-07-05 19:20:51,367 INFO    [trainer_contrastive.py, 272] Train Epoch: 39	Train Iteration: 14840	Time 12.011s / 10iters, (1.201)	Forward Time 1.079s / 10iters, (0.108)	Backward Time 8.140s / 10iters, (0.814)	Loss Time 2.717s / 10iters, (0.272)	Data load 0.074s / 10iters, (0.007418)
Learning rate = [0.006588720970740196, 0.006588720970740196]	Loss = 0.73095828 (ave = 0.85039712)

2023-07-05 19:21:06,934 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 14850	Time 15.398s / 10iters, (1.540)	Forward Time 1.168s / 10iters, (0.117)	Backward Time 8.399s / 10iters, (0.840)	Loss Time 2.817s / 10iters, (0.282)	Data load 3.015s / 10iters, (0.301477)
Learning rate = [0.006586364161897566, 0.006586364161897566]	Loss = 0.69326788 (ave = 0.75806340)

2023-07-05 19:21:19,135 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 14860	Time 12.201s / 10iters, (1.220)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.790s / 10iters, (0.279)	Data load 0.079s / 10iters, (0.007881)
Learning rate = [0.006584007259346702, 0.006584007259346702]	Loss = 0.74802202 (ave = 0.77823858)

2023-07-05 19:21:31,445 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 14870	Time 12.310s / 10iters, (1.231)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.790s / 10iters, (0.279)	Data load 0.100s / 10iters, (0.010039)
Learning rate = [0.006581650263046605, 0.006581650263046605]	Loss = 0.72253913 (ave = 0.82505479)

2023-07-05 19:21:43,741 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 14880	Time 12.296s / 10iters, (1.230)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.286s / 10iters, (0.829)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.090s / 10iters, (0.009000)
Learning rate = [0.0065792931729562396, 0.0065792931729562396]	Loss = 0.77002203 (ave = 0.80500472)

2023-07-05 19:21:56,028 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 14890	Time 12.287s / 10iters, (1.229)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.082s / 10iters, (0.008227)
Learning rate = [0.006576935989034534, 0.006576935989034534]	Loss = 0.86332321 (ave = 0.78354467)

2023-07-05 19:22:08,408 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 14900	Time 12.380s / 10iters, (1.238)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.889s / 10iters, (0.289)	Data load 0.092s / 10iters, (0.009245)
Learning rate = [0.006574578711240385, 0.006574578711240385]	Loss = 0.85574287 (ave = 0.84576973)

2023-07-05 19:22:20,686 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 14910	Time 12.278s / 10iters, (1.228)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.890s / 10iters, (0.289)	Data load 0.082s / 10iters, (0.008224)
Learning rate = [0.006572221339532655, 0.006572221339532655]	Loss = 0.80125415 (ave = 0.79699231)

2023-07-05 19:22:32,930 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 14920	Time 12.244s / 10iters, (1.224)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.805s / 10iters, (0.280)	Data load 0.085s / 10iters, (0.008543)
Learning rate = [0.0065698638738701685, 0.0065698638738701685]	Loss = 0.75510454 (ave = 0.82283612)

2023-07-05 19:22:45,318 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 14930	Time 12.388s / 10iters, (1.239)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.349s / 10iters, (0.835)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.085s / 10iters, (0.008515)
Learning rate = [0.006567506314211722, 0.006567506314211722]	Loss = 0.71323037 (ave = 0.86342262)

2023-07-05 19:22:57,557 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 14940	Time 12.240s / 10iters, (1.224)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.265s / 10iters, (0.827)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.083s / 10iters, (0.008282)
Learning rate = [0.0065651486605160705, 0.0065651486605160705]	Loss = 0.94105762 (ave = 0.78292352)

2023-07-05 19:23:09,847 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 14950	Time 12.290s / 10iters, (1.229)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.281s / 10iters, (0.828)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.079s / 10iters, (0.007853)
Learning rate = [0.006562790912741938, 0.006562790912741938]	Loss = 0.80233216 (ave = 0.79784194)

2023-07-05 19:23:22,087 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 14960	Time 12.239s / 10iters, (1.224)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.235s / 10iters, (0.823)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.078s / 10iters, (0.007799)
Learning rate = [0.006560433070848015, 0.006560433070848015]	Loss = 0.78200072 (ave = 0.81642253)

2023-07-05 19:23:34,374 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 14970	Time 12.288s / 10iters, (1.229)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.253s / 10iters, (0.825)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.086s / 10iters, (0.008644)
Learning rate = [0.006558075134792954, 0.006558075134792954]	Loss = 0.78049535 (ave = 0.84577262)

2023-07-05 19:23:46,522 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 14980	Time 12.148s / 10iters, (1.215)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.192s / 10iters, (0.819)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.078s / 10iters, (0.007806)
Learning rate = [0.006555717104535375, 0.006555717104535375]	Loss = 0.83777499 (ave = 0.80794413)

2023-07-05 19:23:58,830 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 14990	Time 12.308s / 10iters, (1.231)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.355s / 10iters, (0.835)	Loss Time 2.759s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007429)
Learning rate = [0.0065533589800338635, 0.0065533589800338635]	Loss = 0.75199425 (ave = 0.80076766)

2023-07-05 19:24:11,027 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15000	Time 12.197s / 10iters, (1.220)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.242s / 10iters, (0.824)	Loss Time 2.751s / 10iters, (0.275)	Data load 0.094s / 10iters, (0.009412)
Learning rate = [0.006551000761246968, 0.006551000761246968]	Loss = 1.07895136 (ave = 0.86152120)

2023-07-05 19:24:14,405 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 19:24:38,017 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 19:25:00,762 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 19:25:23,604 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 19:25:46,672 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 19:26:09,463 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 19:26:31,913 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 19:26:40,662 INFO    [trainer_contrastive.py, 391] Test Time 146.514s, (2.326)	Loss 0.16510698

2023-07-05 19:26:40,663 INFO    [base.py, 33] Result for seg
2023-07-05 19:26:40,663 INFO    [base.py, 49] Mean IOU: 0.6952479288597159

2023-07-05 19:26:40,664 INFO    [base.py, 50] Pixel ACC: 0.9473673654577754

2023-07-05 19:26:53,031 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15010	Time 162.004s / 10iters, (16.200)	Forward Time 1.142s / 10iters, (0.114)	Backward Time 8.362s / 10iters, (0.836)	Loss Time 2.776s / 10iters, (0.278)	Data load 149.724s / 10iters, (14.972400)
Learning rate = [0.006548642448133207, 0.006548642448133207]	Loss = 0.84704667 (ave = 0.78224458)

2023-07-05 19:27:05,243 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15020	Time 12.212s / 10iters, (1.221)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.745s / 10iters, (0.275)	Data load 0.080s / 10iters, (0.007980)
Learning rate = [0.006546284040651058, 0.006546284040651058]	Loss = 0.85869658 (ave = 0.79759963)

2023-07-05 19:27:17,282 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15030	Time 12.039s / 10iters, (1.204)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.167s / 10iters, (0.817)	Loss Time 2.707s / 10iters, (0.271)	Data load 0.075s / 10iters, (0.007528)
Learning rate = [0.006543925538758967, 0.006543925538758967]	Loss = 0.80092669 (ave = 0.81226722)

2023-07-05 19:27:29,447 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15040	Time 12.165s / 10iters, (1.216)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.085s / 10iters, (0.008492)
Learning rate = [0.006541566942415346, 0.006541566942415346]	Loss = 0.96650636 (ave = 0.83811226)

2023-07-05 19:27:41,769 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15050	Time 12.322s / 10iters, (1.232)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.322s / 10iters, (0.832)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.098s / 10iters, (0.009784)
Learning rate = [0.0065392082515785665, 0.0065392082515785665]	Loss = 0.79561198 (ave = 0.79541661)

2023-07-05 19:27:53,929 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15060	Time 12.160s / 10iters, (1.216)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007525)
Learning rate = [0.006536849466206974, 0.006536849466206974]	Loss = 0.80567253 (ave = 0.78992325)

2023-07-05 19:28:06,128 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15070	Time 12.199s / 10iters, (1.220)	Forward Time 1.082s / 10iters, (0.108)	Backward Time 8.255s / 10iters, (0.825)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.089s / 10iters, (0.008878)
Learning rate = [0.0065344905862588735, 0.0065344905862588735]	Loss = 0.84877348 (ave = 0.80577590)

2023-07-05 19:28:18,330 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15080	Time 12.201s / 10iters, (1.220)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.088s / 10iters, (0.008775)
Learning rate = [0.006532131611692531, 0.006532131611692531]	Loss = 0.88515359 (ave = 0.85138245)

2023-07-05 19:28:30,410 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15090	Time 12.081s / 10iters, (1.208)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.195s / 10iters, (0.819)	Loss Time 2.723s / 10iters, (0.272)	Data load 0.077s / 10iters, (0.007658)
Learning rate = [0.006529772542466187, 0.006529772542466187]	Loss = 0.75211710 (ave = 0.82063842)

2023-07-05 19:28:42,644 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15100	Time 12.234s / 10iters, (1.223)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.279s / 10iters, (0.828)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007447)
Learning rate = [0.006527413378538036, 0.006527413378538036]	Loss = 0.76213145 (ave = 0.82652668)

2023-07-05 19:28:54,925 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15110	Time 12.281s / 10iters, (1.228)	Forward Time 1.084s / 10iters, (0.108)	Backward Time 8.264s / 10iters, (0.826)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.086s / 10iters, (0.008580)
Learning rate = [0.006525054119866247, 0.006525054119866247]	Loss = 0.78816015 (ave = 0.78638570)

2023-07-05 19:29:07,134 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15120	Time 12.209s / 10iters, (1.221)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.808s / 10iters, (0.281)	Data load 0.078s / 10iters, (0.007773)
Learning rate = [0.006522694766408948, 0.006522694766408948]	Loss = 0.69061768 (ave = 0.77741672)

2023-07-05 19:29:19,352 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15130	Time 12.218s / 10iters, (1.222)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007417)
Learning rate = [0.006520335318124232, 0.006520335318124232]	Loss = 0.74094844 (ave = 0.83244464)

2023-07-05 19:29:31,593 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15140	Time 12.241s / 10iters, (1.224)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.077s / 10iters, (0.007698)
Learning rate = [0.00651797577497016, 0.00651797577497016]	Loss = 0.85618901 (ave = 0.79432345)

2023-07-05 19:29:43,824 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15150	Time 12.231s / 10iters, (1.223)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.183s / 10iters, (0.818)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.096s / 10iters, (0.009632)
Learning rate = [0.006515616136904754, 0.006515616136904754]	Loss = 0.80827171 (ave = 0.75466304)

2023-07-05 19:29:56,091 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15160	Time 12.267s / 10iters, (1.227)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.255s / 10iters, (0.825)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.077s / 10iters, (0.007709)
Learning rate = [0.0065132564038859996, 0.0065132564038859996]	Loss = 0.76533115 (ave = 0.79798807)

2023-07-05 19:30:08,309 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15170	Time 12.218s / 10iters, (1.222)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.804s / 10iters, (0.280)	Data load 0.078s / 10iters, (0.007809)
Learning rate = [0.006510896575871854, 0.006510896575871854]	Loss = 0.80939424 (ave = 0.88486674)

2023-07-05 19:30:20,421 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15180	Time 12.113s / 10iters, (1.211)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.175s / 10iters, (0.817)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.079s / 10iters, (0.007858)
Learning rate = [0.00650853665282023, 0.00650853665282023]	Loss = 1.06435573 (ave = 0.79406670)

2023-07-05 19:30:32,771 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15190	Time 12.349s / 10iters, (1.235)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.285s / 10iters, (0.829)	Loss Time 2.868s / 10iters, (0.287)	Data load 0.102s / 10iters, (0.010160)
Learning rate = [0.0065061766346890095, 0.0065061766346890095]	Loss = 0.80281663 (ave = 0.79661978)

2023-07-05 19:30:45,033 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15200	Time 12.262s / 10iters, (1.226)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007583)
Learning rate = [0.0065038165214360375, 0.0065038165214360375]	Loss = 0.71187270 (ave = 0.80841356)

2023-07-05 19:30:56,982 INFO    [trainer_contrastive.py, 272] Train Epoch: 40	Train Iteration: 15210	Time 11.949s / 10iters, (1.195)	Forward Time 1.079s / 10iters, (0.108)	Backward Time 8.093s / 10iters, (0.809)	Loss Time 2.700s / 10iters, (0.270)	Data load 0.076s / 10iters, (0.007601)
Learning rate = [0.0065014563130191255, 0.0065014563130191255]	Loss = 0.66423827 (ave = 0.75370918)

2023-07-05 19:31:12,229 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15220	Time 15.060s / 10iters, (1.506)	Forward Time 1.168s / 10iters, (0.117)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.858s / 10iters, (0.286)	Data load 2.776s / 10iters, (0.277629)
Learning rate = [0.006499096009396046, 0.006499096009396046]	Loss = 0.79421926 (ave = 0.78332559)

2023-07-05 19:31:24,522 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15230	Time 12.293s / 10iters, (1.229)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.818s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007576)
Learning rate = [0.006496735610524538, 0.006496735610524538]	Loss = 0.70491284 (ave = 0.80202099)

2023-07-05 19:31:36,693 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15240	Time 12.171s / 10iters, (1.217)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.175s / 10iters, (0.818)	Loss Time 2.804s / 10iters, (0.280)	Data load 0.080s / 10iters, (0.007972)
Learning rate = [0.006494375116362302, 0.006494375116362302]	Loss = 0.82925791 (ave = 0.86967681)

2023-07-05 19:31:48,858 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15250	Time 12.165s / 10iters, (1.216)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.183s / 10iters, (0.818)	Loss Time 2.795s / 10iters, (0.279)	Data load 0.077s / 10iters, (0.007695)
Learning rate = [0.006492014526867009, 0.006492014526867009]	Loss = 0.96949530 (ave = 0.84464806)

2023-07-05 19:32:01,007 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15260	Time 12.149s / 10iters, (1.215)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.210s / 10iters, (0.821)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007478)
Learning rate = [0.006489653841996285, 0.006489653841996285]	Loss = 0.70585483 (ave = 0.82416189)

2023-07-05 19:32:13,181 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15270	Time 12.174s / 10iters, (1.217)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.079s / 10iters, (0.007900)
Learning rate = [0.0064872930617077265, 0.0064872930617077265]	Loss = 0.78717101 (ave = 0.81472097)

2023-07-05 19:32:25,252 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15280	Time 12.072s / 10iters, (1.207)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.144s / 10iters, (0.814)	Loss Time 2.749s / 10iters, (0.275)	Data load 0.085s / 10iters, (0.008475)
Learning rate = [0.006484932185958893, 0.006484932185958893]	Loss = 0.90657103 (ave = 0.78564498)

2023-07-05 19:32:37,405 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15290	Time 12.152s / 10iters, (1.215)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.202s / 10iters, (0.820)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007476)
Learning rate = [0.0064825712147073035, 0.0064825712147073035]	Loss = 0.73319298 (ave = 0.83718456)

2023-07-05 19:32:49,605 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15300	Time 12.201s / 10iters, (1.220)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.086s / 10iters, (0.008608)
Learning rate = [0.006480210147910449, 0.006480210147910449]	Loss = 1.07382250 (ave = 0.83123428)

2023-07-05 19:33:01,839 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15310	Time 12.233s / 10iters, (1.223)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.077s / 10iters, (0.007712)
Learning rate = [0.006477848985525779, 0.006477848985525779]	Loss = 0.77473724 (ave = 0.80314208)

2023-07-05 19:33:14,129 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15320	Time 12.290s / 10iters, (1.229)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.270s / 10iters, (0.827)	Loss Time 2.825s / 10iters, (0.283)	Data load 0.095s / 10iters, (0.009480)
Learning rate = [0.006475487727510704, 0.006475487727510704]	Loss = 0.93358052 (ave = 0.89112439)

2023-07-05 19:33:26,318 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15330	Time 12.189s / 10iters, (1.219)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.198s / 10iters, (0.820)	Loss Time 2.820s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007570)
Learning rate = [0.006473126373822607, 0.006473126373822607]	Loss = 0.80980927 (ave = 0.77788082)

2023-07-05 19:33:38,570 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15340	Time 12.253s / 10iters, (1.225)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.820s / 10iters, (0.282)	Data load 0.078s / 10iters, (0.007757)
Learning rate = [0.006470764924418825, 0.006470764924418825]	Loss = 0.89857018 (ave = 0.80825939)

2023-07-05 19:33:50,798 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15350	Time 12.227s / 10iters, (1.223)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.233s / 10iters, (0.823)	Loss Time 2.815s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007542)
Learning rate = [0.006468403379256665, 0.006468403379256665]	Loss = 0.73753828 (ave = 0.81023548)

2023-07-05 19:34:03,013 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15360	Time 12.215s / 10iters, (1.221)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007587)
Learning rate = [0.006466041738293399, 0.006466041738293399]	Loss = 0.82976723 (ave = 0.79962083)

2023-07-05 19:34:15,288 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15370	Time 12.276s / 10iters, (1.228)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.078s / 10iters, (0.007827)
Learning rate = [0.006463680001486254, 0.006463680001486254]	Loss = 0.84963953 (ave = 0.83435533)

2023-07-05 19:34:27,503 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15380	Time 12.214s / 10iters, (1.221)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007618)
Learning rate = [0.00646131816879243, 0.00646131816879243]	Loss = 0.96207213 (ave = 0.82612281)

2023-07-05 19:34:39,815 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15390	Time 12.313s / 10iters, (1.231)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.094s / 10iters, (0.009358)
Learning rate = [0.006458956240169086, 0.006458956240169086]	Loss = 0.74877656 (ave = 0.78642452)

2023-07-05 19:34:52,172 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15400	Time 12.357s / 10iters, (1.236)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.315s / 10iters, (0.831)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.077s / 10iters, (0.007668)
Learning rate = [0.0064565942155733426, 0.0064565942155733426]	Loss = 0.79416072 (ave = 0.86603389)

2023-07-05 19:35:04,629 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15410	Time 12.457s / 10iters, (1.246)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.356s / 10iters, (0.836)	Loss Time 2.907s / 10iters, (0.291)	Data load 0.080s / 10iters, (0.007958)
Learning rate = [0.006454232094962291, 0.006454232094962291]	Loss = 0.72888219 (ave = 0.77423772)

2023-07-05 19:35:17,034 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15420	Time 12.405s / 10iters, (1.240)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.305s / 10iters, (0.831)	Loss Time 2.907s / 10iters, (0.291)	Data load 0.079s / 10iters, (0.007866)
Learning rate = [0.0064518698782929755, 0.0064518698782929755]	Loss = 0.93286943 (ave = 0.77079762)

2023-07-05 19:35:29,408 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15430	Time 12.374s / 10iters, (1.237)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.886s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007533)
Learning rate = [0.006449507565522412, 0.006449507565522412]	Loss = 0.74184811 (ave = 0.74997659)

2023-07-05 19:35:41,768 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15440	Time 12.360s / 10iters, (1.236)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.894s / 10iters, (0.289)	Data load 0.082s / 10iters, (0.008176)
Learning rate = [0.006447145156607576, 0.006447145156607576]	Loss = 0.76649040 (ave = 0.80655104)

2023-07-05 19:35:54,019 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15450	Time 12.251s / 10iters, (1.225)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.856s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007527)
Learning rate = [0.006444782651505408, 0.006444782651505408]	Loss = 0.74397194 (ave = 0.74560550)

2023-07-05 19:36:06,362 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15460	Time 12.342s / 10iters, (1.234)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.079s / 10iters, (0.007924)
Learning rate = [0.00644242005017281, 0.00644242005017281]	Loss = 0.96467888 (ave = 0.81024155)

2023-07-05 19:36:18,740 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15470	Time 12.378s / 10iters, (1.238)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.881s / 10iters, (0.288)	Data load 0.091s / 10iters, (0.009065)
Learning rate = [0.0064400573525666485, 0.0064400573525666485]	Loss = 0.88644886 (ave = 0.77726647)

2023-07-05 19:36:31,141 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15480	Time 12.401s / 10iters, (1.240)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.299s / 10iters, (0.830)	Loss Time 2.924s / 10iters, (0.292)	Data load 0.075s / 10iters, (0.007508)
Learning rate = [0.006437694558643751, 0.006437694558643751]	Loss = 0.77412474 (ave = 0.77556893)

2023-07-05 19:36:43,535 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15490	Time 12.394s / 10iters, (1.239)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.900s / 10iters, (0.290)	Data load 0.088s / 10iters, (0.008830)
Learning rate = [0.006435331668360911, 0.006435331668360911]	Loss = 0.88720822 (ave = 0.79916657)

2023-07-05 19:36:55,897 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15500	Time 12.363s / 10iters, (1.236)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.927s / 10iters, (0.293)	Data load 0.083s / 10iters, (0.008306)
Learning rate = [0.006432968681674881, 0.006432968681674881]	Loss = 0.77336061 (ave = 0.79196429)

2023-07-05 19:37:08,313 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15510	Time 12.416s / 10iters, (1.242)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.935s / 10iters, (0.294)	Data load 0.078s / 10iters, (0.007804)
Learning rate = [0.00643060559854238, 0.00643060559854238]	Loss = 0.82508147 (ave = 0.82529562)

2023-07-05 19:37:20,679 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15520	Time 12.366s / 10iters, (1.237)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.223s / 10iters, (0.822)	Loss Time 2.955s / 10iters, (0.296)	Data load 0.082s / 10iters, (0.008221)
Learning rate = [0.006428242418920092, 0.006428242418920092]	Loss = 0.86286336 (ave = 0.86138552)

2023-07-05 19:37:32,926 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15530	Time 12.247s / 10iters, (1.225)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.885s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007499)
Learning rate = [0.006425879142764655, 0.006425879142764655]	Loss = 0.78738642 (ave = 0.83666166)

2023-07-05 19:37:45,222 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15540	Time 12.295s / 10iters, (1.230)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.191s / 10iters, (0.819)	Loss Time 2.912s / 10iters, (0.291)	Data load 0.090s / 10iters, (0.008995)
Learning rate = [0.0064235157700326785, 0.0064235157700326785]	Loss = 1.36108041 (ave = 0.82893413)

2023-07-05 19:37:57,511 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15550	Time 12.289s / 10iters, (1.229)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.202s / 10iters, (0.820)	Loss Time 2.906s / 10iters, (0.291)	Data load 0.077s / 10iters, (0.007733)
Learning rate = [0.006421152300680731, 0.006421152300680731]	Loss = 0.68122458 (ave = 0.78983834)

2023-07-05 19:38:09,780 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15560	Time 12.269s / 10iters, (1.227)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.197s / 10iters, (0.820)	Loss Time 2.892s / 10iters, (0.289)	Data load 0.079s / 10iters, (0.007942)
Learning rate = [0.006418788734665344, 0.006418788734665344]	Loss = 0.69752818 (ave = 0.77652371)

2023-07-05 19:38:21,949 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15570	Time 12.169s / 10iters, (1.217)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007448)
Learning rate = [0.006416425071943013, 0.006416425071943013]	Loss = 0.80804670 (ave = 0.81129999)

2023-07-05 19:38:33,955 INFO    [trainer_contrastive.py, 272] Train Epoch: 41	Train Iteration: 15580	Time 12.006s / 10iters, (1.201)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.125s / 10iters, (0.813)	Loss Time 2.723s / 10iters, (0.272)	Data load 0.077s / 10iters, (0.007725)
Learning rate = [0.006414061312470193, 0.006414061312470193]	Loss = 0.74247712 (ave = 0.81371640)

2023-07-05 19:38:49,133 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15590	Time 14.976s / 10iters, (1.498)	Forward Time 1.161s / 10iters, (0.116)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.765s / 10iters, (0.276)	Data load 2.854s / 10iters, (0.285443)
Learning rate = [0.006411697456203306, 0.006411697456203306]	Loss = 0.73558080 (ave = 0.75629154)

2023-07-05 19:39:01,327 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15600	Time 12.194s / 10iters, (1.219)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.203s / 10iters, (0.820)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007587)
Learning rate = [0.006409333503098733, 0.006409333503098733]	Loss = 0.81987739 (ave = 0.86001256)

2023-07-05 19:39:13,460 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15610	Time 12.132s / 10iters, (1.213)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.163s / 10iters, (0.816)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007501)
Learning rate = [0.0064069694531128174, 0.0064069694531128174]	Loss = 0.77164733 (ave = 0.80694729)

2023-07-05 19:39:25,578 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15620	Time 12.118s / 10iters, (1.212)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.138s / 10iters, (0.814)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.084s / 10iters, (0.008398)
Learning rate = [0.006404605306201868, 0.006404605306201868]	Loss = 0.81918764 (ave = 0.84118863)

2023-07-05 19:39:37,820 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15630	Time 12.242s / 10iters, (1.224)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007497)
Learning rate = [0.006402241062322154, 0.006402241062322154]	Loss = 0.78707784 (ave = 0.78444198)

2023-07-05 19:39:49,978 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15640	Time 12.158s / 10iters, (1.216)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.156s / 10iters, (0.816)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.081s / 10iters, (0.008052)
Learning rate = [0.006399876721429905, 0.006399876721429905]	Loss = 0.77022159 (ave = 0.79692389)

2023-07-05 19:40:02,284 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15650	Time 12.306s / 10iters, (1.231)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.868s / 10iters, (0.287)	Data load 0.085s / 10iters, (0.008475)
Learning rate = [0.0063975122834813184, 0.0063975122834813184]	Loss = 0.75673580 (ave = 0.80915256)

2023-07-05 19:40:14,529 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15660	Time 12.245s / 10iters, (1.225)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.199s / 10iters, (0.820)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007473)
Learning rate = [0.006395147748432546, 0.006395147748432546]	Loss = 0.75059319 (ave = 0.75098209)

2023-07-05 19:40:26,761 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15670	Time 12.231s / 10iters, (1.223)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.215s / 10iters, (0.822)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007527)
Learning rate = [0.006392783116239709, 0.006392783116239709]	Loss = 0.72714961 (ave = 0.76825610)

2023-07-05 19:40:39,051 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15680	Time 12.290s / 10iters, (1.229)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.085s / 10iters, (0.008532)
Learning rate = [0.006390418386858888, 0.006390418386858888]	Loss = 0.86537635 (ave = 0.83498234)

2023-07-05 19:40:51,295 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15690	Time 12.244s / 10iters, (1.224)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007531)
Learning rate = [0.006388053560246124, 0.006388053560246124]	Loss = 0.81251049 (ave = 0.81013767)

2023-07-05 19:41:03,671 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15700	Time 12.376s / 10iters, (1.238)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.327s / 10iters, (0.833)	Loss Time 2.866s / 10iters, (0.287)	Data load 0.087s / 10iters, (0.008655)
Learning rate = [0.006385688636357423, 0.006385688636357423]	Loss = 0.74259055 (ave = 0.85063685)

2023-07-05 19:41:16,062 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15710	Time 12.391s / 10iters, (1.239)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.334s / 10iters, (0.833)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.080s / 10iters, (0.008019)
Learning rate = [0.00638332361514875, 0.00638332361514875]	Loss = 0.79971969 (ave = 0.80277834)

2023-07-05 19:41:28,461 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15720	Time 12.399s / 10iters, (1.240)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.334s / 10iters, (0.833)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.084s / 10iters, (0.008396)
Learning rate = [0.006380958496576035, 0.006380958496576035]	Loss = 0.72728038 (ave = 0.79057504)

2023-07-05 19:41:40,906 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15730	Time 12.445s / 10iters, (1.245)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.393s / 10iters, (0.839)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007438)
Learning rate = [0.00637859328059517, 0.00637859328059517]	Loss = 0.80248523 (ave = 0.79514244)

2023-07-05 19:41:53,266 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15740	Time 12.360s / 10iters, (1.236)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.083s / 10iters, (0.008287)
Learning rate = [0.006376227967162001, 0.006376227967162001]	Loss = 0.81063133 (ave = 0.75439439)

2023-07-05 19:42:05,562 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15750	Time 12.295s / 10iters, (1.230)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.088s / 10iters, (0.008803)
Learning rate = [0.006373862556232347, 0.006373862556232347]	Loss = 0.81201601 (ave = 0.79897525)

2023-07-05 19:42:17,776 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15760	Time 12.214s / 10iters, (1.221)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.201s / 10iters, (0.820)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.079s / 10iters, (0.007892)
Learning rate = [0.006371497047761984, 0.006371497047761984]	Loss = 0.69321072 (ave = 0.78236869)

2023-07-05 19:42:29,952 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15770	Time 12.176s / 10iters, (1.218)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.187s / 10iters, (0.819)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007509)
Learning rate = [0.006369131441706646, 0.006369131441706646]	Loss = 0.81374675 (ave = 0.78743601)

2023-07-05 19:42:42,190 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15780	Time 12.239s / 10iters, (1.224)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.082s / 10iters, (0.008171)
Learning rate = [0.006366765738022035, 0.006366765738022035]	Loss = 0.76833987 (ave = 0.83429881)

2023-07-05 19:42:54,405 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15790	Time 12.215s / 10iters, (1.221)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.203s / 10iters, (0.820)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.082s / 10iters, (0.008228)
Learning rate = [0.00636439993666381, 0.00636439993666381]	Loss = 0.97607160 (ave = 0.84764737)

2023-07-05 19:43:06,616 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15800	Time 12.211s / 10iters, (1.221)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.209s / 10iters, (0.821)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.086s / 10iters, (0.008567)
Learning rate = [0.006362034037587593, 0.006362034037587593]	Loss = 0.71040523 (ave = 0.74447587)

2023-07-05 19:43:18,822 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15810	Time 12.206s / 10iters, (1.221)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.235s / 10iters, (0.823)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.077s / 10iters, (0.007719)
Learning rate = [0.006359668040748971, 0.006359668040748971]	Loss = 0.76666838 (ave = 0.78500258)

2023-07-05 19:43:31,031 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15820	Time 12.209s / 10iters, (1.221)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.093s / 10iters, (0.009337)
Learning rate = [0.006357301946103483, 0.006357301946103483]	Loss = 0.80180520 (ave = 0.77405331)

2023-07-05 19:43:43,195 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15830	Time 12.163s / 10iters, (1.216)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.191s / 10iters, (0.819)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007425)
Learning rate = [0.006354935753606641, 0.006354935753606641]	Loss = 0.82813728 (ave = 0.78116637)

2023-07-05 19:43:55,378 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15840	Time 12.184s / 10iters, (1.218)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.191s / 10iters, (0.819)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007396)
Learning rate = [0.0063525694632139106, 0.0063525694632139106]	Loss = 0.73601848 (ave = 0.77146871)

2023-07-05 19:44:07,601 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15850	Time 12.223s / 10iters, (1.222)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007544)
Learning rate = [0.00635020307488072, 0.00635020307488072]	Loss = 0.80240095 (ave = 0.78834590)

2023-07-05 19:44:19,888 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15860	Time 12.287s / 10iters, (1.229)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007504)
Learning rate = [0.006347836588562463, 0.006347836588562463]	Loss = 0.89066994 (ave = 0.78555189)

2023-07-05 19:44:32,088 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15870	Time 12.200s / 10iters, (1.220)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.809s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007465)
Learning rate = [0.006345470004214486, 0.006345470004214486]	Loss = 0.88854504 (ave = 0.82368394)

2023-07-05 19:44:44,255 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15880	Time 12.167s / 10iters, (1.217)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007500)
Learning rate = [0.006343103321792105, 0.006343103321792105]	Loss = 0.79979467 (ave = 0.81877905)

2023-07-05 19:44:56,472 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15890	Time 12.216s / 10iters, (1.222)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.809s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007540)
Learning rate = [0.006340736541250596, 0.006340736541250596]	Loss = 0.77243453 (ave = 0.80011750)

2023-07-05 19:45:08,631 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15900	Time 12.159s / 10iters, (1.216)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.202s / 10iters, (0.820)	Loss Time 2.786s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007533)
Learning rate = [0.006338369662545187, 0.006338369662545187]	Loss = 0.68203843 (ave = 0.76514995)

2023-07-05 19:45:20,803 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15910	Time 12.172s / 10iters, (1.217)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.187s / 10iters, (0.819)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007587)
Learning rate = [0.00633600268563108, 0.00633600268563108]	Loss = 0.80498707 (ave = 0.81487532)

2023-07-05 19:45:33,011 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15920	Time 12.208s / 10iters, (1.221)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.203s / 10iters, (0.820)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.086s / 10iters, (0.008638)
Learning rate = [0.0063336356104634305, 0.0063336356104634305]	Loss = 0.75342584 (ave = 0.76914015)

2023-07-05 19:45:45,165 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15930	Time 12.154s / 10iters, (1.215)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.203s / 10iters, (0.820)	Loss Time 2.789s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007421)
Learning rate = [0.006331268436997354, 0.006331268436997354]	Loss = 0.76722914 (ave = 0.80558019)

2023-07-05 19:45:57,218 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15940	Time 12.053s / 10iters, (1.205)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.132s / 10iters, (0.813)	Loss Time 2.760s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007374)
Learning rate = [0.006328901165187931, 0.006328901165187931]	Loss = 0.75231761 (ave = 0.80776860)

2023-07-05 19:46:09,289 INFO    [trainer_contrastive.py, 272] Train Epoch: 42	Train Iteration: 15950	Time 12.072s / 10iters, (1.207)	Forward Time 1.076s / 10iters, (0.108)	Backward Time 8.182s / 10iters, (0.818)	Loss Time 2.738s / 10iters, (0.274)	Data load 0.076s / 10iters, (0.007593)
Learning rate = [0.0063265337949902, 0.0063265337949902]	Loss = 0.89598817 (ave = 0.80773788)

2023-07-05 19:46:24,615 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 15960	Time 15.110s / 10iters, (1.511)	Forward Time 1.165s / 10iters, (0.117)	Backward Time 8.129s / 10iters, (0.813)	Loss Time 2.811s / 10iters, (0.281)	Data load 3.005s / 10iters, (0.300462)
Learning rate = [0.00632416632635916, 0.00632416632635916]	Loss = 0.76432383 (ave = 0.74403735)

2023-07-05 19:46:36,804 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 15970	Time 12.189s / 10iters, (1.219)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.163s / 10iters, (0.816)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.087s / 10iters, (0.008691)
Learning rate = [0.006321798759249775, 0.006321798759249775]	Loss = 0.75669456 (ave = 0.75500339)

2023-07-05 19:46:49,210 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 15980	Time 12.406s / 10iters, (1.241)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.928s / 10iters, (0.293)	Data load 0.088s / 10iters, (0.008827)
Learning rate = [0.006319431093616963, 0.006319431093616963]	Loss = 0.79521322 (ave = 0.78145863)

2023-07-05 19:47:01,376 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 15990	Time 12.166s / 10iters, (1.217)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.171s / 10iters, (0.817)	Loss Time 2.816s / 10iters, (0.282)	Data load 0.079s / 10iters, (0.007891)
Learning rate = [0.006317063329415608, 0.006317063329415608]	Loss = 0.82751763 (ave = 0.83253468)

2023-07-05 19:47:13,557 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16000	Time 12.180s / 10iters, (1.218)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.170s / 10iters, (0.817)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007568)
Learning rate = [0.006314695466600552, 0.006314695466600552]	Loss = 0.79257548 (ave = 0.79864416)

2023-07-05 19:47:18,256 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 19:47:41,414 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 19:48:04,302 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 19:48:27,078 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 19:48:50,047 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 19:49:12,575 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 19:49:34,850 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 19:49:43,431 INFO    [trainer_contrastive.py, 391] Test Time 146.774s, (2.330)	Loss 0.16433414

2023-07-05 19:49:43,432 INFO    [base.py, 33] Result for seg
2023-07-05 19:49:43,433 INFO    [base.py, 49] Mean IOU: 0.6767826261541948

2023-07-05 19:49:43,434 INFO    [base.py, 50] Pixel ACC: 0.9498343538850939

2023-07-05 19:49:55,572 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16010	Time 162.015s / 10iters, (16.202)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.204s / 10iters, (0.820)	Loss Time 2.719s / 10iters, (0.272)	Data load 149.975s / 10iters, (14.997461)
Learning rate = [0.006312327505126596, 0.006312327505126596]	Loss = 0.86537969 (ave = 0.84490045)

2023-07-05 19:50:07,437 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16020	Time 11.866s / 10iters, (1.187)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.099s / 10iters, (0.810)	Loss Time 2.586s / 10iters, (0.259)	Data load 0.075s / 10iters, (0.007460)
Learning rate = [0.006309959444948506, 0.006309959444948506]	Loss = 0.69767255 (ave = 0.78496336)

2023-07-05 19:50:19,269 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16030	Time 11.831s / 10iters, (1.183)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.064s / 10iters, (0.806)	Loss Time 2.608s / 10iters, (0.261)	Data load 0.074s / 10iters, (0.007396)
Learning rate = [0.006307591286021007, 0.006307591286021007]	Loss = 0.84683263 (ave = 0.80965245)

2023-07-05 19:50:31,226 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16040	Time 11.958s / 10iters, (1.196)	Forward Time 1.079s / 10iters, (0.108)	Backward Time 8.158s / 10iters, (0.816)	Loss Time 2.640s / 10iters, (0.264)	Data load 0.081s / 10iters, (0.008113)
Learning rate = [0.006305223028298779, 0.006305223028298779]	Loss = 0.79443884 (ave = 0.85581954)

2023-07-05 19:50:43,179 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16050	Time 11.953s / 10iters, (1.195)	Forward Time 1.085s / 10iters, (0.109)	Backward Time 8.145s / 10iters, (0.815)	Loss Time 2.649s / 10iters, (0.265)	Data load 0.074s / 10iters, (0.007402)
Learning rate = [0.0063028546717364695, 0.0063028546717364695]	Loss = 0.87950945 (ave = 0.82914816)

2023-07-05 19:50:55,188 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16060	Time 12.008s / 10iters, (1.201)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.647s / 10iters, (0.265)	Data load 0.082s / 10iters, (0.008155)
Learning rate = [0.006300486216288682, 0.006300486216288682]	Loss = 0.66538614 (ave = 0.79448922)

2023-07-05 19:51:07,246 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16070	Time 12.059s / 10iters, (1.206)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.201s / 10iters, (0.820)	Loss Time 2.699s / 10iters, (0.270)	Data load 0.074s / 10iters, (0.007423)
Learning rate = [0.006298117661909982, 0.006298117661909982]	Loss = 0.76743662 (ave = 0.83858778)

2023-07-05 19:51:19,343 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16080	Time 12.097s / 10iters, (1.210)	Forward Time 1.083s / 10iters, (0.108)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.694s / 10iters, (0.269)	Data load 0.083s / 10iters, (0.008263)
Learning rate = [0.006295749008554894, 0.006295749008554894]	Loss = 0.77882338 (ave = 0.83417042)

2023-07-05 19:51:31,526 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16090	Time 12.183s / 10iters, (1.218)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007628)
Learning rate = [0.006293380256177902, 0.006293380256177902]	Loss = 0.83766389 (ave = 0.89516232)

2023-07-05 19:51:43,662 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16100	Time 12.137s / 10iters, (1.214)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.754s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007519)
Learning rate = [0.006291011404733453, 0.006291011404733453]	Loss = 0.88354647 (ave = 0.81100467)

2023-07-05 19:51:55,890 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16110	Time 12.228s / 10iters, (1.223)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007420)
Learning rate = [0.006288642454175953, 0.006288642454175953]	Loss = 1.34867620 (ave = 0.83791214)

2023-07-05 19:52:08,202 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16120	Time 12.312s / 10iters, (1.231)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.317s / 10iters, (0.832)	Loss Time 2.816s / 10iters, (0.282)	Data load 0.085s / 10iters, (0.008462)
Learning rate = [0.006286273404459763, 0.006286273404459763]	Loss = 0.85001063 (ave = 0.82377878)

2023-07-05 19:52:20,445 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16130	Time 12.243s / 10iters, (1.224)	Forward Time 1.085s / 10iters, (0.109)	Backward Time 8.265s / 10iters, (0.827)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007390)
Learning rate = [0.006283904255539211, 0.006283904255539211]	Loss = 0.87952363 (ave = 0.82457726)

2023-07-05 19:52:32,616 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16140	Time 12.170s / 10iters, (1.217)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.195s / 10iters, (0.819)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007482)
Learning rate = [0.006281535007368579, 0.006281535007368579]	Loss = 0.78621310 (ave = 0.74962457)

2023-07-05 19:52:44,818 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16150	Time 12.202s / 10iters, (1.220)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.207s / 10iters, (0.821)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.079s / 10iters, (0.007862)
Learning rate = [0.006279165659902116, 0.006279165659902116]	Loss = 0.69511878 (ave = 0.77838890)

2023-07-05 19:52:56,983 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16160	Time 12.165s / 10iters, (1.217)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.197s / 10iters, (0.820)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007535)
Learning rate = [0.006276796213094023, 0.006276796213094023]	Loss = 1.17885494 (ave = 0.82314642)

2023-07-05 19:53:09,267 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16170	Time 12.284s / 10iters, (1.228)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.278s / 10iters, (0.828)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.086s / 10iters, (0.008577)
Learning rate = [0.006274426666898461, 0.006274426666898461]	Loss = 0.79228675 (ave = 0.78874968)

2023-07-05 19:53:21,585 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16180	Time 12.318s / 10iters, (1.232)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.083s / 10iters, (0.008325)
Learning rate = [0.00627205702126956, 0.00627205702126956]	Loss = 0.82039309 (ave = 0.88171272)

2023-07-05 19:53:33,937 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16190	Time 12.352s / 10iters, (1.235)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.327s / 10iters, (0.833)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007515)
Learning rate = [0.006269687276161398, 0.006269687276161398]	Loss = 0.90431970 (ave = 0.87293600)

2023-07-05 19:53:46,170 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16200	Time 12.233s / 10iters, (1.223)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.228s / 10iters, (0.823)	Loss Time 2.838s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007580)
Learning rate = [0.006267317431528019, 0.006267317431528019]	Loss = 0.74658638 (ave = 0.81125293)

2023-07-05 19:53:58,431 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16210	Time 12.261s / 10iters, (1.226)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.850s / 10iters, (0.285)	Data load 0.079s / 10iters, (0.007889)
Learning rate = [0.0062649474873234245, 0.0062649474873234245]	Loss = 0.78523105 (ave = 0.82167428)

2023-07-05 19:54:10,630 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16220	Time 12.199s / 10iters, (1.220)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.185s / 10iters, (0.818)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007440)
Learning rate = [0.006262577443501576, 0.006262577443501576]	Loss = 0.86213160 (ave = 0.82374941)

2023-07-05 19:54:22,828 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16230	Time 12.198s / 10iters, (1.220)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.177s / 10iters, (0.818)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007514)
Learning rate = [0.006260207300016395, 0.006260207300016395]	Loss = 0.78305888 (ave = 0.77941237)

2023-07-05 19:54:35,077 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16240	Time 12.249s / 10iters, (1.225)	Forward Time 1.083s / 10iters, (0.108)	Backward Time 8.225s / 10iters, (0.822)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007411)
Learning rate = [0.006257837056821761, 0.006257837056821761]	Loss = 0.87461829 (ave = 0.82844629)

2023-07-05 19:54:47,327 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16250	Time 12.250s / 10iters, (1.225)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.262s / 10iters, (0.826)	Loss Time 2.815s / 10iters, (0.281)	Data load 0.084s / 10iters, (0.008362)
Learning rate = [0.006255466713871512, 0.006255466713871512]	Loss = 0.75749469 (ave = 0.81501219)

2023-07-05 19:54:59,533 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16260	Time 12.206s / 10iters, (1.221)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.084s / 10iters, (0.008421)
Learning rate = [0.0062530962711194495, 0.0062530962711194495]	Loss = 0.77470350 (ave = 0.75538270)

2023-07-05 19:55:11,813 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16270	Time 12.280s / 10iters, (1.228)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007359)
Learning rate = [0.006250725728519327, 0.006250725728519327]	Loss = 0.80907762 (ave = 0.83253776)

2023-07-05 19:55:24,067 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16280	Time 12.254s / 10iters, (1.225)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.205s / 10iters, (0.820)	Loss Time 2.887s / 10iters, (0.289)	Data load 0.074s / 10iters, (0.007440)
Learning rate = [0.006248355086024863, 0.006248355086024863]	Loss = 0.91584301 (ave = 0.85327002)

2023-07-05 19:55:36,309 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16290	Time 12.242s / 10iters, (1.224)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.845s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007415)
Learning rate = [0.006245984343589733, 0.006245984343589733]	Loss = 0.83494622 (ave = 0.80105084)

2023-07-05 19:55:48,690 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16300	Time 12.381s / 10iters, (1.238)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.287s / 10iters, (0.829)	Loss Time 2.911s / 10iters, (0.291)	Data load 0.084s / 10iters, (0.008442)
Learning rate = [0.0062436135011675695, 0.0062436135011675695]	Loss = 0.83833003 (ave = 0.83300840)

2023-07-05 19:56:01,014 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16310	Time 12.324s / 10iters, (1.232)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.285s / 10iters, (0.828)	Loss Time 2.864s / 10iters, (0.286)	Data load 0.079s / 10iters, (0.007885)
Learning rate = [0.006241242558711972, 0.006241242558711972]	Loss = 0.89053214 (ave = 0.80697896)

2023-07-05 19:56:13,025 INFO    [trainer_contrastive.py, 272] Train Epoch: 43	Train Iteration: 16320	Time 12.011s / 10iters, (1.201)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.123s / 10iters, (0.812)	Loss Time 2.727s / 10iters, (0.273)	Data load 0.077s / 10iters, (0.007676)
Learning rate = [0.006238871516176486, 0.006238871516176486]	Loss = 0.81056708 (ave = 0.77867306)

2023-07-05 19:56:28,247 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16330	Time 15.034s / 10iters, (1.503)	Forward Time 1.170s / 10iters, (0.117)	Backward Time 8.226s / 10iters, (0.823)	Loss Time 2.703s / 10iters, (0.270)	Data load 2.935s / 10iters, (0.293451)
Learning rate = [0.006236500373514626, 0.006236500373514626]	Loss = 1.12004042 (ave = 0.81210242)

2023-07-05 19:56:40,583 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16340	Time 12.336s / 10iters, (1.234)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.350s / 10iters, (0.835)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007564)
Learning rate = [0.006234129130679864, 0.006234129130679864]	Loss = 0.70276266 (ave = 0.75785669)

2023-07-05 19:56:52,981 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16350	Time 12.399s / 10iters, (1.240)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.426s / 10iters, (0.843)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.078s / 10iters, (0.007789)
Learning rate = [0.006231757787625624, 0.006231757787625624]	Loss = 0.69438100 (ave = 0.83014028)

2023-07-05 19:57:05,237 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16360	Time 12.256s / 10iters, (1.226)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.080s / 10iters, (0.007972)
Learning rate = [0.006229386344305296, 0.006229386344305296]	Loss = 0.76336563 (ave = 0.80593480)

2023-07-05 19:57:17,512 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16370	Time 12.274s / 10iters, (1.227)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.282s / 10iters, (0.828)	Loss Time 2.786s / 10iters, (0.279)	Data load 0.080s / 10iters, (0.008013)
Learning rate = [0.006227014800672225, 0.006227014800672225]	Loss = 0.74580216 (ave = 0.82782291)

2023-07-05 19:57:29,821 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16380	Time 12.310s / 10iters, (1.231)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.287s / 10iters, (0.829)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.099s / 10iters, (0.009855)
Learning rate = [0.006224643156679715, 0.006224643156679715]	Loss = 0.69586414 (ave = 0.73023409)

2023-07-05 19:57:42,090 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16390	Time 12.268s / 10iters, (1.227)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.235s / 10iters, (0.824)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.090s / 10iters, (0.008960)
Learning rate = [0.006222271412281031, 0.006222271412281031]	Loss = 0.70680976 (ave = 0.75519643)

2023-07-05 19:57:54,470 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16400	Time 12.380s / 10iters, (1.238)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.893s / 10iters, (0.289)	Data load 0.081s / 10iters, (0.008102)
Learning rate = [0.006219899567429393, 0.006219899567429393]	Loss = 0.80797452 (ave = 0.77843290)

2023-07-05 19:58:07,054 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16410	Time 12.584s / 10iters, (1.258)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.421s / 10iters, (0.842)	Loss Time 2.949s / 10iters, (0.295)	Data load 0.079s / 10iters, (0.007931)
Learning rate = [0.006217527622077979, 0.006217527622077979]	Loss = 0.87373239 (ave = 0.84185657)

2023-07-05 19:58:19,499 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16420	Time 12.445s / 10iters, (1.245)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.352s / 10iters, (0.835)	Loss Time 2.895s / 10iters, (0.289)	Data load 0.092s / 10iters, (0.009161)
Learning rate = [0.00621515557617993, 0.00621515557617993]	Loss = 0.80076361 (ave = 0.82801484)

2023-07-05 19:58:31,810 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16430	Time 12.310s / 10iters, (1.231)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.879s / 10iters, (0.288)	Data load 0.079s / 10iters, (0.007875)
Learning rate = [0.00621278342968834, 0.00621278342968834]	Loss = 0.79479557 (ave = 0.81420903)

2023-07-05 19:58:44,201 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16440	Time 12.391s / 10iters, (1.239)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.898s / 10iters, (0.290)	Data load 0.077s / 10iters, (0.007715)
Learning rate = [0.006210411182556265, 0.006210411182556265]	Loss = 0.80526370 (ave = 0.81034107)

2023-07-05 19:58:56,560 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16450	Time 12.359s / 10iters, (1.236)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.265s / 10iters, (0.827)	Loss Time 2.900s / 10iters, (0.290)	Data load 0.090s / 10iters, (0.009028)
Learning rate = [0.006208038834736716, 0.006208038834736716]	Loss = 0.84343988 (ave = 0.80701942)

2023-07-05 19:59:08,892 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16460	Time 12.332s / 10iters, (1.233)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.902s / 10iters, (0.290)	Data load 0.083s / 10iters, (0.008281)
Learning rate = [0.006205666386182666, 0.006205666386182666]	Loss = 0.82509977 (ave = 0.82032087)

2023-07-05 19:59:21,260 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16470	Time 12.368s / 10iters, (1.237)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.897s / 10iters, (0.290)	Data load 0.099s / 10iters, (0.009881)
Learning rate = [0.006203293836847042, 0.006203293836847042]	Loss = 0.67313671 (ave = 0.76225389)

2023-07-05 19:59:33,629 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16480	Time 12.369s / 10iters, (1.237)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.865s / 10iters, (0.286)	Data load 0.078s / 10iters, (0.007778)
Learning rate = [0.006200921186682732, 0.006200921186682732]	Loss = 1.20693994 (ave = 0.87976413)

2023-07-05 19:59:45,988 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16490	Time 12.359s / 10iters, (1.236)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.099s / 10iters, (0.009911)
Learning rate = [0.006198548435642579, 0.006198548435642579]	Loss = 0.76665127 (ave = 0.79827085)

2023-07-05 19:59:58,319 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16500	Time 12.331s / 10iters, (1.233)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.081s / 10iters, (0.008137)
Learning rate = [0.006196175583679389, 0.006196175583679389]	Loss = 0.71924567 (ave = 0.82063373)

2023-07-05 20:00:10,523 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16510	Time 12.204s / 10iters, (1.220)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.744s / 10iters, (0.274)	Data load 0.087s / 10iters, (0.008726)
Learning rate = [0.006193802630745917, 0.006193802630745917]	Loss = 0.80638826 (ave = 0.78426685)

2023-07-05 20:00:22,692 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16520	Time 12.169s / 10iters, (1.217)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.255s / 10iters, (0.825)	Loss Time 2.729s / 10iters, (0.273)	Data load 0.086s / 10iters, (0.008646)
Learning rate = [0.006191429576794887, 0.006191429576794887]	Loss = 0.80720383 (ave = 0.81442751)

2023-07-05 20:00:34,927 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16530	Time 12.234s / 10iters, (1.223)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.262s / 10iters, (0.826)	Loss Time 2.766s / 10iters, (0.277)	Data load 0.080s / 10iters, (0.008027)
Learning rate = [0.006189056421778971, 0.006189056421778971]	Loss = 1.01731443 (ave = 0.84144995)

2023-07-05 20:00:47,174 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16540	Time 12.248s / 10iters, (1.225)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.286s / 10iters, (0.829)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.085s / 10iters, (0.008544)
Learning rate = [0.006186683165650803, 0.006186683165650803]	Loss = 0.81668037 (ave = 0.77571517)

2023-07-05 20:00:59,409 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16550	Time 12.235s / 10iters, (1.223)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.295s / 10iters, (0.829)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.084s / 10iters, (0.008423)
Learning rate = [0.006184309808362977, 0.006184309808362977]	Loss = 0.88076288 (ave = 0.77924126)

2023-07-05 20:01:11,773 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16560	Time 12.364s / 10iters, (1.236)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.363s / 10iters, (0.836)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.078s / 10iters, (0.007762)
Learning rate = [0.006181936349868038, 0.006181936349868038]	Loss = 0.80239064 (ave = 0.79733602)

2023-07-05 20:01:24,121 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16570	Time 12.348s / 10iters, (1.235)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.869s / 10iters, (0.287)	Data load 0.077s / 10iters, (0.007719)
Learning rate = [0.0061795627901184945, 0.0061795627901184945]	Loss = 0.76598251 (ave = 0.76563749)

2023-07-05 20:01:36,436 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16580	Time 12.315s / 10iters, (1.231)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.862s / 10iters, (0.286)	Data load 0.085s / 10iters, (0.008500)
Learning rate = [0.0061771891290668115, 0.0061771891290668115]	Loss = 0.75207520 (ave = 0.77645299)

2023-07-05 20:01:48,827 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16590	Time 12.391s / 10iters, (1.239)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.358s / 10iters, (0.836)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.097s / 10iters, (0.009655)
Learning rate = [0.006174815366665405, 0.006174815366665405]	Loss = 0.80644888 (ave = 0.78424814)

2023-07-05 20:02:01,080 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16600	Time 12.253s / 10iters, (1.225)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.077s / 10iters, (0.007713)
Learning rate = [0.006172441502866658, 0.006172441502866658]	Loss = 0.89119411 (ave = 0.77769414)

2023-07-05 20:02:13,273 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16610	Time 12.193s / 10iters, (1.219)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.758s / 10iters, (0.276)	Data load 0.078s / 10iters, (0.007801)
Learning rate = [0.006170067537622904, 0.006170067537622904]	Loss = 0.60482162 (ave = 0.78244590)

2023-07-05 20:02:25,581 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16620	Time 12.308s / 10iters, (1.231)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.306s / 10iters, (0.831)	Loss Time 2.809s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007448)
Learning rate = [0.006167693470886436, 0.006167693470886436]	Loss = 0.88883483 (ave = 0.81769671)

2023-07-05 20:02:38,204 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16630	Time 12.623s / 10iters, (1.262)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.540s / 10iters, (0.854)	Loss Time 2.875s / 10iters, (0.288)	Data load 0.085s / 10iters, (0.008513)
Learning rate = [0.006165319302609506, 0.006165319302609506]	Loss = 0.72715247 (ave = 0.81426247)

2023-07-05 20:02:50,852 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16640	Time 12.648s / 10iters, (1.265)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.551s / 10iters, (0.855)	Loss Time 2.891s / 10iters, (0.289)	Data load 0.078s / 10iters, (0.007762)
Learning rate = [0.006162945032744318, 0.006162945032744318]	Loss = 0.90412682 (ave = 0.80453761)

2023-07-05 20:03:03,505 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16650	Time 12.654s / 10iters, (1.265)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.504s / 10iters, (0.850)	Loss Time 2.943s / 10iters, (0.294)	Data load 0.076s / 10iters, (0.007571)
Learning rate = [0.006160570661243037, 0.006160570661243037]	Loss = 0.81078112 (ave = 0.80948342)

2023-07-05 20:03:15,880 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16660	Time 12.375s / 10iters, (1.237)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.367s / 10iters, (0.837)	Loss Time 2.803s / 10iters, (0.280)	Data load 0.086s / 10iters, (0.008584)
Learning rate = [0.006158196188057787, 0.006158196188057787]	Loss = 0.88080615 (ave = 0.83224986)

2023-07-05 20:03:28,093 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16670	Time 12.213s / 10iters, (1.221)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.759s / 10iters, (0.276)	Data load 0.087s / 10iters, (0.008678)
Learning rate = [0.0061558216131406395, 0.0061558216131406395]	Loss = 0.92723387 (ave = 0.83763679)

2023-07-05 20:03:40,380 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16680	Time 12.287s / 10iters, (1.229)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.805s / 10iters, (0.281)	Data load 0.087s / 10iters, (0.008685)
Learning rate = [0.006153446936443636, 0.006153446936443636]	Loss = 0.92538983 (ave = 0.89166062)

2023-07-05 20:03:52,440 INFO    [trainer_contrastive.py, 272] Train Epoch: 44	Train Iteration: 16690	Time 12.060s / 10iters, (1.206)	Forward Time 1.081s / 10iters, (0.108)	Backward Time 8.165s / 10iters, (0.817)	Loss Time 2.738s / 10iters, (0.274)	Data load 0.075s / 10iters, (0.007533)
Learning rate = [0.006151072157918765, 0.006151072157918765]	Loss = 0.80284542 (ave = 0.89862177)

2023-07-05 20:04:07,469 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16700	Time 14.866s / 10iters, (1.487)	Forward Time 1.295s / 10iters, (0.129)	Backward Time 8.404s / 10iters, (0.840)	Loss Time 2.702s / 10iters, (0.270)	Data load 2.465s / 10iters, (0.246486)
Learning rate = [0.0061486972775179755, 0.0061486972775179755]	Loss = 0.83704734 (ave = 0.81993179)

2023-07-05 20:04:19,780 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16710	Time 12.311s / 10iters, (1.231)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.358s / 10iters, (0.836)	Loss Time 2.752s / 10iters, (0.275)	Data load 0.087s / 10iters, (0.008729)
Learning rate = [0.006146322295193172, 0.006146322295193172]	Loss = 0.75839210 (ave = 0.84150703)

2023-07-05 20:04:32,058 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16720	Time 12.278s / 10iters, (1.228)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.752s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007515)
Learning rate = [0.006143947210896217, 0.006143947210896217]	Loss = 0.78716671 (ave = 0.78478126)

2023-07-05 20:04:44,279 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16730	Time 12.221s / 10iters, (1.222)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.330s / 10iters, (0.833)	Loss Time 2.688s / 10iters, (0.269)	Data load 0.093s / 10iters, (0.009262)
Learning rate = [0.006141572024578927, 0.006141572024578927]	Loss = 0.63023114 (ave = 0.80668808)

2023-07-05 20:04:56,628 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16740	Time 12.349s / 10iters, (1.235)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.382s / 10iters, (0.838)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.077s / 10iters, (0.007719)
Learning rate = [0.006139196736193081, 0.006139196736193081]	Loss = 0.83485651 (ave = 0.80570205)

2023-07-05 20:05:08,875 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16750	Time 12.247s / 10iters, (1.225)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007405)
Learning rate = [0.006136821345690407, 0.006136821345690407]	Loss = 0.84397590 (ave = 0.76259345)

2023-07-05 20:05:21,232 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16760	Time 12.357s / 10iters, (1.236)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.336s / 10iters, (0.834)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.083s / 10iters, (0.008314)
Learning rate = [0.006134445853022592, 0.006134445853022592]	Loss = 0.80719841 (ave = 0.78984400)

2023-07-05 20:05:33,628 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16770	Time 12.396s / 10iters, (1.240)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.338s / 10iters, (0.834)	Loss Time 2.866s / 10iters, (0.287)	Data load 0.080s / 10iters, (0.007973)
Learning rate = [0.0061320702581412825, 0.0061320702581412825]	Loss = 0.78812313 (ave = 0.88174195)

2023-07-05 20:05:45,938 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16780	Time 12.310s / 10iters, (1.231)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.374s / 10iters, (0.837)	Loss Time 2.759s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007439)
Learning rate = [0.006129694560998077, 0.006129694560998077]	Loss = 0.81937456 (ave = 0.79361107)

2023-07-05 20:05:58,264 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16790	Time 12.325s / 10iters, (1.233)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.384s / 10iters, (0.838)	Loss Time 2.750s / 10iters, (0.275)	Data load 0.085s / 10iters, (0.008469)
Learning rate = [0.006127318761544534, 0.006127318761544534]	Loss = 0.69734228 (ave = 0.84266688)

2023-07-05 20:06:10,425 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16800	Time 12.162s / 10iters, (1.216)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.674s / 10iters, (0.267)	Data load 0.090s / 10iters, (0.008958)
Learning rate = [0.006124942859732164, 0.006124942859732164]	Loss = 0.68923402 (ave = 0.85026484)

2023-07-05 20:06:22,553 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16810	Time 12.128s / 10iters, (1.213)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.661s / 10iters, (0.266)	Data load 0.113s / 10iters, (0.011263)
Learning rate = [0.0061225668555124355, 0.0061225668555124355]	Loss = 0.70776051 (ave = 0.76813439)

2023-07-05 20:06:34,837 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16820	Time 12.284s / 10iters, (1.228)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.390s / 10iters, (0.839)	Loss Time 2.710s / 10iters, (0.271)	Data load 0.081s / 10iters, (0.008132)
Learning rate = [0.006120190748836779, 0.006120190748836779]	Loss = 0.77133334 (ave = 0.81189964)

2023-07-05 20:06:47,054 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16830	Time 12.217s / 10iters, (1.222)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.351s / 10iters, (0.835)	Loss Time 2.678s / 10iters, (0.268)	Data load 0.075s / 10iters, (0.007480)
Learning rate = [0.006117814539656568, 0.006117814539656568]	Loss = 0.78026128 (ave = 0.76200796)

2023-07-05 20:06:59,207 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16840	Time 12.153s / 10iters, (1.215)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.317s / 10iters, (0.832)	Loss Time 2.642s / 10iters, (0.264)	Data load 0.089s / 10iters, (0.008881)
Learning rate = [0.006115438227923142, 0.006115438227923142]	Loss = 0.82356274 (ave = 0.76256045)

2023-07-05 20:07:11,431 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16850	Time 12.224s / 10iters, (1.222)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.350s / 10iters, (0.835)	Loss Time 2.668s / 10iters, (0.267)	Data load 0.082s / 10iters, (0.008248)
Learning rate = [0.006113061813587796, 0.006113061813587796]	Loss = 1.08351684 (ave = 0.77412432)

2023-07-05 20:07:23,769 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16860	Time 12.339s / 10iters, (1.234)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.424s / 10iters, (0.842)	Loss Time 2.709s / 10iters, (0.271)	Data load 0.086s / 10iters, (0.008585)
Learning rate = [0.0061106852966017755, 0.0061106852966017755]	Loss = 0.79815537 (ave = 0.82674227)

2023-07-05 20:07:36,050 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16870	Time 12.281s / 10iters, (1.228)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.406s / 10iters, (0.841)	Loss Time 2.686s / 10iters, (0.269)	Data load 0.076s / 10iters, (0.007575)
Learning rate = [0.006108308676916287, 0.006108308676916287]	Loss = 0.76109225 (ave = 0.80390598)

2023-07-05 20:07:48,292 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16880	Time 12.242s / 10iters, (1.224)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.390s / 10iters, (0.839)	Loss Time 2.655s / 10iters, (0.265)	Data load 0.084s / 10iters, (0.008408)
Learning rate = [0.006105931954482489, 0.006105931954482489]	Loss = 0.75701112 (ave = 0.90312883)

2023-07-05 20:08:00,577 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16890	Time 12.285s / 10iters, (1.229)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.393s / 10iters, (0.839)	Loss Time 2.679s / 10iters, (0.268)	Data load 0.111s / 10iters, (0.011103)
Learning rate = [0.006103555129251496, 0.006103555129251496]	Loss = 0.92262089 (ave = 0.83064719)

2023-07-05 20:08:12,830 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16900	Time 12.253s / 10iters, (1.225)	Forward Time 1.151s / 10iters, (0.115)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.688s / 10iters, (0.269)	Data load 0.074s / 10iters, (0.007437)
Learning rate = [0.006101178201174383, 0.006101178201174383]	Loss = 0.71944714 (ave = 0.76443397)

2023-07-05 20:08:25,116 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16910	Time 12.285s / 10iters, (1.229)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.331s / 10iters, (0.833)	Loss Time 2.760s / 10iters, (0.276)	Data load 0.093s / 10iters, (0.009259)
Learning rate = [0.006098801170202173, 0.006098801170202173]	Loss = 0.80326694 (ave = 0.81083705)

2023-07-05 20:08:37,477 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16920	Time 12.362s / 10iters, (1.236)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.339s / 10iters, (0.834)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.095s / 10iters, (0.009509)
Learning rate = [0.006096424036285851, 0.006096424036285851]	Loss = 0.93538022 (ave = 0.80471189)

2023-07-05 20:08:49,892 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16930	Time 12.414s / 10iters, (1.241)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.386s / 10iters, (0.839)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.100s / 10iters, (0.009962)
Learning rate = [0.006094046799376351, 0.006094046799376351]	Loss = 0.75870442 (ave = 0.78767672)

2023-07-05 20:09:02,371 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16940	Time 12.479s / 10iters, (1.248)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.437s / 10iters, (0.844)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.080s / 10iters, (0.008009)
Learning rate = [0.006091669459424569, 0.006091669459424569]	Loss = 0.80392247 (ave = 0.76856392)

2023-07-05 20:09:14,775 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16950	Time 12.405s / 10iters, (1.240)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.360s / 10iters, (0.836)	Loss Time 2.862s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007530)
Learning rate = [0.006089292016381353, 0.006089292016381353]	Loss = 0.74058980 (ave = 0.81502845)

2023-07-05 20:09:27,185 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16960	Time 12.410s / 10iters, (1.241)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.401s / 10iters, (0.840)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007510)
Learning rate = [0.0060869144701975065, 0.0060869144701975065]	Loss = 1.01473403 (ave = 0.83566242)

2023-07-05 20:09:39,566 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16970	Time 12.381s / 10iters, (1.238)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.364s / 10iters, (0.836)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.077s / 10iters, (0.007661)
Learning rate = [0.0060845368208237854, 0.0060845368208237854]	Loss = 0.78055733 (ave = 0.80467303)

2023-07-05 20:09:52,022 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16980	Time 12.456s / 10iters, (1.246)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.412s / 10iters, (0.841)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.078s / 10iters, (0.007821)
Learning rate = [0.006082159068210908, 0.006082159068210908]	Loss = 0.84671146 (ave = 0.80366627)

2023-07-05 20:10:04,474 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 16990	Time 12.451s / 10iters, (1.245)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.396s / 10iters, (0.840)	Loss Time 2.879s / 10iters, (0.288)	Data load 0.076s / 10iters, (0.007595)
Learning rate = [0.006079781212309537, 0.006079781212309537]	Loss = 1.03742385 (ave = 0.82547723)

2023-07-05 20:10:16,848 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 17000	Time 12.374s / 10iters, (1.237)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.356s / 10iters, (0.836)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.078s / 10iters, (0.007824)
Learning rate = [0.006077403253070302, 0.006077403253070302]	Loss = 0.80964899 (ave = 0.82910342)

2023-07-05 20:10:20,118 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 20:10:44,082 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 20:11:07,380 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 20:11:30,577 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 20:11:53,542 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 20:12:16,667 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 20:12:38,982 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 20:12:47,594 INFO    [trainer_contrastive.py, 391] Test Time 147.716s, (2.345)	Loss 0.16555674

2023-07-05 20:12:47,595 INFO    [base.py, 33] Result for seg
2023-07-05 20:12:47,595 INFO    [base.py, 49] Mean IOU: 0.6938316763713681

2023-07-05 20:12:47,596 INFO    [base.py, 50] Pixel ACC: 0.9476383676272856

2023-07-05 20:12:59,836 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 17010	Time 162.988s / 10iters, (16.299)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.770s / 10iters, (0.277)	Data load 150.841s / 10iters, (15.084107)
Learning rate = [0.006075025190443777, 0.006075025190443777]	Loss = 0.69571376 (ave = 0.87429453)

2023-07-05 20:13:11,913 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 17020	Time 12.077s / 10iters, (1.208)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.199s / 10iters, (0.820)	Loss Time 2.702s / 10iters, (0.270)	Data load 0.091s / 10iters, (0.009148)
Learning rate = [0.006072647024380498, 0.006072647024380498]	Loss = 0.87827271 (ave = 0.82596313)

2023-07-05 20:13:23,995 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 17030	Time 12.081s / 10iters, (1.208)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.695s / 10iters, (0.270)	Data load 0.075s / 10iters, (0.007535)
Learning rate = [0.006070268754830953, 0.006070268754830953]	Loss = 0.67299330 (ave = 0.76115400)

2023-07-05 20:13:36,015 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 17040	Time 12.021s / 10iters, (1.202)	Forward Time 1.076s / 10iters, (0.108)	Backward Time 8.134s / 10iters, (0.813)	Loss Time 2.733s / 10iters, (0.273)	Data load 0.077s / 10iters, (0.007693)
Learning rate = [0.006067890381745586, 0.006067890381745586]	Loss = 0.73812586 (ave = 0.82175688)

2023-07-05 20:13:48,116 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 17050	Time 12.100s / 10iters, (1.210)	Forward Time 1.078s / 10iters, (0.108)	Backward Time 8.179s / 10iters, (0.818)	Loss Time 2.769s / 10iters, (0.277)	Data load 0.074s / 10iters, (0.007431)
Learning rate = [0.006065511905074791, 0.006065511905074791]	Loss = 0.64347130 (ave = 0.76645402)

2023-07-05 20:14:00,099 INFO    [trainer_contrastive.py, 272] Train Epoch: 45	Train Iteration: 17060	Time 11.983s / 10iters, (1.198)	Forward Time 1.069s / 10iters, (0.107)	Backward Time 8.116s / 10iters, (0.812)	Loss Time 2.725s / 10iters, (0.273)	Data load 0.073s / 10iters, (0.007310)
Learning rate = [0.0060631333247689245, 0.0060631333247689245]	Loss = 0.84930831 (ave = 0.82270135)

2023-07-05 20:14:14,785 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17070	Time 14.478s / 10iters, (1.448)	Forward Time 1.242s / 10iters, (0.124)	Backward Time 8.132s / 10iters, (0.813)	Loss Time 2.754s / 10iters, (0.275)	Data load 2.351s / 10iters, (0.235059)
Learning rate = [0.006060754640778291, 0.006060754640778291]	Loss = 0.70282072 (ave = 0.75458401)

2023-07-05 20:14:26,969 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17080	Time 12.184s / 10iters, (1.218)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.719s / 10iters, (0.272)	Data load 0.076s / 10iters, (0.007594)
Learning rate = [0.006058375853053153, 0.006058375853053153]	Loss = 0.75621146 (ave = 0.79096271)

2023-07-05 20:14:39,132 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17090	Time 12.163s / 10iters, (1.216)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.208s / 10iters, (0.821)	Loss Time 2.757s / 10iters, (0.276)	Data load 0.098s / 10iters, (0.009800)
Learning rate = [0.006055996961543725, 0.006055996961543725]	Loss = 0.74780965 (ave = 0.76225841)

2023-07-05 20:14:51,427 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17100	Time 12.295s / 10iters, (1.230)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.345s / 10iters, (0.835)	Loss Time 2.759s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007498)
Learning rate = [0.006053617966200177, 0.006053617966200177]	Loss = 0.81477016 (ave = 0.74448564)

2023-07-05 20:15:03,719 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17110	Time 12.293s / 10iters, (1.229)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.327s / 10iters, (0.833)	Loss Time 2.746s / 10iters, (0.275)	Data load 0.098s / 10iters, (0.009818)
Learning rate = [0.006051238866972635, 0.006051238866972635]	Loss = 0.77346635 (ave = 0.79716302)

2023-07-05 20:15:15,922 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17120	Time 12.202s / 10iters, (1.220)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.681s / 10iters, (0.268)	Data load 0.090s / 10iters, (0.008976)
Learning rate = [0.006048859663811177, 0.006048859663811177]	Loss = 0.76550418 (ave = 0.76875308)

2023-07-05 20:15:28,131 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17130	Time 12.210s / 10iters, (1.221)	Forward Time 1.139s / 10iters, (0.114)	Backward Time 8.315s / 10iters, (0.832)	Loss Time 2.665s / 10iters, (0.266)	Data load 0.091s / 10iters, (0.009080)
Learning rate = [0.006046480356665836, 0.006046480356665836]	Loss = 0.83154017 (ave = 0.77127889)

2023-07-05 20:15:40,321 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17140	Time 12.190s / 10iters, (1.219)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.299s / 10iters, (0.830)	Loss Time 2.693s / 10iters, (0.269)	Data load 0.076s / 10iters, (0.007605)
Learning rate = [0.006044100945486599, 0.006044100945486599]	Loss = 0.71166080 (ave = 0.76372025)

2023-07-05 20:15:52,561 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17150	Time 12.240s / 10iters, (1.224)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.326s / 10iters, (0.833)	Loss Time 2.717s / 10iters, (0.272)	Data load 0.075s / 10iters, (0.007490)
Learning rate = [0.006041721430223405, 0.006041721430223405]	Loss = 0.80076349 (ave = 0.84492279)

2023-07-05 20:16:04,718 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17160	Time 12.157s / 10iters, (1.216)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.697s / 10iters, (0.270)	Data load 0.096s / 10iters, (0.009611)
Learning rate = [0.006039341810826153, 0.006039341810826153]	Loss = 0.73842692 (ave = 0.78994127)

2023-07-05 20:16:16,941 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17170	Time 12.223s / 10iters, (1.222)	Forward Time 1.142s / 10iters, (0.114)	Backward Time 8.288s / 10iters, (0.829)	Loss Time 2.710s / 10iters, (0.271)	Data load 0.083s / 10iters, (0.008272)
Learning rate = [0.006036962087244689, 0.006036962087244689]	Loss = 0.63838941 (ave = 0.77826420)

2023-07-05 20:16:29,219 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17180	Time 12.278s / 10iters, (1.228)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.336s / 10iters, (0.834)	Loss Time 2.713s / 10iters, (0.271)	Data load 0.099s / 10iters, (0.009868)
Learning rate = [0.006034582259428815, 0.006034582259428815]	Loss = 0.78456032 (ave = 0.81399145)

2023-07-05 20:16:41,517 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17190	Time 12.298s / 10iters, (1.230)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.416s / 10iters, (0.842)	Loss Time 2.704s / 10iters, (0.270)	Data load 0.088s / 10iters, (0.008841)
Learning rate = [0.006032202327328291, 0.006032202327328291]	Loss = 0.85968673 (ave = 0.81600929)

2023-07-05 20:16:53,706 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17200	Time 12.189s / 10iters, (1.219)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.690s / 10iters, (0.269)	Data load 0.114s / 10iters, (0.011379)
Learning rate = [0.006029822290892826, 0.006029822290892826]	Loss = 0.82420892 (ave = 0.81644354)

2023-07-05 20:17:05,988 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17210	Time 12.282s / 10iters, (1.228)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.411s / 10iters, (0.841)	Loss Time 2.672s / 10iters, (0.267)	Data load 0.075s / 10iters, (0.007512)
Learning rate = [0.006027442150072082, 0.006027442150072082]	Loss = 0.94565952 (ave = 0.82026210)

2023-07-05 20:17:18,182 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17220	Time 12.194s / 10iters, (1.219)	Forward Time 1.142s / 10iters, (0.114)	Backward Time 8.317s / 10iters, (0.832)	Loss Time 2.649s / 10iters, (0.265)	Data load 0.086s / 10iters, (0.008561)
Learning rate = [0.006025061904815681, 0.006025061904815681]	Loss = 0.70782506 (ave = 0.77703698)

2023-07-05 20:17:30,437 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17230	Time 12.254s / 10iters, (1.225)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.378s / 10iters, (0.838)	Loss Time 2.655s / 10iters, (0.266)	Data load 0.092s / 10iters, (0.009205)
Learning rate = [0.006022681555073188, 0.006022681555073188]	Loss = 0.78213376 (ave = 0.80891302)

2023-07-05 20:17:42,680 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17240	Time 12.243s / 10iters, (1.224)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.368s / 10iters, (0.837)	Loss Time 2.667s / 10iters, (0.267)	Data load 0.083s / 10iters, (0.008348)
Learning rate = [0.006020301100794135, 0.006020301100794135]	Loss = 0.85529518 (ave = 0.78645716)

2023-07-05 20:17:54,964 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17250	Time 12.284s / 10iters, (1.228)	Forward Time 1.136s / 10iters, (0.114)	Backward Time 8.343s / 10iters, (0.834)	Loss Time 2.692s / 10iters, (0.269)	Data load 0.113s / 10iters, (0.011286)
Learning rate = [0.006017920541927995, 0.006017920541927995]	Loss = 0.76759481 (ave = 0.76441692)

2023-07-05 20:18:07,173 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17260	Time 12.209s / 10iters, (1.221)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.377s / 10iters, (0.838)	Loss Time 2.639s / 10iters, (0.264)	Data load 0.089s / 10iters, (0.008931)
Learning rate = [0.0060155398784242, 0.0060155398784242]	Loss = 0.91148716 (ave = 0.81790681)

2023-07-05 20:18:19,455 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17270	Time 12.282s / 10iters, (1.228)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.356s / 10iters, (0.836)	Loss Time 2.744s / 10iters, (0.274)	Data load 0.075s / 10iters, (0.007477)
Learning rate = [0.006013159110232137, 0.006013159110232137]	Loss = 1.04653645 (ave = 0.81076606)

2023-07-05 20:18:31,849 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17280	Time 12.394s / 10iters, (1.239)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.402s / 10iters, (0.840)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007424)
Learning rate = [0.006010778237301142, 0.006010778237301142]	Loss = 0.78609598 (ave = 0.78463783)

2023-07-05 20:18:44,240 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17290	Time 12.391s / 10iters, (1.239)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.365s / 10iters, (0.837)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.093s / 10iters, (0.009269)
Learning rate = [0.0060083972595805085, 0.0060083972595805085]	Loss = 0.84010547 (ave = 0.78745890)

2023-07-05 20:18:56,556 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17300	Time 12.316s / 10iters, (1.232)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.319s / 10iters, (0.832)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.083s / 10iters, (0.008329)
Learning rate = [0.006006016177019478, 0.006006016177019478]	Loss = 0.91800499 (ave = 0.82638794)

2023-07-05 20:19:08,945 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17310	Time 12.389s / 10iters, (1.239)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.371s / 10iters, (0.837)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.087s / 10iters, (0.008682)
Learning rate = [0.00600363498956725, 0.00600363498956725]	Loss = 0.81427336 (ave = 0.79330378)

2023-07-05 20:19:21,314 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17320	Time 12.369s / 10iters, (1.237)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.387s / 10iters, (0.839)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007472)
Learning rate = [0.006001253697172976, 0.006001253697172976]	Loss = 0.76151663 (ave = 0.76008098)

2023-07-05 20:19:33,743 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17330	Time 12.429s / 10iters, (1.243)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.394s / 10iters, (0.839)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.098s / 10iters, (0.009817)
Learning rate = [0.005998872299785756, 0.005998872299785756]	Loss = 0.78579998 (ave = 0.77415360)

2023-07-05 20:19:46,320 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17340	Time 12.577s / 10iters, (1.258)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.510s / 10iters, (0.851)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007456)
Learning rate = [0.005996490797354648, 0.005996490797354648]	Loss = 0.61878616 (ave = 0.79083338)

2023-07-05 20:19:58,621 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17350	Time 12.301s / 10iters, (1.230)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.307s / 10iters, (0.831)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.080s / 10iters, (0.007965)
Learning rate = [0.005994109189828661, 0.005994109189828661]	Loss = 0.68230617 (ave = 0.77403614)

2023-07-05 20:20:11,058 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17360	Time 12.438s / 10iters, (1.244)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.391s / 10iters, (0.839)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.080s / 10iters, (0.007993)
Learning rate = [0.0059917274771567565, 0.0059917274771567565]	Loss = 0.80393624 (ave = 0.81278285)

2023-07-05 20:20:23,380 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17370	Time 12.322s / 10iters, (1.232)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.864s / 10iters, (0.286)	Data load 0.083s / 10iters, (0.008252)
Learning rate = [0.005989345659287847, 0.005989345659287847]	Loss = 0.77880538 (ave = 0.78652819)

2023-07-05 20:20:35,663 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17380	Time 12.283s / 10iters, (1.228)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.282s / 10iters, (0.828)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007464)
Learning rate = [0.005986963736170804, 0.005986963736170804]	Loss = 0.79562843 (ave = 0.79033353)

2023-07-05 20:20:47,956 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17390	Time 12.293s / 10iters, (1.229)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.286s / 10iters, (0.829)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.082s / 10iters, (0.008243)
Learning rate = [0.005984581707754442, 0.005984581707754442]	Loss = 0.70607209 (ave = 0.77645125)

2023-07-05 20:21:00,390 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17400	Time 12.434s / 10iters, (1.243)	Forward Time 1.147s / 10iters, (0.115)	Backward Time 8.362s / 10iters, (0.836)	Loss Time 2.833s / 10iters, (0.283)	Data load 0.093s / 10iters, (0.009315)
Learning rate = [0.005982199573987536, 0.005982199573987536]	Loss = 0.72526276 (ave = 0.81949500)

2023-07-05 20:21:12,885 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17410	Time 12.495s / 10iters, (1.249)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.427s / 10iters, (0.843)	Loss Time 2.868s / 10iters, (0.287)	Data load 0.099s / 10iters, (0.009881)
Learning rate = [0.005979817334818809, 0.005979817334818809]	Loss = 0.72169924 (ave = 0.76736401)

2023-07-05 20:21:25,386 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17420	Time 12.501s / 10iters, (1.250)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.418s / 10iters, (0.842)	Loss Time 2.886s / 10iters, (0.289)	Data load 0.077s / 10iters, (0.007696)
Learning rate = [0.005977434990196937, 0.005977434990196937]	Loss = 0.74965090 (ave = 0.80982370)

2023-07-05 20:21:37,440 INFO    [trainer_contrastive.py, 272] Train Epoch: 46	Train Iteration: 17430	Time 12.054s / 10iters, (1.205)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.155s / 10iters, (0.816)	Loss Time 2.746s / 10iters, (0.275)	Data load 0.073s / 10iters, (0.007326)
Learning rate = [0.005975052540070552, 0.005975052540070552]	Loss = 0.81056815 (ave = 0.78071432)

2023-07-05 20:21:52,567 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17440	Time 14.949s / 10iters, (1.495)	Forward Time 1.196s / 10iters, (0.120)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.703s / 10iters, (0.270)	Data load 2.855s / 10iters, (0.285467)
Learning rate = [0.005972669984388231, 0.005972669984388231]	Loss = 0.73255575 (ave = 0.77938558)

2023-07-05 20:22:04,922 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17450	Time 12.356s / 10iters, (1.236)	Forward Time 1.185s / 10iters, (0.119)	Backward Time 8.367s / 10iters, (0.837)	Loss Time 2.716s / 10iters, (0.272)	Data load 0.088s / 10iters, (0.008753)
Learning rate = [0.005970287323098511, 0.005970287323098511]	Loss = 0.73434997 (ave = 0.84384688)

2023-07-05 20:22:17,240 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17460	Time 12.317s / 10iters, (1.232)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.384s / 10iters, (0.838)	Loss Time 2.733s / 10iters, (0.273)	Data load 0.078s / 10iters, (0.007823)
Learning rate = [0.005967904556149876, 0.005967904556149876]	Loss = 0.83625430 (ave = 0.78296471)

2023-07-05 20:22:29,410 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17470	Time 12.170s / 10iters, (1.217)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.720s / 10iters, (0.272)	Data load 0.093s / 10iters, (0.009308)
Learning rate = [0.00596552168349076, 0.00596552168349076]	Loss = 0.85728383 (ave = 0.76980187)

2023-07-05 20:22:41,759 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17480	Time 12.350s / 10iters, (1.235)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.343s / 10iters, (0.834)	Loss Time 2.797s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007559)
Learning rate = [0.005963138705069557, 0.005963138705069557]	Loss = 0.75433421 (ave = 0.83976927)

2023-07-05 20:22:54,056 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17490	Time 12.296s / 10iters, (1.230)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.286s / 10iters, (0.829)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.102s / 10iters, (0.010175)
Learning rate = [0.005960755620834607, 0.005960755620834607]	Loss = 0.71114892 (ave = 0.78425695)

2023-07-05 20:23:06,474 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17500	Time 12.418s / 10iters, (1.242)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.418s / 10iters, (0.842)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.086s / 10iters, (0.008635)
Learning rate = [0.005958372430734202, 0.005958372430734202]	Loss = 0.88704193 (ave = 0.80254006)

2023-07-05 20:23:18,808 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17510	Time 12.334s / 10iters, (1.233)	Forward Time 1.179s / 10iters, (0.118)	Backward Time 8.324s / 10iters, (0.832)	Loss Time 2.754s / 10iters, (0.275)	Data load 0.076s / 10iters, (0.007634)
Learning rate = [0.005955989134716587, 0.005955989134716587]	Loss = 0.80985391 (ave = 0.76467294)

2023-07-05 20:23:31,166 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17520	Time 12.358s / 10iters, (1.236)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.329s / 10iters, (0.833)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.092s / 10iters, (0.009159)
Learning rate = [0.005953605732729957, 0.005953605732729957]	Loss = 0.77097130 (ave = 0.79302851)

2023-07-05 20:23:43,487 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17530	Time 12.321s / 10iters, (1.232)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007616)
Learning rate = [0.005951222224722464, 0.005951222224722464]	Loss = 0.76590651 (ave = 0.74160367)

2023-07-05 20:23:55,926 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17540	Time 12.440s / 10iters, (1.244)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.389s / 10iters, (0.839)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.090s / 10iters, (0.009007)
Learning rate = [0.005948838610642203, 0.005948838610642203]	Loss = 0.75178933 (ave = 0.74985867)

2023-07-05 20:24:08,397 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17550	Time 12.471s / 10iters, (1.247)	Forward Time 1.148s / 10iters, (0.115)	Backward Time 8.376s / 10iters, (0.838)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007546)
Learning rate = [0.005946454890437228, 0.005946454890437228]	Loss = 0.78606880 (ave = 0.77374932)

2023-07-05 20:24:20,892 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17560	Time 12.495s / 10iters, (1.250)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.410s / 10iters, (0.841)	Loss Time 2.897s / 10iters, (0.290)	Data load 0.076s / 10iters, (0.007566)
Learning rate = [0.00594407106405554, 0.00594407106405554]	Loss = 0.80498946 (ave = 0.77869398)

2023-07-05 20:24:33,401 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17570	Time 12.509s / 10iters, (1.251)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.389s / 10iters, (0.839)	Loss Time 2.902s / 10iters, (0.290)	Data load 0.101s / 10iters, (0.010130)
Learning rate = [0.005941687131445093, 0.005941687131445093]	Loss = 0.71457732 (ave = 0.74653410)

2023-07-05 20:24:45,897 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17580	Time 12.495s / 10iters, (1.250)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.434s / 10iters, (0.843)	Loss Time 2.869s / 10iters, (0.287)	Data load 0.080s / 10iters, (0.008007)
Learning rate = [0.005939303092553791, 0.005939303092553791]	Loss = 0.73635280 (ave = 0.77706787)

2023-07-05 20:24:58,324 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17590	Time 12.427s / 10iters, (1.243)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.353s / 10iters, (0.835)	Loss Time 2.886s / 10iters, (0.289)	Data load 0.088s / 10iters, (0.008842)
Learning rate = [0.005936918947329494, 0.005936918947329494]	Loss = 0.82637161 (ave = 0.79875228)

2023-07-05 20:25:10,717 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17600	Time 12.393s / 10iters, (1.239)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.884s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007520)
Learning rate = [0.005934534695720004, 0.005934534695720004]	Loss = 0.83578908 (ave = 0.77039277)

2023-07-05 20:25:23,048 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17610	Time 12.331s / 10iters, (1.233)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.281s / 10iters, (0.828)	Loss Time 2.845s / 10iters, (0.285)	Data load 0.098s / 10iters, (0.009763)
Learning rate = [0.005932150337673084, 0.005932150337673084]	Loss = 0.72670281 (ave = 0.75722512)

2023-07-05 20:25:35,284 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17620	Time 12.236s / 10iters, (1.224)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.288s / 10iters, (0.829)	Loss Time 2.743s / 10iters, (0.274)	Data load 0.077s / 10iters, (0.007688)
Learning rate = [0.00592976587313644, 0.00592976587313644]	Loss = 0.93722510 (ave = 0.77743840)

2023-07-05 20:25:47,562 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17630	Time 12.278s / 10iters, (1.228)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.306s / 10iters, (0.831)	Loss Time 2.764s / 10iters, (0.276)	Data load 0.095s / 10iters, (0.009540)
Learning rate = [0.005927381302057735, 0.005927381302057735]	Loss = 0.78647476 (ave = 0.77119905)

2023-07-05 20:25:59,879 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17640	Time 12.317s / 10iters, (1.232)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.398s / 10iters, (0.840)	Loss Time 2.734s / 10iters, (0.273)	Data load 0.086s / 10iters, (0.008571)
Learning rate = [0.005924996624384579, 0.005924996624384579]	Loss = 0.80129153 (ave = 0.78387496)

2023-07-05 20:26:12,201 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17650	Time 12.322s / 10iters, (1.232)	Forward Time 1.141s / 10iters, (0.114)	Backward Time 8.363s / 10iters, (0.836)	Loss Time 2.743s / 10iters, (0.274)	Data load 0.075s / 10iters, (0.007461)
Learning rate = [0.005922611840064535, 0.005922611840064535]	Loss = 0.91505527 (ave = 0.81281890)

2023-07-05 20:26:24,573 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17660	Time 12.372s / 10iters, (1.237)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.379s / 10iters, (0.838)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007444)
Learning rate = [0.005920226949045113, 0.005920226949045113]	Loss = 0.77609080 (ave = 0.79939843)

2023-07-05 20:26:36,945 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17670	Time 12.372s / 10iters, (1.237)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.322s / 10iters, (0.832)	Loss Time 2.855s / 10iters, (0.285)	Data load 0.089s / 10iters, (0.008919)
Learning rate = [0.005917841951273781, 0.005917841951273781]	Loss = 0.74343216 (ave = 0.79830655)

2023-07-05 20:26:49,220 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17680	Time 12.275s / 10iters, (1.227)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.287s / 10iters, (0.829)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.082s / 10iters, (0.008170)
Learning rate = [0.005915456846697948, 0.005915456846697948]	Loss = 0.71448439 (ave = 0.82664740)

2023-07-05 20:27:01,337 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17690	Time 12.117s / 10iters, (1.212)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.191s / 10iters, (0.819)	Loss Time 2.707s / 10iters, (0.271)	Data load 0.087s / 10iters, (0.008662)
Learning rate = [0.005913071635264983, 0.005913071635264983]	Loss = 0.78183401 (ave = 0.81691301)

2023-07-05 20:27:13,489 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17700	Time 12.152s / 10iters, (1.215)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.189s / 10iters, (0.819)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.082s / 10iters, (0.008211)
Learning rate = [0.005910686316922198, 0.005910686316922198]	Loss = 0.84876621 (ave = 0.80443662)

2023-07-05 20:27:25,774 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17710	Time 12.284s / 10iters, (1.228)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.260s / 10iters, (0.826)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.083s / 10iters, (0.008269)
Learning rate = [0.005908300891616859, 0.005908300891616859]	Loss = 0.92091620 (ave = 0.78470438)

2023-07-05 20:27:38,146 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17720	Time 12.372s / 10iters, (1.237)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.326s / 10iters, (0.833)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.092s / 10iters, (0.009187)
Learning rate = [0.005905915359296183, 0.005905915359296183]	Loss = 1.05911553 (ave = 0.78084248)

2023-07-05 20:27:50,403 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17730	Time 12.257s / 10iters, (1.226)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.243s / 10iters, (0.824)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.079s / 10iters, (0.007894)
Learning rate = [0.0059035297199073345, 0.0059035297199073345]	Loss = 0.64847636 (ave = 0.76712034)

2023-07-05 20:28:02,738 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17740	Time 12.335s / 10iters, (1.234)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.877s / 10iters, (0.288)	Data load 0.086s / 10iters, (0.008642)
Learning rate = [0.0059011439733974306, 0.0059011439733974306]	Loss = 0.78805149 (ave = 0.80195194)

2023-07-05 20:28:14,983 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17750	Time 12.245s / 10iters, (1.224)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.078s / 10iters, (0.007823)
Learning rate = [0.005898758119713537, 0.005898758119713537]	Loss = 0.73617524 (ave = 0.79481401)

2023-07-05 20:28:27,281 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17760	Time 12.298s / 10iters, (1.230)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.305s / 10iters, (0.831)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.078s / 10iters, (0.007779)
Learning rate = [0.005896372158802671, 0.005896372158802671]	Loss = 0.76717484 (ave = 0.83360067)

2023-07-05 20:28:39,551 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17770	Time 12.270s / 10iters, (1.227)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.315s / 10iters, (0.831)	Loss Time 2.758s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007525)
Learning rate = [0.005893986090611797, 0.005893986090611797]	Loss = 0.78501058 (ave = 0.74263712)

2023-07-05 20:28:51,854 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17780	Time 12.302s / 10iters, (1.230)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.328s / 10iters, (0.833)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.087s / 10iters, (0.008740)
Learning rate = [0.005891599915087833, 0.005891599915087833]	Loss = 0.96228993 (ave = 0.81500939)

2023-07-05 20:29:04,127 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17790	Time 12.274s / 10iters, (1.227)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.285s / 10iters, (0.828)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.081s / 10iters, (0.008137)
Learning rate = [0.005889213632177643, 0.005889213632177643]	Loss = 0.84398413 (ave = 0.80805204)

2023-07-05 20:29:16,326 INFO    [trainer_contrastive.py, 272] Train Epoch: 47	Train Iteration: 17800	Time 12.199s / 10iters, (1.220)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.253s / 10iters, (0.825)	Loss Time 2.766s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007567)
Learning rate = [0.005886827241828044, 0.005886827241828044]	Loss = 0.78112918 (ave = 0.86449838)

2023-07-05 20:29:31,310 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17810	Time 14.795s / 10iters, (1.479)	Forward Time 1.316s / 10iters, (0.132)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.650s / 10iters, (0.265)	Data load 2.608s / 10iters, (0.260809)
Learning rate = [0.005884440743985803, 0.005884440743985803]	Loss = 0.77178329 (ave = 0.84754762)

2023-07-05 20:29:43,628 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17820	Time 12.318s / 10iters, (1.232)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.395s / 10iters, (0.839)	Loss Time 2.719s / 10iters, (0.272)	Data load 0.075s / 10iters, (0.007544)
Learning rate = [0.005882054138597632, 0.005882054138597632]	Loss = 0.84488869 (ave = 0.81922302)

2023-07-05 20:29:55,976 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17830	Time 12.349s / 10iters, (1.235)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.359s / 10iters, (0.836)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.097s / 10iters, (0.009672)
Learning rate = [0.005879667425610199, 0.005879667425610199]	Loss = 0.85020286 (ave = 0.84806076)

2023-07-05 20:30:08,268 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17840	Time 12.292s / 10iters, (1.229)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.790s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007481)
Learning rate = [0.005877280604970114, 0.005877280604970114]	Loss = 0.93109477 (ave = 0.82419308)

2023-07-05 20:30:20,615 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17850	Time 12.347s / 10iters, (1.235)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.358s / 10iters, (0.836)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.078s / 10iters, (0.007802)
Learning rate = [0.0058748936766239435, 0.0058748936766239435]	Loss = 0.69653934 (ave = 0.77998356)

2023-07-05 20:30:32,855 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17860	Time 12.240s / 10iters, (1.224)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.270s / 10iters, (0.827)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007428)
Learning rate = [0.0058725066405182005, 0.0058725066405182005]	Loss = 0.94324446 (ave = 0.84611011)

2023-07-05 20:30:45,115 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17870	Time 12.260s / 10iters, (1.226)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007592)
Learning rate = [0.005870119496599344, 0.005870119496599344]	Loss = 0.79325128 (ave = 0.81539595)

2023-07-05 20:30:57,461 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17880	Time 12.346s / 10iters, (1.235)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.122s / 10iters, (0.012158)
Learning rate = [0.00586773224481379, 0.00586773224481379]	Loss = 1.00188088 (ave = 0.78695607)

2023-07-05 20:31:09,851 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17890	Time 12.390s / 10iters, (1.239)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.365s / 10iters, (0.836)	Loss Time 2.820s / 10iters, (0.282)	Data load 0.085s / 10iters, (0.008461)
Learning rate = [0.0058653448851078965, 0.0058653448851078965]	Loss = 0.77727163 (ave = 0.81455486)

2023-07-05 20:31:22,127 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17900	Time 12.276s / 10iters, (1.228)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.330s / 10iters, (0.833)	Loss Time 2.747s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007462)
Learning rate = [0.00586295741742797, 0.00586295741742797]	Loss = 0.71913326 (ave = 0.75259548)

2023-07-05 20:31:34,500 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17910	Time 12.373s / 10iters, (1.237)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.427s / 10iters, (0.843)	Loss Time 2.747s / 10iters, (0.275)	Data load 0.076s / 10iters, (0.007608)
Learning rate = [0.0058605698417202754, 0.0058605698417202754]	Loss = 0.75281656 (ave = 0.76757041)

2023-07-05 20:31:46,899 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17920	Time 12.399s / 10iters, (1.240)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.398s / 10iters, (0.840)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.079s / 10iters, (0.007948)
Learning rate = [0.005858182157931015, 0.005858182157931015]	Loss = 0.81430739 (ave = 0.78429085)

2023-07-05 20:31:59,249 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17930	Time 12.350s / 10iters, (1.235)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.394s / 10iters, (0.839)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007509)
Learning rate = [0.005855794366006346, 0.005855794366006346]	Loss = 0.66518217 (ave = 0.77415594)

2023-07-05 20:32:11,625 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17940	Time 12.377s / 10iters, (1.238)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.423s / 10iters, (0.842)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.084s / 10iters, (0.008416)
Learning rate = [0.005853406465892376, 0.005853406465892376]	Loss = 0.76352483 (ave = 0.77357551)

2023-07-05 20:32:23,998 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17950	Time 12.372s / 10iters, (1.237)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.409s / 10iters, (0.841)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007433)
Learning rate = [0.005851018457535154, 0.005851018457535154]	Loss = 0.81328869 (ave = 0.76584045)

2023-07-05 20:32:36,325 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17960	Time 12.328s / 10iters, (1.233)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.306s / 10iters, (0.831)	Loss Time 2.805s / 10iters, (0.280)	Data load 0.083s / 10iters, (0.008286)
Learning rate = [0.005848630340880687, 0.005848630340880687]	Loss = 0.69199586 (ave = 0.78460625)

2023-07-05 20:32:48,688 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17970	Time 12.363s / 10iters, (1.236)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.362s / 10iters, (0.836)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007419)
Learning rate = [0.005846242115874925, 0.005846242115874925]	Loss = 0.71493465 (ave = 0.74402650)

2023-07-05 20:33:01,023 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17980	Time 12.335s / 10iters, (1.234)	Forward Time 1.151s / 10iters, (0.115)	Backward Time 8.342s / 10iters, (0.834)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.095s / 10iters, (0.009452)
Learning rate = [0.0058438537824637635, 0.0058438537824637635]	Loss = 0.75413692 (ave = 0.78039755)

2023-07-05 20:33:13,421 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 17990	Time 12.398s / 10iters, (1.240)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.375s / 10iters, (0.837)	Loss Time 2.835s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007456)
Learning rate = [0.005841465340593056, 0.005841465340593056]	Loss = 0.90103453 (ave = 0.76823422)

2023-07-05 20:33:25,824 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 18000	Time 12.402s / 10iters, (1.240)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.354s / 10iters, (0.835)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.087s / 10iters, (0.008735)
Learning rate = [0.005839076790208594, 0.005839076790208594]	Loss = 0.73692763 (ave = 0.76487263)

2023-07-05 20:33:28,913 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 20:33:53,446 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 20:34:16,882 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 20:34:40,118 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 20:35:03,314 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 20:35:26,691 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 20:35:49,476 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 20:35:55,286 INFO    [base.py, 84] Performance 0.727582636251853 -> 0.7294571801110419
2023-07-05 20:36:00,958 INFO    [trainer_contrastive.py, 391] Test Time 149.304s, (2.370)	Loss 0.14158033

2023-07-05 20:36:00,958 INFO    [base.py, 33] Result for seg
2023-07-05 20:36:00,959 INFO    [base.py, 49] Mean IOU: 0.7294571801110419

2023-07-05 20:36:00,960 INFO    [base.py, 50] Pixel ACC: 0.9544678024479831

2023-07-05 20:36:13,178 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 18010	Time 167.354s / 10iters, (16.735)	Forward Time 1.202s / 10iters, (0.120)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.695s / 10iters, (0.270)	Data load 155.219s / 10iters, (15.521948)
Learning rate = [0.005836688131256124, 0.005836688131256124]	Loss = 0.79973370 (ave = 0.74158208)

2023-07-05 20:36:25,265 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 18020	Time 12.087s / 10iters, (1.209)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.187s / 10iters, (0.819)	Loss Time 2.706s / 10iters, (0.271)	Data load 0.074s / 10iters, (0.007435)
Learning rate = [0.005834299363681338, 0.005834299363681338]	Loss = 0.75588733 (ave = 0.77450171)

2023-07-05 20:36:37,485 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 18030	Time 12.220s / 10iters, (1.222)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.298s / 10iters, (0.830)	Loss Time 2.732s / 10iters, (0.273)	Data load 0.075s / 10iters, (0.007484)
Learning rate = [0.005831910487429876, 0.005831910487429876]	Loss = 1.24751508 (ave = 0.84944993)

2023-07-05 20:36:49,679 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 18040	Time 12.194s / 10iters, (1.219)	Forward Time 1.137s / 10iters, (0.114)	Backward Time 8.275s / 10iters, (0.827)	Loss Time 2.697s / 10iters, (0.270)	Data load 0.085s / 10iters, (0.008493)
Learning rate = [0.005829521502447328, 0.005829521502447328]	Loss = 0.74439859 (ave = 0.78682241)

2023-07-05 20:37:01,789 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 18050	Time 12.110s / 10iters, (1.211)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.694s / 10iters, (0.269)	Data load 0.077s / 10iters, (0.007688)
Learning rate = [0.005827132408679231, 0.005827132408679231]	Loss = 0.78132278 (ave = 0.79501480)

2023-07-05 20:37:14,019 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 18060	Time 12.230s / 10iters, (1.223)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.089s / 10iters, (0.008865)
Learning rate = [0.005824743206071067, 0.005824743206071067]	Loss = 0.76504540 (ave = 0.78230349)

2023-07-05 20:37:26,167 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 18070	Time 12.148s / 10iters, (1.215)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.087s / 10iters, (0.008655)
Learning rate = [0.005822353894568272, 0.005822353894568272]	Loss = 0.57103550 (ave = 0.71332443)

2023-07-05 20:37:38,540 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 18080	Time 12.373s / 10iters, (1.237)	Forward Time 1.141s / 10iters, (0.114)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.096s / 10iters, (0.009623)
Learning rate = [0.0058199644741162215, 0.0058199644741162215]	Loss = 0.78725260 (ave = 0.75617526)

2023-07-05 20:37:50,808 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 18090	Time 12.268s / 10iters, (1.227)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.315s / 10iters, (0.831)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007400)
Learning rate = [0.005817574944660247, 0.005817574944660247]	Loss = 0.77660501 (ave = 0.81539634)

2023-07-05 20:38:03,101 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 18100	Time 12.293s / 10iters, (1.229)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.319s / 10iters, (0.832)	Loss Time 2.760s / 10iters, (0.276)	Data load 0.100s / 10iters, (0.010026)
Learning rate = [0.005815185306145625, 0.005815185306145625]	Loss = 0.76774448 (ave = 0.83434895)

2023-07-05 20:38:15,357 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 18110	Time 12.256s / 10iters, (1.226)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.096s / 10iters, (0.009649)
Learning rate = [0.005812795558517574, 0.005812795558517574]	Loss = 0.74576169 (ave = 0.77657329)

2023-07-05 20:38:27,620 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 18120	Time 12.263s / 10iters, (1.226)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007601)
Learning rate = [0.005810405701721267, 0.005810405701721267]	Loss = 0.71909153 (ave = 0.76750425)

2023-07-05 20:38:39,800 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 18130	Time 12.180s / 10iters, (1.218)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.705s / 10iters, (0.271)	Data load 0.104s / 10iters, (0.010391)
Learning rate = [0.005808015735701823, 0.005808015735701823]	Loss = 0.79524100 (ave = 0.73201682)

2023-07-05 20:38:52,042 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 18140	Time 12.242s / 10iters, (1.224)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.332s / 10iters, (0.833)	Loss Time 2.731s / 10iters, (0.273)	Data load 0.081s / 10iters, (0.008098)
Learning rate = [0.0058056256604043024, 0.0058056256604043024]	Loss = 0.84772432 (ave = 0.76075649)

2023-07-05 20:39:04,277 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 18150	Time 12.235s / 10iters, (1.224)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.314s / 10iters, (0.831)	Loss Time 2.701s / 10iters, (0.270)	Data load 0.088s / 10iters, (0.008817)
Learning rate = [0.005803235475773724, 0.005803235475773724]	Loss = 0.68008161 (ave = 0.75529879)

2023-07-05 20:39:16,482 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 18160	Time 12.205s / 10iters, (1.221)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.312s / 10iters, (0.831)	Loss Time 2.722s / 10iters, (0.272)	Data load 0.077s / 10iters, (0.007672)
Learning rate = [0.005800845181755041, 0.005800845181755041]	Loss = 0.72339970 (ave = 0.83301582)

2023-07-05 20:39:28,536 INFO    [trainer_contrastive.py, 272] Train Epoch: 48	Train Iteration: 18170	Time 12.054s / 10iters, (1.205)	Forward Time 1.082s / 10iters, (0.108)	Backward Time 8.177s / 10iters, (0.818)	Loss Time 2.721s / 10iters, (0.272)	Data load 0.074s / 10iters, (0.007380)
Learning rate = [0.005798454778293165, 0.005798454778293165]	Loss = 0.79082996 (ave = 0.81792005)

2023-07-05 20:39:43,383 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18180	Time 14.658s / 10iters, (1.466)	Forward Time 1.176s / 10iters, (0.118)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.741s / 10iters, (0.274)	Data load 2.550s / 10iters, (0.255013)
Learning rate = [0.005796064265332947, 0.005796064265332947]	Loss = 0.75475156 (ave = 0.73832349)

2023-07-05 20:39:55,786 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18190	Time 12.402s / 10iters, (1.240)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.388s / 10iters, (0.839)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.079s / 10iters, (0.007905)
Learning rate = [0.005793673642819186, 0.005793673642819186]	Loss = 1.05207920 (ave = 0.81322088)

2023-07-05 20:40:08,135 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18200	Time 12.349s / 10iters, (1.235)	Forward Time 1.156s / 10iters, (0.116)	Backward Time 8.372s / 10iters, (0.837)	Loss Time 2.743s / 10iters, (0.274)	Data load 0.078s / 10iters, (0.007773)
Learning rate = [0.005791282910696631, 0.005791282910696631]	Loss = 0.84760201 (ave = 0.75014850)

2023-07-05 20:40:20,284 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18210	Time 12.149s / 10iters, (1.215)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.732s / 10iters, (0.273)	Data load 0.075s / 10iters, (0.007526)
Learning rate = [0.005788892068909978, 0.005788892068909978]	Loss = 0.73374075 (ave = 0.81454585)

2023-07-05 20:40:32,471 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18220	Time 12.187s / 10iters, (1.219)	Forward Time 1.143s / 10iters, (0.114)	Backward Time 8.235s / 10iters, (0.824)	Loss Time 2.718s / 10iters, (0.272)	Data load 0.090s / 10iters, (0.009050)
Learning rate = [0.005786501117403864, 0.005786501117403864]	Loss = 0.75560969 (ave = 0.88427330)

2023-07-05 20:40:44,590 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18230	Time 12.119s / 10iters, (1.212)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.716s / 10iters, (0.272)	Data load 0.092s / 10iters, (0.009235)
Learning rate = [0.005784110056122881, 0.005784110056122881]	Loss = 0.82131952 (ave = 0.78158336)

2023-07-05 20:40:56,774 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18240	Time 12.184s / 10iters, (1.218)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.731s / 10iters, (0.273)	Data load 0.091s / 10iters, (0.009091)
Learning rate = [0.005781718885011558, 0.005781718885011558]	Loss = 0.68266124 (ave = 0.80695827)

2023-07-05 20:41:09,057 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18250	Time 12.283s / 10iters, (1.228)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.270s / 10iters, (0.827)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007435)
Learning rate = [0.005779327604014378, 0.005779327604014378]	Loss = 0.93386304 (ave = 0.76541675)

2023-07-05 20:41:21,362 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18260	Time 12.305s / 10iters, (1.231)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.845s / 10iters, (0.284)	Data load 0.077s / 10iters, (0.007732)
Learning rate = [0.005776936213075768, 0.005776936213075768]	Loss = 0.79142946 (ave = 0.78102772)

2023-07-05 20:41:33,702 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18270	Time 12.339s / 10iters, (1.234)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.313s / 10iters, (0.831)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.098s / 10iters, (0.009846)
Learning rate = [0.005774544712140098, 0.005774544712140098]	Loss = 0.88784111 (ave = 0.80979465)

2023-07-05 20:41:46,022 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18280	Time 12.320s / 10iters, (1.232)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.820s / 10iters, (0.282)	Data load 0.084s / 10iters, (0.008414)
Learning rate = [0.005772153101151693, 0.005772153101151693]	Loss = 0.74980605 (ave = 0.80800137)

2023-07-05 20:41:58,330 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18290	Time 12.307s / 10iters, (1.231)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.304s / 10iters, (0.830)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.077s / 10iters, (0.007737)
Learning rate = [0.005769761380054816, 0.005769761380054816]	Loss = 0.83483517 (ave = 0.80771158)

2023-07-05 20:42:10,708 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18300	Time 12.378s / 10iters, (1.238)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.351s / 10iters, (0.835)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.079s / 10iters, (0.007909)
Learning rate = [0.005767369548793675, 0.005767369548793675]	Loss = 0.75878072 (ave = 0.82718271)

2023-07-05 20:42:22,929 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18310	Time 12.222s / 10iters, (1.222)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.078s / 10iters, (0.007769)
Learning rate = [0.005764977607312434, 0.005764977607312434]	Loss = 0.89464080 (ave = 0.80225553)

2023-07-05 20:42:35,164 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18320	Time 12.234s / 10iters, (1.223)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.236s / 10iters, (0.824)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.083s / 10iters, (0.008300)
Learning rate = [0.005762585555555191, 0.005762585555555191]	Loss = 0.88889241 (ave = 0.81021787)

2023-07-05 20:42:47,500 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18330	Time 12.337s / 10iters, (1.234)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.099s / 10iters, (0.009946)
Learning rate = [0.005760193393465999, 0.005760193393465999]	Loss = 0.70440704 (ave = 0.80419142)

2023-07-05 20:42:59,853 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18340	Time 12.353s / 10iters, (1.235)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.317s / 10iters, (0.832)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.091s / 10iters, (0.009133)
Learning rate = [0.0057578011209888525, 0.0057578011209888525]	Loss = 0.83867979 (ave = 0.82815704)

2023-07-05 20:43:12,316 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18350	Time 12.462s / 10iters, (1.246)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.361s / 10iters, (0.836)	Loss Time 2.896s / 10iters, (0.290)	Data load 0.079s / 10iters, (0.007930)
Learning rate = [0.00575540873806769, 0.00575540873806769]	Loss = 0.81621516 (ave = 0.81916885)

2023-07-05 20:43:24,759 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18360	Time 12.443s / 10iters, (1.244)	Forward Time 1.140s / 10iters, (0.114)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.889s / 10iters, (0.289)	Data load 0.106s / 10iters, (0.010639)
Learning rate = [0.005753016244646402, 0.005753016244646402]	Loss = 0.75256860 (ave = 0.84310173)

2023-07-05 20:43:37,194 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18370	Time 12.435s / 10iters, (1.244)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.885s / 10iters, (0.288)	Data load 0.077s / 10iters, (0.007696)
Learning rate = [0.005750623640668817, 0.005750623640668817]	Loss = 0.72249085 (ave = 0.76810654)

2023-07-05 20:43:49,484 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18380	Time 12.290s / 10iters, (1.229)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.082s / 10iters, (0.008173)
Learning rate = [0.005748230926078715, 0.005748230926078715]	Loss = 0.70828283 (ave = 0.80439384)

2023-07-05 20:44:01,830 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18390	Time 12.346s / 10iters, (1.235)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.868s / 10iters, (0.287)	Data load 0.077s / 10iters, (0.007713)
Learning rate = [0.005745838100819819, 0.005745838100819819]	Loss = 0.92624450 (ave = 0.82390684)

2023-07-05 20:44:14,134 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18400	Time 12.303s / 10iters, (1.230)	Forward Time 1.168s / 10iters, (0.117)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.081s / 10iters, (0.008107)
Learning rate = [0.005743445164835796, 0.005743445164835796]	Loss = 0.90152454 (ave = 0.78699766)

2023-07-05 20:44:26,481 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18410	Time 12.347s / 10iters, (1.235)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.264s / 10iters, (0.826)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.113s / 10iters, (0.011252)
Learning rate = [0.005741052118070259, 0.005741052118070259]	Loss = 0.73077381 (ave = 0.79582129)

2023-07-05 20:44:38,812 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18420	Time 12.331s / 10iters, (1.233)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.079s / 10iters, (0.007856)
Learning rate = [0.005738658960466768, 0.005738658960466768]	Loss = 0.76707017 (ave = 0.77704849)

2023-07-05 20:44:51,359 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18430	Time 12.548s / 10iters, (1.255)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.412s / 10iters, (0.841)	Loss Time 2.903s / 10iters, (0.290)	Data load 0.104s / 10iters, (0.010416)
Learning rate = [0.005736265691968826, 0.005736265691968826]	Loss = 0.82410759 (ave = 0.79535159)

2023-07-05 20:45:03,717 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18440	Time 12.357s / 10iters, (1.236)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.875s / 10iters, (0.288)	Data load 0.088s / 10iters, (0.008781)
Learning rate = [0.0057338723125198825, 0.0057338723125198825]	Loss = 0.80681920 (ave = 0.88112391)

2023-07-05 20:45:16,121 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18450	Time 12.404s / 10iters, (1.240)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.285s / 10iters, (0.828)	Loss Time 2.928s / 10iters, (0.293)	Data load 0.082s / 10iters, (0.008214)
Learning rate = [0.0057314788220633305, 0.0057314788220633305]	Loss = 0.81365907 (ave = 0.77383221)

2023-07-05 20:45:28,491 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18460	Time 12.370s / 10iters, (1.237)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.914s / 10iters, (0.291)	Data load 0.081s / 10iters, (0.008099)
Learning rate = [0.005729085220542508, 0.005729085220542508]	Loss = 0.80701083 (ave = 0.79072387)

2023-07-05 20:45:40,824 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18470	Time 12.334s / 10iters, (1.233)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.889s / 10iters, (0.289)	Data load 0.080s / 10iters, (0.008020)
Learning rate = [0.005726691507900702, 0.005726691507900702]	Loss = 0.69750291 (ave = 0.75716850)

2023-07-05 20:45:53,203 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18480	Time 12.379s / 10iters, (1.238)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.919s / 10iters, (0.292)	Data load 0.076s / 10iters, (0.007570)
Learning rate = [0.005724297684081134, 0.005724297684081134]	Loss = 0.74991888 (ave = 0.82522455)

2023-07-05 20:46:05,517 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18490	Time 12.313s / 10iters, (1.231)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.215s / 10iters, (0.822)	Loss Time 2.891s / 10iters, (0.289)	Data load 0.091s / 10iters, (0.009088)
Learning rate = [0.005721903749026982, 0.005721903749026982]	Loss = 0.71131355 (ave = 0.75470641)

2023-07-05 20:46:17,901 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18500	Time 12.384s / 10iters, (1.238)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.897s / 10iters, (0.290)	Data load 0.085s / 10iters, (0.008466)
Learning rate = [0.00571950970268136, 0.00571950970268136]	Loss = 0.80852902 (ave = 0.79951082)

2023-07-05 20:46:30,133 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18510	Time 12.232s / 10iters, (1.223)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.857s / 10iters, (0.286)	Data load 0.079s / 10iters, (0.007912)
Learning rate = [0.0057171155449873305, 0.0057171155449873305]	Loss = 0.80531371 (ave = 0.85808223)

2023-07-05 20:46:42,471 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18520	Time 12.338s / 10iters, (1.234)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.886s / 10iters, (0.289)	Data load 0.092s / 10iters, (0.009244)
Learning rate = [0.005714721275887898, 0.005714721275887898]	Loss = 0.79368705 (ave = 0.85245148)

2023-07-05 20:46:54,714 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18530	Time 12.243s / 10iters, (1.224)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.086s / 10iters, (0.008614)
Learning rate = [0.005712326895326017, 0.005712326895326017]	Loss = 0.69329745 (ave = 0.82764876)

2023-07-05 20:47:06,868 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18540	Time 12.154s / 10iters, (1.215)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.175s / 10iters, (0.818)	Loss Time 2.804s / 10iters, (0.280)	Data load 0.084s / 10iters, (0.008383)
Learning rate = [0.005709932403244577, 0.005709932403244577]	Loss = 0.91973186 (ave = 0.86172656)

2023-07-05 20:47:18,968 INFO    [trainer_contrastive.py, 272] Train Epoch: 49	Train Iteration: 18550	Time 12.100s / 10iters, (1.210)	Forward Time 1.082s / 10iters, (0.108)	Backward Time 8.175s / 10iters, (0.817)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007573)
Learning rate = [0.005707537799586418, 0.005707537799586418]	Loss = 0.69688332 (ave = 0.76470743)

2023-07-05 20:47:34,524 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18560	Time 15.433s / 10iters, (1.543)	Forward Time 1.296s / 10iters, (0.130)	Backward Time 8.560s / 10iters, (0.856)	Loss Time 2.768s / 10iters, (0.277)	Data load 2.809s / 10iters, (0.280927)
Learning rate = [0.0057051430842943235, 0.0057051430842943235]	Loss = 0.71405458 (ave = 0.76321471)

2023-07-05 20:47:46,945 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18570	Time 12.421s / 10iters, (1.242)	Forward Time 1.161s / 10iters, (0.116)	Backward Time 8.358s / 10iters, (0.836)	Loss Time 2.816s / 10iters, (0.282)	Data load 0.086s / 10iters, (0.008613)
Learning rate = [0.005702748257311019, 0.005702748257311019]	Loss = 0.75780135 (ave = 0.81917160)

2023-07-05 20:47:59,438 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18580	Time 12.493s / 10iters, (1.249)	Forward Time 1.151s / 10iters, (0.115)	Backward Time 8.380s / 10iters, (0.838)	Loss Time 2.855s / 10iters, (0.286)	Data load 0.107s / 10iters, (0.010668)
Learning rate = [0.005700353318579175, 0.005700353318579175]	Loss = 0.84975398 (ave = 0.80626278)

2023-07-05 20:48:11,867 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18590	Time 12.429s / 10iters, (1.243)	Forward Time 1.162s / 10iters, (0.116)	Backward Time 8.368s / 10iters, (0.837)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.088s / 10iters, (0.008826)
Learning rate = [0.005697958268041405, 0.005697958268041405]	Loss = 0.83047545 (ave = 0.74643588)

2023-07-05 20:48:24,265 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18600	Time 12.398s / 10iters, (1.240)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.354s / 10iters, (0.835)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.103s / 10iters, (0.010253)
Learning rate = [0.005695563105640269, 0.005695563105640269]	Loss = 0.88460433 (ave = 0.78517205)

2023-07-05 20:48:36,666 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18610	Time 12.401s / 10iters, (1.240)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.373s / 10iters, (0.837)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.102s / 10iters, (0.010213)
Learning rate = [0.005693167831318267, 0.005693167831318267]	Loss = 0.77086496 (ave = 0.77917052)

2023-07-05 20:48:49,199 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18620	Time 12.534s / 10iters, (1.253)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.494s / 10iters, (0.849)	Loss Time 2.815s / 10iters, (0.282)	Data load 0.098s / 10iters, (0.009817)
Learning rate = [0.005690772445017843, 0.005690772445017843]	Loss = 0.83766901 (ave = 0.81001678)

2023-07-05 20:49:01,589 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18630	Time 12.390s / 10iters, (1.239)	Forward Time 1.187s / 10iters, (0.119)	Backward Time 8.369s / 10iters, (0.837)	Loss Time 2.755s / 10iters, (0.276)	Data load 0.079s / 10iters, (0.007858)
Learning rate = [0.005688376946681388, 0.005688376946681388]	Loss = 0.74989849 (ave = 0.81427804)

2023-07-05 20:49:13,757 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18640	Time 12.168s / 10iters, (1.217)	Forward Time 1.196s / 10iters, (0.120)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.655s / 10iters, (0.266)	Data load 0.106s / 10iters, (0.010567)
Learning rate = [0.005685981336251231, 0.005685981336251231]	Loss = 0.76850808 (ave = 0.77501860)

2023-07-05 20:49:26,108 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18650	Time 12.351s / 10iters, (1.235)	Forward Time 1.136s / 10iters, (0.114)	Backward Time 8.349s / 10iters, (0.835)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.090s / 10iters, (0.009005)
Learning rate = [0.0056835856136696495, 0.0056835856136696495]	Loss = 1.00760090 (ave = 0.78433282)

2023-07-05 20:49:38,425 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18660	Time 12.317s / 10iters, (1.232)	Forward Time 1.140s / 10iters, (0.114)	Backward Time 8.368s / 10iters, (0.837)	Loss Time 2.733s / 10iters, (0.273)	Data load 0.076s / 10iters, (0.007585)
Learning rate = [0.00568118977887886, 0.00568118977887886]	Loss = 0.83716035 (ave = 0.76467390)

2023-07-05 20:49:50,709 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18670	Time 12.284s / 10iters, (1.228)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.349s / 10iters, (0.835)	Loss Time 2.744s / 10iters, (0.274)	Data load 0.076s / 10iters, (0.007583)
Learning rate = [0.005678793831821025, 0.005678793831821025]	Loss = 0.91610920 (ave = 0.76630943)

2023-07-05 20:50:03,114 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18680	Time 12.404s / 10iters, (1.240)	Forward Time 1.161s / 10iters, (0.116)	Backward Time 8.378s / 10iters, (0.838)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.093s / 10iters, (0.009269)
Learning rate = [0.005676397772438252, 0.005676397772438252]	Loss = 0.74562371 (ave = 0.80704204)

2023-07-05 20:50:15,424 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18690	Time 12.310s / 10iters, (1.231)	Forward Time 1.230s / 10iters, (0.123)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.689s / 10iters, (0.269)	Data load 0.089s / 10iters, (0.008897)
Learning rate = [0.0056740016006725826, 0.0056740016006725826]	Loss = 0.85429645 (ave = 0.83959718)

2023-07-05 20:50:27,678 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18700	Time 12.254s / 10iters, (1.225)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007624)
Learning rate = [0.005671605316466012, 0.005671605316466012]	Loss = 0.73204941 (ave = 0.85947132)

2023-07-05 20:50:40,099 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18710	Time 12.421s / 10iters, (1.242)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.359s / 10iters, (0.836)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.077s / 10iters, (0.007725)
Learning rate = [0.005669208919760472, 0.005669208919760472]	Loss = 0.77891493 (ave = 0.77735505)

2023-07-05 20:50:52,507 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18720	Time 12.408s / 10iters, (1.241)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.333s / 10iters, (0.833)	Loss Time 2.873s / 10iters, (0.287)	Data load 0.094s / 10iters, (0.009419)
Learning rate = [0.0056668124104978365, 0.0056668124104978365]	Loss = 0.75791293 (ave = 0.80410142)

2023-07-05 20:51:04,851 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18730	Time 12.344s / 10iters, (1.234)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.865s / 10iters, (0.287)	Data load 0.090s / 10iters, (0.008989)
Learning rate = [0.005664415788619929, 0.005664415788619929]	Loss = 0.81888342 (ave = 0.77792110)

2023-07-05 20:51:17,122 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18740	Time 12.271s / 10iters, (1.227)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.230s / 10iters, (0.823)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.081s / 10iters, (0.008097)
Learning rate = [0.0056620190540685065, 0.0056620190540685065]	Loss = 0.81798989 (ave = 0.88125648)

2023-07-05 20:51:29,580 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18750	Time 12.458s / 10iters, (1.246)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.396s / 10iters, (0.840)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.083s / 10iters, (0.008332)
Learning rate = [0.005659622206785274, 0.005659622206785274]	Loss = 0.80617630 (ave = 0.79944115)

2023-07-05 20:51:41,966 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18760	Time 12.386s / 10iters, (1.239)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.418s / 10iters, (0.842)	Loss Time 2.785s / 10iters, (0.279)	Data load 0.080s / 10iters, (0.007978)
Learning rate = [0.00565722524671188, 0.00565722524671188]	Loss = 0.74976885 (ave = 0.79416804)

2023-07-05 20:51:54,371 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18770	Time 12.405s / 10iters, (1.241)	Forward Time 1.151s / 10iters, (0.115)	Backward Time 8.390s / 10iters, (0.839)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.085s / 10iters, (0.008550)
Learning rate = [0.005654828173789908, 0.005654828173789908]	Loss = 0.76464188 (ave = 0.78138527)

2023-07-05 20:52:06,659 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18780	Time 12.288s / 10iters, (1.229)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.314s / 10iters, (0.831)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007580)
Learning rate = [0.005652430987960892, 0.005652430987960892]	Loss = 0.77034497 (ave = 0.74972262)

2023-07-05 20:52:19,007 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18790	Time 12.348s / 10iters, (1.235)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.376s / 10iters, (0.838)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.081s / 10iters, (0.008114)
Learning rate = [0.005650033689166304, 0.005650033689166304]	Loss = 0.86835188 (ave = 0.78572720)

2023-07-05 20:52:31,239 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18800	Time 12.232s / 10iters, (1.223)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.092s / 10iters, (0.009249)
Learning rate = [0.005647636277347557, 0.005647636277347557]	Loss = 0.79534864 (ave = 0.76107439)

2023-07-05 20:52:43,623 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18810	Time 12.384s / 10iters, (1.238)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.380s / 10iters, (0.838)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.094s / 10iters, (0.009374)
Learning rate = [0.005645238752446012, 0.005645238752446012]	Loss = 0.92378122 (ave = 0.81871186)

2023-07-05 20:52:55,895 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18820	Time 12.272s / 10iters, (1.227)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.747s / 10iters, (0.275)	Data load 0.101s / 10iters, (0.010139)
Learning rate = [0.0056428411144029645, 0.0056428411144029645]	Loss = 0.78215367 (ave = 0.81531626)

2023-07-05 20:53:08,228 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18830	Time 12.333s / 10iters, (1.233)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.361s / 10iters, (0.836)	Loss Time 2.760s / 10iters, (0.276)	Data load 0.085s / 10iters, (0.008526)
Learning rate = [0.005640443363159655, 0.005640443363159655]	Loss = 0.76228285 (ave = 0.80729337)

2023-07-05 20:53:20,453 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18840	Time 12.225s / 10iters, (1.222)	Forward Time 1.159s / 10iters, (0.116)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.713s / 10iters, (0.271)	Data load 0.082s / 10iters, (0.008222)
Learning rate = [0.005638045498657269, 0.005638045498657269]	Loss = 0.74646389 (ave = 0.78993356)

2023-07-05 20:53:32,815 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18850	Time 12.362s / 10iters, (1.236)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.335s / 10iters, (0.834)	Loss Time 2.820s / 10iters, (0.282)	Data load 0.088s / 10iters, (0.008764)
Learning rate = [0.005635647520836924, 0.005635647520836924]	Loss = 0.91636717 (ave = 0.81099825)

2023-07-05 20:53:45,099 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18860	Time 12.285s / 10iters, (1.228)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.078s / 10iters, (0.007827)
Learning rate = [0.005633249429639691, 0.005633249429639691]	Loss = 0.71510935 (ave = 0.77072387)

2023-07-05 20:53:57,491 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18870	Time 12.392s / 10iters, (1.239)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.355s / 10iters, (0.836)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007467)
Learning rate = [0.005630851225006573, 0.005630851225006573]	Loss = 0.75691658 (ave = 0.79537473)

2023-07-05 20:54:09,882 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18880	Time 12.391s / 10iters, (1.239)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.098s / 10iters, (0.009794)
Learning rate = [0.005628452906878521, 0.005628452906878521]	Loss = 0.86688095 (ave = 0.80910891)

2023-07-05 20:54:22,281 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18890	Time 12.399s / 10iters, (1.240)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.379s / 10iters, (0.838)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007437)
Learning rate = [0.005626054475196422, 0.005626054475196422]	Loss = 0.78707689 (ave = 0.82147350)

2023-07-05 20:54:34,544 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18900	Time 12.263s / 10iters, (1.226)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.083s / 10iters, (0.008306)
Learning rate = [0.00562365592990111, 0.00562365592990111]	Loss = 0.66518086 (ave = 0.74568119)

2023-07-05 20:54:46,735 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18910	Time 12.191s / 10iters, (1.219)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.078s / 10iters, (0.007761)
Learning rate = [0.005621257270933353, 0.005621257270933353]	Loss = 0.84768850 (ave = 0.74790736)

2023-07-05 20:54:58,788 INFO    [trainer_contrastive.py, 272] Train Epoch: 50	Train Iteration: 18920	Time 12.053s / 10iters, (1.205)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.144s / 10iters, (0.814)	Loss Time 2.742s / 10iters, (0.274)	Data load 0.081s / 10iters, (0.008053)
Learning rate = [0.005618858498233868, 0.005618858498233868]	Loss = 0.78723192 (ave = 0.83011914)

2023-07-05 20:55:14,086 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 18930	Time 15.127s / 10iters, (1.513)	Forward Time 1.192s / 10iters, (0.119)	Backward Time 8.278s / 10iters, (0.828)	Loss Time 2.830s / 10iters, (0.283)	Data load 2.827s / 10iters, (0.282668)
Learning rate = [0.005616459611743304, 0.005616459611743304]	Loss = 0.76889503 (ave = 0.81060311)

2023-07-05 20:55:26,381 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 18940	Time 12.295s / 10iters, (1.230)	Forward Time 1.182s / 10iters, (0.118)	Backward Time 8.233s / 10iters, (0.823)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.086s / 10iters, (0.008634)
Learning rate = [0.005614060611402258, 0.005614060611402258]	Loss = 0.63660443 (ave = 0.75045204)

2023-07-05 20:55:38,840 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 18950	Time 12.459s / 10iters, (1.246)	Forward Time 1.153s / 10iters, (0.115)	Backward Time 8.376s / 10iters, (0.838)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.086s / 10iters, (0.008620)
Learning rate = [0.005611661497151267, 0.005611661497151267]	Loss = 0.67214435 (ave = 0.78167416)

2023-07-05 20:55:51,197 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 18960	Time 12.357s / 10iters, (1.236)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.845s / 10iters, (0.285)	Data load 0.089s / 10iters, (0.008882)
Learning rate = [0.005609262268930802, 0.005609262268930802]	Loss = 1.10405922 (ave = 0.78333709)

2023-07-05 20:56:03,755 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 18970	Time 12.558s / 10iters, (1.256)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.457s / 10iters, (0.846)	Loss Time 2.894s / 10iters, (0.289)	Data load 0.091s / 10iters, (0.009116)
Learning rate = [0.005606862926681285, 0.005606862926681285]	Loss = 0.88431734 (ave = 0.76395610)

2023-07-05 20:56:16,134 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 18980	Time 12.378s / 10iters, (1.238)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.864s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007535)
Learning rate = [0.005604463470343072, 0.005604463470343072]	Loss = 0.76159126 (ave = 0.76726117)

2023-07-05 20:56:28,578 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 18990	Time 12.444s / 10iters, (1.244)	Forward Time 1.141s / 10iters, (0.114)	Backward Time 8.355s / 10iters, (0.836)	Loss Time 2.872s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007529)
Learning rate = [0.005602063899856457, 0.005602063899856457]	Loss = 0.77642739 (ave = 0.82286242)

2023-07-05 20:56:41,044 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19000	Time 12.466s / 10iters, (1.247)	Forward Time 1.137s / 10iters, (0.114)	Backward Time 8.346s / 10iters, (0.835)	Loss Time 2.902s / 10iters, (0.290)	Data load 0.082s / 10iters, (0.008177)
Learning rate = [0.005599664215161682, 0.005599664215161682]	Loss = 0.62872910 (ave = 0.75841990)

2023-07-05 20:56:45,524 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 20:57:09,463 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 20:57:33,247 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 20:57:56,661 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 20:58:20,209 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 20:58:43,383 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 20:59:06,062 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 20:59:14,691 INFO    [trainer_contrastive.py, 391] Test Time 150.613s, (2.391)	Loss 0.14985474

2023-07-05 20:59:14,692 INFO    [base.py, 33] Result for seg
2023-07-05 20:59:14,692 INFO    [base.py, 49] Mean IOU: 0.7249651544275154

2023-07-05 20:59:14,693 INFO    [base.py, 50] Pixel ACC: 0.9539698070362461

2023-07-05 20:59:26,842 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19010	Time 165.798s / 10iters, (16.580)	Forward Time 1.229s / 10iters, (0.123)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.569s / 10iters, (0.257)	Data load 153.744s / 10iters, (15.374388)
Learning rate = [0.005597264416198922, 0.005597264416198922]	Loss = 0.91780913 (ave = 0.74776123)

2023-07-05 20:59:38,943 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19020	Time 12.101s / 10iters, (1.210)	Forward Time 1.160s / 10iters, (0.116)	Backward Time 8.209s / 10iters, (0.821)	Loss Time 2.638s / 10iters, (0.264)	Data load 0.095s / 10iters, (0.009463)
Learning rate = [0.005594864502908298, 0.005594864502908298]	Loss = 0.83734101 (ave = 0.84546331)

2023-07-05 20:59:50,940 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19030	Time 11.996s / 10iters, (1.200)	Forward Time 1.160s / 10iters, (0.116)	Backward Time 8.143s / 10iters, (0.814)	Loss Time 2.598s / 10iters, (0.260)	Data load 0.095s / 10iters, (0.009493)
Learning rate = [0.005592464475229866, 0.005592464475229866]	Loss = 0.79169327 (ave = 0.86066837)

2023-07-05 21:00:02,962 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19040	Time 12.022s / 10iters, (1.202)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.172s / 10iters, (0.817)	Loss Time 2.633s / 10iters, (0.263)	Data load 0.100s / 10iters, (0.009983)
Learning rate = [0.005590064333103625, 0.005590064333103625]	Loss = 0.83120883 (ave = 0.78948328)

2023-07-05 21:00:15,275 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19050	Time 12.313s / 10iters, (1.231)	Forward Time 1.135s / 10iters, (0.113)	Backward Time 8.400s / 10iters, (0.840)	Loss Time 2.696s / 10iters, (0.270)	Data load 0.082s / 10iters, (0.008249)
Learning rate = [0.005587664076469514, 0.005587664076469514]	Loss = 0.83796728 (ave = 0.95593484)

2023-07-05 21:00:27,570 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19060	Time 12.295s / 10iters, (1.229)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.359s / 10iters, (0.836)	Loss Time 2.736s / 10iters, (0.274)	Data load 0.090s / 10iters, (0.008972)
Learning rate = [0.0055852637052674105, 0.0055852637052674105]	Loss = 0.68853140 (ave = 0.79623612)

2023-07-05 21:00:39,897 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19070	Time 12.327s / 10iters, (1.233)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.344s / 10iters, (0.834)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.080s / 10iters, (0.007970)
Learning rate = [0.005582863219437131, 0.005582863219437131]	Loss = 0.99417698 (ave = 0.80744752)

2023-07-05 21:00:52,116 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19080	Time 12.219s / 10iters, (1.222)	Forward Time 1.147s / 10iters, (0.115)	Backward Time 8.164s / 10iters, (0.816)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.091s / 10iters, (0.009051)
Learning rate = [0.005580462618918437, 0.005580462618918437]	Loss = 0.73763722 (ave = 0.78149367)

2023-07-05 21:01:04,608 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19090	Time 12.492s / 10iters, (1.249)	Forward Time 1.141s / 10iters, (0.114)	Backward Time 8.410s / 10iters, (0.841)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.098s / 10iters, (0.009771)
Learning rate = [0.005578061903651018, 0.005578061903651018]	Loss = 0.68594939 (ave = 0.74843510)

2023-07-05 21:01:17,068 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19100	Time 12.459s / 10iters, (1.246)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.422s / 10iters, (0.842)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.095s / 10iters, (0.009479)
Learning rate = [0.005575661073574517, 0.005575661073574517]	Loss = 0.82026076 (ave = 0.79683603)

2023-07-05 21:01:29,486 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19110	Time 12.418s / 10iters, (1.242)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.389s / 10iters, (0.839)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.078s / 10iters, (0.007797)
Learning rate = [0.005573260128628506, 0.005573260128628506]	Loss = 0.82201076 (ave = 0.76252058)

2023-07-05 21:01:41,780 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19120	Time 12.294s / 10iters, (1.229)	Forward Time 1.135s / 10iters, (0.114)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.115s / 10iters, (0.011467)
Learning rate = [0.005570859068752502, 0.005570859068752502]	Loss = 0.80757523 (ave = 0.78976635)

2023-07-05 21:01:54,017 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19130	Time 12.237s / 10iters, (1.224)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.292s / 10iters, (0.829)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.094s / 10iters, (0.009389)
Learning rate = [0.005568457893885956, 0.005568457893885956]	Loss = 0.74103665 (ave = 0.79924697)

2023-07-05 21:02:06,151 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19140	Time 12.134s / 10iters, (1.213)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.209s / 10iters, (0.821)	Loss Time 2.722s / 10iters, (0.272)	Data load 0.099s / 10iters, (0.009888)
Learning rate = [0.005566056603968266, 0.005566056603968266]	Loss = 0.80329198 (ave = 0.81967714)

2023-07-05 21:02:18,248 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19150	Time 12.097s / 10iters, (1.210)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.677s / 10iters, (0.268)	Data load 0.105s / 10iters, (0.010517)
Learning rate = [0.005563655198938758, 0.005563655198938758]	Loss = 0.69697982 (ave = 0.76693840)

2023-07-05 21:02:30,411 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19160	Time 12.164s / 10iters, (1.216)	Forward Time 1.164s / 10iters, (0.116)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.657s / 10iters, (0.266)	Data load 0.079s / 10iters, (0.007908)
Learning rate = [0.005561253678736709, 0.005561253678736709]	Loss = 0.77437252 (ave = 0.75043863)

2023-07-05 21:02:42,621 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19170	Time 12.210s / 10iters, (1.221)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.281s / 10iters, (0.828)	Loss Time 2.713s / 10iters, (0.271)	Data load 0.110s / 10iters, (0.011048)
Learning rate = [0.005558852043301323, 0.005558852043301323]	Loss = 0.80499399 (ave = 0.76101180)

2023-07-05 21:02:54,719 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19180	Time 12.098s / 10iters, (1.210)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.685s / 10iters, (0.268)	Data load 0.091s / 10iters, (0.009083)
Learning rate = [0.005556450292571754, 0.005556450292571754]	Loss = 0.73465961 (ave = 0.81489402)

2023-07-05 21:03:06,873 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19190	Time 12.154s / 10iters, (1.215)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.716s / 10iters, (0.272)	Data load 0.077s / 10iters, (0.007700)
Learning rate = [0.005554048426487085, 0.005554048426487085]	Loss = 0.78992248 (ave = 0.82969155)

2023-07-05 21:03:19,018 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19200	Time 12.145s / 10iters, (1.215)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.697s / 10iters, (0.270)	Data load 0.075s / 10iters, (0.007501)
Learning rate = [0.005551646444986343, 0.005551646444986343]	Loss = 0.82020998 (ave = 0.75856462)

2023-07-05 21:03:31,037 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19210	Time 12.019s / 10iters, (1.202)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.174s / 10iters, (0.817)	Loss Time 2.665s / 10iters, (0.267)	Data load 0.075s / 10iters, (0.007508)
Learning rate = [0.0055492443480084945, 0.0055492443480084945]	Loss = 0.84974813 (ave = 0.79873953)

2023-07-05 21:03:43,206 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19220	Time 12.169s / 10iters, (1.217)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.209s / 10iters, (0.821)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.085s / 10iters, (0.008463)
Learning rate = [0.005546842135492438, 0.005546842135492438]	Loss = 0.82167029 (ave = 0.80249425)

2023-07-05 21:03:55,367 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19230	Time 12.161s / 10iters, (1.216)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.088s / 10iters, (0.008818)
Learning rate = [0.005544439807377017, 0.005544439807377017]	Loss = 0.75614113 (ave = 0.81714079)

2023-07-05 21:04:07,536 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19240	Time 12.169s / 10iters, (1.217)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.766s / 10iters, (0.277)	Data load 0.080s / 10iters, (0.007951)
Learning rate = [0.00554203736360101, 0.00554203736360101]	Loss = 0.82997960 (ave = 0.74439107)

2023-07-05 21:04:19,826 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19250	Time 12.290s / 10iters, (1.229)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.306s / 10iters, (0.831)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007453)
Learning rate = [0.005539634804103132, 0.005539634804103132]	Loss = 0.75209081 (ave = 0.76325194)

2023-07-05 21:04:32,065 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19260	Time 12.239s / 10iters, (1.224)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.805s / 10iters, (0.281)	Data load 0.084s / 10iters, (0.008445)
Learning rate = [0.005537232128822039, 0.005537232128822039]	Loss = 0.93559152 (ave = 0.86064889)

2023-07-05 21:04:44,219 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19270	Time 12.154s / 10iters, (1.215)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.736s / 10iters, (0.274)	Data load 0.076s / 10iters, (0.007611)
Learning rate = [0.005534829337696326, 0.005534829337696326]	Loss = 0.72895312 (ave = 0.81729144)

2023-07-05 21:04:56,251 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19280	Time 12.032s / 10iters, (1.203)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.153s / 10iters, (0.815)	Loss Time 2.717s / 10iters, (0.272)	Data load 0.074s / 10iters, (0.007431)
Learning rate = [0.00553242643066452, 0.00553242643066452]	Loss = 0.76720273 (ave = 0.79245214)

2023-07-05 21:05:08,226 INFO    [trainer_contrastive.py, 272] Train Epoch: 51	Train Iteration: 19290	Time 11.975s / 10iters, (1.197)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.107s / 10iters, (0.811)	Loss Time 2.712s / 10iters, (0.271)	Data load 0.076s / 10iters, (0.007617)
Learning rate = [0.005530023407665092, 0.005530023407665092]	Loss = 0.68650508 (ave = 0.82598979)

2023-07-05 21:05:23,000 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19300	Time 14.621s / 10iters, (1.462)	Forward Time 1.240s / 10iters, (0.124)	Backward Time 8.255s / 10iters, (0.826)	Loss Time 2.721s / 10iters, (0.272)	Data load 2.405s / 10iters, (0.240523)
Learning rate = [0.005527620268636449, 0.005527620268636449]	Loss = 0.81246293 (ave = 0.80740610)

2023-07-05 21:05:35,158 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19310	Time 12.158s / 10iters, (1.216)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.282s / 10iters, (0.828)	Loss Time 2.682s / 10iters, (0.268)	Data load 0.077s / 10iters, (0.007717)
Learning rate = [0.005525217013516929, 0.005525217013516929]	Loss = 0.72406322 (ave = 0.75793625)

2023-07-05 21:05:47,426 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19320	Time 12.268s / 10iters, (1.227)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.356s / 10iters, (0.836)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.085s / 10iters, (0.008495)
Learning rate = [0.0055228136422448195, 0.0055228136422448195]	Loss = 0.79449034 (ave = 0.72840545)

2023-07-05 21:05:59,561 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19330	Time 12.135s / 10iters, (1.214)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.281s / 10iters, (0.828)	Loss Time 2.655s / 10iters, (0.265)	Data load 0.090s / 10iters, (0.008971)
Learning rate = [0.005520410154758334, 0.005520410154758334]	Loss = 0.73177880 (ave = 0.76428052)

2023-07-05 21:06:11,636 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19340	Time 12.075s / 10iters, (1.208)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.687s / 10iters, (0.269)	Data load 0.081s / 10iters, (0.008146)
Learning rate = [0.00551800655099563, 0.00551800655099563]	Loss = 0.78718543 (ave = 0.73787923)

2023-07-05 21:06:23,870 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19350	Time 12.234s / 10iters, (1.223)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.342s / 10iters, (0.834)	Loss Time 2.714s / 10iters, (0.271)	Data load 0.085s / 10iters, (0.008548)
Learning rate = [0.005515602830894799, 0.005515602830894799]	Loss = 0.68729532 (ave = 0.74054320)

2023-07-05 21:06:35,978 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19360	Time 12.108s / 10iters, (1.211)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.253s / 10iters, (0.825)	Loss Time 2.693s / 10iters, (0.269)	Data load 0.074s / 10iters, (0.007404)
Learning rate = [0.005513198994393871, 0.005513198994393871]	Loss = 1.26406384 (ave = 0.81230051)

2023-07-05 21:06:48,201 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19370	Time 12.223s / 10iters, (1.222)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.730s / 10iters, (0.273)	Data load 0.081s / 10iters, (0.008110)
Learning rate = [0.005510795041430814, 0.005510795041430814]	Loss = 0.76591539 (ave = 0.82036473)

2023-07-05 21:07:00,397 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19380	Time 12.197s / 10iters, (1.220)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.078s / 10iters, (0.007753)
Learning rate = [0.005508390971943528, 0.005508390971943528]	Loss = 0.77247661 (ave = 0.88333337)

2023-07-05 21:07:12,577 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19390	Time 12.180s / 10iters, (1.218)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.077s / 10iters, (0.007745)
Learning rate = [0.005505986785869858, 0.005505986785869858]	Loss = 0.85202503 (ave = 0.77097062)

2023-07-05 21:07:24,756 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19400	Time 12.179s / 10iters, (1.218)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.084s / 10iters, (0.008377)
Learning rate = [0.005503582483147577, 0.005503582483147577]	Loss = 0.75477606 (ave = 0.86536045)

2023-07-05 21:07:37,039 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19410	Time 12.282s / 10iters, (1.228)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.803s / 10iters, (0.280)	Data load 0.083s / 10iters, (0.008343)
Learning rate = [0.005501178063714399, 0.005501178063714399]	Loss = 0.73280770 (ave = 0.79370682)

2023-07-05 21:07:49,501 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19420	Time 12.462s / 10iters, (1.246)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.427s / 10iters, (0.843)	Loss Time 2.855s / 10iters, (0.286)	Data load 0.078s / 10iters, (0.007774)
Learning rate = [0.005498773527507977, 0.005498773527507977]	Loss = 0.88402987 (ave = 0.84390108)

2023-07-05 21:08:01,841 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19430	Time 12.340s / 10iters, (1.234)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007554)
Learning rate = [0.005496368874465893, 0.005496368874465893]	Loss = 0.88419080 (ave = 0.78359702)

2023-07-05 21:08:14,173 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19440	Time 12.332s / 10iters, (1.233)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.287s / 10iters, (0.829)	Loss Time 2.874s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007532)
Learning rate = [0.005493964104525669, 0.005493964104525669]	Loss = 0.64848280 (ave = 0.80697213)

2023-07-05 21:08:26,485 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19450	Time 12.311s / 10iters, (1.231)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007448)
Learning rate = [0.00549155921762477, 0.00549155921762477]	Loss = 0.95004618 (ave = 0.82038022)

2023-07-05 21:08:38,777 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19460	Time 12.292s / 10iters, (1.229)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007615)
Learning rate = [0.005489154213700585, 0.005489154213700585]	Loss = 0.78766298 (ave = 0.78596807)

2023-07-05 21:08:51,066 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19470	Time 12.289s / 10iters, (1.229)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.875s / 10iters, (0.288)	Data load 0.083s / 10iters, (0.008342)
Learning rate = [0.005486749092690446, 0.005486749092690446]	Loss = 0.81478149 (ave = 0.79395669)

2023-07-05 21:09:03,344 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19480	Time 12.278s / 10iters, (1.228)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.226s / 10iters, (0.823)	Loss Time 2.886s / 10iters, (0.289)	Data load 0.074s / 10iters, (0.007393)
Learning rate = [0.005484343854531623, 0.005484343854531623]	Loss = 0.80392361 (ave = 0.81550032)

2023-07-05 21:09:15,688 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19490	Time 12.344s / 10iters, (1.234)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.887s / 10iters, (0.289)	Data load 0.076s / 10iters, (0.007569)
Learning rate = [0.005481938499161313, 0.005481938499161313]	Loss = 0.82392102 (ave = 0.75865935)

2023-07-05 21:09:28,021 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19500	Time 12.333s / 10iters, (1.233)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.255s / 10iters, (0.826)	Loss Time 2.888s / 10iters, (0.289)	Data load 0.094s / 10iters, (0.009366)
Learning rate = [0.005479533026516659, 0.005479533026516659]	Loss = 0.75683588 (ave = 0.71384891)

2023-07-05 21:09:40,401 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19510	Time 12.379s / 10iters, (1.238)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.320s / 10iters, (0.832)	Loss Time 2.874s / 10iters, (0.287)	Data load 0.078s / 10iters, (0.007766)
Learning rate = [0.005477127436534732, 0.005477127436534732]	Loss = 0.70284671 (ave = 0.75881125)

2023-07-05 21:09:52,707 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19520	Time 12.307s / 10iters, (1.231)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.223s / 10iters, (0.822)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.086s / 10iters, (0.008615)
Learning rate = [0.005474721729152543, 0.005474721729152543]	Loss = 0.81179106 (ave = 0.76004353)

2023-07-05 21:10:05,065 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19530	Time 12.358s / 10iters, (1.236)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.089s / 10iters, (0.008919)
Learning rate = [0.005472315904307036, 0.005472315904307036]	Loss = 0.62453777 (ave = 0.75690646)

2023-07-05 21:10:17,390 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19540	Time 12.325s / 10iters, (1.233)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.304s / 10iters, (0.830)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.087s / 10iters, (0.008726)
Learning rate = [0.005469909961935091, 0.005469909961935091]	Loss = 0.78042644 (ave = 0.77589465)

2023-07-05 21:10:29,666 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19550	Time 12.276s / 10iters, (1.228)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.082s / 10iters, (0.008156)
Learning rate = [0.005467503901973523, 0.005467503901973523]	Loss = 0.84948111 (ave = 0.75930509)

2023-07-05 21:10:41,962 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19560	Time 12.296s / 10iters, (1.230)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.077s / 10iters, (0.007719)
Learning rate = [0.005465097724359085, 0.005465097724359085]	Loss = 0.72439325 (ave = 0.77779526)

2023-07-05 21:10:54,333 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19570	Time 12.371s / 10iters, (1.237)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.285s / 10iters, (0.828)	Loss Time 2.885s / 10iters, (0.289)	Data load 0.085s / 10iters, (0.008496)
Learning rate = [0.005462691429028458, 0.005462691429028458]	Loss = 0.79111040 (ave = 0.75136752)

2023-07-05 21:11:06,780 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19580	Time 12.447s / 10iters, (1.245)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.399s / 10iters, (0.840)	Loss Time 2.868s / 10iters, (0.287)	Data load 0.078s / 10iters, (0.007836)
Learning rate = [0.005460285015918266, 0.005460285015918266]	Loss = 0.75768906 (ave = 0.78212699)

2023-07-05 21:11:19,193 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19590	Time 12.413s / 10iters, (1.241)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.895s / 10iters, (0.289)	Data load 0.103s / 10iters, (0.010272)
Learning rate = [0.005457878484965062, 0.005457878484965062]	Loss = 0.83063751 (ave = 0.78383541)

2023-07-05 21:11:31,577 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19600	Time 12.383s / 10iters, (1.238)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.887s / 10iters, (0.289)	Data load 0.084s / 10iters, (0.008389)
Learning rate = [0.005455471836105336, 0.005455471836105336]	Loss = 0.80755103 (ave = 0.80050848)

2023-07-05 21:11:44,052 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19610	Time 12.475s / 10iters, (1.248)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.364s / 10iters, (0.836)	Loss Time 2.913s / 10iters, (0.291)	Data load 0.081s / 10iters, (0.008130)
Learning rate = [0.005453065069275515, 0.005453065069275515]	Loss = 0.82856351 (ave = 0.81642033)

2023-07-05 21:11:56,463 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19620	Time 12.411s / 10iters, (1.241)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.333s / 10iters, (0.833)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.093s / 10iters, (0.009315)
Learning rate = [0.005450658184411955, 0.005450658184411955]	Loss = 0.73823053 (ave = 0.79563354)

2023-07-05 21:12:08,817 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19630	Time 12.354s / 10iters, (1.235)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.105s / 10iters, (0.010462)
Learning rate = [0.005448251181450949, 0.005448251181450949]	Loss = 0.66715699 (ave = 0.81202927)

2023-07-05 21:12:21,176 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19640	Time 12.358s / 10iters, (1.236)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.855s / 10iters, (0.286)	Data load 0.078s / 10iters, (0.007764)
Learning rate = [0.005445844060328731, 0.005445844060328731]	Loss = 0.74261653 (ave = 0.79163957)

2023-07-05 21:12:33,462 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19650	Time 12.286s / 10iters, (1.229)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.864s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007541)
Learning rate = [0.005443436820981454, 0.005443436820981454]	Loss = 0.83315170 (ave = 0.77841772)

2023-07-05 21:12:45,445 INFO    [trainer_contrastive.py, 272] Train Epoch: 52	Train Iteration: 19660	Time 11.983s / 10iters, (1.198)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.128s / 10iters, (0.813)	Loss Time 2.699s / 10iters, (0.270)	Data load 0.076s / 10iters, (0.007605)
Learning rate = [0.005441029463345221, 0.005441029463345221]	Loss = 1.08814871 (ave = 0.80512207)

2023-07-05 21:13:00,591 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19670	Time 15.014s / 10iters, (1.501)	Forward Time 1.271s / 10iters, (0.127)	Backward Time 8.325s / 10iters, (0.832)	Loss Time 2.729s / 10iters, (0.273)	Data load 2.689s / 10iters, (0.268918)
Learning rate = [0.005438621987356059, 0.005438621987356059]	Loss = 0.83226645 (ave = 0.78794776)

2023-07-05 21:13:12,963 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19680	Time 12.372s / 10iters, (1.237)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.332s / 10iters, (0.833)	Loss Time 2.850s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007578)
Learning rate = [0.005436214392949932, 0.005436214392949932]	Loss = 0.65546113 (ave = 0.77991387)

2023-07-05 21:13:25,331 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19690	Time 12.368s / 10iters, (1.237)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.305s / 10iters, (0.830)	Loss Time 2.884s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007521)
Learning rate = [0.00543380668006274, 0.00543380668006274]	Loss = 0.76008534 (ave = 0.75105373)

2023-07-05 21:13:37,696 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19700	Time 12.366s / 10iters, (1.237)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.272s / 10iters, (0.827)	Loss Time 2.897s / 10iters, (0.290)	Data load 0.084s / 10iters, (0.008424)
Learning rate = [0.005431398848630312, 0.005431398848630312]	Loss = 0.78582889 (ave = 0.78006043)

2023-07-05 21:13:50,126 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19710	Time 12.430s / 10iters, (1.243)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.327s / 10iters, (0.833)	Loss Time 2.929s / 10iters, (0.293)	Data load 0.075s / 10iters, (0.007512)
Learning rate = [0.005428990898588415, 0.005428990898588415]	Loss = 0.71691692 (ave = 0.80642253)

2023-07-05 21:14:02,449 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19720	Time 12.323s / 10iters, (1.232)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.875s / 10iters, (0.288)	Data load 0.076s / 10iters, (0.007561)
Learning rate = [0.00542658282987275, 0.00542658282987275]	Loss = 0.76035362 (ave = 0.73627170)

2023-07-05 21:14:14,915 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19730	Time 12.466s / 10iters, (1.247)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.348s / 10iters, (0.835)	Loss Time 2.920s / 10iters, (0.292)	Data load 0.088s / 10iters, (0.008818)
Learning rate = [0.005424174642418943, 0.005424174642418943]	Loss = 0.81312406 (ave = 0.79754436)

2023-07-05 21:14:27,130 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19740	Time 12.215s / 10iters, (1.222)	Forward Time 1.136s / 10iters, (0.114)	Backward Time 8.226s / 10iters, (0.823)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.077s / 10iters, (0.007749)
Learning rate = [0.0054217663361625645, 0.0054217663361625645]	Loss = 0.71605909 (ave = 0.73167899)

2023-07-05 21:14:39,483 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19750	Time 12.353s / 10iters, (1.235)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.328s / 10iters, (0.833)	Loss Time 2.845s / 10iters, (0.285)	Data load 0.081s / 10iters, (0.008135)
Learning rate = [0.005419357911039111, 0.005419357911039111]	Loss = 0.69290841 (ave = 0.74586185)

2023-07-05 21:14:51,777 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19760	Time 12.293s / 10iters, (1.229)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.086s / 10iters, (0.008576)
Learning rate = [0.005416949366984015, 0.005416949366984015]	Loss = 0.82109737 (ave = 0.76246609)

2023-07-05 21:15:04,067 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19770	Time 12.290s / 10iters, (1.229)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.255s / 10iters, (0.826)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.085s / 10iters, (0.008496)
Learning rate = [0.005414540703932642, 0.005414540703932642]	Loss = 0.67469841 (ave = 0.78042790)

2023-07-05 21:15:16,391 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19780	Time 12.324s / 10iters, (1.232)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.838s / 10iters, (0.284)	Data load 0.095s / 10iters, (0.009469)
Learning rate = [0.005412131921820289, 0.005412131921820289]	Loss = 0.79125273 (ave = 0.75523646)

2023-07-05 21:15:28,755 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19790	Time 12.365s / 10iters, (1.236)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.313s / 10iters, (0.831)	Loss Time 2.880s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007400)
Learning rate = [0.005409723020582187, 0.005409723020582187]	Loss = 0.89656448 (ave = 0.75377094)

2023-07-05 21:15:41,038 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19800	Time 12.282s / 10iters, (1.228)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.084s / 10iters, (0.008355)
Learning rate = [0.0054073140001534995, 0.0054073140001534995]	Loss = 0.80115551 (ave = 0.78628148)

2023-07-05 21:15:53,309 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19810	Time 12.271s / 10iters, (1.227)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.322s / 10iters, (0.832)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007538)
Learning rate = [0.005404904860469319, 0.005404904860469319]	Loss = 0.66188622 (ave = 0.73586818)

2023-07-05 21:16:05,678 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19820	Time 12.369s / 10iters, (1.237)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.380s / 10iters, (0.838)	Loss Time 2.808s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007477)
Learning rate = [0.005402495601464679, 0.005402495601464679]	Loss = 0.69978362 (ave = 0.75555195)

2023-07-05 21:16:17,992 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19830	Time 12.315s / 10iters, (1.231)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.368s / 10iters, (0.837)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007610)
Learning rate = [0.005400086223074537, 0.005400086223074537]	Loss = 0.83047837 (ave = 0.73328653)

2023-07-05 21:16:30,198 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19840	Time 12.205s / 10iters, (1.221)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.255s / 10iters, (0.826)	Loss Time 2.758s / 10iters, (0.276)	Data load 0.087s / 10iters, (0.008689)
Learning rate = [0.005397676725233787, 0.005397676725233787]	Loss = 0.76355779 (ave = 0.78453112)

2023-07-05 21:16:42,423 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19850	Time 12.225s / 10iters, (1.223)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.086s / 10iters, (0.008562)
Learning rate = [0.005395267107877253, 0.005395267107877253]	Loss = 0.76021940 (ave = 0.74005057)

2023-07-05 21:16:54,723 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19860	Time 12.300s / 10iters, (1.230)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.309s / 10iters, (0.831)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007440)
Learning rate = [0.005392857370939695, 0.005392857370939695]	Loss = 0.73190939 (ave = 0.78858755)

2023-07-05 21:17:07,124 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19870	Time 12.402s / 10iters, (1.240)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.343s / 10iters, (0.834)	Loss Time 2.865s / 10iters, (0.286)	Data load 0.084s / 10iters, (0.008434)
Learning rate = [0.005390447514355799, 0.005390447514355799]	Loss = 0.79923260 (ave = 0.79070544)

2023-07-05 21:17:19,420 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19880	Time 12.295s / 10iters, (1.230)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.275s / 10iters, (0.827)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.091s / 10iters, (0.009067)
Learning rate = [0.0053880375380601885, 0.0053880375380601885]	Loss = 0.83086199 (ave = 0.77749027)

2023-07-05 21:17:31,604 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19890	Time 12.184s / 10iters, (1.218)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.228s / 10iters, (0.823)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007427)
Learning rate = [0.005385627441987414, 0.005385627441987414]	Loss = 0.75197339 (ave = 0.74126432)

2023-07-05 21:17:43,883 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19900	Time 12.279s / 10iters, (1.228)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.295s / 10iters, (0.830)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.081s / 10iters, (0.008140)
Learning rate = [0.005383217226071962, 0.005383217226071962]	Loss = 0.82585078 (ave = 0.77371194)

2023-07-05 21:17:56,199 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19910	Time 12.316s / 10iters, (1.232)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.315s / 10iters, (0.832)	Loss Time 2.792s / 10iters, (0.279)	Data load 0.084s / 10iters, (0.008353)
Learning rate = [0.00538080689024825, 0.00538080689024825]	Loss = 0.73546302 (ave = 0.75650091)

2023-07-05 21:18:08,397 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19920	Time 12.198s / 10iters, (1.220)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.227s / 10iters, (0.823)	Loss Time 2.775s / 10iters, (0.277)	Data load 0.087s / 10iters, (0.008665)
Learning rate = [0.005378396434450621, 0.005378396434450621]	Loss = 0.77288902 (ave = 0.78604511)

2023-07-05 21:18:20,598 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19930	Time 12.200s / 10iters, (1.220)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.086s / 10iters, (0.008571)
Learning rate = [0.005375985858613358, 0.005375985858613358]	Loss = 0.75934654 (ave = 0.73171289)

2023-07-05 21:18:32,948 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19940	Time 12.351s / 10iters, (1.235)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.325s / 10iters, (0.833)	Loss Time 2.845s / 10iters, (0.284)	Data load 0.086s / 10iters, (0.008558)
Learning rate = [0.005373575162670669, 0.005373575162670669]	Loss = 0.75644803 (ave = 0.74167632)

2023-07-05 21:18:45,277 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19950	Time 12.328s / 10iters, (1.233)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.818s / 10iters, (0.282)	Data load 0.077s / 10iters, (0.007725)
Learning rate = [0.005371164346556696, 0.005371164346556696]	Loss = 0.73354673 (ave = 0.73966345)

2023-07-05 21:18:57,587 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19960	Time 12.311s / 10iters, (1.231)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.288s / 10iters, (0.829)	Loss Time 2.809s / 10iters, (0.281)	Data load 0.107s / 10iters, (0.010711)
Learning rate = [0.0053687534102055115, 0.0053687534102055115]	Loss = 0.79041779 (ave = 0.77708936)

2023-07-05 21:19:09,784 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19970	Time 12.196s / 10iters, (1.220)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.790s / 10iters, (0.279)	Data load 0.087s / 10iters, (0.008686)
Learning rate = [0.005366342353551116, 0.005366342353551116]	Loss = 0.80341196 (ave = 0.80538086)

2023-07-05 21:19:22,141 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19980	Time 12.357s / 10iters, (1.236)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.855s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007401)
Learning rate = [0.005363931176527448, 0.005363931176527448]	Loss = 0.80678576 (ave = 0.87064214)

2023-07-05 21:19:34,469 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 19990	Time 12.328s / 10iters, (1.233)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.306s / 10iters, (0.831)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.088s / 10iters, (0.008772)
Learning rate = [0.00536151987906837, 0.00536151987906837]	Loss = 0.78432000 (ave = 0.83760192)

2023-07-05 21:19:46,777 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 20000	Time 12.308s / 10iters, (1.231)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.341s / 10iters, (0.834)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.087s / 10iters, (0.008665)
Learning rate = [0.005359108461107674, 0.005359108461107674]	Loss = 0.86075276 (ave = 0.81589524)

2023-07-05 21:19:51,651 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 21:20:15,095 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 21:20:38,318 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 21:21:01,416 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 21:21:24,616 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 21:21:47,627 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 21:22:10,412 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 21:22:18,720 INFO    [trainer_contrastive.py, 391] Test Time 149.284s, (2.370)	Loss 0.17533744

2023-07-05 21:22:18,721 INFO    [base.py, 33] Result for seg
2023-07-05 21:22:18,721 INFO    [base.py, 49] Mean IOU: 0.7016279795922532

2023-07-05 21:22:18,722 INFO    [base.py, 50] Pixel ACC: 0.9455714267501536

2023-07-05 21:22:30,928 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 20010	Time 164.151s / 10iters, (16.415)	Forward Time 1.150s / 10iters, (0.115)	Backward Time 8.216s / 10iters, (0.822)	Loss Time 2.734s / 10iters, (0.273)	Data load 152.051s / 10iters, (15.205103)
Learning rate = [0.0053566969225790914, 0.0053566969225790914]	Loss = 0.71515900 (ave = 0.76835215)

2023-07-05 21:22:43,036 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 20020	Time 12.108s / 10iters, (1.211)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.236s / 10iters, (0.824)	Loss Time 2.694s / 10iters, (0.269)	Data load 0.083s / 10iters, (0.008334)
Learning rate = [0.005354285263416276, 0.005354285263416276]	Loss = 0.99890304 (ave = 0.82907258)

2023-07-05 21:22:54,952 INFO    [trainer_contrastive.py, 272] Train Epoch: 53	Train Iteration: 20030	Time 11.915s / 10iters, (1.192)	Forward Time 1.073s / 10iters, (0.107)	Backward Time 8.089s / 10iters, (0.809)	Loss Time 2.681s / 10iters, (0.268)	Data load 0.073s / 10iters, (0.007339)
Learning rate = [0.005351873483552815, 0.005351873483552815]	Loss = 0.85286111 (ave = 0.82692529)

2023-07-05 21:23:10,072 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20040	Time 14.947s / 10iters, (1.495)	Forward Time 1.171s / 10iters, (0.117)	Backward Time 8.226s / 10iters, (0.823)	Loss Time 2.707s / 10iters, (0.271)	Data load 2.842s / 10iters, (0.284171)
Learning rate = [0.0053494615829222224, 0.0053494615829222224]	Loss = 0.77663589 (ave = 0.79645880)

2023-07-05 21:23:22,160 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20050	Time 12.087s / 10iters, (1.209)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.659s / 10iters, (0.266)	Data load 0.118s / 10iters, (0.011816)
Learning rate = [0.0053470495614579465, 0.0053470495614579465]	Loss = 0.67153811 (ave = 0.79244088)

2023-07-05 21:23:34,220 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20060	Time 12.060s / 10iters, (1.206)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.641s / 10iters, (0.264)	Data load 0.088s / 10iters, (0.008767)
Learning rate = [0.005344637419093364, 0.005344637419093364]	Loss = 0.82849181 (ave = 0.77914152)

2023-07-05 21:23:46,363 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20070	Time 12.143s / 10iters, (1.214)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.695s / 10iters, (0.270)	Data load 0.098s / 10iters, (0.009792)
Learning rate = [0.005342225155761782, 0.005342225155761782]	Loss = 0.76026756 (ave = 0.79747527)

2023-07-05 21:23:58,684 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20080	Time 12.321s / 10iters, (1.232)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.358s / 10iters, (0.836)	Loss Time 2.755s / 10iters, (0.275)	Data load 0.093s / 10iters, (0.009348)
Learning rate = [0.005339812771396435, 0.005339812771396435]	Loss = 0.75969487 (ave = 0.78776106)

2023-07-05 21:24:10,816 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20090	Time 12.133s / 10iters, (1.213)	Forward Time 1.172s / 10iters, (0.117)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.635s / 10iters, (0.264)	Data load 0.087s / 10iters, (0.008654)
Learning rate = [0.0053374002659304885, 0.0053374002659304885]	Loss = 0.75430715 (ave = 0.78831921)

2023-07-05 21:24:23,145 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20100	Time 12.329s / 10iters, (1.233)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.361s / 10iters, (0.836)	Loss Time 2.734s / 10iters, (0.273)	Data load 0.107s / 10iters, (0.010730)
Learning rate = [0.005334987639297041, 0.005334987639297041]	Loss = 0.77428788 (ave = 0.79647403)

2023-07-05 21:24:35,507 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20110	Time 12.362s / 10iters, (1.236)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.413s / 10iters, (0.841)	Loss Time 2.763s / 10iters, (0.276)	Data load 0.082s / 10iters, (0.008200)
Learning rate = [0.005332574891429114, 0.005332574891429114]	Loss = 0.63828939 (ave = 0.77509714)

2023-07-05 21:24:47,692 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20120	Time 12.185s / 10iters, (1.218)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.671s / 10iters, (0.267)	Data load 0.075s / 10iters, (0.007496)
Learning rate = [0.005330162022259662, 0.005330162022259662]	Loss = 0.82241476 (ave = 0.75780156)

2023-07-05 21:24:59,869 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20130	Time 12.177s / 10iters, (1.218)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.287s / 10iters, (0.829)	Loss Time 2.684s / 10iters, (0.268)	Data load 0.086s / 10iters, (0.008583)
Learning rate = [0.0053277490317215695, 0.0053277490317215695]	Loss = 0.79976737 (ave = 0.80239689)

2023-07-05 21:25:12,149 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20140	Time 12.280s / 10iters, (1.228)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.319s / 10iters, (0.832)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.096s / 10iters, (0.009629)
Learning rate = [0.005325335919747647, 0.005325335919747647]	Loss = 0.80402076 (ave = 0.76534829)

2023-07-05 21:25:24,351 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20150	Time 12.202s / 10iters, (1.220)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.715s / 10iters, (0.271)	Data load 0.075s / 10iters, (0.007540)
Learning rate = [0.0053229226862706374, 0.0053229226862706374]	Loss = 0.68053091 (ave = 0.81168211)

2023-07-05 21:25:36,670 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20160	Time 12.319s / 10iters, (1.232)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.332s / 10iters, (0.833)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.081s / 10iters, (0.008104)
Learning rate = [0.005320509331223209, 0.005320509331223209]	Loss = 0.64760834 (ave = 0.76942995)

2023-07-05 21:25:48,942 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20170	Time 12.272s / 10iters, (1.227)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.084s / 10iters, (0.008434)
Learning rate = [0.005318095854537961, 0.005318095854537961]	Loss = 0.79933017 (ave = 0.73869188)

2023-07-05 21:26:01,224 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20180	Time 12.282s / 10iters, (1.228)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.804s / 10iters, (0.280)	Data load 0.085s / 10iters, (0.008471)
Learning rate = [0.005315682256147421, 0.005315682256147421]	Loss = 0.72833514 (ave = 0.73043153)

2023-07-05 21:26:13,582 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20190	Time 12.358s / 10iters, (1.236)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.335s / 10iters, (0.833)	Loss Time 2.805s / 10iters, (0.281)	Data load 0.093s / 10iters, (0.009315)
Learning rate = [0.005313268535984046, 0.005313268535984046]	Loss = 0.74345404 (ave = 0.79541350)

2023-07-05 21:26:25,846 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20200	Time 12.263s / 10iters, (1.226)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.808s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007441)
Learning rate = [0.005310854693980218, 0.005310854693980218]	Loss = 0.66672432 (ave = 0.77171017)

2023-07-05 21:26:38,161 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20210	Time 12.315s / 10iters, (1.232)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.870s / 10iters, (0.287)	Data load 0.091s / 10iters, (0.009061)
Learning rate = [0.005308440730068252, 0.005308440730068252]	Loss = 0.81490499 (ave = 0.81679996)

2023-07-05 21:26:50,689 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20220	Time 12.528s / 10iters, (1.253)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.455s / 10iters, (0.845)	Loss Time 2.908s / 10iters, (0.291)	Data load 0.074s / 10iters, (0.007395)
Learning rate = [0.005306026644180386, 0.005306026644180386]	Loss = 0.77997613 (ave = 0.78152819)

2023-07-05 21:27:03,019 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20230	Time 12.330s / 10iters, (1.233)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.297s / 10iters, (0.830)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.082s / 10iters, (0.008171)
Learning rate = [0.0053036124362487915, 0.0053036124362487915]	Loss = 0.69574422 (ave = 0.73959178)

2023-07-05 21:27:15,410 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20240	Time 12.391s / 10iters, (1.239)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.335s / 10iters, (0.834)	Loss Time 2.833s / 10iters, (0.283)	Data load 0.091s / 10iters, (0.009109)
Learning rate = [0.0053011981062055635, 0.0053011981062055635]	Loss = 0.80176079 (ave = 0.79807898)

2023-07-05 21:27:27,684 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20250	Time 12.275s / 10iters, (1.227)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.325s / 10iters, (0.832)	Loss Time 2.715s / 10iters, (0.271)	Data load 0.101s / 10iters, (0.010070)
Learning rate = [0.005298783653982727, 0.005298783653982727]	Loss = 0.69382739 (ave = 0.77558875)

2023-07-05 21:27:39,892 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20260	Time 12.208s / 10iters, (1.221)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.304s / 10iters, (0.830)	Loss Time 2.673s / 10iters, (0.267)	Data load 0.104s / 10iters, (0.010388)
Learning rate = [0.005296369079512234, 0.005296369079512234]	Loss = 0.75223941 (ave = 0.75658857)

2023-07-05 21:27:52,107 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20270	Time 12.215s / 10iters, (1.222)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.345s / 10iters, (0.834)	Loss Time 2.677s / 10iters, (0.268)	Data load 0.086s / 10iters, (0.008556)
Learning rate = [0.005293954382725966, 0.005293954382725966]	Loss = 0.89893615 (ave = 0.75943602)

2023-07-05 21:28:04,384 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20280	Time 12.277s / 10iters, (1.228)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.375s / 10iters, (0.838)	Loss Time 2.709s / 10iters, (0.271)	Data load 0.088s / 10iters, (0.008776)
Learning rate = [0.0052915395635557295, 0.0052915395635557295]	Loss = 0.85503006 (ave = 0.83425441)

2023-07-05 21:28:16,710 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20290	Time 12.326s / 10iters, (1.233)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.389s / 10iters, (0.839)	Loss Time 2.744s / 10iters, (0.274)	Data load 0.096s / 10iters, (0.009581)
Learning rate = [0.005289124621933258, 0.005289124621933258]	Loss = 0.63996607 (ave = 0.76687889)

2023-07-05 21:28:29,010 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20300	Time 12.300s / 10iters, (1.230)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.350s / 10iters, (0.835)	Loss Time 2.735s / 10iters, (0.274)	Data load 0.092s / 10iters, (0.009164)
Learning rate = [0.005286709557790216, 0.005286709557790216]	Loss = 0.88972533 (ave = 0.85070150)

2023-07-05 21:28:41,379 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20310	Time 12.369s / 10iters, (1.237)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.389s / 10iters, (0.839)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.089s / 10iters, (0.008877)
Learning rate = [0.00528429437105819, 0.00528429437105819]	Loss = 0.70615631 (ave = 0.80302557)

2023-07-05 21:28:53,667 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20320	Time 12.288s / 10iters, (1.229)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.085s / 10iters, (0.008505)
Learning rate = [0.005281879061668699, 0.005281879061668699]	Loss = 0.74397171 (ave = 0.78321722)

2023-07-05 21:29:06,060 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20330	Time 12.393s / 10iters, (1.239)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.368s / 10iters, (0.837)	Loss Time 2.825s / 10iters, (0.283)	Data load 0.084s / 10iters, (0.008447)
Learning rate = [0.005279463629553184, 0.005279463629553184]	Loss = 0.77558708 (ave = 0.79760619)

2023-07-05 21:29:18,446 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20340	Time 12.386s / 10iters, (1.239)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.355s / 10iters, (0.835)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007439)
Learning rate = [0.005277048074643016, 0.005277048074643016]	Loss = 0.86187792 (ave = 0.76188765)

2023-07-05 21:29:30,818 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20350	Time 12.372s / 10iters, (1.237)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.346s / 10iters, (0.835)	Loss Time 2.833s / 10iters, (0.283)	Data load 0.082s / 10iters, (0.008186)
Learning rate = [0.005274632396869492, 0.005274632396869492]	Loss = 0.90887028 (ave = 0.84249685)

2023-07-05 21:29:43,269 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20360	Time 12.451s / 10iters, (1.245)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.423s / 10iters, (0.842)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.086s / 10iters, (0.008559)
Learning rate = [0.005272216596163835, 0.005272216596163835]	Loss = 0.74618345 (ave = 0.82006722)

2023-07-05 21:29:55,711 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20370	Time 12.442s / 10iters, (1.244)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.389s / 10iters, (0.839)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.082s / 10iters, (0.008228)
Learning rate = [0.005269800672457193, 0.005269800672457193]	Loss = 0.70231253 (ave = 0.75434656)

2023-07-05 21:30:07,953 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20380	Time 12.242s / 10iters, (1.224)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007511)
Learning rate = [0.005267384625680644, 0.005267384625680644]	Loss = 0.83582062 (ave = 0.82659330)

2023-07-05 21:30:20,306 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20390	Time 12.353s / 10iters, (1.235)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.381s / 10iters, (0.838)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.081s / 10iters, (0.008143)
Learning rate = [0.005264968455765192, 0.005264968455765192]	Loss = 0.69586134 (ave = 0.75197723)

2023-07-05 21:30:32,411 INFO    [trainer_contrastive.py, 272] Train Epoch: 54	Train Iteration: 20400	Time 12.105s / 10iters, (1.210)	Forward Time 1.078s / 10iters, (0.108)	Backward Time 8.202s / 10iters, (0.820)	Loss Time 2.752s / 10iters, (0.275)	Data load 0.073s / 10iters, (0.007283)
Learning rate = [0.005262552162641763, 0.005262552162641763]	Loss = 0.77623290 (ave = 0.83264513)

2023-07-05 21:30:47,080 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20410	Time 14.528s / 10iters, (1.453)	Forward Time 1.286s / 10iters, (0.129)	Backward Time 8.233s / 10iters, (0.823)	Loss Time 2.633s / 10iters, (0.263)	Data load 2.376s / 10iters, (0.237606)
Learning rate = [0.0052601357462412094, 0.0052601357462412094]	Loss = 0.70318645 (ave = 0.72509425)

2023-07-05 21:30:59,329 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20420	Time 12.249s / 10iters, (1.225)	Forward Time 1.179s / 10iters, (0.118)	Backward Time 8.314s / 10iters, (0.831)	Loss Time 2.655s / 10iters, (0.265)	Data load 0.101s / 10iters, (0.010096)
Learning rate = [0.005257719206494316, 0.005257719206494316]	Loss = 0.68267912 (ave = 0.81040263)

2023-07-05 21:31:11,598 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20430	Time 12.269s / 10iters, (1.227)	Forward Time 1.187s / 10iters, (0.119)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.706s / 10iters, (0.271)	Data load 0.074s / 10iters, (0.007449)
Learning rate = [0.005255302543331787, 0.005255302543331787]	Loss = 0.82109237 (ave = 0.77468173)

2023-07-05 21:31:24,151 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20440	Time 12.552s / 10iters, (1.255)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.539s / 10iters, (0.854)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007462)
Learning rate = [0.005252885756684254, 0.005252885756684254]	Loss = 0.68355834 (ave = 0.74595571)

2023-07-05 21:31:36,703 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20450	Time 12.552s / 10iters, (1.255)	Forward Time 1.145s / 10iters, (0.114)	Backward Time 8.506s / 10iters, (0.851)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.087s / 10iters, (0.008666)
Learning rate = [0.005250468846482272, 0.005250468846482272]	Loss = 0.79055417 (ave = 0.75221747)

2023-07-05 21:31:49,177 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20460	Time 12.474s / 10iters, (1.247)	Forward Time 1.147s / 10iters, (0.115)	Backward Time 8.421s / 10iters, (0.842)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007420)
Learning rate = [0.005248051812656327, 0.005248051812656327]	Loss = 0.64447778 (ave = 0.81368314)

2023-07-05 21:32:01,721 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20470	Time 12.545s / 10iters, (1.254)	Forward Time 1.136s / 10iters, (0.114)	Backward Time 8.408s / 10iters, (0.841)	Loss Time 2.912s / 10iters, (0.291)	Data load 0.089s / 10iters, (0.008885)
Learning rate = [0.005245634655136826, 0.005245634655136826]	Loss = 0.85337836 (ave = 0.77839279)

2023-07-05 21:32:14,337 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20480	Time 12.615s / 10iters, (1.262)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.517s / 10iters, (0.852)	Loss Time 2.879s / 10iters, (0.288)	Data load 0.089s / 10iters, (0.008855)
Learning rate = [0.005243217373854102, 0.005243217373854102]	Loss = 0.84159964 (ave = 0.76859619)

2023-07-05 21:32:26,777 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20490	Time 12.440s / 10iters, (1.244)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.363s / 10iters, (0.836)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.085s / 10iters, (0.008467)
Learning rate = [0.005240799968738412, 0.005240799968738412]	Loss = 0.78361654 (ave = 0.79201077)

2023-07-05 21:32:39,022 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20500	Time 12.244s / 10iters, (1.224)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.272s / 10iters, (0.827)	Loss Time 2.803s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007426)
Learning rate = [0.005238382439719942, 0.005238382439719942]	Loss = 0.72565269 (ave = 0.76019030)

2023-07-05 21:32:51,304 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20510	Time 12.283s / 10iters, (1.228)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.097s / 10iters, (0.009749)
Learning rate = [0.005235964786728798, 0.005235964786728798]	Loss = 0.66173065 (ave = 0.72396032)

2023-07-05 21:33:03,740 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20520	Time 12.435s / 10iters, (1.244)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.449s / 10iters, (0.845)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.085s / 10iters, (0.008455)
Learning rate = [0.005233547009695011, 0.005233547009695011]	Loss = 0.92394608 (ave = 0.77401569)

2023-07-05 21:33:15,990 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20530	Time 12.251s / 10iters, (1.225)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.331s / 10iters, (0.833)	Loss Time 2.734s / 10iters, (0.273)	Data load 0.084s / 10iters, (0.008445)
Learning rate = [0.005231129108548539, 0.005231129108548539]	Loss = 0.74205887 (ave = 0.76076822)

2023-07-05 21:33:28,385 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20540	Time 12.395s / 10iters, (1.239)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.415s / 10iters, (0.842)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.093s / 10iters, (0.009346)
Learning rate = [0.005228711083219266, 0.005228711083219266]	Loss = 1.31511712 (ave = 0.87264622)

2023-07-05 21:33:40,723 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20550	Time 12.338s / 10iters, (1.234)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.346s / 10iters, (0.835)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.085s / 10iters, (0.008482)
Learning rate = [0.005226292933636997, 0.005226292933636997]	Loss = 0.86607975 (ave = 0.82797968)

2023-07-05 21:33:53,091 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20560	Time 12.368s / 10iters, (1.237)	Forward Time 1.154s / 10iters, (0.115)	Backward Time 8.360s / 10iters, (0.836)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007534)
Learning rate = [0.00522387465973146, 0.00522387465973146]	Loss = 0.66786021 (ave = 0.81555178)

2023-07-05 21:34:05,478 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20570	Time 12.386s / 10iters, (1.239)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.369s / 10iters, (0.837)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007521)
Learning rate = [0.005221456261432312, 0.005221456261432312]	Loss = 0.70971441 (ave = 0.75326482)

2023-07-05 21:34:17,878 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20580	Time 12.400s / 10iters, (1.240)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.367s / 10iters, (0.837)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.082s / 10iters, (0.008165)
Learning rate = [0.005219037738669129, 0.005219037738669129]	Loss = 0.81462741 (ave = 0.77932565)

2023-07-05 21:34:30,169 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20590	Time 12.292s / 10iters, (1.229)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.270s / 10iters, (0.827)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.086s / 10iters, (0.008636)
Learning rate = [0.005216619091371415, 0.005216619091371415]	Loss = 0.65766752 (ave = 0.74325079)

2023-07-05 21:34:42,835 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20600	Time 12.665s / 10iters, (1.267)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.546s / 10iters, (0.855)	Loss Time 2.900s / 10iters, (0.290)	Data load 0.094s / 10iters, (0.009432)
Learning rate = [0.005214200319468595, 0.005214200319468595]	Loss = 0.87726772 (ave = 0.74730452)

2023-07-05 21:34:55,368 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20610	Time 12.534s / 10iters, (1.253)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.439s / 10iters, (0.844)	Loss Time 2.912s / 10iters, (0.291)	Data load 0.079s / 10iters, (0.007929)
Learning rate = [0.0052117814228900185, 0.0052117814228900185]	Loss = 0.71465319 (ave = 0.73931417)

2023-07-05 21:35:07,819 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20620	Time 12.450s / 10iters, (1.245)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.376s / 10iters, (0.838)	Loss Time 2.877s / 10iters, (0.288)	Data load 0.091s / 10iters, (0.009080)
Learning rate = [0.005209362401564958, 0.005209362401564958]	Loss = 0.74456745 (ave = 0.75996578)

2023-07-05 21:35:20,242 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20630	Time 12.424s / 10iters, (1.242)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.378s / 10iters, (0.838)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.090s / 10iters, (0.009041)
Learning rate = [0.0052069432554226105, 0.0052069432554226105]	Loss = 0.84100717 (ave = 0.83002419)

2023-07-05 21:35:32,917 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20640	Time 12.675s / 10iters, (1.267)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.549s / 10iters, (0.855)	Loss Time 2.927s / 10iters, (0.293)	Data load 0.075s / 10iters, (0.007499)
Learning rate = [0.005204523984392096, 0.005204523984392096]	Loss = 0.75663757 (ave = 0.81897643)

2023-07-05 21:35:45,499 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20650	Time 12.582s / 10iters, (1.258)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.498s / 10iters, (0.850)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.085s / 10iters, (0.008460)
Learning rate = [0.005202104588402454, 0.005202104588402454]	Loss = 0.76853955 (ave = 0.79291182)

2023-07-05 21:35:58,053 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20660	Time 12.554s / 10iters, (1.255)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.414s / 10iters, (0.841)	Loss Time 2.934s / 10iters, (0.293)	Data load 0.091s / 10iters, (0.009075)
Learning rate = [0.005199685067382655, 0.005199685067382655]	Loss = 0.70592123 (ave = 0.71239938)

2023-07-05 21:36:10,588 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20670	Time 12.534s / 10iters, (1.253)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.453s / 10iters, (0.845)	Loss Time 2.877s / 10iters, (0.288)	Data load 0.095s / 10iters, (0.009463)
Learning rate = [0.005197265421261583, 0.005197265421261583]	Loss = 0.81774193 (ave = 0.76543042)

2023-07-05 21:36:23,036 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20680	Time 12.448s / 10iters, (1.245)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.401s / 10iters, (0.840)	Loss Time 2.865s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007427)
Learning rate = [0.005194845649968053, 0.005194845649968053]	Loss = 0.60947925 (ave = 0.77496094)

2023-07-05 21:36:35,485 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20690	Time 12.450s / 10iters, (1.245)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.373s / 10iters, (0.837)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.095s / 10iters, (0.009465)
Learning rate = [0.005192425753430795, 0.005192425753430795]	Loss = 0.89914542 (ave = 0.76705317)

2023-07-05 21:36:48,058 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20700	Time 12.572s / 10iters, (1.257)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.539s / 10iters, (0.854)	Loss Time 2.857s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007455)
Learning rate = [0.005190005731578469, 0.005190005731578469]	Loss = 0.75241446 (ave = 0.80684226)

2023-07-05 21:37:00,326 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20710	Time 12.269s / 10iters, (1.227)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.100s / 10iters, (0.010011)
Learning rate = [0.005187585584339651, 0.005187585584339651]	Loss = 0.88519144 (ave = 0.83925079)

2023-07-05 21:37:12,692 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20720	Time 12.366s / 10iters, (1.237)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.364s / 10iters, (0.836)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.085s / 10iters, (0.008487)
Learning rate = [0.0051851653116428455, 0.0051851653116428455]	Loss = 0.71713877 (ave = 0.78959052)

2023-07-05 21:37:25,050 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20730	Time 12.357s / 10iters, (1.236)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.385s / 10iters, (0.839)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.078s / 10iters, (0.007807)
Learning rate = [0.0051827449134164705, 0.0051827449134164705]	Loss = 0.70877951 (ave = 0.82224236)

2023-07-05 21:37:37,421 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20740	Time 12.371s / 10iters, (1.237)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.406s / 10iters, (0.841)	Loss Time 2.763s / 10iters, (0.276)	Data load 0.091s / 10iters, (0.009122)
Learning rate = [0.005180324389588875, 0.005180324389588875]	Loss = 0.70152938 (ave = 0.77061208)

2023-07-05 21:37:49,700 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20750	Time 12.279s / 10iters, (1.228)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.747s / 10iters, (0.275)	Data load 0.092s / 10iters, (0.009230)
Learning rate = [0.005177903740088327, 0.005177903740088327]	Loss = 0.91498226 (ave = 0.79279240)

2023-07-05 21:38:02,055 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20760	Time 12.355s / 10iters, (1.236)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.380s / 10iters, (0.838)	Loss Time 2.777s / 10iters, (0.278)	Data load 0.077s / 10iters, (0.007726)
Learning rate = [0.005175482964843011, 0.005175482964843011]	Loss = 0.78064036 (ave = 0.77381040)

2023-07-05 21:38:14,097 INFO    [trainer_contrastive.py, 272] Train Epoch: 55	Train Iteration: 20770	Time 12.042s / 10iters, (1.204)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.156s / 10iters, (0.816)	Loss Time 2.725s / 10iters, (0.273)	Data load 0.073s / 10iters, (0.007334)
Learning rate = [0.005173062063781039, 0.005173062063781039]	Loss = 0.82302535 (ave = 0.76474216)

2023-07-05 21:38:29,049 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20780	Time 14.750s / 10iters, (1.475)	Forward Time 1.250s / 10iters, (0.125)	Backward Time 8.215s / 10iters, (0.822)	Loss Time 2.675s / 10iters, (0.267)	Data load 2.610s / 10iters, (0.261004)
Learning rate = [0.005170641036830444, 0.005170641036830444]	Loss = 0.71498531 (ave = 0.77432013)

2023-07-05 21:38:41,511 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20790	Time 12.462s / 10iters, (1.246)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.362s / 10iters, (0.836)	Loss Time 2.914s / 10iters, (0.291)	Data load 0.085s / 10iters, (0.008540)
Learning rate = [0.00516821988391918, 0.00516821988391918]	Loss = 0.75087982 (ave = 0.73800673)

2023-07-05 21:38:53,884 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20800	Time 12.373s / 10iters, (1.237)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.093s / 10iters, (0.009291)
Learning rate = [0.00516579860497512, 0.00516579860497512]	Loss = 0.70828760 (ave = 0.71355549)

2023-07-05 21:39:06,364 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20810	Time 12.480s / 10iters, (1.248)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.409s / 10iters, (0.841)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.079s / 10iters, (0.007894)
Learning rate = [0.005163377199926057, 0.005163377199926057]	Loss = 0.81688458 (ave = 0.75967560)

2023-07-05 21:39:18,707 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20820	Time 12.343s / 10iters, (1.234)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.287s / 10iters, (0.829)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.077s / 10iters, (0.007654)
Learning rate = [0.005160955668699713, 0.005160955668699713]	Loss = 0.75638610 (ave = 0.80618273)

2023-07-05 21:39:30,938 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20830	Time 12.230s / 10iters, (1.223)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.272s / 10iters, (0.827)	Loss Time 2.769s / 10iters, (0.277)	Data load 0.093s / 10iters, (0.009285)
Learning rate = [0.005158534011223721, 0.005158534011223721]	Loss = 0.83489037 (ave = 0.81219085)

2023-07-05 21:39:43,206 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20840	Time 12.268s / 10iters, (1.227)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.093s / 10iters, (0.009301)
Learning rate = [0.005156112227425643, 0.005156112227425643]	Loss = 0.81020617 (ave = 0.77260356)

2023-07-05 21:39:55,498 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20850	Time 12.292s / 10iters, (1.229)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.309s / 10iters, (0.831)	Loss Time 2.803s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007461)
Learning rate = [0.005153690317232953, 0.005153690317232953]	Loss = 0.78584450 (ave = 0.74464269)

2023-07-05 21:40:07,728 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20860	Time 12.231s / 10iters, (1.223)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.786s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007448)
Learning rate = [0.005151268280573054, 0.005151268280573054]	Loss = 0.76832652 (ave = 0.78109816)

2023-07-05 21:40:19,919 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20870	Time 12.190s / 10iters, (1.219)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.760s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007409)
Learning rate = [0.005148846117373265, 0.005148846117373265]	Loss = 0.84784269 (ave = 0.80330338)

2023-07-05 21:40:32,186 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20880	Time 12.268s / 10iters, (1.227)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.076s / 10iters, (0.007584)
Learning rate = [0.005146423827560825, 0.005146423827560825]	Loss = 0.69301105 (ave = 0.78352383)

2023-07-05 21:40:44,517 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20890	Time 12.330s / 10iters, (1.233)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.903s / 10iters, (0.290)	Data load 0.084s / 10iters, (0.008398)
Learning rate = [0.005144001411062893, 0.005144001411062893]	Loss = 0.89269859 (ave = 0.87598881)

2023-07-05 21:40:56,810 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20900	Time 12.294s / 10iters, (1.229)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.908s / 10iters, (0.291)	Data load 0.075s / 10iters, (0.007458)
Learning rate = [0.005141578867806551, 0.005141578867806551]	Loss = 0.85379952 (ave = 0.78383353)

2023-07-05 21:41:09,244 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20910	Time 12.433s / 10iters, (1.243)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.320s / 10iters, (0.832)	Loss Time 2.937s / 10iters, (0.294)	Data load 0.079s / 10iters, (0.007858)
Learning rate = [0.0051391561977187986, 0.0051391561977187986]	Loss = 0.79539710 (ave = 0.81880098)

2023-07-05 21:41:21,544 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20920	Time 12.301s / 10iters, (1.230)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.838s / 10iters, (0.284)	Data load 0.077s / 10iters, (0.007697)
Learning rate = [0.005136733400726553, 0.005136733400726553]	Loss = 0.78272772 (ave = 0.77804095)

2023-07-05 21:41:33,812 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20930	Time 12.267s / 10iters, (1.227)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.228s / 10iters, (0.823)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.083s / 10iters, (0.008321)
Learning rate = [0.005134310476756654, 0.005134310476756654]	Loss = 0.73584235 (ave = 0.72822723)

2023-07-05 21:41:46,177 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20940	Time 12.365s / 10iters, (1.237)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.298s / 10iters, (0.830)	Loss Time 2.885s / 10iters, (0.288)	Data load 0.083s / 10iters, (0.008251)
Learning rate = [0.005131887425735861, 0.005131887425735861]	Loss = 0.79454583 (ave = 0.77797247)

2023-07-05 21:41:58,522 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20950	Time 12.345s / 10iters, (1.234)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.107s / 10iters, (0.010695)
Learning rate = [0.005129464247590852, 0.005129464247590852]	Loss = 0.71288013 (ave = 0.75419900)

2023-07-05 21:42:10,889 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20960	Time 12.367s / 10iters, (1.237)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.335s / 10iters, (0.834)	Loss Time 2.850s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007453)
Learning rate = [0.005127040942248222, 0.005127040942248222]	Loss = 0.89629805 (ave = 0.86592621)

2023-07-05 21:42:23,338 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20970	Time 12.449s / 10iters, (1.245)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.371s / 10iters, (0.837)	Loss Time 2.907s / 10iters, (0.291)	Data load 0.074s / 10iters, (0.007422)
Learning rate = [0.005124617509634487, 0.005124617509634487]	Loss = 0.82592064 (ave = 0.78213115)

2023-07-05 21:42:35,666 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20980	Time 12.327s / 10iters, (1.233)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.285s / 10iters, (0.829)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.083s / 10iters, (0.008335)
Learning rate = [0.005122193949676084, 0.005122193949676084]	Loss = 0.76901811 (ave = 0.77834226)

2023-07-05 21:42:48,056 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 20990	Time 12.390s / 10iters, (1.239)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.322s / 10iters, (0.832)	Loss Time 2.892s / 10iters, (0.289)	Data load 0.077s / 10iters, (0.007654)
Learning rate = [0.005119770262299365, 0.005119770262299365]	Loss = 0.75410140 (ave = 0.74962569)

2023-07-05 21:43:00,414 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 21000	Time 12.358s / 10iters, (1.236)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.889s / 10iters, (0.289)	Data load 0.074s / 10iters, (0.007410)
Learning rate = [0.005117346447430603, 0.005117346447430603]	Loss = 0.86295038 (ave = 0.80120129)

2023-07-05 21:43:05,536 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 21:43:29,282 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 21:43:52,797 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 21:44:16,059 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 21:44:39,459 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 21:45:02,461 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 21:45:24,947 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 21:45:30,709 INFO    [base.py, 84] Performance 0.7294571801110419 -> 0.7337941978231273
2023-07-05 21:45:35,027 INFO    [trainer_contrastive.py, 391] Test Time 150.114s, (2.383)	Loss 0.14384972

2023-07-05 21:45:35,028 INFO    [base.py, 33] Result for seg
2023-07-05 21:45:35,029 INFO    [base.py, 49] Mean IOU: 0.7337941978231273

2023-07-05 21:45:35,029 INFO    [base.py, 50] Pixel ACC: 0.953319262900925

2023-07-05 21:45:47,120 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 21010	Time 166.705s / 10iters, (16.671)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.175s / 10iters, (0.818)	Loss Time 2.706s / 10iters, (0.271)	Data load 154.703s / 10iters, (15.470255)
Learning rate = [0.005114922504995986, 0.005114922504995986]	Loss = 0.72123271 (ave = 0.76724944)

2023-07-05 21:45:59,134 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 21020	Time 12.015s / 10iters, (1.201)	Forward Time 1.077s / 10iters, (0.108)	Backward Time 8.195s / 10iters, (0.819)	Loss Time 2.668s / 10iters, (0.267)	Data load 0.074s / 10iters, (0.007438)
Learning rate = [0.005112498434921627, 0.005112498434921627]	Loss = 0.74968791 (ave = 0.77669597)

2023-07-05 21:46:11,108 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 21030	Time 11.973s / 10iters, (1.197)	Forward Time 1.077s / 10iters, (0.108)	Backward Time 8.151s / 10iters, (0.815)	Loss Time 2.670s / 10iters, (0.267)	Data load 0.075s / 10iters, (0.007476)
Learning rate = [0.0051100742371335516, 0.0051100742371335516]	Loss = 0.70442176 (ave = 0.77759607)

2023-07-05 21:46:23,087 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 21040	Time 11.979s / 10iters, (1.198)	Forward Time 1.083s / 10iters, (0.108)	Backward Time 8.160s / 10iters, (0.816)	Loss Time 2.660s / 10iters, (0.266)	Data load 0.076s / 10iters, (0.007565)
Learning rate = [0.005107649911557706, 0.005107649911557706]	Loss = 0.84607345 (ave = 0.75752670)

2023-07-05 21:46:35,155 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 21050	Time 12.068s / 10iters, (1.207)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.686s / 10iters, (0.269)	Data load 0.074s / 10iters, (0.007420)
Learning rate = [0.005105225458119952, 0.005105225458119952]	Loss = 0.70353055 (ave = 0.75463049)

2023-07-05 21:46:47,166 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 21060	Time 12.011s / 10iters, (1.201)	Forward Time 1.082s / 10iters, (0.108)	Backward Time 8.170s / 10iters, (0.817)	Loss Time 2.671s / 10iters, (0.267)	Data load 0.089s / 10iters, (0.008864)
Learning rate = [0.005102800876746072, 0.005102800876746072]	Loss = 0.76707453 (ave = 0.76320442)

2023-07-05 21:46:59,101 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 21070	Time 11.935s / 10iters, (1.193)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.142s / 10iters, (0.814)	Loss Time 2.626s / 10iters, (0.263)	Data load 0.074s / 10iters, (0.007413)
Learning rate = [0.005100376167361766, 0.005100376167361766]	Loss = 0.73504096 (ave = 0.75807542)

2023-07-05 21:47:11,105 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 21080	Time 12.004s / 10iters, (1.200)	Forward Time 1.083s / 10iters, (0.108)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.652s / 10iters, (0.265)	Data load 0.076s / 10iters, (0.007554)
Learning rate = [0.0050979513298926495, 0.0050979513298926495]	Loss = 0.73984760 (ave = 0.77282754)

2023-07-05 21:47:23,260 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 21090	Time 12.155s / 10iters, (1.215)	Forward Time 1.084s / 10iters, (0.108)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.742s / 10iters, (0.274)	Data load 0.077s / 10iters, (0.007730)
Learning rate = [0.0050955263642642554, 0.0050955263642642554]	Loss = 0.88744354 (ave = 0.80436594)

2023-07-05 21:47:35,392 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 21100	Time 12.133s / 10iters, (1.213)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.209s / 10iters, (0.821)	Loss Time 2.751s / 10iters, (0.275)	Data load 0.079s / 10iters, (0.007947)
Learning rate = [0.0050931012704020385, 0.0050931012704020385]	Loss = 0.84872824 (ave = 0.81599721)

2023-07-05 21:47:47,429 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 21110	Time 12.037s / 10iters, (1.204)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.164s / 10iters, (0.816)	Loss Time 2.700s / 10iters, (0.270)	Data load 0.074s / 10iters, (0.007414)
Learning rate = [0.005090676048231364, 0.005090676048231364]	Loss = 0.81497568 (ave = 0.79139837)

2023-07-05 21:47:59,618 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 21120	Time 12.189s / 10iters, (1.219)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.079s / 10iters, (0.007906)
Learning rate = [0.005088250697677519, 0.005088250697677519]	Loss = 0.82456845 (ave = 0.82328799)

2023-07-05 21:48:11,734 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 21130	Time 12.116s / 10iters, (1.212)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.225s / 10iters, (0.822)	Loss Time 2.726s / 10iters, (0.273)	Data load 0.074s / 10iters, (0.007446)
Learning rate = [0.005085825218665705, 0.005085825218665705]	Loss = 0.79936135 (ave = 0.86161584)

2023-07-05 21:48:23,667 INFO    [trainer_contrastive.py, 272] Train Epoch: 56	Train Iteration: 21140	Time 11.933s / 10iters, (1.193)	Forward Time 1.077s / 10iters, (0.108)	Backward Time 8.105s / 10iters, (0.811)	Loss Time 2.674s / 10iters, (0.267)	Data load 0.077s / 10iters, (0.007679)
Learning rate = [0.0050833996111210415, 0.0050833996111210415]	Loss = 0.98722184 (ave = 0.77842864)

2023-07-05 21:48:38,509 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21150	Time 14.678s / 10iters, (1.468)	Forward Time 1.288s / 10iters, (0.129)	Backward Time 8.228s / 10iters, (0.823)	Loss Time 2.615s / 10iters, (0.261)	Data load 2.547s / 10iters, (0.254689)
Learning rate = [0.005080973874968565, 0.005080973874968565]	Loss = 0.76701510 (ave = 0.79766407)

2023-07-05 21:48:50,834 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21160	Time 12.324s / 10iters, (1.232)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.359s / 10iters, (0.836)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.082s / 10iters, (0.008249)
Learning rate = [0.005078548010133228, 0.005078548010133228]	Loss = 0.73612797 (ave = 0.70681320)

2023-07-05 21:49:02,911 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21170	Time 12.077s / 10iters, (1.208)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.177s / 10iters, (0.818)	Loss Time 2.721s / 10iters, (0.272)	Data load 0.075s / 10iters, (0.007491)
Learning rate = [0.005076122016539899, 0.005076122016539899]	Loss = 0.84057617 (ave = 0.78308972)

2023-07-05 21:49:15,032 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21180	Time 12.121s / 10iters, (1.212)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.710s / 10iters, (0.271)	Data load 0.075s / 10iters, (0.007519)
Learning rate = [0.005073695894113362, 0.005073695894113362]	Loss = 0.74338549 (ave = 0.75380504)

2023-07-05 21:49:27,124 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21190	Time 12.092s / 10iters, (1.209)	Forward Time 1.084s / 10iters, (0.108)	Backward Time 8.191s / 10iters, (0.819)	Loss Time 2.743s / 10iters, (0.274)	Data load 0.074s / 10iters, (0.007404)
Learning rate = [0.005071269642778319, 0.005071269642778319]	Loss = 0.78595245 (ave = 0.75693357)

2023-07-05 21:49:39,323 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21200	Time 12.199s / 10iters, (1.220)	Forward Time 1.083s / 10iters, (0.108)	Backward Time 8.245s / 10iters, (0.824)	Loss Time 2.797s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007400)
Learning rate = [0.005068843262459386, 0.005068843262459386]	Loss = 0.71827835 (ave = 0.76046999)

2023-07-05 21:49:51,534 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21210	Time 12.211s / 10iters, (1.221)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.228s / 10iters, (0.823)	Loss Time 2.805s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007522)
Learning rate = [0.0050664167530810955, 0.0050664167530810955]	Loss = 0.75712788 (ave = 0.77245193)

2023-07-05 21:50:03,926 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21220	Time 12.392s / 10iters, (1.239)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.373s / 10iters, (0.837)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.083s / 10iters, (0.008266)
Learning rate = [0.005063990114567897, 0.005063990114567897]	Loss = 0.88038063 (ave = 0.76999619)

2023-07-05 21:50:16,227 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21230	Time 12.301s / 10iters, (1.230)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.317s / 10iters, (0.832)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.080s / 10iters, (0.008040)
Learning rate = [0.005061563346844155, 0.005061563346844155]	Loss = 0.84592509 (ave = 0.79324809)

2023-07-05 21:50:28,441 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21240	Time 12.215s / 10iters, (1.221)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007603)
Learning rate = [0.005059136449834146, 0.005059136449834146]	Loss = 0.72141337 (ave = 0.75724514)

2023-07-05 21:50:40,706 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21250	Time 12.265s / 10iters, (1.226)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.080s / 10iters, (0.008038)
Learning rate = [0.005056709423462067, 0.005056709423462067]	Loss = 0.83231568 (ave = 0.83652651)

2023-07-05 21:50:53,036 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21260	Time 12.329s / 10iters, (1.233)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.079s / 10iters, (0.007937)
Learning rate = [0.005054282267652026, 0.005054282267652026]	Loss = 0.75713676 (ave = 0.77826138)

2023-07-05 21:51:05,364 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21270	Time 12.328s / 10iters, (1.233)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.275s / 10iters, (0.828)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.085s / 10iters, (0.008524)
Learning rate = [0.005051854982328049, 0.005051854982328049]	Loss = 0.73057199 (ave = 0.76257315)

2023-07-05 21:51:17,751 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21280	Time 12.387s / 10iters, (1.239)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.331s / 10iters, (0.833)	Loss Time 2.864s / 10iters, (0.286)	Data load 0.084s / 10iters, (0.008431)
Learning rate = [0.005049427567414075, 0.005049427567414075]	Loss = 0.71235442 (ave = 0.75460883)

2023-07-05 21:51:30,066 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21290	Time 12.315s / 10iters, (1.231)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.255s / 10iters, (0.826)	Loss Time 2.877s / 10iters, (0.288)	Data load 0.082s / 10iters, (0.008171)
Learning rate = [0.005047000022833959, 0.005047000022833959]	Loss = 0.66176939 (ave = 0.73830895)

2023-07-05 21:51:42,350 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21300	Time 12.284s / 10iters, (1.228)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.245s / 10iters, (0.825)	Loss Time 2.845s / 10iters, (0.284)	Data load 0.078s / 10iters, (0.007835)
Learning rate = [0.005044572348511465, 0.005044572348511465]	Loss = 0.77617449 (ave = 0.89216861)

2023-07-05 21:51:54,570 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21310	Time 12.220s / 10iters, (1.222)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007506)
Learning rate = [0.005042144544370282, 0.005042144544370282]	Loss = 0.82594973 (ave = 0.79464863)

2023-07-05 21:52:06,999 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21320	Time 12.428s / 10iters, (1.243)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.374s / 10iters, (0.837)	Loss Time 2.869s / 10iters, (0.287)	Data load 0.085s / 10iters, (0.008451)
Learning rate = [0.0050397166103340035, 0.0050397166103340035]	Loss = 0.70552349 (ave = 0.83469229)

2023-07-05 21:52:19,442 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21330	Time 12.443s / 10iters, (1.244)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.417s / 10iters, (0.842)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007442)
Learning rate = [0.005037288546326142, 0.005037288546326142]	Loss = 0.70944649 (ave = 0.81454624)

2023-07-05 21:52:31,742 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21340	Time 12.300s / 10iters, (1.230)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.345s / 10iters, (0.834)	Loss Time 2.766s / 10iters, (0.277)	Data load 0.092s / 10iters, (0.009206)
Learning rate = [0.005034860352270122, 0.005034860352270122]	Loss = 0.74080604 (ave = 0.74965635)

2023-07-05 21:52:43,911 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21350	Time 12.169s / 10iters, (1.217)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.743s / 10iters, (0.274)	Data load 0.078s / 10iters, (0.007753)
Learning rate = [0.005032432028089284, 0.005032432028089284]	Loss = 0.67699784 (ave = 0.78498912)

2023-07-05 21:52:56,237 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21360	Time 12.326s / 10iters, (1.233)	Forward Time 1.138s / 10iters, (0.114)	Backward Time 8.295s / 10iters, (0.830)	Loss Time 2.815s / 10iters, (0.282)	Data load 0.077s / 10iters, (0.007691)
Learning rate = [0.005030003573706881, 0.005030003573706881]	Loss = 0.89179468 (ave = 0.78980331)

2023-07-05 21:53:08,546 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21370	Time 12.310s / 10iters, (1.231)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.331s / 10iters, (0.833)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007490)
Learning rate = [0.0050275749890460785, 0.0050275749890460785]	Loss = 0.77111870 (ave = 0.76119534)

2023-07-05 21:53:20,875 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21380	Time 12.329s / 10iters, (1.233)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.306s / 10iters, (0.831)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007396)
Learning rate = [0.005025146274029956, 0.005025146274029956]	Loss = 0.71406567 (ave = 0.79937682)

2023-07-05 21:53:33,151 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21390	Time 12.276s / 10iters, (1.228)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.084s / 10iters, (0.008392)
Learning rate = [0.0050227174285815065, 0.0050227174285815065]	Loss = 0.80650544 (ave = 0.77084013)

2023-07-05 21:53:45,489 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21400	Time 12.338s / 10iters, (1.234)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.345s / 10iters, (0.834)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007442)
Learning rate = [0.005020288452623637, 0.005020288452623637]	Loss = 0.97442299 (ave = 0.74284819)

2023-07-05 21:53:57,834 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21410	Time 12.345s / 10iters, (1.234)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.334s / 10iters, (0.833)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007378)
Learning rate = [0.005017859346079166, 0.005017859346079166]	Loss = 0.83860373 (ave = 0.75675778)

2023-07-05 21:54:10,167 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21420	Time 12.333s / 10iters, (1.233)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.082s / 10iters, (0.008235)
Learning rate = [0.005015430108870824, 0.005015430108870824]	Loss = 0.71114254 (ave = 0.74270466)

2023-07-05 21:54:22,552 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21430	Time 12.385s / 10iters, (1.239)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.344s / 10iters, (0.834)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.078s / 10iters, (0.007761)
Learning rate = [0.0050130007409212585, 0.0050130007409212585]	Loss = 0.90678978 (ave = 0.76013626)

2023-07-05 21:54:34,865 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21440	Time 12.313s / 10iters, (1.231)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.084s / 10iters, (0.008394)
Learning rate = [0.005010571242153026, 0.005010571242153026]	Loss = 0.78799498 (ave = 0.74313236)

2023-07-05 21:54:47,168 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21450	Time 12.303s / 10iters, (1.230)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.856s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007398)
Learning rate = [0.0050081416124885935, 0.0050081416124885935]	Loss = 0.83408511 (ave = 0.77328420)

2023-07-05 21:54:59,597 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21460	Time 12.428s / 10iters, (1.243)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.362s / 10iters, (0.836)	Loss Time 2.879s / 10iters, (0.288)	Data load 0.079s / 10iters, (0.007896)
Learning rate = [0.005005711851850344, 0.005005711851850344]	Loss = 0.67606241 (ave = 0.76445778)

2023-07-05 21:55:11,883 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21470	Time 12.286s / 10iters, (1.229)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.082s / 10iters, (0.008200)
Learning rate = [0.005003281960160573, 0.005003281960160573]	Loss = 0.78341341 (ave = 0.72737865)

2023-07-05 21:55:24,206 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21480	Time 12.323s / 10iters, (1.232)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.297s / 10iters, (0.830)	Loss Time 2.825s / 10iters, (0.283)	Data load 0.104s / 10iters, (0.010433)
Learning rate = [0.005000851937341484, 0.005000851937341484]	Loss = 0.71495241 (ave = 0.79143347)

2023-07-05 21:55:36,505 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21490	Time 12.298s / 10iters, (1.230)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.272s / 10iters, (0.827)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007627)
Learning rate = [0.004998421783315196, 0.004998421783315196]	Loss = 0.87365395 (ave = 0.83680465)

2023-07-05 21:55:48,830 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21500	Time 12.326s / 10iters, (1.233)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.305s / 10iters, (0.831)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007357)
Learning rate = [0.0049959914980037354, 0.0049959914980037354]	Loss = 0.81171107 (ave = 0.83852194)

2023-07-05 21:56:00,927 INFO    [trainer_contrastive.py, 272] Train Epoch: 57	Train Iteration: 21510	Time 12.097s / 10iters, (1.210)	Forward Time 1.084s / 10iters, (0.108)	Backward Time 8.230s / 10iters, (0.823)	Loss Time 2.706s / 10iters, (0.271)	Data load 0.076s / 10iters, (0.007625)
Learning rate = [0.0049935610813290465, 0.0049935610813290465]	Loss = 0.70401305 (ave = 0.77263404)

2023-07-05 21:56:15,977 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21520	Time 14.921s / 10iters, (1.492)	Forward Time 1.208s / 10iters, (0.121)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.667s / 10iters, (0.267)	Data load 2.737s / 10iters, (0.273739)
Learning rate = [0.00499113053321298, 0.00499113053321298]	Loss = 0.69497019 (ave = 0.79457939)

2023-07-05 21:56:28,216 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21530	Time 12.240s / 10iters, (1.224)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.306s / 10iters, (0.831)	Loss Time 2.732s / 10iters, (0.273)	Data load 0.087s / 10iters, (0.008700)
Learning rate = [0.004988699853577298, 0.004988699853577298]	Loss = 0.76410478 (ave = 0.77093415)

2023-07-05 21:56:40,419 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21540	Time 12.203s / 10iters, (1.220)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.711s / 10iters, (0.271)	Data load 0.075s / 10iters, (0.007474)
Learning rate = [0.004986269042343675, 0.004986269042343675]	Loss = 0.74963921 (ave = 0.81188866)

2023-07-05 21:56:52,684 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21550	Time 12.265s / 10iters, (1.226)	Forward Time 1.136s / 10iters, (0.114)	Backward Time 8.323s / 10iters, (0.832)	Loss Time 2.710s / 10iters, (0.271)	Data load 0.095s / 10iters, (0.009543)
Learning rate = [0.004983838099433698, 0.004983838099433698]	Loss = 0.95110178 (ave = 0.78356695)

2023-07-05 21:57:04,908 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21560	Time 12.224s / 10iters, (1.222)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.320s / 10iters, (0.832)	Loss Time 2.708s / 10iters, (0.271)	Data load 0.087s / 10iters, (0.008726)
Learning rate = [0.004981407024768861, 0.004981407024768861]	Loss = 0.79071522 (ave = 0.76548735)

2023-07-05 21:57:17,270 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21570	Time 12.362s / 10iters, (1.236)	Forward Time 1.138s / 10iters, (0.114)	Backward Time 8.411s / 10iters, (0.841)	Loss Time 2.715s / 10iters, (0.272)	Data load 0.098s / 10iters, (0.009757)
Learning rate = [0.004978975818270571, 0.004978975818270571]	Loss = 0.64627355 (ave = 0.73662533)

2023-07-05 21:57:29,544 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21580	Time 12.274s / 10iters, (1.227)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.339s / 10iters, (0.834)	Loss Time 2.715s / 10iters, (0.272)	Data load 0.098s / 10iters, (0.009795)
Learning rate = [0.004976544479860144, 0.004976544479860144]	Loss = 0.70783389 (ave = 0.79944795)

2023-07-05 21:57:41,853 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21590	Time 12.309s / 10iters, (1.231)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.089s / 10iters, (0.008881)
Learning rate = [0.004974113009458809, 0.004974113009458809]	Loss = 0.93189788 (ave = 0.76341472)

2023-07-05 21:57:54,294 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21600	Time 12.441s / 10iters, (1.244)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.423s / 10iters, (0.842)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.086s / 10iters, (0.008555)
Learning rate = [0.0049716814069877035, 0.0049716814069877035]	Loss = 0.71873593 (ave = 0.80034658)

2023-07-05 21:58:06,558 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21610	Time 12.264s / 10iters, (1.226)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.202s / 10iters, (0.820)	Loss Time 2.845s / 10iters, (0.284)	Data load 0.103s / 10iters, (0.010321)
Learning rate = [0.004969249672367873, 0.004969249672367873]	Loss = 0.77061856 (ave = 0.77532492)

2023-07-05 21:58:18,953 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21620	Time 12.394s / 10iters, (1.239)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.856s / 10iters, (0.286)	Data load 0.083s / 10iters, (0.008308)
Learning rate = [0.004966817805520276, 0.004966817805520276]	Loss = 0.75062662 (ave = 0.71800584)

2023-07-05 21:58:31,269 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21630	Time 12.317s / 10iters, (1.232)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.288s / 10iters, (0.829)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.092s / 10iters, (0.009201)
Learning rate = [0.004964385806365779, 0.004964385806365779]	Loss = 0.70255041 (ave = 0.81238779)

2023-07-05 21:58:43,652 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21640	Time 12.382s / 10iters, (1.238)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.341s / 10iters, (0.834)	Loss Time 2.852s / 10iters, (0.285)	Data load 0.082s / 10iters, (0.008156)
Learning rate = [0.004961953674825158, 0.004961953674825158]	Loss = 0.84908855 (ave = 0.78577217)

2023-07-05 21:58:56,062 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21650	Time 12.410s / 10iters, (1.241)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.394s / 10iters, (0.839)	Loss Time 2.809s / 10iters, (0.281)	Data load 0.089s / 10iters, (0.008935)
Learning rate = [0.0049595214108191015, 0.0049595214108191015]	Loss = 0.88446838 (ave = 0.76307933)

2023-07-05 21:59:08,434 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21660	Time 12.372s / 10iters, (1.237)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.367s / 10iters, (0.837)	Loss Time 2.797s / 10iters, (0.280)	Data load 0.107s / 10iters, (0.010673)
Learning rate = [0.0049570890142682, 0.0049570890142682]	Loss = 0.67264426 (ave = 0.79743415)

2023-07-05 21:59:20,863 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21670	Time 12.429s / 10iters, (1.243)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.381s / 10iters, (0.838)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.078s / 10iters, (0.007843)
Learning rate = [0.0049546564850929615, 0.0049546564850929615]	Loss = 0.78968799 (ave = 0.77881001)

2023-07-05 21:59:33,183 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21680	Time 12.320s / 10iters, (1.232)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.351s / 10iters, (0.835)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.097s / 10iters, (0.009686)
Learning rate = [0.004952223823213798, 0.004952223823213798]	Loss = 0.78172767 (ave = 0.75090759)

2023-07-05 21:59:45,418 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21690	Time 12.234s / 10iters, (1.223)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.286s / 10iters, (0.829)	Loss Time 2.709s / 10iters, (0.271)	Data load 0.106s / 10iters, (0.010642)
Learning rate = [0.004949791028551031, 0.004949791028551031]	Loss = 0.65201235 (ave = 0.73568224)

2023-07-05 21:59:57,635 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21700	Time 12.217s / 10iters, (1.222)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.764s / 10iters, (0.276)	Data load 0.076s / 10iters, (0.007552)
Learning rate = [0.0049473581010248905, 0.0049473581010248905]	Loss = 0.78647971 (ave = 0.77714384)

2023-07-05 22:00:09,974 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21710	Time 12.339s / 10iters, (1.234)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.366s / 10iters, (0.837)	Loss Time 2.790s / 10iters, (0.279)	Data load 0.078s / 10iters, (0.007836)
Learning rate = [0.004944925040555517, 0.004944925040555517]	Loss = 0.77670085 (ave = 0.74610978)

2023-07-05 22:00:22,289 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21720	Time 12.315s / 10iters, (1.232)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.375s / 10iters, (0.837)	Loss Time 2.759s / 10iters, (0.276)	Data load 0.077s / 10iters, (0.007669)
Learning rate = [0.004942491847062956, 0.004942491847062956]	Loss = 0.88375044 (ave = 0.76366618)

2023-07-05 22:00:34,551 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21730	Time 12.262s / 10iters, (1.226)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.744s / 10iters, (0.274)	Data load 0.083s / 10iters, (0.008342)
Learning rate = [0.004940058520467164, 0.004940058520467164]	Loss = 0.71023804 (ave = 0.76848072)

2023-07-05 22:00:46,823 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21740	Time 12.272s / 10iters, (1.227)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.313s / 10iters, (0.831)	Loss Time 2.765s / 10iters, (0.276)	Data load 0.076s / 10iters, (0.007640)
Learning rate = [0.004937625060688003, 0.004937625060688003]	Loss = 0.81632775 (ave = 0.80552494)

2023-07-05 22:00:59,192 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21750	Time 12.369s / 10iters, (1.237)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.365s / 10iters, (0.837)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.097s / 10iters, (0.009696)
Learning rate = [0.0049351914676452465, 0.0049351914676452465]	Loss = 0.68125123 (ave = 0.73531937)

2023-07-05 22:01:11,449 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21760	Time 12.257s / 10iters, (1.226)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.083s / 10iters, (0.008280)
Learning rate = [0.004932757741258573, 0.004932757741258573]	Loss = 0.77977264 (ave = 0.73892100)

2023-07-05 22:01:23,794 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21770	Time 12.345s / 10iters, (1.234)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.306s / 10iters, (0.831)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.097s / 10iters, (0.009727)
Learning rate = [0.004930323881447567, 0.004930323881447567]	Loss = 0.76022732 (ave = 0.74657357)

2023-07-05 22:01:36,127 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21780	Time 12.333s / 10iters, (1.233)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.309s / 10iters, (0.831)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.093s / 10iters, (0.009343)
Learning rate = [0.004927889888131724, 0.004927889888131724]	Loss = 0.76430571 (ave = 0.79941746)

2023-07-05 22:01:48,429 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21790	Time 12.302s / 10iters, (1.230)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.292s / 10iters, (0.829)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.078s / 10iters, (0.007821)
Learning rate = [0.004925455761230445, 0.004925455761230445]	Loss = 0.83601344 (ave = 0.76067443)

2023-07-05 22:02:00,862 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21800	Time 12.433s / 10iters, (1.243)	Forward Time 1.155s / 10iters, (0.115)	Backward Time 8.373s / 10iters, (0.837)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007649)
Learning rate = [0.004923021500663038, 0.004923021500663038]	Loss = 0.77658617 (ave = 0.80116061)

2023-07-05 22:02:13,298 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21810	Time 12.436s / 10iters, (1.244)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.413s / 10iters, (0.841)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.082s / 10iters, (0.008201)
Learning rate = [0.004920587106348717, 0.004920587106348717]	Loss = 0.72862780 (ave = 0.75662163)

2023-07-05 22:02:25,707 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21820	Time 12.409s / 10iters, (1.241)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.359s / 10iters, (0.836)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.093s / 10iters, (0.009262)
Learning rate = [0.0049181525782066035, 0.0049181525782066035]	Loss = 0.70754063 (ave = 0.81680639)

2023-07-05 22:02:38,091 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21830	Time 12.384s / 10iters, (1.238)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.338s / 10iters, (0.834)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.084s / 10iters, (0.008412)
Learning rate = [0.004915717916155728, 0.004915717916155728]	Loss = 0.87472296 (ave = 0.80839769)

2023-07-05 22:02:50,610 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21840	Time 12.519s / 10iters, (1.252)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.482s / 10iters, (0.848)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.091s / 10iters, (0.009079)
Learning rate = [0.004913283120115024, 0.004913283120115024]	Loss = 0.73528057 (ave = 0.75664663)

2023-07-05 22:03:02,985 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21850	Time 12.375s / 10iters, (1.237)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.339s / 10iters, (0.834)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.079s / 10iters, (0.007854)
Learning rate = [0.004910848190003332, 0.004910848190003332]	Loss = 0.70144981 (ave = 0.79207150)

2023-07-05 22:03:15,374 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21860	Time 12.389s / 10iters, (1.239)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.325s / 10iters, (0.832)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007510)
Learning rate = [0.004908413125739399, 0.004908413125739399]	Loss = 0.94194210 (ave = 0.76843629)

2023-07-05 22:03:27,772 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21870	Time 12.398s / 10iters, (1.240)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.350s / 10iters, (0.835)	Loss Time 2.879s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007443)
Learning rate = [0.00490597792724188, 0.00490597792724188]	Loss = 0.69657588 (ave = 0.79229001)

2023-07-05 22:03:39,905 INFO    [trainer_contrastive.py, 272] Train Epoch: 58	Train Iteration: 21880	Time 12.133s / 10iters, (1.213)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.201s / 10iters, (0.820)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.074s / 10iters, (0.007425)
Learning rate = [0.0049035425944293325, 0.0049035425944293325]	Loss = 0.83807784 (ave = 0.79874339)

2023-07-05 22:03:55,005 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 21890	Time 14.940s / 10iters, (1.494)	Forward Time 1.164s / 10iters, (0.116)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.745s / 10iters, (0.274)	Data load 2.814s / 10iters, (0.281392)
Learning rate = [0.0049011071272202205, 0.0049011071272202205]	Loss = 0.73257035 (ave = 0.80943937)

2023-07-05 22:04:07,284 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 21900	Time 12.279s / 10iters, (1.228)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.757s / 10iters, (0.276)	Data load 0.091s / 10iters, (0.009149)
Learning rate = [0.004898671525532913, 0.004898671525532913]	Loss = 0.68735945 (ave = 0.82751915)

2023-07-05 22:04:19,572 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 21910	Time 12.288s / 10iters, (1.229)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.365s / 10iters, (0.837)	Loss Time 2.728s / 10iters, (0.273)	Data load 0.086s / 10iters, (0.008563)
Learning rate = [0.004896235789285687, 0.004896235789285687]	Loss = 0.77314329 (ave = 0.75940528)

2023-07-05 22:04:31,802 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 21920	Time 12.230s / 10iters, (1.223)	Forward Time 1.141s / 10iters, (0.114)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.733s / 10iters, (0.273)	Data load 0.076s / 10iters, (0.007561)
Learning rate = [0.004893799918396722, 0.004893799918396722]	Loss = 0.85075009 (ave = 0.75027122)

2023-07-05 22:04:44,195 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 21930	Time 12.393s / 10iters, (1.239)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.406s / 10iters, (0.841)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.089s / 10iters, (0.008870)
Learning rate = [0.004891363912784104, 0.004891363912784104]	Loss = 0.81739271 (ave = 0.79927470)

2023-07-05 22:04:56,577 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 21940	Time 12.382s / 10iters, (1.238)	Forward Time 1.146s / 10iters, (0.115)	Backward Time 8.382s / 10iters, (0.838)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.081s / 10iters, (0.008055)
Learning rate = [0.004888927772365821, 0.004888927772365821]	Loss = 0.68886614 (ave = 0.75419675)

2023-07-05 22:05:08,992 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 21950	Time 12.415s / 10iters, (1.242)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.419s / 10iters, (0.842)	Loss Time 2.786s / 10iters, (0.279)	Data load 0.087s / 10iters, (0.008671)
Learning rate = [0.004886491497059771, 0.004886491497059771]	Loss = 0.81316066 (ave = 0.76011946)

2023-07-05 22:05:21,280 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 21960	Time 12.287s / 10iters, (1.229)	Forward Time 1.159s / 10iters, (0.116)	Backward Time 8.292s / 10iters, (0.829)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.097s / 10iters, (0.009715)
Learning rate = [0.00488405508678375, 0.00488405508678375]	Loss = 0.87330914 (ave = 0.75070991)

2023-07-05 22:05:33,663 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 21970	Time 12.384s / 10iters, (1.238)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.337s / 10iters, (0.834)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.088s / 10iters, (0.008816)
Learning rate = [0.0048816185414554646, 0.0048816185414554646]	Loss = 0.77071464 (ave = 0.74511850)

2023-07-05 22:05:45,970 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 21980	Time 12.307s / 10iters, (1.231)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.100s / 10iters, (0.009951)
Learning rate = [0.004879181860992518, 0.004879181860992518]	Loss = 0.97232527 (ave = 0.79540254)

2023-07-05 22:05:58,211 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 21990	Time 12.241s / 10iters, (1.224)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007580)
Learning rate = [0.0048767450453124275, 0.0048767450453124275]	Loss = 0.93252504 (ave = 0.77413064)

2023-07-05 22:06:10,543 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22000	Time 12.332s / 10iters, (1.233)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.327s / 10iters, (0.833)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.084s / 10iters, (0.008403)
Learning rate = [0.004874308094332604, 0.004874308094332604]	Loss = 0.71730065 (ave = 0.81979645)

2023-07-05 22:06:13,677 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 22:06:37,846 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 22:07:01,035 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 22:07:24,130 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 22:07:47,000 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 22:08:09,490 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 22:08:31,649 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 22:08:40,194 INFO    [trainer_contrastive.py, 391] Test Time 146.681s, (2.328)	Loss 0.14663334

2023-07-05 22:08:40,195 INFO    [base.py, 33] Result for seg
2023-07-05 22:08:40,195 INFO    [base.py, 49] Mean IOU: 0.7265349748956941

2023-07-05 22:08:40,196 INFO    [base.py, 50] Pixel ACC: 0.9537337812607615

2023-07-05 22:08:52,450 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22010	Time 161.907s / 10iters, (16.191)	Forward Time 1.148s / 10iters, (0.115)	Backward Time 8.304s / 10iters, (0.830)	Loss Time 2.707s / 10iters, (0.271)	Data load 149.747s / 10iters, (14.974735)
Learning rate = [0.004871871007970369, 0.004871871007970369]	Loss = 1.16354394 (ave = 0.80639568)

2023-07-05 22:09:04,448 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22020	Time 11.998s / 10iters, (1.200)	Forward Time 1.227s / 10iters, (0.123)	Backward Time 8.100s / 10iters, (0.810)	Loss Time 2.583s / 10iters, (0.258)	Data load 0.087s / 10iters, (0.008718)
Learning rate = [0.0048694337861429435, 0.0048694337861429435]	Loss = 0.76915610 (ave = 0.79774670)

2023-07-05 22:09:16,579 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22030	Time 12.131s / 10iters, (1.213)	Forward Time 1.142s / 10iters, (0.114)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.694s / 10iters, (0.269)	Data load 0.080s / 10iters, (0.007954)
Learning rate = [0.004866996428767456, 0.004866996428767456]	Loss = 0.68998182 (ave = 0.71776602)

2023-07-05 22:09:28,734 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22040	Time 12.155s / 10iters, (1.216)	Forward Time 1.136s / 10iters, (0.114)	Backward Time 8.210s / 10iters, (0.821)	Loss Time 2.733s / 10iters, (0.273)	Data load 0.077s / 10iters, (0.007681)
Learning rate = [0.004864558935760933, 0.004864558935760933]	Loss = 0.74788105 (ave = 0.74615347)

2023-07-05 22:09:40,884 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22050	Time 12.150s / 10iters, (1.215)	Forward Time 1.218s / 10iters, (0.122)	Backward Time 8.198s / 10iters, (0.820)	Loss Time 2.625s / 10iters, (0.263)	Data load 0.109s / 10iters, (0.010852)
Learning rate = [0.004862121307040308, 0.004862121307040308]	Loss = 0.68617541 (ave = 0.73314846)

2023-07-05 22:09:52,924 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22060	Time 12.040s / 10iters, (1.204)	Forward Time 1.214s / 10iters, (0.121)	Backward Time 8.112s / 10iters, (0.811)	Loss Time 2.636s / 10iters, (0.264)	Data load 0.078s / 10iters, (0.007830)
Learning rate = [0.004859683542522414, 0.004859683542522414]	Loss = 0.73514605 (ave = 0.75866458)

2023-07-05 22:10:05,048 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22070	Time 12.124s / 10iters, (1.212)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.208s / 10iters, (0.821)	Loss Time 2.695s / 10iters, (0.269)	Data load 0.089s / 10iters, (0.008870)
Learning rate = [0.004857245642123991, 0.004857245642123991]	Loss = 0.72077638 (ave = 0.74274815)

2023-07-05 22:10:17,220 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22080	Time 12.171s / 10iters, (1.217)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.078s / 10iters, (0.007844)
Learning rate = [0.004854807605761678, 0.004854807605761678]	Loss = 0.71224117 (ave = 0.74114370)

2023-07-05 22:10:29,618 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22090	Time 12.398s / 10iters, (1.240)	Forward Time 1.175s / 10iters, (0.118)	Backward Time 8.370s / 10iters, (0.837)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.077s / 10iters, (0.007741)
Learning rate = [0.004852369433352017, 0.004852369433352017]	Loss = 0.80153298 (ave = 0.77446681)

2023-07-05 22:10:41,954 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22100	Time 12.336s / 10iters, (1.234)	Forward Time 1.205s / 10iters, (0.120)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.731s / 10iters, (0.273)	Data load 0.090s / 10iters, (0.009045)
Learning rate = [0.004849931124811452, 0.004849931124811452]	Loss = 0.68073225 (ave = 0.77431790)

2023-07-05 22:10:54,370 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22110	Time 12.416s / 10iters, (1.242)	Forward Time 1.151s / 10iters, (0.115)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.103s / 10iters, (0.010348)
Learning rate = [0.004847492680056332, 0.004847492680056332]	Loss = 0.70441473 (ave = 0.78757792)

2023-07-05 22:11:06,910 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22120	Time 12.540s / 10iters, (1.254)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.470s / 10iters, (0.847)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.089s / 10iters, (0.008924)
Learning rate = [0.004845054099002903, 0.004845054099002903]	Loss = 0.82049388 (ave = 0.75928444)

2023-07-05 22:11:19,367 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22130	Time 12.456s / 10iters, (1.246)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.442s / 10iters, (0.844)	Loss Time 2.825s / 10iters, (0.283)	Data load 0.100s / 10iters, (0.010028)
Learning rate = [0.004842615381567315, 0.004842615381567315]	Loss = 0.79170340 (ave = 0.72252050)

2023-07-05 22:11:31,616 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22140	Time 12.249s / 10iters, (1.225)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.343s / 10iters, (0.834)	Loss Time 2.703s / 10iters, (0.270)	Data load 0.091s / 10iters, (0.009121)
Learning rate = [0.0048401765276656185, 0.0048401765276656185]	Loss = 0.76063150 (ave = 0.76666122)

2023-07-05 22:11:43,743 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22150	Time 12.127s / 10iters, (1.213)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.228s / 10iters, (0.823)	Loss Time 2.673s / 10iters, (0.267)	Data load 0.095s / 10iters, (0.009464)
Learning rate = [0.004837737537213769, 0.004837737537213769]	Loss = 0.62895799 (ave = 0.74967957)

2023-07-05 22:11:56,101 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22160	Time 12.358s / 10iters, (1.236)	Forward Time 1.141s / 10iters, (0.114)	Backward Time 8.405s / 10iters, (0.841)	Loss Time 2.713s / 10iters, (0.271)	Data load 0.099s / 10iters, (0.009945)
Learning rate = [0.0048352984101276185, 0.0048352984101276185]	Loss = 0.65390533 (ave = 0.71535683)

2023-07-05 22:12:08,691 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22170	Time 12.590s / 10iters, (1.259)	Forward Time 1.137s / 10iters, (0.114)	Backward Time 8.518s / 10iters, (0.852)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.086s / 10iters, (0.008613)
Learning rate = [0.004832859146322923, 0.004832859146322923]	Loss = 0.75868326 (ave = 0.78244966)

2023-07-05 22:12:21,160 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22180	Time 12.469s / 10iters, (1.247)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.435s / 10iters, (0.843)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.100s / 10iters, (0.010029)
Learning rate = [0.004830419745715336, 0.004830419745715336]	Loss = 0.72966141 (ave = 0.72431669)

2023-07-05 22:12:33,614 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22190	Time 12.454s / 10iters, (1.245)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.400s / 10iters, (0.840)	Loss Time 2.815s / 10iters, (0.282)	Data load 0.113s / 10iters, (0.011340)
Learning rate = [0.004827980208220415, 0.004827980208220415]	Loss = 0.89087152 (ave = 0.77848138)

2023-07-05 22:12:46,068 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22200	Time 12.454s / 10iters, (1.245)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.410s / 10iters, (0.841)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.087s / 10iters, (0.008691)
Learning rate = [0.004825540533753616, 0.004825540533753616]	Loss = 0.86275244 (ave = 0.77928122)

2023-07-05 22:12:58,412 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22210	Time 12.344s / 10iters, (1.234)	Forward Time 1.143s / 10iters, (0.114)	Backward Time 8.309s / 10iters, (0.831)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.080s / 10iters, (0.008011)
Learning rate = [0.004823100722230296, 0.004823100722230296]	Loss = 0.85088581 (ave = 0.73937679)

2023-07-05 22:13:10,709 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22220	Time 12.296s / 10iters, (1.230)	Forward Time 1.171s / 10iters, (0.117)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.756s / 10iters, (0.276)	Data load 0.098s / 10iters, (0.009845)
Learning rate = [0.004820660773565711, 0.004820660773565711]	Loss = 0.79968065 (ave = 0.77249638)

2023-07-05 22:13:23,089 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22230	Time 12.380s / 10iters, (1.238)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.367s / 10iters, (0.837)	Loss Time 2.785s / 10iters, (0.279)	Data load 0.098s / 10iters, (0.009837)
Learning rate = [0.00481822068767502, 0.00481822068767502]	Loss = 0.78811198 (ave = 0.72079992)

2023-07-05 22:13:35,671 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22240	Time 12.582s / 10iters, (1.258)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.480s / 10iters, (0.848)	Loss Time 2.874s / 10iters, (0.287)	Data load 0.094s / 10iters, (0.009405)
Learning rate = [0.004815780464473279, 0.004815780464473279]	Loss = 0.78501189 (ave = 0.76535429)

2023-07-05 22:13:47,729 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22250	Time 12.059s / 10iters, (1.206)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.132s / 10iters, (0.813)	Loss Time 2.749s / 10iters, (0.275)	Data load 0.087s / 10iters, (0.008718)
Learning rate = [0.004813340103875442, 0.004813340103875442]	Loss = 0.83164322 (ave = 0.73228433)

2023-07-05 22:13:59,683 INFO    [trainer_contrastive.py, 272] Train Epoch: 59	Train Iteration: 22260	Time 11.954s / 10iters, (1.195)	Forward Time 1.076s / 10iters, (0.108)	Backward Time 8.095s / 10iters, (0.809)	Loss Time 2.709s / 10iters, (0.271)	Data load 0.073s / 10iters, (0.007302)
Learning rate = [0.004810899605796367, 0.004810899605796367]	Loss = 0.76374221 (ave = 0.71749498)

2023-07-05 22:14:14,870 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22270	Time 14.981s / 10iters, (1.498)	Forward Time 1.187s / 10iters, (0.119)	Backward Time 8.233s / 10iters, (0.823)	Loss Time 2.768s / 10iters, (0.277)	Data load 2.793s / 10iters, (0.279315)
Learning rate = [0.004808458970150808, 0.004808458970150808]	Loss = 0.78010434 (ave = 0.75918810)

2023-07-05 22:14:27,201 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22280	Time 12.331s / 10iters, (1.233)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.322s / 10iters, (0.832)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.085s / 10iters, (0.008473)
Learning rate = [0.004806018196853418, 0.004806018196853418]	Loss = 0.78071707 (ave = 0.82053105)

2023-07-05 22:14:39,557 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22290	Time 12.357s / 10iters, (1.236)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.362s / 10iters, (0.836)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007569)
Learning rate = [0.0048035772858187505, 0.0048035772858187505]	Loss = 0.71852672 (ave = 0.75102703)

2023-07-05 22:14:51,992 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22300	Time 12.435s / 10iters, (1.243)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.420s / 10iters, (0.842)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.081s / 10iters, (0.008130)
Learning rate = [0.0048011362369612546, 0.0048011362369612546]	Loss = 0.61288810 (ave = 0.73477055)

2023-07-05 22:15:04,216 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22310	Time 12.223s / 10iters, (1.222)	Forward Time 1.148s / 10iters, (0.115)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.713s / 10iters, (0.271)	Data load 0.078s / 10iters, (0.007802)
Learning rate = [0.004798695050195284, 0.004798695050195284]	Loss = 0.85573828 (ave = 0.77993855)

2023-07-05 22:15:16,559 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22320	Time 12.343s / 10iters, (1.234)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.376s / 10iters, (0.838)	Loss Time 2.759s / 10iters, (0.276)	Data load 0.086s / 10iters, (0.008615)
Learning rate = [0.004796253725435084, 0.004796253725435084]	Loss = 0.85382813 (ave = 0.77323005)

2023-07-05 22:15:28,719 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22330	Time 12.161s / 10iters, (1.216)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.299s / 10iters, (0.830)	Loss Time 2.679s / 10iters, (0.268)	Data load 0.075s / 10iters, (0.007504)
Learning rate = [0.004793812262594802, 0.004793812262594802]	Loss = 0.78205985 (ave = 0.77806966)

2023-07-05 22:15:40,864 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22340	Time 12.145s / 10iters, (1.215)	Forward Time 1.152s / 10iters, (0.115)	Backward Time 8.287s / 10iters, (0.829)	Loss Time 2.630s / 10iters, (0.263)	Data load 0.076s / 10iters, (0.007630)
Learning rate = [0.004791370661588481, 0.004791370661588481]	Loss = 0.74562639 (ave = 0.72098117)

2023-07-05 22:15:53,207 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22350	Time 12.342s / 10iters, (1.234)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.429s / 10iters, (0.843)	Loss Time 2.700s / 10iters, (0.270)	Data load 0.100s / 10iters, (0.010025)
Learning rate = [0.004788928922330064, 0.004788928922330064]	Loss = 0.70732236 (ave = 0.74039255)

2023-07-05 22:16:05,516 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22360	Time 12.309s / 10iters, (1.231)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.403s / 10iters, (0.840)	Loss Time 2.723s / 10iters, (0.272)	Data load 0.082s / 10iters, (0.008193)
Learning rate = [0.004786487044733392, 0.004786487044733392]	Loss = 0.77759159 (ave = 0.76603034)

2023-07-05 22:16:17,668 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22370	Time 12.152s / 10iters, (1.215)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.298s / 10iters, (0.830)	Loss Time 2.670s / 10iters, (0.267)	Data load 0.091s / 10iters, (0.009058)
Learning rate = [0.004784045028712201, 0.004784045028712201]	Loss = 0.91847575 (ave = 0.76301150)

2023-07-05 22:16:30,032 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22380	Time 12.365s / 10iters, (1.236)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.433s / 10iters, (0.843)	Loss Time 2.721s / 10iters, (0.272)	Data load 0.099s / 10iters, (0.009870)
Learning rate = [0.0047816028741801235, 0.0047816028741801235]	Loss = 0.78858894 (ave = 0.75798881)

2023-07-05 22:16:42,183 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22390	Time 12.150s / 10iters, (1.215)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.719s / 10iters, (0.272)	Data load 0.089s / 10iters, (0.008918)
Learning rate = [0.004779160581050691, 0.004779160581050691]	Loss = 0.95997691 (ave = 0.79100376)

2023-07-05 22:16:54,334 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22400	Time 12.152s / 10iters, (1.215)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.078s / 10iters, (0.007763)
Learning rate = [0.004776718149237336, 0.004776718149237336]	Loss = 0.77704704 (ave = 0.78295111)

2023-07-05 22:17:06,692 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22410	Time 12.357s / 10iters, (1.236)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.305s / 10iters, (0.831)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.101s / 10iters, (0.010090)
Learning rate = [0.00477427557865338, 0.00477427557865338]	Loss = 0.67803234 (ave = 0.77011109)

2023-07-05 22:17:18,877 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22420	Time 12.185s / 10iters, (1.218)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.174s / 10iters, (0.817)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.080s / 10iters, (0.008045)
Learning rate = [0.004771832869212045, 0.004771832869212045]	Loss = 0.72112703 (ave = 0.73922503)

2023-07-05 22:17:31,078 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22430	Time 12.202s / 10iters, (1.220)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.186s / 10iters, (0.819)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.086s / 10iters, (0.008567)
Learning rate = [0.004769390020826448, 0.004769390020826448]	Loss = 0.73230231 (ave = 0.76216359)

2023-07-05 22:17:43,352 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22440	Time 12.274s / 10iters, (1.227)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.233s / 10iters, (0.823)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007477)
Learning rate = [0.0047669470334096055, 0.0047669470334096055]	Loss = 0.73188359 (ave = 0.72894589)

2023-07-05 22:17:55,674 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22450	Time 12.321s / 10iters, (1.232)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.908s / 10iters, (0.291)	Data load 0.078s / 10iters, (0.007834)
Learning rate = [0.004764503906874425, 0.004764503906874425]	Loss = 0.75904000 (ave = 0.77807810)

2023-07-05 22:18:07,941 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22460	Time 12.267s / 10iters, (1.227)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.894s / 10iters, (0.289)	Data load 0.074s / 10iters, (0.007435)
Learning rate = [0.004762060641133715, 0.004762060641133715]	Loss = 0.86905724 (ave = 0.78379653)

2023-07-05 22:18:20,213 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22470	Time 12.272s / 10iters, (1.227)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.890s / 10iters, (0.289)	Data load 0.073s / 10iters, (0.007346)
Learning rate = [0.004759617236100174, 0.004759617236100174]	Loss = 0.66750991 (ave = 0.76925986)

2023-07-05 22:18:32,480 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22480	Time 12.267s / 10iters, (1.227)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.879s / 10iters, (0.288)	Data load 0.079s / 10iters, (0.007930)
Learning rate = [0.004757173691686401, 0.004757173691686401]	Loss = 0.77325380 (ave = 0.75992000)

2023-07-05 22:18:44,750 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22490	Time 12.271s / 10iters, (1.227)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.230s / 10iters, (0.823)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007403)
Learning rate = [0.0047547300078048865, 0.0047547300078048865]	Loss = 0.82536650 (ave = 0.71307925)

2023-07-05 22:18:56,946 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22500	Time 12.195s / 10iters, (1.220)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.159s / 10iters, (0.816)	Loss Time 2.872s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007401)
Learning rate = [0.004752286184368019, 0.004752286184368019]	Loss = 0.71315670 (ave = 0.72294245)

2023-07-05 22:19:09,191 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22510	Time 12.246s / 10iters, (1.225)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.872s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007439)
Learning rate = [0.004749842221288078, 0.004749842221288078]	Loss = 0.80924821 (ave = 0.72340732)

2023-07-05 22:19:21,460 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22520	Time 12.269s / 10iters, (1.227)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.900s / 10iters, (0.290)	Data load 0.073s / 10iters, (0.007344)
Learning rate = [0.004747398118477244, 0.004747398118477244]	Loss = 0.74184632 (ave = 0.75255230)

2023-07-05 22:19:33,727 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22530	Time 12.267s / 10iters, (1.227)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.207s / 10iters, (0.821)	Loss Time 2.895s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007459)
Learning rate = [0.004744953875847586, 0.004744953875847586]	Loss = 0.76697236 (ave = 0.84583453)

2023-07-05 22:19:45,956 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22540	Time 12.228s / 10iters, (1.223)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007391)
Learning rate = [0.004742509493311069, 0.004742509493311069]	Loss = 0.92070127 (ave = 0.79678179)

2023-07-05 22:19:58,100 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22550	Time 12.144s / 10iters, (1.214)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.179s / 10iters, (0.818)	Loss Time 2.804s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007395)
Learning rate = [0.004740064970779553, 0.004740064970779553]	Loss = 0.86300206 (ave = 0.80701879)

2023-07-05 22:20:10,324 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22560	Time 12.225s / 10iters, (1.222)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007410)
Learning rate = [0.004737620308164792, 0.004737620308164792]	Loss = 0.63650852 (ave = 0.69781648)

2023-07-05 22:20:22,554 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22570	Time 12.229s / 10iters, (1.223)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.195s / 10iters, (0.820)	Loss Time 2.845s / 10iters, (0.285)	Data load 0.083s / 10iters, (0.008304)
Learning rate = [0.004735175505378434, 0.004735175505378434]	Loss = 0.68663371 (ave = 0.71971083)

2023-07-05 22:20:34,882 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22580	Time 12.328s / 10iters, (1.233)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.279s / 10iters, (0.828)	Loss Time 2.861s / 10iters, (0.286)	Data load 0.081s / 10iters, (0.008125)
Learning rate = [0.004732730562332018, 0.004732730562332018]	Loss = 0.72113979 (ave = 0.75258487)

2023-07-05 22:20:47,124 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22590	Time 12.242s / 10iters, (1.224)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.079s / 10iters, (0.007937)
Learning rate = [0.0047302854789369785, 0.0047302854789369785]	Loss = 0.76965070 (ave = 0.74637240)

2023-07-05 22:20:59,448 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22600	Time 12.323s / 10iters, (1.232)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.078s / 10iters, (0.007847)
Learning rate = [0.004727840255104644, 0.004727840255104644]	Loss = 0.92390132 (ave = 0.79405786)

2023-07-05 22:21:11,676 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22610	Time 12.229s / 10iters, (1.223)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.209s / 10iters, (0.821)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.084s / 10iters, (0.008403)
Learning rate = [0.004725394890746234, 0.004725394890746234]	Loss = 0.66702849 (ave = 0.74518677)

2023-07-05 22:21:23,741 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22620	Time 12.065s / 10iters, (1.206)	Forward Time 1.083s / 10iters, (0.108)	Backward Time 8.146s / 10iters, (0.815)	Loss Time 2.762s / 10iters, (0.276)	Data load 0.073s / 10iters, (0.007335)
Learning rate = [0.004722949385772862, 0.004722949385772862]	Loss = 0.80353975 (ave = 0.74322976)

2023-07-05 22:21:35,634 INFO    [trainer_contrastive.py, 272] Train Epoch: 60	Train Iteration: 22630	Time 11.893s / 10iters, (1.189)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.071s / 10iters, (0.807)	Loss Time 2.664s / 10iters, (0.266)	Data load 0.077s / 10iters, (0.007733)
Learning rate = [0.0047205037400955335, 0.0047205037400955335]	Loss = 0.73128194 (ave = 0.73137344)

2023-07-05 22:21:50,838 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22640	Time 15.067s / 10iters, (1.507)	Forward Time 1.153s / 10iters, (0.115)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.713s / 10iters, (0.271)	Data load 2.933s / 10iters, (0.293252)
Learning rate = [0.004718057953625147, 0.004718057953625147]	Loss = 0.70092160 (ave = 0.73361548)

2023-07-05 22:22:02,923 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22650	Time 12.085s / 10iters, (1.208)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.232s / 10iters, (0.823)	Loss Time 2.656s / 10iters, (0.266)	Data load 0.083s / 10iters, (0.008286)
Learning rate = [0.004715612026272492, 0.004715612026272492]	Loss = 0.72311914 (ave = 0.79063904)

2023-07-05 22:22:15,169 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22660	Time 12.246s / 10iters, (1.225)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.354s / 10iters, (0.835)	Loss Time 2.689s / 10iters, (0.269)	Data load 0.075s / 10iters, (0.007530)
Learning rate = [0.004713165957948252, 0.004713165957948252]	Loss = 0.82984245 (ave = 0.75260030)

2023-07-05 22:22:27,326 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22670	Time 12.156s / 10iters, (1.216)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.688s / 10iters, (0.269)	Data load 0.082s / 10iters, (0.008224)
Learning rate = [0.004710719748563, 0.004710719748563]	Loss = 0.85918236 (ave = 0.77270927)

2023-07-05 22:22:39,416 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22680	Time 12.090s / 10iters, (1.209)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.717s / 10iters, (0.272)	Data load 0.074s / 10iters, (0.007372)
Learning rate = [0.004708273398027204, 0.004708273398027204]	Loss = 0.76993150 (ave = 0.80176219)

2023-07-05 22:22:51,626 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22690	Time 12.210s / 10iters, (1.221)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007395)
Learning rate = [0.004705826906251219, 0.004705826906251219]	Loss = 0.73755497 (ave = 0.75924825)

2023-07-05 22:23:03,860 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22700	Time 12.234s / 10iters, (1.223)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.795s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007419)
Learning rate = [0.004703380273145295, 0.004703380273145295]	Loss = 0.83997202 (ave = 0.78439109)

2023-07-05 22:23:16,118 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22710	Time 12.259s / 10iters, (1.226)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.288s / 10iters, (0.829)	Loss Time 2.762s / 10iters, (0.276)	Data load 0.101s / 10iters, (0.010091)
Learning rate = [0.004700933498619569, 0.004700933498619569]	Loss = 0.70568275 (ave = 0.78748500)

2023-07-05 22:23:28,263 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22720	Time 12.144s / 10iters, (1.214)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.083s / 10iters, (0.008251)
Learning rate = [0.0046984865825840764, 0.0046984865825840764]	Loss = 0.84698975 (ave = 0.80677851)

2023-07-05 22:23:40,439 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22730	Time 12.176s / 10iters, (1.218)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007539)
Learning rate = [0.004696039524948735, 0.004696039524948735]	Loss = 0.71701270 (ave = 0.71809526)

2023-07-05 22:23:52,602 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22740	Time 12.163s / 10iters, (1.216)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.759s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007409)
Learning rate = [0.004693592325623356, 0.004693592325623356]	Loss = 1.03309131 (ave = 0.80004276)

2023-07-05 22:24:04,826 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22750	Time 12.223s / 10iters, (1.222)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.226s / 10iters, (0.823)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007491)
Learning rate = [0.004691144984517641, 0.004691144984517641]	Loss = 0.67198426 (ave = 0.75914155)

2023-07-05 22:24:17,113 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22760	Time 12.288s / 10iters, (1.229)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.225s / 10iters, (0.822)	Loss Time 2.888s / 10iters, (0.289)	Data load 0.087s / 10iters, (0.008667)
Learning rate = [0.004688697501541186, 0.004688697501541186]	Loss = 0.62129718 (ave = 0.74124932)

2023-07-05 22:24:29,347 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22770	Time 12.234s / 10iters, (1.223)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007427)
Learning rate = [0.004686249876603469, 0.004686249876603469]	Loss = 1.05865252 (ave = 0.76164690)

2023-07-05 22:24:41,673 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22780	Time 12.326s / 10iters, (1.233)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.919s / 10iters, (0.292)	Data load 0.074s / 10iters, (0.007432)
Learning rate = [0.004683802109613862, 0.004683802109613862]	Loss = 0.70770937 (ave = 0.74903599)

2023-07-05 22:24:53,974 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22790	Time 12.302s / 10iters, (1.230)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.227s / 10iters, (0.823)	Loss Time 2.915s / 10iters, (0.291)	Data load 0.074s / 10iters, (0.007395)
Learning rate = [0.0046813542004816265, 0.0046813542004816265]	Loss = 0.60233492 (ave = 0.73296065)

2023-07-05 22:25:06,219 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22800	Time 12.244s / 10iters, (1.224)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.181s / 10iters, (0.818)	Loss Time 2.903s / 10iters, (0.290)	Data load 0.074s / 10iters, (0.007408)
Learning rate = [0.004678906149115913, 0.004678906149115913]	Loss = 0.79931277 (ave = 0.74122063)

2023-07-05 22:25:18,492 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22810	Time 12.274s / 10iters, (1.227)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.204s / 10iters, (0.820)	Loss Time 2.905s / 10iters, (0.291)	Data load 0.076s / 10iters, (0.007553)
Learning rate = [0.004676457955425761, 0.004676457955425761]	Loss = 0.75942671 (ave = 0.75378597)

2023-07-05 22:25:30,790 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22820	Time 12.297s / 10iters, (1.230)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007443)
Learning rate = [0.0046740096193200985, 0.0046740096193200985]	Loss = 0.73714817 (ave = 0.77007576)

2023-07-05 22:25:43,120 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22830	Time 12.330s / 10iters, (1.233)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.347s / 10iters, (0.835)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007524)
Learning rate = [0.004671561140707742, 0.004671561140707742]	Loss = 0.70337725 (ave = 0.77614011)

2023-07-05 22:25:55,454 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22840	Time 12.334s / 10iters, (1.233)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.368s / 10iters, (0.837)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.084s / 10iters, (0.008417)
Learning rate = [0.004669112519497397, 0.004669112519497397]	Loss = 0.87196147 (ave = 0.75047147)

2023-07-05 22:26:07,664 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22850	Time 12.209s / 10iters, (1.221)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.754s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007527)
Learning rate = [0.004666663755597658, 0.004666663755597658]	Loss = 0.81466901 (ave = 0.78897957)

2023-07-05 22:26:19,869 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22860	Time 12.205s / 10iters, (1.220)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.260s / 10iters, (0.826)	Loss Time 2.762s / 10iters, (0.276)	Data load 0.088s / 10iters, (0.008781)
Learning rate = [0.004664214848917007, 0.004664214848917007]	Loss = 0.73232764 (ave = 0.73833743)

2023-07-05 22:26:32,000 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22870	Time 12.132s / 10iters, (1.213)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.707s / 10iters, (0.271)	Data load 0.075s / 10iters, (0.007509)
Learning rate = [0.00466176579936381, 0.00466176579936381]	Loss = 0.68746972 (ave = 0.72253622)

2023-07-05 22:26:44,126 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22880	Time 12.126s / 10iters, (1.213)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.205s / 10iters, (0.820)	Loss Time 2.742s / 10iters, (0.274)	Data load 0.076s / 10iters, (0.007562)
Learning rate = [0.00465931660684633, 0.00465931660684633]	Loss = 0.62273824 (ave = 0.74342731)

2023-07-05 22:26:56,301 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22890	Time 12.175s / 10iters, (1.218)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.755s / 10iters, (0.275)	Data load 0.086s / 10iters, (0.008562)
Learning rate = [0.004656867271272709, 0.004656867271272709]	Loss = 0.67842710 (ave = 0.80030842)

2023-07-05 22:27:08,514 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22900	Time 12.213s / 10iters, (1.221)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007437)
Learning rate = [0.004654417792550978, 0.004654417792550978]	Loss = 0.72803879 (ave = 0.76211357)

2023-07-05 22:27:20,738 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22910	Time 12.224s / 10iters, (1.222)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.848s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007573)
Learning rate = [0.004651968170589056, 0.004651968170589056]	Loss = 0.75028861 (ave = 0.78557478)

2023-07-05 22:27:33,046 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22920	Time 12.308s / 10iters, (1.231)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.868s / 10iters, (0.287)	Data load 0.091s / 10iters, (0.009064)
Learning rate = [0.004649518405294752, 0.004649518405294752]	Loss = 0.67817503 (ave = 0.75796409)

2023-07-05 22:27:45,239 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22930	Time 12.193s / 10iters, (1.219)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.175s / 10iters, (0.817)	Loss Time 2.855s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007380)
Learning rate = [0.004647068496575755, 0.004647068496575755]	Loss = 0.81169939 (ave = 0.85042191)

2023-07-05 22:27:57,421 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22940	Time 12.181s / 10iters, (1.218)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.175s / 10iters, (0.817)	Loss Time 2.845s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007444)
Learning rate = [0.004644618444339647, 0.004644618444339647]	Loss = 0.85144305 (ave = 0.78838645)

2023-07-05 22:28:09,550 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22950	Time 12.129s / 10iters, (1.213)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.143s / 10iters, (0.814)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007411)
Learning rate = [0.004642168248493891, 0.004642168248493891]	Loss = 0.79617453 (ave = 0.76654846)

2023-07-05 22:28:21,790 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22960	Time 12.240s / 10iters, (1.224)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007362)
Learning rate = [0.004639717908945839, 0.004639717908945839]	Loss = 0.81356895 (ave = 0.76286943)

2023-07-05 22:28:34,018 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22970	Time 12.229s / 10iters, (1.223)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.223s / 10iters, (0.822)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007411)
Learning rate = [0.004637267425602731, 0.004637267425602731]	Loss = 0.71676677 (ave = 0.71157045)

2023-07-05 22:28:46,218 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22980	Time 12.200s / 10iters, (1.220)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.188s / 10iters, (0.819)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007403)
Learning rate = [0.004634816798371685, 0.004634816798371685]	Loss = 0.73635948 (ave = 0.77029278)

2023-07-05 22:28:58,388 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 22990	Time 12.169s / 10iters, (1.217)	Forward Time 1.084s / 10iters, (0.108)	Backward Time 8.175s / 10iters, (0.818)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007371)
Learning rate = [0.004632366027159711, 0.004632366027159711]	Loss = 0.70327532 (ave = 0.74276375)

2023-07-05 22:29:10,358 INFO    [trainer_contrastive.py, 272] Train Epoch: 61	Train Iteration: 23000	Time 11.970s / 10iters, (1.197)	Forward Time 1.075s / 10iters, (0.107)	Backward Time 8.100s / 10iters, (0.810)	Loss Time 2.719s / 10iters, (0.272)	Data load 0.076s / 10iters, (0.007648)
Learning rate = [0.004629915111873704, 0.004629915111873704]	Loss = 0.73081529 (ave = 0.72476171)

2023-07-05 22:29:13,735 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 22:29:37,357 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 22:30:00,271 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 22:30:23,553 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 22:30:46,906 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 22:31:09,761 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 22:31:31,720 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 22:31:40,029 INFO    [trainer_contrastive.py, 391] Test Time 146.888s, (2.332)	Loss 0.14685701

2023-07-05 22:31:40,030 INFO    [base.py, 33] Result for seg
2023-07-05 22:31:40,031 INFO    [base.py, 49] Mean IOU: 0.7262293694334927

2023-07-05 22:31:40,031 INFO    [base.py, 50] Pixel ACC: 0.9536399183768257

2023-07-05 22:31:54,985 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23010	Time 164.490s / 10iters, (16.449)	Forward Time 1.308s / 10iters, (0.131)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.779s / 10iters, (0.278)	Data load 152.133s / 10iters, (15.213260)
Learning rate = [0.004627464052420441, 0.004627464052420441]	Loss = 0.82002187 (ave = 0.79568015)

2023-07-05 22:32:07,101 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23020	Time 12.117s / 10iters, (1.212)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.697s / 10iters, (0.270)	Data load 0.085s / 10iters, (0.008514)
Learning rate = [0.0046250128487065854, 0.0046250128487065854]	Loss = 0.76505810 (ave = 0.78116079)

2023-07-05 22:32:19,227 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23030	Time 12.125s / 10iters, (1.213)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.260s / 10iters, (0.826)	Loss Time 2.697s / 10iters, (0.270)	Data load 0.077s / 10iters, (0.007683)
Learning rate = [0.004622561500638683, 0.004622561500638683]	Loss = 0.76987284 (ave = 0.81044673)

2023-07-05 22:32:31,348 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23040	Time 12.121s / 10iters, (1.212)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.724s / 10iters, (0.272)	Data load 0.083s / 10iters, (0.008336)
Learning rate = [0.00462011000812317, 0.00462011000812317]	Loss = 0.70063251 (ave = 0.72375391)

2023-07-05 22:32:43,558 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23050	Time 12.210s / 10iters, (1.221)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007476)
Learning rate = [0.004617658371066359, 0.004617658371066359]	Loss = 0.67443007 (ave = 0.71992716)

2023-07-05 22:32:55,779 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23060	Time 12.221s / 10iters, (1.222)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.763s / 10iters, (0.276)	Data load 0.080s / 10iters, (0.008050)
Learning rate = [0.004615206589374452, 0.004615206589374452]	Loss = 0.85680389 (ave = 0.79352447)

2023-07-05 22:33:07,891 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23070	Time 12.112s / 10iters, (1.211)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.147s / 10iters, (0.815)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.082s / 10iters, (0.008200)
Learning rate = [0.004612754662953531, 0.004612754662953531]	Loss = 0.66015953 (ave = 0.71602125)

2023-07-05 22:33:20,095 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23080	Time 12.204s / 10iters, (1.220)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.235s / 10iters, (0.823)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.083s / 10iters, (0.008292)
Learning rate = [0.004610302591709566, 0.004610302591709566]	Loss = 0.70574093 (ave = 0.76560416)

2023-07-05 22:33:32,508 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23090	Time 12.413s / 10iters, (1.241)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.343s / 10iters, (0.834)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.109s / 10iters, (0.010885)
Learning rate = [0.004607850375548406, 0.004607850375548406]	Loss = 0.79388303 (ave = 0.76607334)

2023-07-05 22:33:44,712 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23100	Time 12.203s / 10iters, (1.220)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.186s / 10iters, (0.819)	Loss Time 2.792s / 10iters, (0.279)	Data load 0.100s / 10iters, (0.010004)
Learning rate = [0.0046053980143757845, 0.0046053980143757845]	Loss = 0.61522877 (ave = 0.74615268)

2023-07-05 22:33:57,105 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23110	Time 12.393s / 10iters, (1.239)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.329s / 10iters, (0.833)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007438)
Learning rate = [0.004602945508097318, 0.004602945508097318]	Loss = 0.76479203 (ave = 0.75660241)

2023-07-05 22:34:09,536 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23120	Time 12.431s / 10iters, (1.243)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.334s / 10iters, (0.833)	Loss Time 2.845s / 10iters, (0.285)	Data load 0.122s / 10iters, (0.012169)
Learning rate = [0.004600492856618508, 0.004600492856618508]	Loss = 0.68550146 (ave = 0.80215285)

2023-07-05 22:34:21,865 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23130	Time 12.329s / 10iters, (1.233)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.077s / 10iters, (0.007689)
Learning rate = [0.0045980400598447345, 0.0045980400598447345]	Loss = 0.68109912 (ave = 0.78802593)

2023-07-05 22:34:34,108 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23140	Time 12.243s / 10iters, (1.224)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007424)
Learning rate = [0.0045955871176812605, 0.0045955871176812605]	Loss = 0.82848817 (ave = 0.76488311)

2023-07-05 22:34:46,407 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23150	Time 12.299s / 10iters, (1.230)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.076s / 10iters, (0.007584)
Learning rate = [0.004593134030033233, 0.004593134030033233]	Loss = 0.70925808 (ave = 0.78951265)

2023-07-05 22:34:58,707 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23160	Time 12.300s / 10iters, (1.230)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.081s / 10iters, (0.008056)
Learning rate = [0.004590680796805681, 0.004590680796805681]	Loss = 0.71815753 (ave = 0.73210074)

2023-07-05 22:35:11,045 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23170	Time 12.338s / 10iters, (1.234)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.109s / 10iters, (0.010875)
Learning rate = [0.004588227417903512, 0.004588227417903512]	Loss = 0.73387080 (ave = 0.76667643)

2023-07-05 22:35:23,295 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23180	Time 12.250s / 10iters, (1.225)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.082s / 10iters, (0.008189)
Learning rate = [0.004585773893231517, 0.004585773893231517]	Loss = 0.75574756 (ave = 0.79159203)

2023-07-05 22:35:35,513 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23190	Time 12.218s / 10iters, (1.222)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007400)
Learning rate = [0.004583320222694367, 0.004583320222694367]	Loss = 0.78751135 (ave = 0.84367384)

2023-07-05 22:35:47,859 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23200	Time 12.346s / 10iters, (1.235)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.358s / 10iters, (0.836)	Loss Time 2.815s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007434)
Learning rate = [0.004580866406196618, 0.004580866406196618]	Loss = 0.89720827 (ave = 0.87141641)

2023-07-05 22:36:00,199 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23210	Time 12.340s / 10iters, (1.234)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.087s / 10iters, (0.008717)
Learning rate = [0.0045784124436427, 0.0045784124436427]	Loss = 0.81397343 (ave = 0.77247385)

2023-07-05 22:36:12,452 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23220	Time 12.254s / 10iters, (1.225)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007448)
Learning rate = [0.004575958334936929, 0.004575958334936929]	Loss = 0.81893253 (ave = 0.77749228)

2023-07-05 22:36:24,708 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23230	Time 12.255s / 10iters, (1.226)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.091s / 10iters, (0.009059)
Learning rate = [0.0045735040799834955, 0.0045735040799834955]	Loss = 0.83914286 (ave = 0.75078172)

2023-07-05 22:36:36,981 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23240	Time 12.274s / 10iters, (1.227)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.081s / 10iters, (0.008107)
Learning rate = [0.004571049678686478, 0.004571049678686478]	Loss = 0.74162292 (ave = 0.76375069)

2023-07-05 22:36:49,309 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23250	Time 12.327s / 10iters, (1.233)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.864s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007408)
Learning rate = [0.004568595130949828, 0.004568595130949828]	Loss = 0.74861330 (ave = 0.78021547)

2023-07-05 22:37:01,535 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23260	Time 12.227s / 10iters, (1.223)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.230s / 10iters, (0.823)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007543)
Learning rate = [0.004566140436677381, 0.004566140436677381]	Loss = 0.73045337 (ave = 0.77787543)

2023-07-05 22:37:13,740 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23270	Time 12.205s / 10iters, (1.220)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.217s / 10iters, (0.822)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007404)
Learning rate = [0.0045636855957728465, 0.0045636855957728465]	Loss = 1.04521453 (ave = 0.78742051)

2023-07-05 22:37:25,997 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23280	Time 12.256s / 10iters, (1.226)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007415)
Learning rate = [0.00456123060813982, 0.00456123060813982]	Loss = 0.87012273 (ave = 0.75896086)

2023-07-05 22:37:38,370 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23290	Time 12.373s / 10iters, (1.237)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.347s / 10iters, (0.835)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007416)
Learning rate = [0.004558775473681772, 0.004558775473681772]	Loss = 0.73197025 (ave = 0.77376817)

2023-07-05 22:37:50,657 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23300	Time 12.288s / 10iters, (1.229)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.082s / 10iters, (0.008236)
Learning rate = [0.00455632019230205, 0.00455632019230205]	Loss = 0.70488203 (ave = 0.80806301)

2023-07-05 22:38:03,031 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23310	Time 12.374s / 10iters, (1.237)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.890s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007495)
Learning rate = [0.004553864763903883, 0.004553864763903883]	Loss = 0.74702698 (ave = 0.77588455)

2023-07-05 22:38:15,313 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23320	Time 12.282s / 10iters, (1.228)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.245s / 10iters, (0.825)	Loss Time 2.869s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007478)
Learning rate = [0.004551409188390379, 0.004551409188390379]	Loss = 0.80102986 (ave = 0.77541994)

2023-07-05 22:38:27,577 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23330	Time 12.264s / 10iters, (1.226)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.079s / 10iters, (0.007853)
Learning rate = [0.004548953465664521, 0.004548953465664521]	Loss = 0.67793018 (ave = 0.75273594)

2023-07-05 22:38:39,749 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23340	Time 12.171s / 10iters, (1.217)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007430)
Learning rate = [0.004546497595629172, 0.004546497595629172]	Loss = 0.86832261 (ave = 0.72202000)

2023-07-05 22:38:51,914 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23350	Time 12.166s / 10iters, (1.217)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.174s / 10iters, (0.817)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.077s / 10iters, (0.007750)
Learning rate = [0.004544041578187069, 0.004544041578187069]	Loss = 0.69076651 (ave = 0.75976329)

2023-07-05 22:39:04,020 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23360	Time 12.106s / 10iters, (1.211)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.186s / 10iters, (0.819)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007391)
Learning rate = [0.004541585413240833, 0.004541585413240833]	Loss = 0.68448812 (ave = 0.72816689)

2023-07-05 22:39:16,040 INFO    [trainer_contrastive.py, 272] Train Epoch: 62	Train Iteration: 23370	Time 12.019s / 10iters, (1.202)	Forward Time 1.078s / 10iters, (0.108)	Backward Time 8.133s / 10iters, (0.813)	Loss Time 2.732s / 10iters, (0.273)	Data load 0.077s / 10iters, (0.007690)
Learning rate = [0.004539129100692956, 0.004539129100692956]	Loss = 0.93598390 (ave = 0.77280675)

2023-07-05 22:39:31,002 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23380	Time 14.778s / 10iters, (1.478)	Forward Time 1.284s / 10iters, (0.128)	Backward Time 8.328s / 10iters, (0.833)	Loss Time 2.659s / 10iters, (0.266)	Data load 2.507s / 10iters, (0.250740)
Learning rate = [0.00453667264044581, 0.00453667264044581]	Loss = 0.71457577 (ave = 0.74531965)

2023-07-05 22:39:43,240 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23390	Time 12.238s / 10iters, (1.224)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007475)
Learning rate = [0.004534216032401641, 0.004534216032401641]	Loss = 0.83319914 (ave = 0.76427205)

2023-07-05 22:39:55,687 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23400	Time 12.447s / 10iters, (1.245)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.455s / 10iters, (0.845)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007438)
Learning rate = [0.004531759276462575, 0.004531759276462575]	Loss = 0.70857894 (ave = 0.73885126)

2023-07-05 22:40:08,007 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23410	Time 12.320s / 10iters, (1.232)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.325s / 10iters, (0.833)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007558)
Learning rate = [0.004529302372530611, 0.004529302372530611]	Loss = 0.68267441 (ave = 0.73536359)

2023-07-05 22:40:20,201 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23420	Time 12.194s / 10iters, (1.219)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.769s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007495)
Learning rate = [0.004526845320507627, 0.004526845320507627]	Loss = 0.71493220 (ave = 0.78090496)

2023-07-05 22:40:32,487 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23430	Time 12.286s / 10iters, (1.229)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.262s / 10iters, (0.826)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007612)
Learning rate = [0.004524388120295372, 0.004524388120295372]	Loss = 0.73934901 (ave = 0.76505983)

2023-07-05 22:40:44,730 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23440	Time 12.244s / 10iters, (1.224)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.225s / 10iters, (0.823)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.089s / 10iters, (0.008854)
Learning rate = [0.004521930771795476, 0.004521930771795476]	Loss = 0.78123575 (ave = 0.83309779)

2023-07-05 22:40:56,921 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23450	Time 12.191s / 10iters, (1.219)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.162s / 10iters, (0.816)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007489)
Learning rate = [0.004519473274909441, 0.004519473274909441]	Loss = 0.89683247 (ave = 0.76634178)

2023-07-05 22:41:09,147 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23460	Time 12.226s / 10iters, (1.223)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.195s / 10iters, (0.819)	Loss Time 2.870s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007510)
Learning rate = [0.004517015629538645, 0.004517015629538645]	Loss = 0.68839484 (ave = 0.75742025)

2023-07-05 22:41:21,495 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23470	Time 12.347s / 10iters, (1.235)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.903s / 10iters, (0.290)	Data load 0.074s / 10iters, (0.007427)
Learning rate = [0.004514557835584339, 0.004514557835584339]	Loss = 0.72232866 (ave = 0.71522369)

2023-07-05 22:41:33,750 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23480	Time 12.256s / 10iters, (1.226)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007368)
Learning rate = [0.004512099892947653, 0.004512099892947653]	Loss = 0.77548355 (ave = 0.72820321)

2023-07-05 22:41:46,036 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23490	Time 12.286s / 10iters, (1.229)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.910s / 10iters, (0.291)	Data load 0.074s / 10iters, (0.007419)
Learning rate = [0.004509641801529587, 0.004509641801529587]	Loss = 0.74580246 (ave = 0.83201517)

2023-07-05 22:41:58,312 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23500	Time 12.276s / 10iters, (1.228)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.887s / 10iters, (0.289)	Data load 0.074s / 10iters, (0.007384)
Learning rate = [0.0045071835612310145, 0.0045071835612310145]	Loss = 0.72596425 (ave = 0.78284773)

2023-07-05 22:42:10,696 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23510	Time 12.384s / 10iters, (1.238)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.920s / 10iters, (0.292)	Data load 0.074s / 10iters, (0.007405)
Learning rate = [0.004504725171952687, 0.004504725171952687]	Loss = 0.75132912 (ave = 0.77209232)

2023-07-05 22:42:22,997 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23520	Time 12.301s / 10iters, (1.230)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.228s / 10iters, (0.823)	Loss Time 2.903s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007547)
Learning rate = [0.004502266633595227, 0.004502266633595227]	Loss = 0.80082953 (ave = 0.73706453)

2023-07-05 22:42:35,186 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23530	Time 12.189s / 10iters, (1.219)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.202s / 10iters, (0.820)	Loss Time 2.815s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007572)
Learning rate = [0.004499807946059131, 0.004499807946059131]	Loss = 0.83246386 (ave = 0.77195679)

2023-07-05 22:42:47,530 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23540	Time 12.344s / 10iters, (1.234)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.363s / 10iters, (0.836)	Loss Time 2.808s / 10iters, (0.281)	Data load 0.078s / 10iters, (0.007849)
Learning rate = [0.004497349109244768, 0.004497349109244768]	Loss = 0.74265933 (ave = 0.74636831)

2023-07-05 22:42:59,796 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23550	Time 12.267s / 10iters, (1.227)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.323s / 10iters, (0.832)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007380)
Learning rate = [0.00449489012305238, 0.00449489012305238]	Loss = 0.80763948 (ave = 0.73682927)

2023-07-05 22:43:12,006 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23560	Time 12.209s / 10iters, (1.221)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.750s / 10iters, (0.275)	Data load 0.074s / 10iters, (0.007422)
Learning rate = [0.004492430987382083, 0.004492430987382083]	Loss = 0.86490679 (ave = 0.74432976)

2023-07-05 22:43:24,163 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23570	Time 12.157s / 10iters, (1.216)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.079s / 10iters, (0.007880)
Learning rate = [0.004489971702133863, 0.004489971702133863]	Loss = 0.83350325 (ave = 0.73730791)

2023-07-05 22:43:36,465 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23580	Time 12.302s / 10iters, (1.230)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.323s / 10iters, (0.832)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.080s / 10iters, (0.008044)
Learning rate = [0.0044875122672075815, 0.0044875122672075815]	Loss = 0.78997785 (ave = 0.74097527)

2023-07-05 22:43:48,712 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23590	Time 12.248s / 10iters, (1.225)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.282s / 10iters, (0.828)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007504)
Learning rate = [0.004485052682502968, 0.004485052682502968]	Loss = 0.69929588 (ave = 0.69638788)

2023-07-05 22:44:00,926 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23600	Time 12.213s / 10iters, (1.221)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.236s / 10iters, (0.824)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007491)
Learning rate = [0.004482592947919628, 0.004482592947919628]	Loss = 0.73802435 (ave = 0.76288016)

2023-07-05 22:44:13,233 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23610	Time 12.308s / 10iters, (1.231)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.815s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007452)
Learning rate = [0.004480133063357034, 0.004480133063357034]	Loss = 0.70869434 (ave = 0.76954004)

2023-07-05 22:44:25,467 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23620	Time 12.233s / 10iters, (1.223)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007412)
Learning rate = [0.004477673028714532, 0.004477673028714532]	Loss = 0.71742374 (ave = 0.78718467)

2023-07-05 22:44:37,735 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23630	Time 12.268s / 10iters, (1.227)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007456)
Learning rate = [0.004475212843891341, 0.004475212843891341]	Loss = 0.82506424 (ave = 0.73980555)

2023-07-05 22:44:50,152 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23640	Time 12.417s / 10iters, (1.242)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.387s / 10iters, (0.839)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007424)
Learning rate = [0.004472752508786544, 0.004472752508786544]	Loss = 0.74721664 (ave = 0.74837227)

2023-07-05 22:45:02,422 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23650	Time 12.270s / 10iters, (1.227)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.077s / 10iters, (0.007658)
Learning rate = [0.0044702920232991055, 0.0044702920232991055]	Loss = 0.74946010 (ave = 0.73361732)

2023-07-05 22:45:14,775 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23660	Time 12.353s / 10iters, (1.235)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.872s / 10iters, (0.287)	Data load 0.091s / 10iters, (0.009129)
Learning rate = [0.004467831387327848, 0.004467831387327848]	Loss = 0.76755506 (ave = 0.80090426)

2023-07-05 22:45:27,086 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23670	Time 12.311s / 10iters, (1.231)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.285s / 10iters, (0.829)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.078s / 10iters, (0.007824)
Learning rate = [0.004465370600771473, 0.004465370600771473]	Loss = 0.75458354 (ave = 0.73404300)

2023-07-05 22:45:39,491 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23680	Time 12.404s / 10iters, (1.240)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.343s / 10iters, (0.834)	Loss Time 2.872s / 10iters, (0.287)	Data load 0.077s / 10iters, (0.007651)
Learning rate = [0.004462909663528546, 0.004462909663528546]	Loss = 0.76988697 (ave = 0.75393977)

2023-07-05 22:45:51,814 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23690	Time 12.323s / 10iters, (1.232)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.838s / 10iters, (0.284)	Data load 0.077s / 10iters, (0.007697)
Learning rate = [0.004460448575497506, 0.004460448575497506]	Loss = 0.75404072 (ave = 0.76373466)

2023-07-05 22:46:04,107 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23700	Time 12.293s / 10iters, (1.229)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.856s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007492)
Learning rate = [0.004457987336576659, 0.004457987336576659]	Loss = 0.71820015 (ave = 0.78121893)

2023-07-05 22:46:16,412 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23710	Time 12.305s / 10iters, (1.230)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.312s / 10iters, (0.831)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.086s / 10iters, (0.008601)
Learning rate = [0.004455525946664182, 0.004455525946664182]	Loss = 0.75169533 (ave = 0.77610512)

2023-07-05 22:46:28,693 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23720	Time 12.281s / 10iters, (1.228)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007483)
Learning rate = [0.004453064405658117, 0.004453064405658117]	Loss = 0.74296683 (ave = 0.74354014)

2023-07-05 22:46:40,986 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23730	Time 12.293s / 10iters, (1.229)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007467)
Learning rate = [0.00445060271345638, 0.00445060271345638]	Loss = 0.72146761 (ave = 0.84292555)

2023-07-05 22:46:52,973 INFO    [trainer_contrastive.py, 272] Train Epoch: 63	Train Iteration: 23740	Time 11.987s / 10iters, (1.199)	Forward Time 1.082s / 10iters, (0.108)	Backward Time 8.123s / 10iters, (0.812)	Loss Time 2.705s / 10iters, (0.271)	Data load 0.076s / 10iters, (0.007644)
Learning rate = [0.004448140869956749, 0.004448140869956749]	Loss = 0.84383488 (ave = 0.80125824)

2023-07-05 22:47:08,118 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23750	Time 15.006s / 10iters, (1.501)	Forward Time 1.164s / 10iters, (0.116)	Backward Time 8.192s / 10iters, (0.819)	Loss Time 2.728s / 10iters, (0.273)	Data load 2.921s / 10iters, (0.292117)
Learning rate = [0.004445678875056875, 0.004445678875056875]	Loss = 0.72711313 (ave = 0.74057871)

2023-07-05 22:47:20,386 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23760	Time 12.267s / 10iters, (1.227)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.304s / 10iters, (0.830)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007550)
Learning rate = [0.004443216728654272, 0.004443216728654272]	Loss = 0.79963130 (ave = 0.76441284)

2023-07-05 22:47:32,569 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23770	Time 12.183s / 10iters, (1.218)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.742s / 10iters, (0.274)	Data load 0.096s / 10iters, (0.009580)
Learning rate = [0.004440754430646328, 0.004440754430646328]	Loss = 0.70159286 (ave = 0.74134833)

2023-07-05 22:47:44,864 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23780	Time 12.295s / 10iters, (1.230)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.338s / 10iters, (0.834)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.077s / 10iters, (0.007685)
Learning rate = [0.004438291980930295, 0.004438291980930295]	Loss = 0.73392820 (ave = 0.77766581)

2023-07-05 22:47:57,117 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23790	Time 12.253s / 10iters, (1.225)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.298s / 10iters, (0.830)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007529)
Learning rate = [0.004435829379403287, 0.004435829379403287]	Loss = 0.75734949 (ave = 0.71983542)

2023-07-05 22:48:09,465 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23800	Time 12.348s / 10iters, (1.235)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.357s / 10iters, (0.836)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007532)
Learning rate = [0.004433366625962292, 0.004433366625962292]	Loss = 0.61659992 (ave = 0.75438635)

2023-07-05 22:48:21,654 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23810	Time 12.189s / 10iters, (1.219)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.225s / 10iters, (0.822)	Loss Time 2.790s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007500)
Learning rate = [0.004430903720504162, 0.004430903720504162]	Loss = 0.68110681 (ave = 0.80906740)

2023-07-05 22:48:33,901 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23820	Time 12.247s / 10iters, (1.225)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.295s / 10iters, (0.829)	Loss Time 2.752s / 10iters, (0.275)	Data load 0.101s / 10iters, (0.010072)
Learning rate = [0.004428440662925615, 0.004428440662925615]	Loss = 0.69071865 (ave = 0.77175316)

2023-07-05 22:48:46,165 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23830	Time 12.264s / 10iters, (1.226)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007472)
Learning rate = [0.004425977453123234, 0.004425977453123234]	Loss = 0.75522327 (ave = 0.84108668)

2023-07-05 22:48:58,441 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23840	Time 12.276s / 10iters, (1.228)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.313s / 10iters, (0.831)	Loss Time 2.795s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007407)
Learning rate = [0.004423514090993467, 0.004423514090993467]	Loss = 0.84293377 (ave = 0.84305301)

2023-07-05 22:49:10,685 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23850	Time 12.243s / 10iters, (1.224)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.292s / 10iters, (0.829)	Loss Time 2.790s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007444)
Learning rate = [0.004421050576432633, 0.004421050576432633]	Loss = 0.67223126 (ave = 0.76299838)

2023-07-05 22:49:23,014 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23860	Time 12.329s / 10iters, (1.233)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.327s / 10iters, (0.833)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007455)
Learning rate = [0.004418586909336908, 0.004418586909336908]	Loss = 0.81250805 (ave = 0.84363439)

2023-07-05 22:49:35,274 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23870	Time 12.260s / 10iters, (1.226)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.242s / 10iters, (0.824)	Loss Time 2.856s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007412)
Learning rate = [0.004416123089602341, 0.004416123089602341]	Loss = 0.69077152 (ave = 0.74714026)

2023-07-05 22:49:47,612 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23880	Time 12.338s / 10iters, (1.234)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007532)
Learning rate = [0.004413659117124839, 0.004413659117124839]	Loss = 0.72849476 (ave = 0.78500178)

2023-07-05 22:49:59,921 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23890	Time 12.309s / 10iters, (1.231)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.079s / 10iters, (0.007890)
Learning rate = [0.004411194991800176, 0.004411194991800176]	Loss = 0.74525970 (ave = 0.78135069)

2023-07-05 22:50:12,311 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23900	Time 12.390s / 10iters, (1.239)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.337s / 10iters, (0.834)	Loss Time 2.887s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007536)
Learning rate = [0.004408730713523993, 0.004408730713523993]	Loss = 0.68748420 (ave = 0.74913260)

2023-07-05 22:50:24,614 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23910	Time 12.303s / 10iters, (1.230)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.242s / 10iters, (0.824)	Loss Time 2.885s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007516)
Learning rate = [0.004406266282191791, 0.004406266282191791]	Loss = 1.44916487 (ave = 0.80624635)

2023-07-05 22:50:36,953 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23920	Time 12.339s / 10iters, (1.234)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.880s / 10iters, (0.288)	Data load 0.085s / 10iters, (0.008474)
Learning rate = [0.004403801697698932, 0.004403801697698932]	Loss = 0.96875936 (ave = 0.75400819)

2023-07-05 22:50:49,317 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23930	Time 12.364s / 10iters, (1.236)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.285s / 10iters, (0.828)	Loss Time 2.902s / 10iters, (0.290)	Data load 0.074s / 10iters, (0.007444)
Learning rate = [0.004401336959940652, 0.004401336959940652]	Loss = 0.86472750 (ave = 0.76660962)

2023-07-05 22:51:01,629 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23940	Time 12.312s / 10iters, (1.231)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.855s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007618)
Learning rate = [0.004398872068812038, 0.004398872068812038]	Loss = 0.65850240 (ave = 0.75225084)

2023-07-05 22:51:13,874 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23950	Time 12.245s / 10iters, (1.224)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.209s / 10iters, (0.821)	Loss Time 2.865s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007545)
Learning rate = [0.004396407024208048, 0.004396407024208048]	Loss = 0.78918946 (ave = 0.73562009)

2023-07-05 22:51:26,243 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23960	Time 12.369s / 10iters, (1.237)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.898s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007510)
Learning rate = [0.004393941826023496, 0.004393941826023496]	Loss = 0.63331407 (ave = 0.80218886)

2023-07-05 22:51:38,530 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23970	Time 12.287s / 10iters, (1.229)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.857s / 10iters, (0.286)	Data load 0.076s / 10iters, (0.007628)
Learning rate = [0.004391476474153067, 0.004391476474153067]	Loss = 0.72667396 (ave = 0.72498612)

2023-07-05 22:51:50,727 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23980	Time 12.196s / 10iters, (1.220)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.157s / 10iters, (0.816)	Loss Time 2.852s / 10iters, (0.285)	Data load 0.089s / 10iters, (0.008898)
Learning rate = [0.004389010968491299, 0.004389010968491299]	Loss = 0.79691529 (ave = 0.74039749)

2023-07-05 22:52:02,957 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 23990	Time 12.231s / 10iters, (1.223)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.865s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007412)
Learning rate = [0.004386545308932599, 0.004386545308932599]	Loss = 0.79519677 (ave = 0.80565661)

2023-07-05 22:52:15,204 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 24000	Time 12.246s / 10iters, (1.225)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.216s / 10iters, (0.822)	Loss Time 2.852s / 10iters, (0.285)	Data load 0.083s / 10iters, (0.008271)
Learning rate = [0.0043840794953712275, 0.0043840794953712275]	Loss = 0.81202620 (ave = 0.76082444)

2023-07-05 22:52:19,652 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 22:52:42,883 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 22:53:05,621 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 22:53:28,365 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 22:53:50,998 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 22:54:13,562 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 22:54:35,864 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 22:54:44,594 INFO    [trainer_contrastive.py, 391] Test Time 146.233s, (2.321)	Loss 0.15163020

2023-07-05 22:54:44,595 INFO    [base.py, 33] Result for seg
2023-07-05 22:54:44,596 INFO    [base.py, 49] Mean IOU: 0.729930831100769

2023-07-05 22:54:44,596 INFO    [base.py, 50] Pixel ACC: 0.9510810583013228

2023-07-05 22:54:56,778 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 24010	Time 161.574s / 10iters, (16.157)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.287s / 10iters, (0.829)	Loss Time 2.686s / 10iters, (0.269)	Data load 149.476s / 10iters, (14.947604)
Learning rate = [0.004381613527701316, 0.004381613527701316]	Loss = 0.70824325 (ave = 0.72207094)

2023-07-05 22:55:08,925 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 24020	Time 12.146s / 10iters, (1.215)	Forward Time 1.081s / 10iters, (0.108)	Backward Time 8.327s / 10iters, (0.833)	Loss Time 2.663s / 10iters, (0.266)	Data load 0.076s / 10iters, (0.007571)
Learning rate = [0.004379147405816849, 0.004379147405816849]	Loss = 0.69492888 (ave = 0.71101505)

2023-07-05 22:55:20,994 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 24030	Time 12.069s / 10iters, (1.207)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.672s / 10iters, (0.267)	Data load 0.076s / 10iters, (0.007618)
Learning rate = [0.004376681129611675, 0.004376681129611675]	Loss = 0.86512190 (ave = 0.74956368)

2023-07-05 22:55:33,087 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 24040	Time 12.092s / 10iters, (1.209)	Forward Time 1.077s / 10iters, (0.108)	Backward Time 8.235s / 10iters, (0.823)	Loss Time 2.706s / 10iters, (0.271)	Data load 0.075s / 10iters, (0.007457)
Learning rate = [0.004374214698979503, 0.004374214698979503]	Loss = 0.68553489 (ave = 0.76814287)

2023-07-05 22:55:45,195 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 24050	Time 12.109s / 10iters, (1.211)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.660s / 10iters, (0.266)	Data load 0.075s / 10iters, (0.007468)
Learning rate = [0.004371748113813902, 0.004371748113813902]	Loss = 0.70240074 (ave = 0.72200030)

2023-07-05 22:55:57,241 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 24060	Time 12.046s / 10iters, (1.205)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.195s / 10iters, (0.819)	Loss Time 2.678s / 10iters, (0.268)	Data load 0.084s / 10iters, (0.008442)
Learning rate = [0.0043692813740083, 0.0043692813740083]	Loss = 0.77085835 (ave = 0.79333726)

2023-07-05 22:56:09,288 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 24070	Time 12.047s / 10iters, (1.205)	Forward Time 1.082s / 10iters, (0.108)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.629s / 10iters, (0.263)	Data load 0.074s / 10iters, (0.007418)
Learning rate = [0.0043668144794559854, 0.0043668144794559854]	Loss = 0.81744707 (ave = 0.78767188)

2023-07-05 22:56:21,352 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 24080	Time 12.064s / 10iters, (1.206)	Forward Time 1.083s / 10iters, (0.108)	Backward Time 8.245s / 10iters, (0.825)	Loss Time 2.648s / 10iters, (0.265)	Data load 0.088s / 10iters, (0.008817)
Learning rate = [0.004364347430050104, 0.004364347430050104]	Loss = 0.83505410 (ave = 0.74565599)

2023-07-05 22:56:33,500 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 24090	Time 12.147s / 10iters, (1.215)	Forward Time 1.081s / 10iters, (0.108)	Backward Time 8.335s / 10iters, (0.833)	Loss Time 2.657s / 10iters, (0.266)	Data load 0.075s / 10iters, (0.007459)
Learning rate = [0.004361880225683666, 0.004361880225683666]	Loss = 0.70354676 (ave = 0.74850321)

2023-07-05 22:56:45,630 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 24100	Time 12.130s / 10iters, (1.213)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.235s / 10iters, (0.823)	Loss Time 2.721s / 10iters, (0.272)	Data load 0.095s / 10iters, (0.009489)
Learning rate = [0.004359412866249534, 0.004359412866249534]	Loss = 0.74989676 (ave = 0.78899915)

2023-07-05 22:56:57,527 INFO    [trainer_contrastive.py, 272] Train Epoch: 64	Train Iteration: 24110	Time 11.897s / 10iters, (1.190)	Forward Time 1.070s / 10iters, (0.107)	Backward Time 8.071s / 10iters, (0.807)	Loss Time 2.683s / 10iters, (0.268)	Data load 0.073s / 10iters, (0.007288)
Learning rate = [0.004356945351640433, 0.004356945351640433]	Loss = 0.74066579 (ave = 0.75728060)

2023-07-05 22:57:12,373 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24120	Time 14.659s / 10iters, (1.466)	Forward Time 1.260s / 10iters, (0.126)	Backward Time 8.255s / 10iters, (0.826)	Loss Time 2.680s / 10iters, (0.268)	Data load 2.464s / 10iters, (0.246370)
Learning rate = [0.004354477681748943, 0.004354477681748943]	Loss = 0.76133209 (ave = 0.76027415)

2023-07-05 22:57:24,615 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24130	Time 12.243s / 10iters, (1.224)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.326s / 10iters, (0.833)	Loss Time 2.751s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007548)
Learning rate = [0.004352009856467506, 0.004352009856467506]	Loss = 0.81904852 (ave = 0.75561459)

2023-07-05 22:57:36,767 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24140	Time 12.151s / 10iters, (1.215)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.725s / 10iters, (0.272)	Data load 0.085s / 10iters, (0.008512)
Learning rate = [0.0043495418756884195, 0.0043495418756884195]	Loss = 0.70732230 (ave = 0.74053567)

2023-07-05 22:57:48,881 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24150	Time 12.115s / 10iters, (1.211)	Forward Time 1.085s / 10iters, (0.109)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.704s / 10iters, (0.270)	Data load 0.074s / 10iters, (0.007432)
Learning rate = [0.004347073739303838, 0.004347073739303838]	Loss = 0.64943337 (ave = 0.69417865)

2023-07-05 22:58:01,124 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24160	Time 12.243s / 10iters, (1.224)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.322s / 10iters, (0.832)	Loss Time 2.749s / 10iters, (0.275)	Data load 0.082s / 10iters, (0.008243)
Learning rate = [0.004344605447205773, 0.004344605447205773]	Loss = 0.71657735 (ave = 0.70510932)

2023-07-05 22:58:13,337 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24170	Time 12.213s / 10iters, (1.221)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.763s / 10iters, (0.276)	Data load 0.081s / 10iters, (0.008081)
Learning rate = [0.004342136999286096, 0.004342136999286096]	Loss = 0.75846362 (ave = 0.72572738)

2023-07-05 22:58:25,619 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24180	Time 12.282s / 10iters, (1.228)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.093s / 10iters, (0.009320)
Learning rate = [0.0043396683954365295, 0.0043396683954365295]	Loss = 0.67589980 (ave = 0.75134661)

2023-07-05 22:58:37,693 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24190	Time 12.073s / 10iters, (1.207)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.150s / 10iters, (0.815)	Loss Time 2.735s / 10iters, (0.274)	Data load 0.083s / 10iters, (0.008344)
Learning rate = [0.004337199635548658, 0.004337199635548658]	Loss = 0.66003549 (ave = 0.75336778)

2023-07-05 22:58:49,809 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24200	Time 12.116s / 10iters, (1.212)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.194s / 10iters, (0.819)	Loss Time 2.762s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007422)
Learning rate = [0.004334730719513917, 0.004334730719513917]	Loss = 0.79211652 (ave = 0.87056897)

2023-07-05 22:59:02,106 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24210	Time 12.297s / 10iters, (1.230)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.265s / 10iters, (0.826)	Loss Time 2.835s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007592)
Learning rate = [0.004332261647223603, 0.004332261647223603]	Loss = 0.80768323 (ave = 0.76562924)

2023-07-05 22:59:14,278 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24220	Time 12.173s / 10iters, (1.217)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.076s / 10iters, (0.007586)
Learning rate = [0.0043297924185688634, 0.0043297924185688634]	Loss = 0.72056752 (ave = 0.79768327)

2023-07-05 22:59:26,459 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24230	Time 12.181s / 10iters, (1.218)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.737s / 10iters, (0.274)	Data load 0.075s / 10iters, (0.007520)
Learning rate = [0.004327323033440702, 0.004327323033440702]	Loss = 0.80372012 (ave = 0.78082855)

2023-07-05 22:59:38,592 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24240	Time 12.133s / 10iters, (1.213)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.723s / 10iters, (0.272)	Data load 0.074s / 10iters, (0.007422)
Learning rate = [0.004324853491729977, 0.004324853491729977]	Loss = 0.78544283 (ave = 0.75986598)

2023-07-05 22:59:50,898 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24250	Time 12.306s / 10iters, (1.231)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.320s / 10iters, (0.832)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.083s / 10iters, (0.008277)
Learning rate = [0.004322383793327404, 0.004322383793327404]	Loss = 0.67163980 (ave = 0.76368372)

2023-07-05 23:00:03,171 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24260	Time 12.274s / 10iters, (1.227)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.297s / 10iters, (0.830)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007485)
Learning rate = [0.00431991393812355, 0.00431991393812355]	Loss = 0.68442070 (ave = 0.72518297)

2023-07-05 23:00:15,408 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24270	Time 12.236s / 10iters, (1.224)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.740s / 10iters, (0.274)	Data load 0.108s / 10iters, (0.010819)
Learning rate = [0.004317443926008838, 0.004317443926008838]	Loss = 0.74048662 (ave = 0.72925180)

2023-07-05 23:00:27,579 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24280	Time 12.171s / 10iters, (1.217)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.735s / 10iters, (0.274)	Data load 0.088s / 10iters, (0.008846)
Learning rate = [0.00431497375687354, 0.00431497375687354]	Loss = 0.80280089 (ave = 0.78643805)

2023-07-05 23:00:39,854 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24290	Time 12.275s / 10iters, (1.228)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.331s / 10iters, (0.833)	Loss Time 2.777s / 10iters, (0.278)	Data load 0.078s / 10iters, (0.007833)
Learning rate = [0.0043125034306077895, 0.0043125034306077895]	Loss = 0.79250509 (ave = 0.78898067)

2023-07-05 23:00:52,130 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24300	Time 12.276s / 10iters, (1.228)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.087s / 10iters, (0.008740)
Learning rate = [0.0043100329471015665, 0.0043100329471015665]	Loss = 0.71333486 (ave = 0.73338724)

2023-07-05 23:01:04,377 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24310	Time 12.247s / 10iters, (1.225)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.315s / 10iters, (0.832)	Loss Time 2.750s / 10iters, (0.275)	Data load 0.085s / 10iters, (0.008462)
Learning rate = [0.004307562306244706, 0.004307562306244706]	Loss = 0.71704686 (ave = 0.72034166)

2023-07-05 23:01:16,597 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24320	Time 12.220s / 10iters, (1.222)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007434)
Learning rate = [0.004305091507926895, 0.004305091507926895]	Loss = 0.73226184 (ave = 0.73793749)

2023-07-05 23:01:28,867 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24330	Time 12.270s / 10iters, (1.227)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.083s / 10iters, (0.008331)
Learning rate = [0.004302620552037675, 0.004302620552037675]	Loss = 0.86276567 (ave = 0.74066114)

2023-07-05 23:01:41,164 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24340	Time 12.297s / 10iters, (1.230)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.090s / 10iters, (0.009017)
Learning rate = [0.004300149438466437, 0.004300149438466437]	Loss = 0.72049850 (ave = 0.75234380)

2023-07-05 23:01:53,473 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24350	Time 12.309s / 10iters, (1.231)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.820s / 10iters, (0.282)	Data load 0.080s / 10iters, (0.007968)
Learning rate = [0.004297678167102425, 0.004297678167102425]	Loss = 0.76184583 (ave = 0.71189122)

2023-07-05 23:02:05,788 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24360	Time 12.315s / 10iters, (1.231)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.089s / 10iters, (0.008940)
Learning rate = [0.004295206737834731, 0.004295206737834731]	Loss = 0.71911103 (ave = 0.70047326)

2023-07-05 23:02:18,134 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24370	Time 12.346s / 10iters, (1.235)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.333s / 10iters, (0.833)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.087s / 10iters, (0.008669)
Learning rate = [0.004292735150552305, 0.004292735150552305]	Loss = 0.61307043 (ave = 0.72271466)

2023-07-05 23:02:30,563 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24380	Time 12.429s / 10iters, (1.243)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.387s / 10iters, (0.839)	Loss Time 2.866s / 10iters, (0.287)	Data load 0.084s / 10iters, (0.008416)
Learning rate = [0.004290263405143942, 0.004290263405143942]	Loss = 0.61950386 (ave = 0.73774546)

2023-07-05 23:02:42,925 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24390	Time 12.362s / 10iters, (1.236)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.325s / 10iters, (0.832)	Loss Time 2.845s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007419)
Learning rate = [0.004287791501498289, 0.004287791501498289]	Loss = 0.64068198 (ave = 0.75896581)

2023-07-05 23:02:55,249 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24400	Time 12.324s / 10iters, (1.232)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.866s / 10iters, (0.287)	Data load 0.093s / 10iters, (0.009300)
Learning rate = [0.004285319439503842, 0.004285319439503842]	Loss = 0.74686372 (ave = 0.75732870)

2023-07-05 23:03:07,516 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24410	Time 12.266s / 10iters, (1.227)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007422)
Learning rate = [0.004282847219048952, 0.004282847219048952]	Loss = 0.74746305 (ave = 0.79293931)

2023-07-05 23:03:19,813 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24420	Time 12.297s / 10iters, (1.230)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007444)
Learning rate = [0.004280374840021814, 0.004280374840021814]	Loss = 0.65388733 (ave = 0.72503341)

2023-07-05 23:03:32,157 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24430	Time 12.344s / 10iters, (1.234)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.322s / 10iters, (0.832)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.083s / 10iters, (0.008259)
Learning rate = [0.0042779023023104745, 0.0042779023023104745]	Loss = 0.78611636 (ave = 0.76834131)

2023-07-05 23:03:44,581 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24440	Time 12.424s / 10iters, (1.242)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.888s / 10iters, (0.289)	Data load 0.108s / 10iters, (0.010778)
Learning rate = [0.004275429605802826, 0.004275429605802826]	Loss = 0.76368243 (ave = 0.77383085)

2023-07-05 23:03:56,972 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24450	Time 12.390s / 10iters, (1.239)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.298s / 10iters, (0.830)	Loss Time 2.901s / 10iters, (0.290)	Data load 0.084s / 10iters, (0.008362)
Learning rate = [0.004272956750386618, 0.004272956750386618]	Loss = 0.77111679 (ave = 0.76886205)

2023-07-05 23:04:09,358 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24460	Time 12.386s / 10iters, (1.239)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.314s / 10iters, (0.831)	Loss Time 2.894s / 10iters, (0.289)	Data load 0.078s / 10iters, (0.007792)
Learning rate = [0.004270483735949439, 0.004270483735949439]	Loss = 0.74403006 (ave = 0.73609474)

2023-07-05 23:04:21,660 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24470	Time 12.302s / 10iters, (1.230)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.217s / 10iters, (0.822)	Loss Time 2.886s / 10iters, (0.289)	Data load 0.087s / 10iters, (0.008661)
Learning rate = [0.00426801056237873, 0.00426801056237873]	Loss = 0.64822483 (ave = 0.72204978)

2023-07-05 23:04:33,700 INFO    [trainer_contrastive.py, 272] Train Epoch: 65	Train Iteration: 24480	Time 12.040s / 10iters, (1.204)	Forward Time 1.077s / 10iters, (0.108)	Backward Time 8.152s / 10iters, (0.815)	Loss Time 2.735s / 10iters, (0.274)	Data load 0.077s / 10iters, (0.007670)
Learning rate = [0.004265537229561781, 0.004265537229561781]	Loss = 0.66985607 (ave = 0.73884184)

2023-07-05 23:04:48,643 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24490	Time 14.789s / 10iters, (1.479)	Forward Time 1.258s / 10iters, (0.126)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.751s / 10iters, (0.275)	Data load 2.477s / 10iters, (0.247710)
Learning rate = [0.0042630637373857255, 0.0042630637373857255]	Loss = 0.74529397 (ave = 0.80152120)

2023-07-05 23:05:00,884 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24500	Time 12.241s / 10iters, (1.224)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.297s / 10iters, (0.830)	Loss Time 2.757s / 10iters, (0.276)	Data load 0.086s / 10iters, (0.008557)
Learning rate = [0.004260590085737549, 0.004260590085737549]	Loss = 0.80858505 (ave = 0.73852248)

2023-07-05 23:05:13,144 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24510	Time 12.260s / 10iters, (1.226)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.279s / 10iters, (0.828)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.090s / 10iters, (0.009000)
Learning rate = [0.0042581162745040785, 0.0042581162745040785]	Loss = 0.65033019 (ave = 0.75760632)

2023-07-05 23:05:25,409 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24520	Time 12.266s / 10iters, (1.227)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.084s / 10iters, (0.008397)
Learning rate = [0.004255642303571991, 0.004255642303571991]	Loss = 0.82966667 (ave = 0.76989926)

2023-07-05 23:05:37,664 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24530	Time 12.254s / 10iters, (1.225)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.769s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007491)
Learning rate = [0.004253168172827812, 0.004253168172827812]	Loss = 0.72801852 (ave = 0.77213956)

2023-07-05 23:05:49,959 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24540	Time 12.295s / 10iters, (1.230)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.307s / 10iters, (0.831)	Loss Time 2.804s / 10iters, (0.280)	Data load 0.079s / 10iters, (0.007935)
Learning rate = [0.004250693882157908, 0.004250693882157908]	Loss = 0.70424080 (ave = 0.73364477)

2023-07-05 23:06:02,294 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24550	Time 12.335s / 10iters, (1.234)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.312s / 10iters, (0.831)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007641)
Learning rate = [0.004248219431448493, 0.004248219431448493]	Loss = 0.71488047 (ave = 0.74789348)

2023-07-05 23:06:14,737 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24560	Time 12.443s / 10iters, (1.244)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.384s / 10iters, (0.838)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.092s / 10iters, (0.009186)
Learning rate = [0.004245744820585627, 0.004245744820585627]	Loss = 0.90210092 (ave = 0.78005695)

2023-07-05 23:06:27,010 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24570	Time 12.274s / 10iters, (1.227)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007493)
Learning rate = [0.0042432700494552155, 0.0042432700494552155]	Loss = 0.67957211 (ave = 0.69238836)

2023-07-05 23:06:39,367 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24580	Time 12.357s / 10iters, (1.236)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.305s / 10iters, (0.831)	Loss Time 2.865s / 10iters, (0.286)	Data load 0.076s / 10iters, (0.007614)
Learning rate = [0.004240795117943008, 0.004240795117943008]	Loss = 0.76890129 (ave = 0.73987364)

2023-07-05 23:06:51,694 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24590	Time 12.327s / 10iters, (1.233)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007501)
Learning rate = [0.004238320025934598, 0.004238320025934598]	Loss = 0.82257485 (ave = 0.74894526)

2023-07-05 23:07:03,953 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24600	Time 12.259s / 10iters, (1.226)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.332s / 10iters, (0.833)	Loss Time 2.750s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007537)
Learning rate = [0.004235844773315421, 0.004235844773315421]	Loss = 0.71384043 (ave = 0.74965590)

2023-07-05 23:07:16,109 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24610	Time 12.157s / 10iters, (1.216)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.706s / 10iters, (0.271)	Data load 0.076s / 10iters, (0.007602)
Learning rate = [0.004233369359970763, 0.004233369359970763]	Loss = 0.59628564 (ave = 0.68802860)

2023-07-05 23:07:28,433 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24620	Time 12.323s / 10iters, (1.232)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.338s / 10iters, (0.834)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.082s / 10iters, (0.008152)
Learning rate = [0.0042308937857857476, 0.0042308937857857476]	Loss = 0.75887835 (ave = 0.70344133)

2023-07-05 23:07:40,756 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24630	Time 12.323s / 10iters, (1.232)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.346s / 10iters, (0.835)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007591)
Learning rate = [0.0042284180506453415, 0.0042284180506453415]	Loss = 0.74190927 (ave = 0.69767404)

2023-07-05 23:07:53,095 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24640	Time 12.339s / 10iters, (1.234)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.084s / 10iters, (0.008387)
Learning rate = [0.0042259421544343576, 0.0042259421544343576]	Loss = 0.70587677 (ave = 0.76489517)

2023-07-05 23:08:05,425 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24650	Time 12.330s / 10iters, (1.233)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.878s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007432)
Learning rate = [0.004223466097037449, 0.004223466097037449]	Loss = 0.84396654 (ave = 0.81427587)

2023-07-05 23:08:17,763 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24660	Time 12.338s / 10iters, (1.234)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.315s / 10iters, (0.832)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007560)
Learning rate = [0.004220989878339112, 0.004220989878339112]	Loss = 0.73646098 (ave = 0.75758766)

2023-07-05 23:08:30,140 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24670	Time 12.377s / 10iters, (1.238)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.896s / 10iters, (0.290)	Data load 0.104s / 10iters, (0.010378)
Learning rate = [0.004218513498223685, 0.004218513498223685]	Loss = 0.83671522 (ave = 0.77923606)

2023-07-05 23:08:42,439 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24680	Time 12.299s / 10iters, (1.230)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.260s / 10iters, (0.826)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007410)
Learning rate = [0.004216036956575345, 0.004216036956575345]	Loss = 0.67261243 (ave = 0.73301097)

2023-07-05 23:08:54,865 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24690	Time 12.425s / 10iters, (1.243)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.901s / 10iters, (0.290)	Data load 0.092s / 10iters, (0.009230)
Learning rate = [0.0042135602532781145, 0.0042135602532781145]	Loss = 0.66820550 (ave = 0.70116072)

2023-07-05 23:09:07,299 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24700	Time 12.434s / 10iters, (1.243)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.370s / 10iters, (0.837)	Loss Time 2.857s / 10iters, (0.286)	Data load 0.079s / 10iters, (0.007919)
Learning rate = [0.004211083388215855, 0.004211083388215855]	Loss = 0.82367939 (ave = 0.71032020)

2023-07-05 23:09:19,739 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24710	Time 12.440s / 10iters, (1.244)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.319s / 10iters, (0.832)	Loss Time 2.886s / 10iters, (0.289)	Data load 0.121s / 10iters, (0.012068)
Learning rate = [0.004208606361272269, 0.004208606361272269]	Loss = 0.70674986 (ave = 0.74602168)

2023-07-05 23:09:32,075 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24720	Time 12.337s / 10iters, (1.234)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.900s / 10iters, (0.290)	Data load 0.074s / 10iters, (0.007416)
Learning rate = [0.004206129172330897, 0.004206129172330897]	Loss = 0.74649549 (ave = 0.82688808)

2023-07-05 23:09:44,263 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24730	Time 12.188s / 10iters, (1.219)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007428)
Learning rate = [0.0042036518212751235, 0.0042036518212751235]	Loss = 0.70031017 (ave = 0.81409242)

2023-07-05 23:09:56,498 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24740	Time 12.235s / 10iters, (1.224)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.230s / 10iters, (0.823)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007439)
Learning rate = [0.00420117430798817, 0.00420117430798817]	Loss = 0.62056738 (ave = 0.75879877)

2023-07-05 23:10:08,966 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24750	Time 12.468s / 10iters, (1.247)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.385s / 10iters, (0.839)	Loss Time 2.904s / 10iters, (0.290)	Data load 0.090s / 10iters, (0.008978)
Learning rate = [0.004198696632353097, 0.004198696632353097]	Loss = 0.70003343 (ave = 0.75298616)

2023-07-05 23:10:21,279 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24760	Time 12.313s / 10iters, (1.231)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.870s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007422)
Learning rate = [0.004196218794252803, 0.004196218794252803]	Loss = 0.75427431 (ave = 0.76911857)

2023-07-05 23:10:33,634 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24770	Time 12.355s / 10iters, (1.236)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.872s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007420)
Learning rate = [0.004193740793570031, 0.004193740793570031]	Loss = 0.77081949 (ave = 0.79788911)

2023-07-05 23:10:46,043 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24780	Time 12.408s / 10iters, (1.241)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.350s / 10iters, (0.835)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.085s / 10iters, (0.008490)
Learning rate = [0.004191262630187357, 0.004191262630187357]	Loss = 0.72698277 (ave = 0.80656576)

2023-07-05 23:10:58,333 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24790	Time 12.291s / 10iters, (1.229)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.825s / 10iters, (0.283)	Data load 0.077s / 10iters, (0.007682)
Learning rate = [0.004188784303987194, 0.004188784303987194]	Loss = 0.70150334 (ave = 0.75767447)

2023-07-05 23:11:10,560 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24800	Time 12.226s / 10iters, (1.223)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.095s / 10iters, (0.009480)
Learning rate = [0.004186305814851797, 0.004186305814851797]	Loss = 0.67395318 (ave = 0.75572565)

2023-07-05 23:11:22,875 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24810	Time 12.316s / 10iters, (1.232)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007518)
Learning rate = [0.0041838271626632555, 0.0041838271626632555]	Loss = 0.72301841 (ave = 0.74239649)

2023-07-05 23:11:35,193 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24820	Time 12.317s / 10iters, (1.232)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.325s / 10iters, (0.833)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007573)
Learning rate = [0.004181348347303496, 0.004181348347303496]	Loss = 0.64436668 (ave = 0.69503067)

2023-07-05 23:11:47,465 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24830	Time 12.273s / 10iters, (1.227)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.275s / 10iters, (0.827)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007519)
Learning rate = [0.004178869368654284, 0.004178869368654284]	Loss = 0.62585360 (ave = 0.72230843)

2023-07-05 23:11:59,728 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24840	Time 12.263s / 10iters, (1.226)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.084s / 10iters, (0.008361)
Learning rate = [0.004176390226597218, 0.004176390226597218]	Loss = 0.63873237 (ave = 0.74986080)

2023-07-05 23:12:11,726 INFO    [trainer_contrastive.py, 272] Train Epoch: 66	Train Iteration: 24850	Time 11.998s / 10iters, (1.200)	Forward Time 1.079s / 10iters, (0.108)	Backward Time 8.123s / 10iters, (0.812)	Loss Time 2.720s / 10iters, (0.272)	Data load 0.076s / 10iters, (0.007565)
Learning rate = [0.004173910921013736, 0.004173910921013736]	Loss = 0.64753133 (ave = 0.75018759)

2023-07-05 23:12:26,674 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 24860	Time 14.754s / 10iters, (1.475)	Forward Time 1.227s / 10iters, (0.123)	Backward Time 8.226s / 10iters, (0.823)	Loss Time 2.689s / 10iters, (0.269)	Data load 2.612s / 10iters, (0.261191)
Learning rate = [0.004171431451785109, 0.004171431451785109]	Loss = 0.78225780 (ave = 0.78455544)

2023-07-05 23:12:38,876 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 24870	Time 12.202s / 10iters, (1.220)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.076s / 10iters, (0.007608)
Learning rate = [0.004168951818792443, 0.004168951818792443]	Loss = 0.59254748 (ave = 0.73670767)

2023-07-05 23:12:51,046 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 24880	Time 12.170s / 10iters, (1.217)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.233s / 10iters, (0.823)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007617)
Learning rate = [0.004166472021916682, 0.004166472021916682]	Loss = 0.77816665 (ave = 0.71312162)

2023-07-05 23:13:03,365 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 24890	Time 12.320s / 10iters, (1.232)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.314s / 10iters, (0.831)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.086s / 10iters, (0.008640)
Learning rate = [0.004163992061038601, 0.004163992061038601]	Loss = 0.77508336 (ave = 0.70184863)

2023-07-05 23:13:15,575 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 24900	Time 12.210s / 10iters, (1.221)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.775s / 10iters, (0.278)	Data load 0.093s / 10iters, (0.009271)
Learning rate = [0.004161511936038813, 0.004161511936038813]	Loss = 0.61877346 (ave = 0.71307530)

2023-07-05 23:13:27,847 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 24910	Time 12.271s / 10iters, (1.227)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.286s / 10iters, (0.829)	Loss Time 2.805s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007552)
Learning rate = [0.004159031646797763, 0.004159031646797763]	Loss = 0.83492577 (ave = 0.75504839)

2023-07-05 23:13:40,122 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 24920	Time 12.276s / 10iters, (1.228)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.335s / 10iters, (0.833)	Loss Time 2.762s / 10iters, (0.276)	Data load 0.086s / 10iters, (0.008550)
Learning rate = [0.004156551193195727, 0.004156551193195727]	Loss = 0.80962402 (ave = 0.73673370)

2023-07-05 23:13:52,501 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 24930	Time 12.378s / 10iters, (1.238)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.408s / 10iters, (0.841)	Loss Time 2.792s / 10iters, (0.279)	Data load 0.078s / 10iters, (0.007807)
Learning rate = [0.004154070575112819, 0.004154070575112819]	Loss = 0.76903033 (ave = 0.74441037)

2023-07-05 23:14:04,736 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 24940	Time 12.235s / 10iters, (1.224)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.809s / 10iters, (0.281)	Data load 0.080s / 10iters, (0.008044)
Learning rate = [0.004151589792428985, 0.004151589792428985]	Loss = 0.71307600 (ave = 0.76624037)

2023-07-05 23:14:16,959 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 24950	Time 12.223s / 10iters, (1.222)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.078s / 10iters, (0.007827)
Learning rate = [0.004149108845024001, 0.004149108845024001]	Loss = 0.71901357 (ave = 0.70984871)

2023-07-05 23:14:29,218 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 24960	Time 12.259s / 10iters, (1.226)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007462)
Learning rate = [0.004146627732777477, 0.004146627732777477]	Loss = 0.70993054 (ave = 0.73591433)

2023-07-05 23:14:41,474 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 24970	Time 12.257s / 10iters, (1.226)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.848s / 10iters, (0.285)	Data load 0.087s / 10iters, (0.008745)
Learning rate = [0.004144146455568854, 0.004144146455568854]	Loss = 0.82319510 (ave = 0.73633201)

2023-07-05 23:14:53,689 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 24980	Time 12.215s / 10iters, (1.222)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.201s / 10iters, (0.820)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.090s / 10iters, (0.008965)
Learning rate = [0.004141665013277407, 0.004141665013277407]	Loss = 0.79426545 (ave = 0.74528816)

2023-07-05 23:15:06,005 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 24990	Time 12.316s / 10iters, (1.232)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.864s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007525)
Learning rate = [0.00413918340578224, 0.00413918340578224]	Loss = 0.73869121 (ave = 0.75496875)

2023-07-05 23:15:18,346 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25000	Time 12.341s / 10iters, (1.234)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007482)
Learning rate = [0.004136701632962287, 0.004136701632962287]	Loss = 0.76706761 (ave = 0.76674595)

2023-07-05 23:15:23,175 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 23:15:46,457 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 23:16:09,225 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 23:16:32,024 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 23:16:54,770 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 23:17:17,343 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 23:17:39,406 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 23:17:49,472 INFO    [trainer_contrastive.py, 391] Test Time 146.558s, (2.326)	Loss 0.13806884

2023-07-05 23:17:49,473 INFO    [base.py, 33] Result for seg
2023-07-05 23:17:49,474 INFO    [base.py, 49] Mean IOU: 0.7280315391524056

2023-07-05 23:17:49,475 INFO    [base.py, 50] Pixel ACC: 0.9555608861884136

2023-07-05 23:18:01,651 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25010	Time 163.305s / 10iters, (16.331)	Forward Time 1.153s / 10iters, (0.115)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.697s / 10iters, (0.270)	Data load 151.214s / 10iters, (15.121411)
Learning rate = [0.004134219694696314, 0.004134219694696314]	Loss = 0.70432544 (ave = 0.77556144)

2023-07-05 23:18:13,703 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25020	Time 12.052s / 10iters, (1.205)	Forward Time 1.074s / 10iters, (0.107)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.690s / 10iters, (0.269)	Data load 0.074s / 10iters, (0.007430)
Learning rate = [0.004131737590862919, 0.004131737590862919]	Loss = 0.79214221 (ave = 0.76778234)

2023-07-05 23:18:25,829 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25030	Time 12.126s / 10iters, (1.213)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.295s / 10iters, (0.829)	Loss Time 2.654s / 10iters, (0.265)	Data load 0.074s / 10iters, (0.007428)
Learning rate = [0.004129255321340527, 0.004129255321340527]	Loss = 0.77421385 (ave = 0.70745569)

2023-07-05 23:18:37,882 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25040	Time 12.053s / 10iters, (1.205)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.171s / 10iters, (0.817)	Loss Time 2.704s / 10iters, (0.270)	Data load 0.082s / 10iters, (0.008230)
Learning rate = [0.004126772886007392, 0.004126772886007392]	Loss = 0.71509862 (ave = 0.75213729)

2023-07-05 23:18:50,084 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25050	Time 12.202s / 10iters, (1.220)	Forward Time 1.082s / 10iters, (0.108)	Backward Time 8.304s / 10iters, (0.830)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.074s / 10iters, (0.007388)
Learning rate = [0.004124290284741599, 0.004124290284741599]	Loss = 0.69863737 (ave = 0.75037677)

2023-07-05 23:19:02,247 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25060	Time 12.163s / 10iters, (1.216)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.297s / 10iters, (0.830)	Loss Time 2.706s / 10iters, (0.271)	Data load 0.075s / 10iters, (0.007482)
Learning rate = [0.0041218075174210625, 0.0041218075174210625]	Loss = 0.70271921 (ave = 0.75632142)

2023-07-05 23:19:14,349 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25070	Time 12.102s / 10iters, (1.210)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.189s / 10iters, (0.819)	Loss Time 2.732s / 10iters, (0.273)	Data load 0.086s / 10iters, (0.008601)
Learning rate = [0.004119324583923522, 0.004119324583923522]	Loss = 0.75674999 (ave = 0.75504889)

2023-07-05 23:19:26,542 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25080	Time 12.193s / 10iters, (1.219)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.265s / 10iters, (0.827)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.083s / 10iters, (0.008349)
Learning rate = [0.004116841484126549, 0.004116841484126549]	Loss = 0.73688787 (ave = 0.71803839)

2023-07-05 23:19:38,683 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25090	Time 12.141s / 10iters, (1.214)	Forward Time 1.081s / 10iters, (0.108)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.727s / 10iters, (0.273)	Data load 0.074s / 10iters, (0.007433)
Learning rate = [0.004114358217907538, 0.004114358217907538]	Loss = 0.80756706 (ave = 0.78714111)

2023-07-05 23:19:50,979 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25100	Time 12.295s / 10iters, (1.230)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.325s / 10iters, (0.833)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.086s / 10iters, (0.008619)
Learning rate = [0.004111874785143716, 0.004111874785143716]	Loss = 0.72510815 (ave = 0.84490327)

2023-07-05 23:20:03,101 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25110	Time 12.122s / 10iters, (1.212)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.171s / 10iters, (0.817)	Loss Time 2.769s / 10iters, (0.277)	Data load 0.085s / 10iters, (0.008523)
Learning rate = [0.004109391185712135, 0.004109391185712135]	Loss = 0.78100836 (ave = 0.77496017)

2023-07-05 23:20:15,289 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25120	Time 12.188s / 10iters, (1.219)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.245s / 10iters, (0.825)	Loss Time 2.766s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007558)
Learning rate = [0.004106907419489672, 0.004106907419489672]	Loss = 0.78596991 (ave = 0.78272467)

2023-07-05 23:20:27,523 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25130	Time 12.234s / 10iters, (1.223)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.077s / 10iters, (0.007699)
Learning rate = [0.00410442348635303, 0.00410442348635303]	Loss = 0.83403951 (ave = 0.77779025)

2023-07-05 23:20:39,739 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25140	Time 12.215s / 10iters, (1.222)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007622)
Learning rate = [0.004101939386178742, 0.004101939386178742]	Loss = 0.78364563 (ave = 0.80474289)

2023-07-05 23:20:51,889 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25150	Time 12.150s / 10iters, (1.215)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.235s / 10iters, (0.823)	Loss Time 2.738s / 10iters, (0.274)	Data load 0.074s / 10iters, (0.007446)
Learning rate = [0.004099455118843164, 0.004099455118843164]	Loss = 0.70882785 (ave = 0.78285061)

2023-07-05 23:21:04,134 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25160	Time 12.245s / 10iters, (1.224)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.764s / 10iters, (0.276)	Data load 0.076s / 10iters, (0.007605)
Learning rate = [0.004096970684222474, 0.004096970684222474]	Loss = 1.08937466 (ave = 0.77926722)

2023-07-05 23:21:16,344 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25170	Time 12.210s / 10iters, (1.221)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007369)
Learning rate = [0.0040944860821926785, 0.0040944860821926785]	Loss = 0.73684996 (ave = 0.75391374)

2023-07-05 23:21:28,580 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25180	Time 12.237s / 10iters, (1.224)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.260s / 10iters, (0.826)	Loss Time 2.804s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007562)
Learning rate = [0.004092001312629609, 0.004092001312629609]	Loss = 0.83407408 (ave = 0.72263744)

2023-07-05 23:21:40,690 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25190	Time 12.110s / 10iters, (1.211)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.139s / 10iters, (0.814)	Loss Time 2.789s / 10iters, (0.279)	Data load 0.090s / 10iters, (0.008961)
Learning rate = [0.004089516375408921, 0.004089516375408921]	Loss = 0.67186141 (ave = 0.70918539)

2023-07-05 23:21:52,870 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25200	Time 12.180s / 10iters, (1.218)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.195s / 10iters, (0.820)	Loss Time 2.805s / 10iters, (0.281)	Data load 0.087s / 10iters, (0.008711)
Learning rate = [0.0040870312704060895, 0.0040870312704060895]	Loss = 0.72541875 (ave = 0.72837534)

2023-07-05 23:22:05,044 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25210	Time 12.174s / 10iters, (1.217)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.197s / 10iters, (0.820)	Loss Time 2.795s / 10iters, (0.280)	Data load 0.091s / 10iters, (0.009102)
Learning rate = [0.004084545997496416, 0.004084545997496416]	Loss = 0.72205305 (ave = 0.75141867)

2023-07-05 23:22:17,117 INFO    [trainer_contrastive.py, 272] Train Epoch: 67	Train Iteration: 25220	Time 12.074s / 10iters, (1.207)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.171s / 10iters, (0.817)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.076s / 10iters, (0.007622)
Learning rate = [0.004082060556555028, 0.004082060556555028]	Loss = 0.67418253 (ave = 0.75067112)

2023-07-05 23:22:32,042 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25230	Time 14.720s / 10iters, (1.472)	Forward Time 1.324s / 10iters, (0.132)	Backward Time 8.177s / 10iters, (0.818)	Loss Time 2.626s / 10iters, (0.263)	Data load 2.594s / 10iters, (0.259416)
Learning rate = [0.004079574947456869, 0.004079574947456869]	Loss = 0.69669139 (ave = 0.73134468)

2023-07-05 23:22:44,266 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25240	Time 12.224s / 10iters, (1.222)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.285s / 10iters, (0.829)	Loss Time 2.762s / 10iters, (0.276)	Data load 0.077s / 10iters, (0.007741)
Learning rate = [0.004077089170076709, 0.004077089170076709]	Loss = 0.65338165 (ave = 0.80864002)

2023-07-05 23:22:56,408 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25250	Time 12.143s / 10iters, (1.214)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.742s / 10iters, (0.274)	Data load 0.078s / 10iters, (0.007769)
Learning rate = [0.004074603224289137, 0.004074603224289137]	Loss = 0.82411444 (ave = 0.74080341)

2023-07-05 23:23:08,629 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25260	Time 12.221s / 10iters, (1.222)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.282s / 10iters, (0.828)	Loss Time 2.765s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007499)
Learning rate = [0.004072117109968569, 0.004072117109968569]	Loss = 0.80955100 (ave = 0.76592079)

2023-07-05 23:23:20,831 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25270	Time 12.201s / 10iters, (1.220)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.759s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007540)
Learning rate = [0.004069630826989236, 0.004069630826989236]	Loss = 0.68377650 (ave = 0.72355286)

2023-07-05 23:23:32,956 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25280	Time 12.126s / 10iters, (1.213)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.202s / 10iters, (0.820)	Loss Time 2.754s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007493)
Learning rate = [0.004067144375225193, 0.004067144375225193]	Loss = 0.56005222 (ave = 0.71342180)

2023-07-05 23:23:45,170 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25290	Time 12.214s / 10iters, (1.221)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.076s / 10iters, (0.007596)
Learning rate = [0.004064657754550312, 0.004064657754550312]	Loss = 0.69735062 (ave = 0.71438205)

2023-07-05 23:23:57,386 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25300	Time 12.215s / 10iters, (1.222)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.090s / 10iters, (0.008981)
Learning rate = [0.004062170964838291, 0.004062170964838291]	Loss = 0.83444375 (ave = 0.72362066)

2023-07-05 23:24:09,545 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25310	Time 12.160s / 10iters, (1.216)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.202s / 10iters, (0.820)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007492)
Learning rate = [0.004059684005962642, 0.004059684005962642]	Loss = 0.77021569 (ave = 0.71418971)

2023-07-05 23:24:21,690 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25320	Time 12.145s / 10iters, (1.214)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.204s / 10iters, (0.820)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007531)
Learning rate = [0.004057196877796697, 0.004057196877796697]	Loss = 0.70401067 (ave = 0.72755185)

2023-07-05 23:24:33,891 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25330	Time 12.201s / 10iters, (1.220)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.797s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007485)
Learning rate = [0.004054709580213609, 0.004054709580213609]	Loss = 0.73115158 (ave = 0.74388646)

2023-07-05 23:24:46,194 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25340	Time 12.303s / 10iters, (1.230)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.320s / 10iters, (0.832)	Loss Time 2.804s / 10iters, (0.280)	Data load 0.080s / 10iters, (0.008004)
Learning rate = [0.00405222211308635, 0.00405222211308635]	Loss = 0.73578197 (ave = 0.83227817)

2023-07-05 23:24:58,404 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25350	Time 12.210s / 10iters, (1.221)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.816s / 10iters, (0.282)	Data load 0.095s / 10iters, (0.009460)
Learning rate = [0.004049734476287706, 0.004049734476287706]	Loss = 0.68640250 (ave = 0.78404804)

2023-07-05 23:25:10,752 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25360	Time 12.348s / 10iters, (1.235)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.319s / 10iters, (0.832)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007481)
Learning rate = [0.004047246669690283, 0.004047246669690283]	Loss = 0.71583021 (ave = 0.73934633)

2023-07-05 23:25:23,108 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25370	Time 12.356s / 10iters, (1.236)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.287s / 10iters, (0.829)	Loss Time 2.887s / 10iters, (0.289)	Data load 0.082s / 10iters, (0.008214)
Learning rate = [0.004044758693166505, 0.004044758693166505]	Loss = 0.74163389 (ave = 0.76670420)

2023-07-05 23:25:35,343 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25380	Time 12.235s / 10iters, (1.224)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.085s / 10iters, (0.008480)
Learning rate = [0.004042270546588613, 0.004042270546588613]	Loss = 0.74010372 (ave = 0.80484722)

2023-07-05 23:25:47,591 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25390	Time 12.248s / 10iters, (1.225)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.878s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007442)
Learning rate = [0.004039782229828663, 0.004039782229828663]	Loss = 0.90949064 (ave = 0.86733818)

2023-07-05 23:25:59,890 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25400	Time 12.299s / 10iters, (1.230)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.887s / 10iters, (0.289)	Data load 0.076s / 10iters, (0.007611)
Learning rate = [0.004037293742758527, 0.004037293742758527]	Loss = 0.95805287 (ave = 0.83642343)

2023-07-05 23:26:12,092 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25410	Time 12.202s / 10iters, (1.220)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.155s / 10iters, (0.815)	Loss Time 2.877s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007519)
Learning rate = [0.004034805085249894, 0.004034805085249894]	Loss = 0.75943357 (ave = 0.77407234)

2023-07-05 23:26:24,416 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25420	Time 12.324s / 10iters, (1.232)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.898s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007496)
Learning rate = [0.004032316257174269, 0.004032316257174269]	Loss = 0.74315900 (ave = 0.79241067)

2023-07-05 23:26:36,738 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25430	Time 12.322s / 10iters, (1.232)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.893s / 10iters, (0.289)	Data load 0.076s / 10iters, (0.007647)
Learning rate = [0.004029827258402969, 0.004029827258402969]	Loss = 0.91101348 (ave = 0.80549403)

2023-07-05 23:26:48,955 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25440	Time 12.217s / 10iters, (1.222)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.174s / 10iters, (0.817)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.076s / 10iters, (0.007565)
Learning rate = [0.004027338088807128, 0.004027338088807128]	Loss = 0.62733155 (ave = 0.81816112)

2023-07-05 23:27:01,244 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25450	Time 12.289s / 10iters, (1.229)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.850s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007614)
Learning rate = [0.004024848748257693, 0.004024848748257693]	Loss = 0.81355190 (ave = 0.75440642)

2023-07-05 23:27:13,558 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25460	Time 12.314s / 10iters, (1.231)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.275s / 10iters, (0.828)	Loss Time 2.869s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007487)
Learning rate = [0.0040223592366254255, 0.0040223592366254255]	Loss = 0.77984607 (ave = 0.78542184)

2023-07-05 23:27:25,829 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25470	Time 12.272s / 10iters, (1.227)	Forward Time 1.135s / 10iters, (0.114)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007549)
Learning rate = [0.004019869553780901, 0.004019869553780901]	Loss = 0.84419256 (ave = 0.79466301)

2023-07-05 23:27:38,116 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25480	Time 12.287s / 10iters, (1.229)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007645)
Learning rate = [0.004017379699594506, 0.004017379699594506]	Loss = 0.70300877 (ave = 0.75744762)

2023-07-05 23:27:50,406 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25490	Time 12.290s / 10iters, (1.229)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.210s / 10iters, (0.821)	Loss Time 2.885s / 10iters, (0.288)	Data load 0.090s / 10iters, (0.008952)
Learning rate = [0.0040148896739364386, 0.0040148896739364386]	Loss = 0.86206537 (ave = 0.78676444)

2023-07-05 23:28:02,693 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25500	Time 12.287s / 10iters, (1.229)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.896s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007546)
Learning rate = [0.004012399476676714, 0.004012399476676714]	Loss = 0.77385968 (ave = 0.78942772)

2023-07-05 23:28:14,964 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25510	Time 12.270s / 10iters, (1.227)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007592)
Learning rate = [0.004009909107685156, 0.004009909107685156]	Loss = 0.74789399 (ave = 0.74192938)

2023-07-05 23:28:27,289 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25520	Time 12.325s / 10iters, (1.233)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.083s / 10iters, (0.008274)
Learning rate = [0.004007418566831398, 0.004007418566831398]	Loss = 0.76736331 (ave = 0.75932546)

2023-07-05 23:28:39,589 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25530	Time 12.300s / 10iters, (1.230)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.320s / 10iters, (0.832)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007503)
Learning rate = [0.0040049278539848856, 0.0040049278539848856]	Loss = 0.59098697 (ave = 0.72530481)

2023-07-05 23:28:51,867 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25540	Time 12.278s / 10iters, (1.228)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.285s / 10iters, (0.829)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007487)
Learning rate = [0.004002436969014879, 0.004002436969014879]	Loss = 0.64120585 (ave = 0.78539823)

2023-07-05 23:29:04,091 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25550	Time 12.224s / 10iters, (1.222)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.095s / 10iters, (0.009527)
Learning rate = [0.003999945911790441, 0.003999945911790441]	Loss = 0.63364327 (ave = 0.74333817)

2023-07-05 23:29:16,375 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25560	Time 12.284s / 10iters, (1.228)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007544)
Learning rate = [0.003997454682180451, 0.003997454682180451]	Loss = 0.74537742 (ave = 0.74553770)

2023-07-05 23:29:28,740 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25570	Time 12.365s / 10iters, (1.237)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.354s / 10iters, (0.835)	Loss Time 2.808s / 10iters, (0.281)	Data load 0.078s / 10iters, (0.007794)
Learning rate = [0.003994963280053594, 0.003994963280053594]	Loss = 0.65962327 (ave = 0.76129897)

2023-07-05 23:29:41,257 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25580	Time 12.517s / 10iters, (1.252)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.412s / 10iters, (0.841)	Loss Time 2.905s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007530)
Learning rate = [0.003992471705278364, 0.003992471705278364]	Loss = 0.67996508 (ave = 0.79370657)

2023-07-05 23:29:53,392 INFO    [trainer_contrastive.py, 272] Train Epoch: 68	Train Iteration: 25590	Time 12.135s / 10iters, (1.213)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.174s / 10iters, (0.817)	Loss Time 2.790s / 10iters, (0.279)	Data load 0.084s / 10iters, (0.008437)
Learning rate = [0.003989979957723067, 0.003989979957723067]	Loss = 0.89094490 (ave = 0.79692116)

2023-07-05 23:30:08,093 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25600	Time 14.500s / 10iters, (1.450)	Forward Time 1.180s / 10iters, (0.118)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.724s / 10iters, (0.272)	Data load 2.407s / 10iters, (0.240652)
Learning rate = [0.003987488037255811, 0.003987488037255811]	Loss = 0.64637232 (ave = 0.72128891)

2023-07-05 23:30:20,385 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25610	Time 12.293s / 10iters, (1.229)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.805s / 10iters, (0.280)	Data load 0.083s / 10iters, (0.008273)
Learning rate = [0.003984995943744516, 0.003984995943744516]	Loss = 0.66178328 (ave = 0.69260839)

2023-07-05 23:30:32,598 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25620	Time 12.213s / 10iters, (1.221)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.777s / 10iters, (0.278)	Data load 0.085s / 10iters, (0.008547)
Learning rate = [0.00398250367705691, 0.00398250367705691]	Loss = 0.77395916 (ave = 0.79238636)

2023-07-05 23:30:44,933 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25630	Time 12.335s / 10iters, (1.233)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007599)
Learning rate = [0.003980011237060524, 0.003980011237060524]	Loss = 0.77298653 (ave = 0.75783585)

2023-07-05 23:30:57,099 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25640	Time 12.166s / 10iters, (1.217)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.076s / 10iters, (0.007551)
Learning rate = [0.0039775186236227, 0.0039775186236227]	Loss = 0.68571097 (ave = 0.75479918)

2023-07-05 23:31:09,277 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25650	Time 12.178s / 10iters, (1.218)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.255s / 10iters, (0.826)	Loss Time 2.752s / 10iters, (0.275)	Data load 0.077s / 10iters, (0.007709)
Learning rate = [0.0039750258366105795, 0.0039750258366105795]	Loss = 0.65149748 (ave = 0.76257926)

2023-07-05 23:31:21,593 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25660	Time 12.316s / 10iters, (1.232)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.375s / 10iters, (0.838)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.082s / 10iters, (0.008218)
Learning rate = [0.003972532875891117, 0.003972532875891117]	Loss = 0.66337484 (ave = 0.75387991)

2023-07-05 23:31:33,956 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25670	Time 12.363s / 10iters, (1.236)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.371s / 10iters, (0.837)	Loss Time 2.789s / 10iters, (0.279)	Data load 0.076s / 10iters, (0.007612)
Learning rate = [0.00397003974133107, 0.00397003974133107]	Loss = 0.69160849 (ave = 0.74422851)

2023-07-05 23:31:46,138 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25680	Time 12.181s / 10iters, (1.218)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.076s / 10iters, (0.007594)
Learning rate = [0.003967546432796996, 0.003967546432796996]	Loss = 0.64767730 (ave = 0.75430686)

2023-07-05 23:31:58,291 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25690	Time 12.153s / 10iters, (1.215)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.077s / 10iters, (0.007706)
Learning rate = [0.003965052950155262, 0.003965052950155262]	Loss = 0.83210009 (ave = 0.73755633)

2023-07-05 23:32:10,576 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25700	Time 12.285s / 10iters, (1.228)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.344s / 10iters, (0.834)	Loss Time 2.764s / 10iters, (0.276)	Data load 0.079s / 10iters, (0.007855)
Learning rate = [0.003962559293272037, 0.003962559293272037]	Loss = 0.64891589 (ave = 0.72665176)

2023-07-05 23:32:22,787 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25710	Time 12.212s / 10iters, (1.221)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.730s / 10iters, (0.273)	Data load 0.079s / 10iters, (0.007927)
Learning rate = [0.003960065462013295, 0.003960065462013295]	Loss = 0.73216516 (ave = 0.72901201)

2023-07-05 23:32:34,838 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25720	Time 12.051s / 10iters, (1.205)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.173s / 10iters, (0.817)	Loss Time 2.702s / 10iters, (0.270)	Data load 0.077s / 10iters, (0.007675)
Learning rate = [0.003957571456244811, 0.003957571456244811]	Loss = 0.80270815 (ave = 0.76254022)

2023-07-05 23:32:46,992 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25730	Time 12.153s / 10iters, (1.215)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.724s / 10iters, (0.272)	Data load 0.090s / 10iters, (0.008972)
Learning rate = [0.0039550772758321605, 0.0039550772758321605]	Loss = 0.70315874 (ave = 0.72496180)

2023-07-05 23:32:59,217 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25740	Time 12.225s / 10iters, (1.222)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.086s / 10iters, (0.008571)
Learning rate = [0.003952582920640729, 0.003952582920640729]	Loss = 0.83716565 (ave = 0.84967640)

2023-07-05 23:33:11,437 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25750	Time 12.221s / 10iters, (1.222)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.085s / 10iters, (0.008500)
Learning rate = [0.003950088390535697, 0.003950088390535697]	Loss = 0.73997533 (ave = 0.78642394)

2023-07-05 23:33:23,559 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25760	Time 12.121s / 10iters, (1.212)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.195s / 10iters, (0.819)	Loss Time 2.742s / 10iters, (0.274)	Data load 0.083s / 10iters, (0.008257)
Learning rate = [0.003947593685382047, 0.003947593685382047]	Loss = 0.85441703 (ave = 0.78693313)

2023-07-05 23:33:35,823 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25770	Time 12.265s / 10iters, (1.226)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.282s / 10iters, (0.828)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.093s / 10iters, (0.009269)
Learning rate = [0.003945098805044563, 0.003945098805044563]	Loss = 0.73313206 (ave = 0.70531461)

2023-07-05 23:33:48,039 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25780	Time 12.215s / 10iters, (1.222)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.282s / 10iters, (0.828)	Loss Time 2.746s / 10iters, (0.275)	Data load 0.081s / 10iters, (0.008086)
Learning rate = [0.003942603749387834, 0.003942603749387834]	Loss = 0.64620060 (ave = 0.85150743)

2023-07-05 23:34:00,178 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25790	Time 12.140s / 10iters, (1.214)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.745s / 10iters, (0.274)	Data load 0.085s / 10iters, (0.008500)
Learning rate = [0.003940108518276242, 0.003940108518276242]	Loss = 0.81846279 (ave = 0.78582873)

2023-07-05 23:34:12,374 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25800	Time 12.196s / 10iters, (1.220)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.272s / 10iters, (0.827)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.079s / 10iters, (0.007867)
Learning rate = [0.003937613111573972, 0.003937613111573972]	Loss = 0.75929701 (ave = 0.79552833)

2023-07-05 23:34:24,479 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25810	Time 12.105s / 10iters, (1.211)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.166s / 10iters, (0.817)	Loss Time 2.752s / 10iters, (0.275)	Data load 0.091s / 10iters, (0.009088)
Learning rate = [0.003935117529145007, 0.003935117529145007]	Loss = 0.78290570 (ave = 0.77048753)

2023-07-05 23:34:36,652 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25820	Time 12.172s / 10iters, (1.217)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.215s / 10iters, (0.822)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.083s / 10iters, (0.008259)
Learning rate = [0.003932621770853131, 0.003932621770853131]	Loss = 0.77441013 (ave = 0.77116014)

2023-07-05 23:34:48,847 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25830	Time 12.195s / 10iters, (1.219)	Forward Time 1.084s / 10iters, (0.108)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.084s / 10iters, (0.008358)
Learning rate = [0.003930125836561925, 0.003930125836561925]	Loss = 0.68335086 (ave = 0.70673084)

2023-07-05 23:35:01,133 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25840	Time 12.286s / 10iters, (1.229)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.080s / 10iters, (0.008038)
Learning rate = [0.003927629726134767, 0.003927629726134767]	Loss = 0.81265688 (ave = 0.73766093)

2023-07-05 23:35:13,287 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25850	Time 12.154s / 10iters, (1.215)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007501)
Learning rate = [0.003925133439434832, 0.003925133439434832]	Loss = 0.84098959 (ave = 0.73249678)

2023-07-05 23:35:25,597 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25860	Time 12.311s / 10iters, (1.231)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.873s / 10iters, (0.287)	Data load 0.080s / 10iters, (0.008023)
Learning rate = [0.003922636976325095, 0.003922636976325095]	Loss = 0.74274743 (ave = 0.76004318)

2023-07-05 23:35:37,816 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25870	Time 12.219s / 10iters, (1.222)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.818s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007506)
Learning rate = [0.003920140336668324, 0.003920140336668324]	Loss = 0.69655347 (ave = 0.75834684)

2023-07-05 23:35:50,082 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25880	Time 12.265s / 10iters, (1.227)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007617)
Learning rate = [0.003917643520327085, 0.003917643520327085]	Loss = 0.75369400 (ave = 0.75003743)

2023-07-05 23:36:02,306 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25890	Time 12.224s / 10iters, (1.222)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.815s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007609)
Learning rate = [0.003915146527163739, 0.003915146527163739]	Loss = 0.81208622 (ave = 0.72830647)

2023-07-05 23:36:14,598 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25900	Time 12.292s / 10iters, (1.229)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007458)
Learning rate = [0.003912649357040444, 0.003912649357040444]	Loss = 0.68957722 (ave = 0.71143441)

2023-07-05 23:36:26,867 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25910	Time 12.268s / 10iters, (1.227)	Forward Time 1.141s / 10iters, (0.114)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.820s / 10iters, (0.282)	Data load 0.088s / 10iters, (0.008764)
Learning rate = [0.003910152009819148, 0.003910152009819148]	Loss = 0.77485263 (ave = 0.74150813)

2023-07-05 23:36:39,181 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25920	Time 12.314s / 10iters, (1.231)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.081s / 10iters, (0.008131)
Learning rate = [0.003907654485361599, 0.003907654485361599]	Loss = 0.98263329 (ave = 0.78595804)

2023-07-05 23:36:51,548 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25930	Time 12.367s / 10iters, (1.237)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.100s / 10iters, (0.009956)
Learning rate = [0.003905156783529333, 0.003905156783529333]	Loss = 0.70617318 (ave = 0.77524658)

2023-07-05 23:37:03,840 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25940	Time 12.292s / 10iters, (1.229)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.084s / 10iters, (0.008351)
Learning rate = [0.003902658904183685, 0.003902658904183685]	Loss = 0.80834484 (ave = 0.78725821)

2023-07-05 23:37:16,066 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25950	Time 12.226s / 10iters, (1.223)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.198s / 10iters, (0.820)	Loss Time 2.815s / 10iters, (0.282)	Data load 0.090s / 10iters, (0.008963)
Learning rate = [0.00390016084718578, 0.00390016084718578]	Loss = 0.67900926 (ave = 0.77295523)

2023-07-05 23:37:28,161 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25960	Time 12.095s / 10iters, (1.210)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.173s / 10iters, (0.817)	Loss Time 2.757s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007436)
Learning rate = [0.003897662612396536, 0.003897662612396536]	Loss = 0.82367146 (ave = 0.73656200)

2023-07-05 23:37:40,179 INFO    [trainer_contrastive.py, 272] Train Epoch: 69	Train Iteration: 25970	Time 12.017s / 10iters, (1.202)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.132s / 10iters, (0.813)	Loss Time 2.721s / 10iters, (0.272)	Data load 0.077s / 10iters, (0.007663)
Learning rate = [0.00389516419967666, 0.00389516419967666]	Loss = 0.64577961 (ave = 0.73224573)

2023-07-05 23:37:55,810 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 25980	Time 15.410s / 10iters, (1.541)	Forward Time 1.206s / 10iters, (0.121)	Backward Time 8.351s / 10iters, (0.835)	Loss Time 2.825s / 10iters, (0.283)	Data load 3.028s / 10iters, (0.302780)
Learning rate = [0.003892665608886657, 0.003892665608886657]	Loss = 0.60886723 (ave = 0.73676382)

2023-07-05 23:38:08,005 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 25990	Time 12.195s / 10iters, (1.219)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.255s / 10iters, (0.826)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.085s / 10iters, (0.008483)
Learning rate = [0.0038901668398868172, 0.0038901668398868172]	Loss = 0.72131443 (ave = 0.71382985)

2023-07-05 23:38:20,218 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26000	Time 12.213s / 10iters, (1.221)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.763s / 10iters, (0.276)	Data load 0.077s / 10iters, (0.007729)
Learning rate = [0.003887667892537224, 0.003887667892537224]	Loss = 0.68342102 (ave = 0.72316914)

2023-07-05 23:38:23,575 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-05 23:38:47,354 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-05 23:39:10,558 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-05 23:39:33,850 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-05 23:39:57,590 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-05 23:40:21,173 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-05 23:40:43,712 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-05 23:40:49,418 INFO    [base.py, 84] Performance 0.7337941978231273 -> 0.7380807594131795
2023-07-05 23:40:55,197 INFO    [trainer_contrastive.py, 391] Test Time 149.016s, (2.365)	Loss 0.13607436

2023-07-05 23:40:55,197 INFO    [base.py, 33] Result for seg
2023-07-05 23:40:55,199 INFO    [base.py, 49] Mean IOU: 0.7380807594131795

2023-07-05 23:40:55,201 INFO    [base.py, 50] Pixel ACC: 0.9574346815596212

2023-07-05 23:41:07,358 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26010	Time 167.140s / 10iters, (16.714)	Forward Time 1.147s / 10iters, (0.115)	Backward Time 8.236s / 10iters, (0.824)	Loss Time 2.672s / 10iters, (0.267)	Data load 155.086s / 10iters, (15.508585)
Learning rate = [0.003885168766697749, 0.003885168766697749]	Loss = 0.67017698 (ave = 0.72556525)

2023-07-05 23:41:19,486 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26020	Time 12.128s / 10iters, (1.213)	Forward Time 1.077s / 10iters, (0.108)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.703s / 10iters, (0.270)	Data load 0.074s / 10iters, (0.007446)
Learning rate = [0.003882669462228058, 0.003882669462228058]	Loss = 0.70444280 (ave = 0.71542205)

2023-07-05 23:41:31,603 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26030	Time 12.116s / 10iters, (1.212)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.181s / 10iters, (0.818)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.078s / 10iters, (0.007784)
Learning rate = [0.0038801699789876003, 0.0038801699789876003]	Loss = 1.33996272 (ave = 0.79549800)

2023-07-05 23:41:43,651 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26040	Time 12.048s / 10iters, (1.205)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.155s / 10iters, (0.816)	Loss Time 2.722s / 10iters, (0.272)	Data load 0.075s / 10iters, (0.007475)
Learning rate = [0.0038776703168356174, 0.0038776703168356174]	Loss = 0.67269427 (ave = 0.77902774)

2023-07-05 23:41:55,639 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26050	Time 11.988s / 10iters, (1.199)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.116s / 10iters, (0.812)	Loss Time 2.696s / 10iters, (0.270)	Data load 0.078s / 10iters, (0.007814)
Learning rate = [0.003875170475631138, 0.003875170475631138]	Loss = 0.76218313 (ave = 0.77016374)

2023-07-05 23:42:07,676 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26060	Time 12.037s / 10iters, (1.204)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.155s / 10iters, (0.815)	Loss Time 2.715s / 10iters, (0.271)	Data load 0.075s / 10iters, (0.007456)
Learning rate = [0.003872670455232979, 0.003872670455232979]	Loss = 1.02003372 (ave = 0.77136576)

2023-07-05 23:42:19,912 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26070	Time 12.236s / 10iters, (1.224)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.198s / 10iters, (0.820)	Loss Time 2.872s / 10iters, (0.287)	Data load 0.076s / 10iters, (0.007645)
Learning rate = [0.0038701702554997447, 0.0038701702554997447]	Loss = 0.65744317 (ave = 0.72238104)

2023-07-05 23:42:32,253 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26080	Time 12.342s / 10iters, (1.234)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.320s / 10iters, (0.832)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007445)
Learning rate = [0.003867669876289826, 0.003867669876289826]	Loss = 0.66019398 (ave = 0.71693402)

2023-07-05 23:42:44,680 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26090	Time 12.426s / 10iters, (1.243)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.383s / 10iters, (0.838)	Loss Time 2.850s / 10iters, (0.285)	Data load 0.080s / 10iters, (0.008027)
Learning rate = [0.003865169317461398, 0.003865169317461398]	Loss = 0.65131819 (ave = 0.77989695)

2023-07-05 23:42:56,903 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26100	Time 12.224s / 10iters, (1.222)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.080s / 10iters, (0.007960)
Learning rate = [0.003862668578872427, 0.003862668578872427]	Loss = 0.59605438 (ave = 0.73331934)

2023-07-05 23:43:09,192 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26110	Time 12.289s / 10iters, (1.229)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.253s / 10iters, (0.825)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.086s / 10iters, (0.008619)
Learning rate = [0.00386016766038066, 0.00386016766038066]	Loss = 0.66970980 (ave = 0.75949866)

2023-07-05 23:43:21,365 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26120	Time 12.173s / 10iters, (1.217)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.180s / 10iters, (0.818)	Loss Time 2.809s / 10iters, (0.281)	Data load 0.085s / 10iters, (0.008530)
Learning rate = [0.0038576665618436307, 0.0038576665618436307]	Loss = 0.78894150 (ave = 0.77074170)

2023-07-05 23:43:33,634 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26130	Time 12.270s / 10iters, (1.227)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007488)
Learning rate = [0.003855165283118657, 0.003855165283118657]	Loss = 0.69486642 (ave = 0.70704104)

2023-07-05 23:43:45,914 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26140	Time 12.279s / 10iters, (1.228)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.219s / 10iters, (0.822)	Loss Time 2.887s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007494)
Learning rate = [0.0038526638240628393, 0.0038526638240628393]	Loss = 0.75803387 (ave = 0.80330302)

2023-07-05 23:43:58,247 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26150	Time 12.333s / 10iters, (1.233)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.255s / 10iters, (0.826)	Loss Time 2.879s / 10iters, (0.288)	Data load 0.108s / 10iters, (0.010792)
Learning rate = [0.0038501621845330658, 0.0038501621845330658]	Loss = 0.77352911 (ave = 0.70035570)

2023-07-05 23:44:10,448 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26160	Time 12.201s / 10iters, (1.220)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.189s / 10iters, (0.819)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.083s / 10iters, (0.008297)
Learning rate = [0.0038476603643860037, 0.0038476603643860037]	Loss = 0.72936654 (ave = 0.74317323)

2023-07-05 23:44:22,765 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26170	Time 12.317s / 10iters, (1.232)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.286s / 10iters, (0.829)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.076s / 10iters, (0.007623)
Learning rate = [0.003845158363478104, 0.003845158363478104]	Loss = 0.82014000 (ave = 0.76488038)

2023-07-05 23:44:34,925 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26180	Time 12.159s / 10iters, (1.216)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.155s / 10iters, (0.815)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007513)
Learning rate = [0.003842656181665598, 0.003842656181665598]	Loss = 0.63021797 (ave = 0.70526574)

2023-07-05 23:44:47,075 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26190	Time 12.151s / 10iters, (1.215)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.151s / 10iters, (0.815)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.086s / 10iters, (0.008566)
Learning rate = [0.003840153818804503, 0.003840153818804503]	Loss = 0.66597897 (ave = 0.74776635)

2023-07-05 23:44:59,435 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26200	Time 12.360s / 10iters, (1.236)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.878s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007483)
Learning rate = [0.003837651274750614, 0.003837651274750614]	Loss = 0.70788193 (ave = 0.80451276)

2023-07-05 23:45:11,650 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26210	Time 12.215s / 10iters, (1.221)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.186s / 10iters, (0.819)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.098s / 10iters, (0.009809)
Learning rate = [0.0038351485493595063, 0.0038351485493595063]	Loss = 0.69274366 (ave = 0.74857017)

2023-07-05 23:45:23,874 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26220	Time 12.224s / 10iters, (1.222)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.077s / 10iters, (0.007747)
Learning rate = [0.003832645642486535, 0.003832645642486535]	Loss = 0.86506486 (ave = 0.77038814)

2023-07-05 23:45:36,057 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26230	Time 12.183s / 10iters, (1.218)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.178s / 10iters, (0.818)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007525)
Learning rate = [0.0038301425539868385, 0.0038301425539868385]	Loss = 0.72508478 (ave = 0.79422518)

2023-07-05 23:45:48,269 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26240	Time 12.213s / 10iters, (1.221)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.189s / 10iters, (0.819)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007443)
Learning rate = [0.0038276392837153306, 0.0038276392837153306]	Loss = 0.67837226 (ave = 0.72020231)

2023-07-05 23:46:00,504 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26250	Time 12.234s / 10iters, (1.223)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.203s / 10iters, (0.820)	Loss Time 2.855s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007458)
Learning rate = [0.003825135831526705, 0.003825135831526705]	Loss = 0.80402601 (ave = 0.70324348)

2023-07-05 23:46:12,899 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26260	Time 12.395s / 10iters, (1.239)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.896s / 10iters, (0.290)	Data load 0.085s / 10iters, (0.008482)
Learning rate = [0.003822632197275432, 0.003822632197275432]	Loss = 0.64641720 (ave = 0.74945644)

2023-07-05 23:46:25,347 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26270	Time 12.448s / 10iters, (1.245)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.312s / 10iters, (0.831)	Loss Time 2.934s / 10iters, (0.293)	Data load 0.087s / 10iters, (0.008748)
Learning rate = [0.003820128380815762, 0.003820128380815762]	Loss = 0.81022441 (ave = 0.76616456)

2023-07-05 23:46:37,751 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26280	Time 12.405s / 10iters, (1.240)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.919s / 10iters, (0.292)	Data load 0.080s / 10iters, (0.007967)
Learning rate = [0.003817624382001722, 0.003817624382001722]	Loss = 0.77003878 (ave = 0.76448105)

2023-07-05 23:46:50,137 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26290	Time 12.385s / 10iters, (1.239)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.896s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007455)
Learning rate = [0.003815120200687113, 0.003815120200687113]	Loss = 0.76598322 (ave = 0.76076702)

2023-07-05 23:47:02,416 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26300	Time 12.279s / 10iters, (1.228)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.861s / 10iters, (0.286)	Data load 0.078s / 10iters, (0.007830)
Learning rate = [0.003812615836725514, 0.003812615836725514]	Loss = 0.72561049 (ave = 0.74391099)

2023-07-05 23:47:14,739 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26310	Time 12.323s / 10iters, (1.232)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007447)
Learning rate = [0.003810111289970282, 0.003810111289970282]	Loss = 0.77677280 (ave = 0.69878689)

2023-07-05 23:47:27,404 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26320	Time 12.664s / 10iters, (1.266)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.506s / 10iters, (0.851)	Loss Time 2.950s / 10iters, (0.295)	Data load 0.087s / 10iters, (0.008727)
Learning rate = [0.0038076065602745436, 0.0038076065602745436]	Loss = 0.71525717 (ave = 0.78925399)

2023-07-05 23:47:39,731 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26330	Time 12.328s / 10iters, (1.233)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007379)
Learning rate = [0.0038051016474912043, 0.0038051016474912043]	Loss = 0.82311267 (ave = 0.77679137)

2023-07-05 23:47:51,829 INFO    [trainer_contrastive.py, 272] Train Epoch: 70	Train Iteration: 26340	Time 12.098s / 10iters, (1.210)	Forward Time 1.081s / 10iters, (0.108)	Backward Time 8.189s / 10iters, (0.819)	Loss Time 2.751s / 10iters, (0.275)	Data load 0.076s / 10iters, (0.007637)
Learning rate = [0.003802596551472941, 0.003802596551472941]	Loss = 0.79454744 (ave = 0.83270611)

2023-07-05 23:48:07,221 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26350	Time 15.182s / 10iters, (1.518)	Forward Time 1.275s / 10iters, (0.127)	Backward Time 8.406s / 10iters, (0.841)	Loss Time 2.714s / 10iters, (0.271)	Data load 2.788s / 10iters, (0.278845)
Learning rate = [0.003800091272072207, 0.003800091272072207]	Loss = 0.72705168 (ave = 0.74116339)

2023-07-05 23:48:19,522 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26360	Time 12.301s / 10iters, (1.230)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.326s / 10iters, (0.833)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007573)
Learning rate = [0.0037975858091412263, 0.0037975858091412263]	Loss = 0.67908895 (ave = 0.72163340)

2023-07-05 23:48:32,014 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26370	Time 12.492s / 10iters, (1.249)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.488s / 10iters, (0.849)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.110s / 10iters, (0.011020)
Learning rate = [0.003795080162531996, 0.003795080162531996]	Loss = 0.83480859 (ave = 0.74101068)

2023-07-05 23:48:44,472 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26380	Time 12.458s / 10iters, (1.246)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.470s / 10iters, (0.847)	Loss Time 2.785s / 10iters, (0.279)	Data load 0.076s / 10iters, (0.007616)
Learning rate = [0.0037925743320962836, 0.0037925743320962836]	Loss = 0.84078109 (ave = 0.76152111)

2023-07-05 23:48:56,777 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26390	Time 12.306s / 10iters, (1.231)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.356s / 10iters, (0.836)	Loss Time 2.752s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007458)
Learning rate = [0.0037900683176856327, 0.0037900683176856327]	Loss = 0.73304486 (ave = 0.74818809)

2023-07-05 23:49:09,237 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26400	Time 12.460s / 10iters, (1.246)	Forward Time 1.149s / 10iters, (0.115)	Backward Time 8.452s / 10iters, (0.845)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.076s / 10iters, (0.007639)
Learning rate = [0.003787562119151353, 0.003787562119151353]	Loss = 0.71515340 (ave = 0.78958743)

2023-07-05 23:49:21,557 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26410	Time 12.320s / 10iters, (1.232)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.351s / 10iters, (0.835)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.087s / 10iters, (0.008738)
Learning rate = [0.0037850557363445264, 0.0037850557363445264]	Loss = 0.83315587 (ave = 0.72241240)

2023-07-05 23:49:33,826 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26420	Time 12.269s / 10iters, (1.227)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.090s / 10iters, (0.009022)
Learning rate = [0.0037825491691160043, 0.0037825491691160043]	Loss = 0.60328794 (ave = 0.74465269)

2023-07-05 23:49:46,144 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26430	Time 12.318s / 10iters, (1.232)	Forward Time 1.137s / 10iters, (0.114)	Backward Time 8.306s / 10iters, (0.831)	Loss Time 2.790s / 10iters, (0.279)	Data load 0.084s / 10iters, (0.008429)
Learning rate = [0.0037800424173164092, 0.0037800424173164092]	Loss = 0.70448381 (ave = 0.75981299)

2023-07-05 23:49:58,559 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26440	Time 12.415s / 10iters, (1.242)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.423s / 10iters, (0.842)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.089s / 10iters, (0.008897)
Learning rate = [0.003777535480796131, 0.003777535480796131]	Loss = 0.71275973 (ave = 0.73994773)

2023-07-05 23:50:10,897 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26450	Time 12.338s / 10iters, (1.234)	Forward Time 1.135s / 10iters, (0.114)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007517)
Learning rate = [0.0037750283594053277, 0.0037750283594053277]	Loss = 0.72661966 (ave = 0.73954579)

2023-07-05 23:50:23,209 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26460	Time 12.312s / 10iters, (1.231)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.096s / 10iters, (0.009560)
Learning rate = [0.0037725210529939235, 0.0037725210529939235]	Loss = 0.77702826 (ave = 0.69607450)

2023-07-05 23:50:35,528 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26470	Time 12.319s / 10iters, (1.232)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.328s / 10iters, (0.833)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.109s / 10iters, (0.010924)
Learning rate = [0.0037700135614116156, 0.0037700135614116156]	Loss = 0.70732915 (ave = 0.71451972)

2023-07-05 23:50:47,990 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26480	Time 12.462s / 10iters, (1.246)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.431s / 10iters, (0.843)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.099s / 10iters, (0.009931)
Learning rate = [0.0037675058845078615, 0.0037675058845078615]	Loss = 0.73243213 (ave = 0.74722707)

2023-07-05 23:51:00,334 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26490	Time 12.344s / 10iters, (1.234)	Forward Time 1.169s / 10iters, (0.117)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.090s / 10iters, (0.008991)
Learning rate = [0.0037649980221318873, 0.0037649980221318873]	Loss = 0.73650151 (ave = 0.74478392)

2023-07-05 23:51:12,881 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26500	Time 12.547s / 10iters, (1.255)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.478s / 10iters, (0.848)	Loss Time 2.872s / 10iters, (0.287)	Data load 0.083s / 10iters, (0.008277)
Learning rate = [0.003762489974132685, 0.003762489974132685]	Loss = 0.74487364 (ave = 0.78549581)

2023-07-05 23:51:25,414 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26510	Time 12.533s / 10iters, (1.253)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.508s / 10iters, (0.851)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.080s / 10iters, (0.007996)
Learning rate = [0.0037599817403590136, 0.0037599817403590136]	Loss = 0.70953721 (ave = 0.71369165)

2023-07-05 23:51:37,721 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26520	Time 12.307s / 10iters, (1.231)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.101s / 10iters, (0.010083)
Learning rate = [0.003757473320659393, 0.003757473320659393]	Loss = 0.82212859 (ave = 0.75365517)

2023-07-05 23:51:50,191 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26530	Time 12.470s / 10iters, (1.247)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.401s / 10iters, (0.840)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.105s / 10iters, (0.010532)
Learning rate = [0.0037549647148821096, 0.0037549647148821096]	Loss = 0.68486911 (ave = 0.70539106)

2023-07-05 23:52:02,624 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26540	Time 12.433s / 10iters, (1.243)	Forward Time 1.140s / 10iters, (0.114)	Backward Time 8.341s / 10iters, (0.834)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.092s / 10iters, (0.009158)
Learning rate = [0.0037524559228752103, 0.0037524559228752103]	Loss = 0.81453067 (ave = 0.72140269)

2023-07-05 23:52:15,034 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26550	Time 12.410s / 10iters, (1.241)	Forward Time 1.135s / 10iters, (0.114)	Backward Time 8.356s / 10iters, (0.836)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.086s / 10iters, (0.008625)
Learning rate = [0.0037499469444865104, 0.0037499469444865104]	Loss = 0.80962193 (ave = 0.74306949)

2023-07-05 23:52:27,620 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26560	Time 12.586s / 10iters, (1.259)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.492s / 10iters, (0.849)	Loss Time 2.892s / 10iters, (0.289)	Data load 0.084s / 10iters, (0.008428)
Learning rate = [0.0037474377795635823, 0.0037474377795635823]	Loss = 0.67458749 (ave = 0.78075307)

2023-07-05 23:52:40,032 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26570	Time 12.412s / 10iters, (1.241)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.342s / 10iters, (0.834)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.076s / 10iters, (0.007612)
Learning rate = [0.0037449284279537634, 0.0037449284279537634]	Loss = 0.72924387 (ave = 0.74363168)

2023-07-05 23:52:52,571 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26580	Time 12.539s / 10iters, (1.254)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.449s / 10iters, (0.845)	Loss Time 2.898s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007477)
Learning rate = [0.0037424188895041487, 0.0037424188895041487]	Loss = 0.75047410 (ave = 0.79712616)

2023-07-05 23:53:04,956 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26590	Time 12.385s / 10iters, (1.239)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.334s / 10iters, (0.833)	Loss Time 2.848s / 10iters, (0.285)	Data load 0.093s / 10iters, (0.009325)
Learning rate = [0.0037399091640615994, 0.0037399091640615994]	Loss = 0.86843014 (ave = 0.73095372)

2023-07-05 23:53:17,491 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26600	Time 12.535s / 10iters, (1.253)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.425s / 10iters, (0.842)	Loss Time 2.933s / 10iters, (0.293)	Data load 0.074s / 10iters, (0.007421)
Learning rate = [0.003737399251472734, 0.003737399251472734]	Loss = 0.78754950 (ave = 0.74231290)

2023-07-05 23:53:29,907 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26610	Time 12.416s / 10iters, (1.242)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.855s / 10iters, (0.286)	Data load 0.087s / 10iters, (0.008700)
Learning rate = [0.003734889151583929, 0.003734889151583929]	Loss = 0.64286506 (ave = 0.68569956)

2023-07-05 23:53:42,375 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26620	Time 12.468s / 10iters, (1.247)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.422s / 10iters, (0.842)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007601)
Learning rate = [0.003732378864241321, 0.003732378864241321]	Loss = 0.71871507 (ave = 0.72729827)

2023-07-05 23:53:54,931 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26630	Time 12.556s / 10iters, (1.256)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.456s / 10iters, (0.846)	Loss Time 2.909s / 10iters, (0.291)	Data load 0.076s / 10iters, (0.007589)
Learning rate = [0.0037298683892908083, 0.0037298683892908083]	Loss = 0.69071037 (ave = 0.73053519)

2023-07-05 23:54:07,383 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26640	Time 12.452s / 10iters, (1.245)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.389s / 10iters, (0.839)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.090s / 10iters, (0.008986)
Learning rate = [0.0037273577265780427, 0.0037273577265780427]	Loss = 0.83149660 (ave = 0.70215261)

2023-07-05 23:54:19,887 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26650	Time 12.504s / 10iters, (1.250)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.382s / 10iters, (0.838)	Loss Time 2.886s / 10iters, (0.289)	Data load 0.113s / 10iters, (0.011281)
Learning rate = [0.0037248468759484366, 0.0037248468759484366]	Loss = 0.70591283 (ave = 0.73531554)

2023-07-05 23:54:32,332 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26660	Time 12.445s / 10iters, (1.244)	Forward Time 1.159s / 10iters, (0.116)	Backward Time 8.336s / 10iters, (0.834)	Loss Time 2.845s / 10iters, (0.284)	Data load 0.104s / 10iters, (0.010432)
Learning rate = [0.003722335837247156, 0.003722335837247156]	Loss = 0.68784446 (ave = 0.72457462)

2023-07-05 23:54:44,719 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26670	Time 12.387s / 10iters, (1.239)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.332s / 10iters, (0.833)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.093s / 10iters, (0.009339)
Learning rate = [0.003719824610319127, 0.003719824610319127]	Loss = 0.57084668 (ave = 0.75329763)

2023-07-05 23:54:57,246 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26680	Time 12.527s / 10iters, (1.253)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.428s / 10iters, (0.843)	Loss Time 2.890s / 10iters, (0.289)	Data load 0.088s / 10iters, (0.008751)
Learning rate = [0.0037173131950090288, 0.0037173131950090288]	Loss = 0.68994701 (ave = 0.69778795)

2023-07-05 23:55:09,702 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26690	Time 12.456s / 10iters, (1.246)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.402s / 10iters, (0.840)	Loss Time 2.869s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007498)
Learning rate = [0.0037148015911612963, 0.0037148015911612963]	Loss = 0.67912030 (ave = 0.74820232)

2023-07-05 23:55:21,977 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26700	Time 12.275s / 10iters, (1.227)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.278s / 10iters, (0.828)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.084s / 10iters, (0.008429)
Learning rate = [0.003712289798620118, 0.003712289798620118]	Loss = 0.65966195 (ave = 0.73049871)

2023-07-05 23:55:34,029 INFO    [trainer_contrastive.py, 272] Train Epoch: 71	Train Iteration: 26710	Time 12.052s / 10iters, (1.205)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.163s / 10iters, (0.816)	Loss Time 2.733s / 10iters, (0.273)	Data load 0.076s / 10iters, (0.007604)
Learning rate = [0.0037097778172294404, 0.0037097778172294404]	Loss = 0.81180847 (ave = 0.73540419)

2023-07-05 23:55:49,479 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26720	Time 15.255s / 10iters, (1.526)	Forward Time 1.174s / 10iters, (0.117)	Backward Time 8.187s / 10iters, (0.819)	Loss Time 2.789s / 10iters, (0.279)	Data load 3.106s / 10iters, (0.310588)
Learning rate = [0.0037072656468329587, 0.0037072656468329587]	Loss = 0.73961973 (ave = 0.76911180)

2023-07-05 23:56:01,782 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26730	Time 12.303s / 10iters, (1.230)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.835s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007478)
Learning rate = [0.0037047532872741223, 0.0037047532872741223]	Loss = 0.71884286 (ave = 0.76326634)

2023-07-05 23:56:14,253 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26740	Time 12.471s / 10iters, (1.247)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.438s / 10iters, (0.844)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.110s / 10iters, (0.010962)
Learning rate = [0.0037022407383961327, 0.0037022407383961327]	Loss = 0.77228093 (ave = 0.73692608)

2023-07-05 23:56:26,465 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26750	Time 12.211s / 10iters, (1.221)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.085s / 10iters, (0.008467)
Learning rate = [0.0036997280000419463, 0.0036997280000419463]	Loss = 0.71611279 (ave = 0.73937809)

2023-07-05 23:56:38,725 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26760	Time 12.260s / 10iters, (1.226)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.278s / 10iters, (0.828)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.093s / 10iters, (0.009305)
Learning rate = [0.0036972150720542664, 0.0036972150720542664]	Loss = 0.80597204 (ave = 0.71014696)

2023-07-05 23:56:50,975 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26770	Time 12.251s / 10iters, (1.225)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.287s / 10iters, (0.829)	Loss Time 2.766s / 10iters, (0.277)	Data load 0.091s / 10iters, (0.009064)
Learning rate = [0.003694701954275549, 0.003694701954275549]	Loss = 0.68426293 (ave = 0.70673207)

2023-07-05 23:57:03,184 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26780	Time 12.208s / 10iters, (1.221)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.081s / 10iters, (0.008066)
Learning rate = [0.0036921886465479978, 0.0036921886465479978]	Loss = 0.76111817 (ave = 0.74947280)

2023-07-05 23:57:15,518 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26790	Time 12.335s / 10iters, (1.233)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.339s / 10iters, (0.834)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.092s / 10iters, (0.009172)
Learning rate = [0.003689675148713569, 0.003689675148713569]	Loss = 0.78313792 (ave = 0.74496287)

2023-07-05 23:57:27,800 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26800	Time 12.282s / 10iters, (1.228)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.086s / 10iters, (0.008570)
Learning rate = [0.003687161460613967, 0.003687161460613967]	Loss = 0.69414020 (ave = 0.74355184)

2023-07-05 23:57:40,109 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26810	Time 12.309s / 10iters, (1.231)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.307s / 10iters, (0.831)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007453)
Learning rate = [0.0036846475820906423, 0.0036846475820906423]	Loss = 0.82971162 (ave = 0.75677373)

2023-07-05 23:57:52,541 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26820	Time 12.433s / 10iters, (1.243)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.393s / 10iters, (0.839)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.089s / 10iters, (0.008889)
Learning rate = [0.003682133512984793, 0.003682133512984793]	Loss = 0.84564650 (ave = 0.76229137)

2023-07-05 23:58:04,849 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26830	Time 12.307s / 10iters, (1.231)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007457)
Learning rate = [0.003679619253137367, 0.003679619253137367]	Loss = 0.75293368 (ave = 0.78528498)

2023-07-05 23:58:17,139 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26840	Time 12.291s / 10iters, (1.229)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.083s / 10iters, (0.008320)
Learning rate = [0.0036771048023890567, 0.0036771048023890567]	Loss = 0.58420074 (ave = 0.72327145)

2023-07-05 23:58:29,415 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26850	Time 12.276s / 10iters, (1.228)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.835s / 10iters, (0.284)	Data load 0.098s / 10iters, (0.009815)
Learning rate = [0.0036745901605803005, 0.0036745901605803005]	Loss = 0.80555832 (ave = 0.72573254)

2023-07-05 23:58:41,652 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26860	Time 12.237s / 10iters, (1.224)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.098s / 10iters, (0.009803)
Learning rate = [0.0036720753275512807, 0.0036720753275512807]	Loss = 0.65376198 (ave = 0.74289463)

2023-07-05 23:58:53,893 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26870	Time 12.241s / 10iters, (1.224)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.081s / 10iters, (0.008069)
Learning rate = [0.003669560303141928, 0.003669560303141928]	Loss = 0.65345132 (ave = 0.70638395)

2023-07-05 23:59:06,230 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26880	Time 12.337s / 10iters, (1.234)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.079s / 10iters, (0.007871)
Learning rate = [0.0036670450871919124, 0.0036670450871919124]	Loss = 0.72727388 (ave = 0.80527189)

2023-07-05 23:59:18,536 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26890	Time 12.306s / 10iters, (1.231)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.090s / 10iters, (0.008955)
Learning rate = [0.003664529679540651, 0.003664529679540651]	Loss = 0.94699359 (ave = 0.72703928)

2023-07-05 23:59:30,808 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26900	Time 12.273s / 10iters, (1.227)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.848s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007581)
Learning rate = [0.0036620140800273, 0.0036620140800273]	Loss = 0.82419032 (ave = 0.72798344)

2023-07-05 23:59:43,056 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26910	Time 12.248s / 10iters, (1.225)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.223s / 10iters, (0.822)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.077s / 10iters, (0.007736)
Learning rate = [0.003659498288490763, 0.003659498288490763]	Loss = 0.71338630 (ave = 0.72975404)

2023-07-05 23:59:55,417 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26920	Time 12.361s / 10iters, (1.236)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007530)
Learning rate = [0.00365698230476968, 0.00365698230476968]	Loss = 0.70732033 (ave = 0.73096485)

2023-07-06 00:00:07,887 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26930	Time 12.469s / 10iters, (1.247)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.365s / 10iters, (0.837)	Loss Time 2.904s / 10iters, (0.290)	Data load 0.086s / 10iters, (0.008588)
Learning rate = [0.003654466128702435, 0.003654466128702435]	Loss = 0.69682008 (ave = 0.74726443)

2023-07-06 00:00:20,163 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26940	Time 12.276s / 10iters, (1.228)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.855s / 10iters, (0.285)	Data load 0.087s / 10iters, (0.008724)
Learning rate = [0.0036519497601271494, 0.0036519497601271494]	Loss = 0.70979244 (ave = 0.75775129)

2023-07-06 00:00:32,655 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26950	Time 12.492s / 10iters, (1.249)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.426s / 10iters, (0.843)	Loss Time 2.872s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007543)
Learning rate = [0.00364943319888169, 0.00364943319888169]	Loss = 0.70117807 (ave = 0.73975024)

2023-07-06 00:00:44,910 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26960	Time 12.254s / 10iters, (1.225)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.207s / 10iters, (0.821)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.092s / 10iters, (0.009171)
Learning rate = [0.003646916444803656, 0.003646916444803656]	Loss = 0.72428012 (ave = 0.75639184)

2023-07-06 00:00:57,275 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26970	Time 12.366s / 10iters, (1.237)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.304s / 10iters, (0.830)	Loss Time 2.870s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007477)
Learning rate = [0.0036443994977303894, 0.0036443994977303894]	Loss = 0.87818551 (ave = 0.74444539)

2023-07-06 00:01:09,550 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26980	Time 12.274s / 10iters, (1.227)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.227s / 10iters, (0.823)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007506)
Learning rate = [0.0036418823574989674, 0.0036418823574989674]	Loss = 0.69872051 (ave = 0.74978433)

2023-07-06 00:01:21,904 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 26990	Time 12.354s / 10iters, (1.235)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.272s / 10iters, (0.827)	Loss Time 2.881s / 10iters, (0.288)	Data load 0.097s / 10iters, (0.009667)
Learning rate = [0.0036393650239462073, 0.0036393650239462073]	Loss = 0.84396905 (ave = 0.79281235)

2023-07-06 00:01:34,300 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 27000	Time 12.397s / 10iters, (1.240)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.865s / 10iters, (0.287)	Data load 0.084s / 10iters, (0.008369)
Learning rate = [0.0036368474969086613, 0.0036368474969086613]	Loss = 0.88523901 (ave = 0.81535203)

2023-07-06 00:01:39,504 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-06 00:02:03,117 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-06 00:02:26,396 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-06 00:02:49,892 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-06 00:03:13,431 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-06 00:03:36,305 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-06 00:03:58,628 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-06 00:04:04,371 INFO    [base.py, 84] Performance 0.7380807594131795 -> 0.7425268176200625
2023-07-06 00:04:08,672 INFO    [trainer_contrastive.py, 391] Test Time 149.892s, (2.379)	Loss 0.14138655

2023-07-06 00:04:08,672 INFO    [base.py, 33] Result for seg
2023-07-06 00:04:08,673 INFO    [base.py, 49] Mean IOU: 0.7425268176200625

2023-07-06 00:04:08,673 INFO    [base.py, 50] Pixel ACC: 0.9542378954149964

2023-07-06 00:04:20,733 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 27010	Time 166.433s / 10iters, (16.643)	Forward Time 1.144s / 10iters, (0.114)	Backward Time 8.169s / 10iters, (0.817)	Loss Time 2.658s / 10iters, (0.266)	Data load 154.462s / 10iters, (15.446172)
Learning rate = [0.0036343297762226174, 0.0036343297762226174]	Loss = 0.60024112 (ave = 0.76350060)

2023-07-06 00:04:32,788 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 27020	Time 12.055s / 10iters, (1.205)	Forward Time 1.138s / 10iters, (0.114)	Backward Time 8.199s / 10iters, (0.820)	Loss Time 2.633s / 10iters, (0.263)	Data load 0.085s / 10iters, (0.008460)
Learning rate = [0.003631811861724098, 0.003631811861724098]	Loss = 0.92087209 (ave = 0.77766941)

2023-07-06 00:04:44,863 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 27030	Time 12.075s / 10iters, (1.207)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.170s / 10iters, (0.817)	Loss Time 2.706s / 10iters, (0.271)	Data load 0.101s / 10iters, (0.010105)
Learning rate = [0.003629293753248864, 0.003629293753248864]	Loss = 0.75733984 (ave = 0.86576840)

2023-07-06 00:04:57,090 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 27040	Time 12.228s / 10iters, (1.223)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.769s / 10iters, (0.277)	Data load 0.094s / 10iters, (0.009422)
Learning rate = [0.0036267754506324073, 0.0036267754506324073]	Loss = 0.84559768 (ave = 0.77667793)

2023-07-06 00:05:09,154 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 27050	Time 12.064s / 10iters, (1.206)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.153s / 10iters, (0.815)	Loss Time 2.724s / 10iters, (0.272)	Data load 0.092s / 10iters, (0.009187)
Learning rate = [0.0036242569537099528, 0.0036242569537099528]	Loss = 0.75992948 (ave = 0.70868947)

2023-07-06 00:05:21,158 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 27060	Time 12.003s / 10iters, (1.200)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.171s / 10iters, (0.817)	Loss Time 2.671s / 10iters, (0.267)	Data load 0.075s / 10iters, (0.007469)
Learning rate = [0.003621738262316459, 0.003621738262316459]	Loss = 0.77353328 (ave = 0.72297342)

2023-07-06 00:05:33,154 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 27070	Time 11.996s / 10iters, (1.200)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.157s / 10iters, (0.816)	Loss Time 2.659s / 10iters, (0.266)	Data load 0.083s / 10iters, (0.008347)
Learning rate = [0.003619219376286618, 0.003619219376286618]	Loss = 0.82669878 (ave = 0.77257684)

2023-07-06 00:05:45,056 INFO    [trainer_contrastive.py, 272] Train Epoch: 72	Train Iteration: 27080	Time 11.902s / 10iters, (1.190)	Forward Time 1.073s / 10iters, (0.107)	Backward Time 8.101s / 10iters, (0.810)	Loss Time 2.652s / 10iters, (0.265)	Data load 0.076s / 10iters, (0.007595)
Learning rate = [0.003616700295454853, 0.003616700295454853]	Loss = 0.68557656 (ave = 0.77794356)

2023-07-06 00:06:00,358 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27090	Time 15.110s / 10iters, (1.511)	Forward Time 1.173s / 10iters, (0.117)	Backward Time 8.233s / 10iters, (0.823)	Loss Time 2.700s / 10iters, (0.270)	Data load 3.004s / 10iters, (0.300393)
Learning rate = [0.003614181019655316, 0.003614181019655316]	Loss = 0.80726027 (ave = 0.74541245)

2023-07-06 00:06:12,431 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27100	Time 12.073s / 10iters, (1.207)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.191s / 10iters, (0.819)	Loss Time 2.688s / 10iters, (0.269)	Data load 0.084s / 10iters, (0.008409)
Learning rate = [0.003611661548721889, 0.003611661548721889]	Loss = 0.88606024 (ave = 0.77166752)

2023-07-06 00:06:24,638 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27110	Time 12.207s / 10iters, (1.221)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.749s / 10iters, (0.275)	Data load 0.089s / 10iters, (0.008938)
Learning rate = [0.003609141882488189, 0.003609141882488189]	Loss = 0.76770222 (ave = 0.74057160)

2023-07-06 00:06:36,822 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27120	Time 12.184s / 10iters, (1.218)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.223s / 10iters, (0.822)	Loss Time 2.760s / 10iters, (0.276)	Data load 0.094s / 10iters, (0.009388)
Learning rate = [0.003606622020787556, 0.003606622020787556]	Loss = 0.85943496 (ave = 0.79477646)

2023-07-06 00:06:49,137 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27130	Time 12.315s / 10iters, (1.232)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.345s / 10iters, (0.835)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.082s / 10iters, (0.008178)
Learning rate = [0.00360410196345306, 0.00360410196345306]	Loss = 0.76257765 (ave = 0.79559730)

2023-07-06 00:07:01,334 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27140	Time 12.197s / 10iters, (1.220)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.792s / 10iters, (0.279)	Data load 0.086s / 10iters, (0.008552)
Learning rate = [0.0036015817103174992, 0.0036015817103174992]	Loss = 0.70772636 (ave = 0.75285370)

2023-07-06 00:07:13,453 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27150	Time 12.119s / 10iters, (1.212)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.153s / 10iters, (0.815)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.082s / 10iters, (0.008238)
Learning rate = [0.0035990612612134, 0.0035990612612134]	Loss = 0.72356105 (ave = 0.72632178)

2023-07-06 00:07:25,699 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27160	Time 12.247s / 10iters, (1.225)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.238s / 10iters, (0.824)	Loss Time 2.818s / 10iters, (0.282)	Data load 0.087s / 10iters, (0.008693)
Learning rate = [0.0035965406159730122, 0.0035965406159730122]	Loss = 0.80593979 (ave = 0.74121374)

2023-07-06 00:07:37,896 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27170	Time 12.196s / 10iters, (1.220)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.194s / 10iters, (0.819)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.078s / 10iters, (0.007826)
Learning rate = [0.0035940197744283135, 0.0035940197744283135]	Loss = 0.68771160 (ave = 0.69050941)

2023-07-06 00:07:50,203 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27180	Time 12.308s / 10iters, (1.231)	Forward Time 1.135s / 10iters, (0.114)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.084s / 10iters, (0.008394)
Learning rate = [0.0035914987364110045, 0.0035914987364110045]	Loss = 0.79005694 (ave = 0.73347319)

2023-07-06 00:08:02,387 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27190	Time 12.183s / 10iters, (1.218)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.724s / 10iters, (0.272)	Data load 0.098s / 10iters, (0.009768)
Learning rate = [0.0035889775017525147, 0.0035889775017525147]	Loss = 0.82699287 (ave = 0.72680935)

2023-07-06 00:08:14,588 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27200	Time 12.202s / 10iters, (1.220)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.760s / 10iters, (0.276)	Data load 0.076s / 10iters, (0.007615)
Learning rate = [0.003586456070283991, 0.003586456070283991]	Loss = 0.72735620 (ave = 0.75349036)

2023-07-06 00:08:26,792 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27210	Time 12.203s / 10iters, (1.220)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.750s / 10iters, (0.275)	Data load 0.092s / 10iters, (0.009209)
Learning rate = [0.003583934441836308, 0.003583934441836308]	Loss = 0.78111541 (ave = 0.73912528)

2023-07-06 00:08:39,127 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27220	Time 12.336s / 10iters, (1.234)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.379s / 10iters, (0.838)	Loss Time 2.752s / 10iters, (0.275)	Data load 0.091s / 10iters, (0.009054)
Learning rate = [0.0035814126162400585, 0.0035814126162400585]	Loss = 0.67915690 (ave = 0.69882010)

2023-07-06 00:08:51,178 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27230	Time 12.050s / 10iters, (1.205)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.161s / 10iters, (0.816)	Loss Time 2.691s / 10iters, (0.269)	Data load 0.094s / 10iters, (0.009447)
Learning rate = [0.0035788905933255627, 0.0035788905933255627]	Loss = 0.65361905 (ave = 0.67028670)

2023-07-06 00:09:03,343 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27240	Time 12.166s / 10iters, (1.217)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.238s / 10iters, (0.824)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.085s / 10iters, (0.008497)
Learning rate = [0.0035763683729228574, 0.0035763683729228574]	Loss = 0.73662484 (ave = 0.72879242)

2023-07-06 00:09:15,512 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27250	Time 12.169s / 10iters, (1.217)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007469)
Learning rate = [0.0035738459548617, 0.0035738459548617]	Loss = 0.68357921 (ave = 0.72943050)

2023-07-06 00:09:27,824 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27260	Time 12.312s / 10iters, (1.231)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.339s / 10iters, (0.834)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.076s / 10iters, (0.007560)
Learning rate = [0.003571323338971568, 0.003571323338971568]	Loss = 0.70829761 (ave = 0.72723610)

2023-07-06 00:09:40,155 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27270	Time 12.332s / 10iters, (1.233)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.341s / 10iters, (0.834)	Loss Time 2.816s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007561)
Learning rate = [0.0035688005250816596, 0.0035688005250816596]	Loss = 0.66579950 (ave = 0.73127463)

2023-07-06 00:09:52,451 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27280	Time 12.296s / 10iters, (1.230)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.285s / 10iters, (0.828)	Loss Time 2.786s / 10iters, (0.279)	Data load 0.090s / 10iters, (0.009046)
Learning rate = [0.0035662775130208897, 0.0035662775130208897]	Loss = 0.75580764 (ave = 0.73302479)

2023-07-06 00:10:04,751 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27290	Time 12.300s / 10iters, (1.230)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.295s / 10iters, (0.830)	Loss Time 2.818s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007584)
Learning rate = [0.0035637543026178892, 0.0035637543026178892]	Loss = 0.73309362 (ave = 0.71072541)

2023-07-06 00:10:17,085 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27300	Time 12.334s / 10iters, (1.233)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.082s / 10iters, (0.008186)
Learning rate = [0.003561230893701008, 0.003561230893701008]	Loss = 0.74584293 (ave = 0.71159181)

2023-07-06 00:10:29,526 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27310	Time 12.441s / 10iters, (1.244)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.386s / 10iters, (0.839)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.086s / 10iters, (0.008607)
Learning rate = [0.0035587072860983134, 0.0035587072860983134]	Loss = 0.66568971 (ave = 0.79187017)

2023-07-06 00:10:42,045 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27320	Time 12.519s / 10iters, (1.252)	Forward Time 1.145s / 10iters, (0.115)	Backward Time 8.480s / 10iters, (0.848)	Loss Time 2.818s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007560)
Learning rate = [0.003556183479637584, 0.003556183479637584]	Loss = 0.72861606 (ave = 0.74882037)

2023-07-06 00:10:54,360 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27330	Time 12.315s / 10iters, (1.231)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.333s / 10iters, (0.833)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007528)
Learning rate = [0.003553659474146318, 0.003553659474146318]	Loss = 0.72701621 (ave = 0.77336937)

2023-07-06 00:11:06,594 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27340	Time 12.234s / 10iters, (1.223)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.236s / 10iters, (0.824)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.079s / 10iters, (0.007916)
Learning rate = [0.003551135269451723, 0.003551135269451723]	Loss = 0.75795484 (ave = 0.72022214)

2023-07-06 00:11:18,846 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27350	Time 12.252s / 10iters, (1.225)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.085s / 10iters, (0.008502)
Learning rate = [0.0035486108653807243, 0.0035486108653807243]	Loss = 0.69990718 (ave = 0.70917153)

2023-07-06 00:11:31,092 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27360	Time 12.246s / 10iters, (1.225)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.235s / 10iters, (0.824)	Loss Time 2.818s / 10iters, (0.282)	Data load 0.079s / 10iters, (0.007877)
Learning rate = [0.003546086261759957, 0.003546086261759957]	Loss = 0.65776742 (ave = 0.73476623)

2023-07-06 00:11:43,431 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27370	Time 12.339s / 10iters, (1.234)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007473)
Learning rate = [0.0035435614584157695, 0.0035435614584157695]	Loss = 0.64629430 (ave = 0.73013651)

2023-07-06 00:11:55,809 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27380	Time 12.378s / 10iters, (1.238)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.358s / 10iters, (0.836)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007601)
Learning rate = [0.003541036455174221, 0.003541036455174221]	Loss = 0.79882908 (ave = 0.79493834)

2023-07-06 00:12:08,122 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27390	Time 12.313s / 10iters, (1.231)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.852s / 10iters, (0.285)	Data load 0.078s / 10iters, (0.007828)
Learning rate = [0.0035385112518610796, 0.0035385112518610796]	Loss = 0.71592879 (ave = 0.78191615)

2023-07-06 00:12:20,336 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27400	Time 12.215s / 10iters, (1.221)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007450)
Learning rate = [0.0035359858483018283, 0.0035359858483018283]	Loss = 0.88117731 (ave = 0.79002831)

2023-07-06 00:12:32,633 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27410	Time 12.297s / 10iters, (1.230)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.270s / 10iters, (0.827)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.085s / 10iters, (0.008485)
Learning rate = [0.003533460244321654, 0.003533460244321654]	Loss = 0.70550340 (ave = 0.75449050)

2023-07-06 00:12:44,928 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27420	Time 12.295s / 10iters, (1.229)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.080s / 10iters, (0.008039)
Learning rate = [0.003530934439745455, 0.003530934439745455]	Loss = 0.71367753 (ave = 0.73197676)

2023-07-06 00:12:57,255 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27430	Time 12.327s / 10iters, (1.233)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.086s / 10iters, (0.008563)
Learning rate = [0.0035284084343978335, 0.0035284084343978335]	Loss = 0.76204109 (ave = 0.74558986)

2023-07-06 00:13:09,612 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27440	Time 12.357s / 10iters, (1.236)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.086s / 10iters, (0.008620)
Learning rate = [0.003525882228103105, 0.003525882228103105]	Loss = 0.81297410 (ave = 0.76635889)

2023-07-06 00:13:21,741 INFO    [trainer_contrastive.py, 272] Train Epoch: 73	Train Iteration: 27450	Time 12.129s / 10iters, (1.213)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.210s / 10iters, (0.821)	Loss Time 2.744s / 10iters, (0.274)	Data load 0.076s / 10iters, (0.007638)
Learning rate = [0.003523355820685287, 0.003523355820685287]	Loss = 0.62551844 (ave = 0.71572137)

2023-07-06 00:13:36,796 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27460	Time 14.910s / 10iters, (1.491)	Forward Time 1.225s / 10iters, (0.123)	Backward Time 8.235s / 10iters, (0.824)	Loss Time 2.685s / 10iters, (0.269)	Data load 2.763s / 10iters, (0.276308)
Learning rate = [0.003520829211968102, 0.003520829211968102]	Loss = 0.72024053 (ave = 0.71628674)

2023-07-06 00:13:49,004 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27470	Time 12.209s / 10iters, (1.221)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.236s / 10iters, (0.824)	Loss Time 2.777s / 10iters, (0.278)	Data load 0.091s / 10iters, (0.009060)
Learning rate = [0.0035183024017749784, 0.0035183024017749784]	Loss = 0.71462536 (ave = 0.76800950)

2023-07-06 00:14:01,252 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27480	Time 12.248s / 10iters, (1.225)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.324s / 10iters, (0.832)	Loss Time 2.752s / 10iters, (0.275)	Data load 0.077s / 10iters, (0.007749)
Learning rate = [0.0035157753899290505, 0.0035157753899290505]	Loss = 0.74257416 (ave = 0.75235450)

2023-07-06 00:14:13,513 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27490	Time 12.261s / 10iters, (1.226)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.275s / 10iters, (0.828)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.087s / 10iters, (0.008669)
Learning rate = [0.0035132481762531545, 0.0035132481762531545]	Loss = 0.77817953 (ave = 0.73111443)

2023-07-06 00:14:25,726 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27500	Time 12.212s / 10iters, (1.221)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.264s / 10iters, (0.826)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.089s / 10iters, (0.008870)
Learning rate = [0.0035107207605698273, 0.0035107207605698273]	Loss = 1.42551434 (ave = 0.77323388)

2023-07-06 00:14:38,036 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27510	Time 12.310s / 10iters, (1.231)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.250s / 10iters, (0.825)	Loss Time 2.898s / 10iters, (0.290)	Data load 0.074s / 10iters, (0.007412)
Learning rate = [0.0035081931427013097, 0.0035081931427013097]	Loss = 0.64553285 (ave = 0.72206457)

2023-07-06 00:14:50,327 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27520	Time 12.291s / 10iters, (1.229)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007394)
Learning rate = [0.0035056653224695444, 0.0035056653224695444]	Loss = 0.85115427 (ave = 0.77826494)

2023-07-06 00:15:02,720 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27530	Time 12.393s / 10iters, (1.239)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.877s / 10iters, (0.288)	Data load 0.101s / 10iters, (0.010126)
Learning rate = [0.003503137299696174, 0.003503137299696174]	Loss = 0.75899410 (ave = 0.70854930)

2023-07-06 00:15:15,062 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27540	Time 12.342s / 10iters, (1.234)	Forward Time 1.151s / 10iters, (0.115)	Backward Time 8.236s / 10iters, (0.824)	Loss Time 2.881s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007414)
Learning rate = [0.0035006090742025387, 0.0035006090742025387]	Loss = 0.77634376 (ave = 0.72879372)

2023-07-06 00:15:27,490 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27550	Time 12.428s / 10iters, (1.243)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.366s / 10iters, (0.837)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.100s / 10iters, (0.010028)
Learning rate = [0.0034980806458096785, 0.0034980806458096785]	Loss = 0.77628714 (ave = 0.71542966)

2023-07-06 00:15:39,870 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27560	Time 12.380s / 10iters, (1.238)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.306s / 10iters, (0.831)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.090s / 10iters, (0.008961)
Learning rate = [0.003495552014338335, 0.003495552014338335]	Loss = 0.72716582 (ave = 0.71944005)

2023-07-06 00:15:52,120 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27570	Time 12.250s / 10iters, (1.225)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.804s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007506)
Learning rate = [0.0034930231796089424, 0.0034930231796089424]	Loss = 0.82959288 (ave = 0.75387012)

2023-07-06 00:16:04,541 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27580	Time 12.421s / 10iters, (1.242)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.377s / 10iters, (0.838)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.097s / 10iters, (0.009710)
Learning rate = [0.0034904941414416334, 0.0034904941414416334]	Loss = 0.71921027 (ave = 0.70935073)

2023-07-06 00:16:16,991 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27590	Time 12.451s / 10iters, (1.245)	Forward Time 1.138s / 10iters, (0.114)	Backward Time 8.369s / 10iters, (0.837)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.105s / 10iters, (0.010478)
Learning rate = [0.0034879648996562367, 0.0034879648996562367]	Loss = 0.65160048 (ave = 0.74100559)

2023-07-06 00:16:29,410 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27600	Time 12.419s / 10iters, (1.242)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.384s / 10iters, (0.838)	Loss Time 2.833s / 10iters, (0.283)	Data load 0.086s / 10iters, (0.008577)
Learning rate = [0.003485435454072277, 0.003485435454072277]	Loss = 0.75901181 (ave = 0.72523629)

2023-07-06 00:16:41,838 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27610	Time 12.427s / 10iters, (1.243)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.319s / 10iters, (0.832)	Loss Time 2.896s / 10iters, (0.290)	Data load 0.079s / 10iters, (0.007867)
Learning rate = [0.003482905804508973, 0.003482905804508973]	Loss = 0.70164466 (ave = 0.73743842)

2023-07-06 00:16:54,613 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27620	Time 12.776s / 10iters, (1.278)	Forward Time 1.208s / 10iters, (0.121)	Backward Time 8.599s / 10iters, (0.860)	Loss Time 2.884s / 10iters, (0.288)	Data load 0.084s / 10iters, (0.008368)
Learning rate = [0.0034803759507852352, 0.0034803759507852352]	Loss = 0.76720262 (ave = 0.75224591)

2023-07-06 00:17:06,917 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27630	Time 12.304s / 10iters, (1.230)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.804s / 10iters, (0.280)	Data load 0.078s / 10iters, (0.007791)
Learning rate = [0.003477845892719667, 0.003477845892719667]	Loss = 0.74374479 (ave = 0.73657348)

2023-07-06 00:17:19,307 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27640	Time 12.390s / 10iters, (1.239)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.111s / 10iters, (0.011122)
Learning rate = [0.0034753156301305685, 0.0034753156301305685]	Loss = 0.76017898 (ave = 0.77433928)

2023-07-06 00:17:31,587 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27650	Time 12.280s / 10iters, (1.228)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.288s / 10iters, (0.829)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.078s / 10iters, (0.007831)
Learning rate = [0.0034727851628359252, 0.0034727851628359252]	Loss = 1.00393867 (ave = 0.76025338)

2023-07-06 00:17:43,957 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27660	Time 12.370s / 10iters, (1.237)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.352s / 10iters, (0.835)	Loss Time 2.815s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007646)
Learning rate = [0.003470254490653417, 0.003470254490653417]	Loss = 0.69328493 (ave = 0.76077986)

2023-07-06 00:17:56,473 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27670	Time 12.517s / 10iters, (1.252)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.481s / 10iters, (0.848)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007512)
Learning rate = [0.00346772361340041, 0.00346772361340041]	Loss = 0.79190063 (ave = 0.79887990)

2023-07-06 00:18:08,894 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27680	Time 12.421s / 10iters, (1.242)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.450s / 10iters, (0.845)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007484)
Learning rate = [0.003465192530893964, 0.003465192530893964]	Loss = 0.70838112 (ave = 0.70669767)

2023-07-06 00:18:21,243 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27690	Time 12.349s / 10iters, (1.235)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.375s / 10iters, (0.837)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007531)
Learning rate = [0.003462661242950824, 0.003462661242950824]	Loss = 0.63730842 (ave = 0.75991767)

2023-07-06 00:18:33,474 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27700	Time 12.231s / 10iters, (1.223)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.756s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007405)
Learning rate = [0.0034601297493874216, 0.0034601297493874216]	Loss = 0.82454312 (ave = 0.72007906)

2023-07-06 00:18:45,746 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27710	Time 12.272s / 10iters, (1.227)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.087s / 10iters, (0.008721)
Learning rate = [0.0034575980500198755, 0.0034575980500198755]	Loss = 0.67103183 (ave = 0.75708348)

2023-07-06 00:18:57,964 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27720	Time 12.218s / 10iters, (1.222)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.255s / 10iters, (0.826)	Loss Time 2.758s / 10iters, (0.276)	Data load 0.086s / 10iters, (0.008565)
Learning rate = [0.0034550661446639936, 0.0034550661446639936]	Loss = 0.63322783 (ave = 0.70217101)

2023-07-06 00:19:10,309 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27730	Time 12.345s / 10iters, (1.235)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.324s / 10iters, (0.832)	Loss Time 2.790s / 10iters, (0.279)	Data load 0.106s / 10iters, (0.010613)
Learning rate = [0.003452534033135264, 0.003452534033135264]	Loss = 0.72465277 (ave = 0.73630407)

2023-07-06 00:19:22,585 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27740	Time 12.276s / 10iters, (1.228)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.297s / 10iters, (0.830)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007522)
Learning rate = [0.003450001715248862, 0.003450001715248862]	Loss = 0.66626269 (ave = 0.66731911)

2023-07-06 00:19:34,946 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27750	Time 12.361s / 10iters, (1.236)	Forward Time 1.145s / 10iters, (0.115)	Backward Time 8.320s / 10iters, (0.832)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.100s / 10iters, (0.010038)
Learning rate = [0.0034474691908196447, 0.0034474691908196447]	Loss = 0.72437048 (ave = 0.74781398)

2023-07-06 00:19:47,221 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27760	Time 12.275s / 10iters, (1.227)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.077s / 10iters, (0.007669)
Learning rate = [0.0034449364596621543, 0.0034449364596621543]	Loss = 0.72044146 (ave = 0.72433173)

2023-07-06 00:19:59,545 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27770	Time 12.324s / 10iters, (1.232)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.864s / 10iters, (0.286)	Data load 0.108s / 10iters, (0.010774)
Learning rate = [0.003442403521590611, 0.003442403521590611]	Loss = 0.63375926 (ave = 0.73042030)

2023-07-06 00:20:11,826 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27780	Time 12.281s / 10iters, (1.228)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.253s / 10iters, (0.825)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.077s / 10iters, (0.007749)
Learning rate = [0.0034398703764189206, 0.0034398703764189206]	Loss = 0.81465226 (ave = 0.73797248)

2023-07-06 00:20:24,256 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27790	Time 12.430s / 10iters, (1.243)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.326s / 10iters, (0.833)	Loss Time 2.888s / 10iters, (0.289)	Data load 0.091s / 10iters, (0.009120)
Learning rate = [0.0034373370239606633, 0.0034373370239606633]	Loss = 0.72383094 (ave = 0.72665755)

2023-07-06 00:20:36,636 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27800	Time 12.380s / 10iters, (1.238)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.903s / 10iters, (0.290)	Data load 0.086s / 10iters, (0.008553)
Learning rate = [0.003434803464029105, 0.003434803464029105]	Loss = 0.69591165 (ave = 0.72445133)

2023-07-06 00:20:49,255 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27810	Time 12.619s / 10iters, (1.262)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.488s / 10iters, (0.849)	Loss Time 2.917s / 10iters, (0.292)	Data load 0.085s / 10iters, (0.008520)
Learning rate = [0.0034322696964371865, 0.0034322696964371865]	Loss = 0.77398884 (ave = 0.70652320)

2023-07-06 00:21:01,436 INFO    [trainer_contrastive.py, 272] Train Epoch: 74	Train Iteration: 27820	Time 12.181s / 10iters, (1.218)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.754s / 10iters, (0.275)	Data load 0.073s / 10iters, (0.007293)
Learning rate = [0.0034297357209975266, 0.0034297357209975266]	Loss = 0.70939767 (ave = 0.73755711)

2023-07-06 00:21:16,935 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 27830	Time 15.319s / 10iters, (1.532)	Forward Time 1.241s / 10iters, (0.124)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.707s / 10iters, (0.271)	Data load 3.063s / 10iters, (0.306338)
Learning rate = [0.0034272015375224206, 0.0034272015375224206]	Loss = 0.74821699 (ave = 0.73633373)

2023-07-06 00:21:29,161 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 27840	Time 12.226s / 10iters, (1.223)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007585)
Learning rate = [0.0034246671458238436, 0.0034246671458238436]	Loss = 0.65357536 (ave = 0.74484463)

2023-07-06 00:21:41,487 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 27850	Time 12.326s / 10iters, (1.233)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.341s / 10iters, (0.834)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.089s / 10iters, (0.008941)
Learning rate = [0.0034221325457134415, 0.0034221325457134415]	Loss = 0.63237184 (ave = 0.68872802)

2023-07-06 00:21:53,903 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 27860	Time 12.416s / 10iters, (1.242)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.358s / 10iters, (0.836)	Loss Time 2.850s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007630)
Learning rate = [0.0034195977370025366, 0.0034195977370025366]	Loss = 0.78105342 (ave = 0.74740274)

2023-07-06 00:22:06,181 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 27870	Time 12.278s / 10iters, (1.228)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.087s / 10iters, (0.008739)
Learning rate = [0.003417062719502123, 0.003417062719502123]	Loss = 0.68790781 (ave = 0.72649893)

2023-07-06 00:22:18,486 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 27880	Time 12.305s / 10iters, (1.231)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.084s / 10iters, (0.008443)
Learning rate = [0.0034145274930228726, 0.0034145274930228726]	Loss = 0.66171581 (ave = 0.76575565)

2023-07-06 00:22:30,690 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 27890	Time 12.204s / 10iters, (1.220)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.754s / 10iters, (0.275)	Data load 0.085s / 10iters, (0.008506)
Learning rate = [0.003411992057375124, 0.003411992057375124]	Loss = 0.69765025 (ave = 0.70987141)

2023-07-06 00:22:42,943 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 27900	Time 12.253s / 10iters, (1.225)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.319s / 10iters, (0.832)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.078s / 10iters, (0.007751)
Learning rate = [0.0034094564123688894, 0.0034094564123688894]	Loss = 0.84915900 (ave = 0.77528608)

2023-07-06 00:22:55,160 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 27910	Time 12.217s / 10iters, (1.222)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.746s / 10iters, (0.275)	Data load 0.083s / 10iters, (0.008284)
Learning rate = [0.003406920557813849, 0.003406920557813849]	Loss = 0.83570683 (ave = 0.70708529)

2023-07-06 00:23:07,392 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 27920	Time 12.232s / 10iters, (1.223)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.322s / 10iters, (0.832)	Loss Time 2.735s / 10iters, (0.273)	Data load 0.080s / 10iters, (0.008046)
Learning rate = [0.0034043844935193563, 0.0034043844935193563]	Loss = 0.57148874 (ave = 0.70013270)

2023-07-06 00:23:19,575 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 27930	Time 12.182s / 10iters, (1.218)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.708s / 10iters, (0.271)	Data load 0.087s / 10iters, (0.008654)
Learning rate = [0.003401848219294431, 0.003401848219294431]	Loss = 0.77387613 (ave = 0.74164972)

2023-07-06 00:23:31,841 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 27940	Time 12.266s / 10iters, (1.227)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.320s / 10iters, (0.832)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.077s / 10iters, (0.007707)
Learning rate = [0.0033993117349477605, 0.0033993117349477605]	Loss = 0.76025611 (ave = 0.73189420)

2023-07-06 00:23:44,188 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 27950	Time 12.347s / 10iters, (1.235)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.335s / 10iters, (0.833)	Loss Time 2.816s / 10iters, (0.282)	Data load 0.087s / 10iters, (0.008668)
Learning rate = [0.0033967750402876975, 0.0033967750402876975]	Loss = 0.74585342 (ave = 0.71613843)

2023-07-06 00:23:56,428 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 27960	Time 12.240s / 10iters, (1.224)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.077s / 10iters, (0.007732)
Learning rate = [0.003394238135122265, 0.003394238135122265]	Loss = 0.73197043 (ave = 0.68913579)

2023-07-06 00:24:08,688 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 27970	Time 12.261s / 10iters, (1.226)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.792s / 10iters, (0.279)	Data load 0.083s / 10iters, (0.008331)
Learning rate = [0.003391701019259149, 0.003391701019259149]	Loss = 0.70825219 (ave = 0.71687749)

2023-07-06 00:24:21,005 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 27980	Time 12.317s / 10iters, (1.232)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.861s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007490)
Learning rate = [0.003389163692505698, 0.003389163692505698]	Loss = 0.68344462 (ave = 0.70586637)

2023-07-06 00:24:33,292 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 27990	Time 12.287s / 10iters, (1.229)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.088s / 10iters, (0.008780)
Learning rate = [0.0033866261546689246, 0.0033866261546689246]	Loss = 0.71063995 (ave = 0.72892460)

2023-07-06 00:24:45,485 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28000	Time 12.192s / 10iters, (1.219)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.188s / 10iters, (0.819)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.079s / 10iters, (0.007936)
Learning rate = [0.0033840884055555084, 0.0033840884055555084]	Loss = 0.76654094 (ave = 0.74817535)

2023-07-06 00:24:49,097 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-06 00:25:12,855 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-06 00:25:36,159 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-06 00:25:59,207 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-06 00:26:22,212 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-06 00:26:45,213 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-06 00:27:08,460 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-06 00:27:14,591 INFO    [base.py, 84] Performance 0.7425268176200625 -> 0.7588134374009878
2023-07-06 00:27:18,967 INFO    [trainer_contrastive.py, 391] Test Time 148.834s, (2.362)	Loss 0.13649941

2023-07-06 00:27:18,968 INFO    [base.py, 33] Result for seg
2023-07-06 00:27:18,969 INFO    [base.py, 49] Mean IOU: 0.7588134374009878

2023-07-06 00:27:18,969 INFO    [base.py, 50] Pixel ACC: 0.9568034369261229

2023-07-06 00:27:31,129 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28010	Time 165.645s / 10iters, (16.564)	Forward Time 1.167s / 10iters, (0.117)	Backward Time 8.181s / 10iters, (0.818)	Loss Time 2.727s / 10iters, (0.273)	Data load 153.570s / 10iters, (15.356960)
Learning rate = [0.0033815504449717843, 0.0033815504449717843]	Loss = 0.87847871 (ave = 0.74917508)

2023-07-06 00:27:43,219 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28020	Time 12.090s / 10iters, (1.209)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.191s / 10iters, (0.819)	Loss Time 2.706s / 10iters, (0.271)	Data load 0.077s / 10iters, (0.007667)
Learning rate = [0.0033790122727237522, 0.0033790122727237522]	Loss = 0.68258679 (ave = 0.73326369)

2023-07-06 00:27:55,378 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28030	Time 12.159s / 10iters, (1.216)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.707s / 10iters, (0.271)	Data load 0.088s / 10iters, (0.008808)
Learning rate = [0.003376473888617069, 0.003376473888617069]	Loss = 0.71233749 (ave = 0.73116450)

2023-07-06 00:28:07,511 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28040	Time 12.133s / 10iters, (1.213)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.740s / 10iters, (0.274)	Data load 0.077s / 10iters, (0.007720)
Learning rate = [0.0033739352924570536, 0.0033739352924570536]	Loss = 0.73129421 (ave = 0.74041684)

2023-07-06 00:28:19,725 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28050	Time 12.213s / 10iters, (1.221)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.705s / 10iters, (0.270)	Data load 0.084s / 10iters, (0.008418)
Learning rate = [0.0033713964840486827, 0.0033713964840486827]	Loss = 0.74916518 (ave = 0.73013217)

2023-07-06 00:28:31,724 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28060	Time 11.999s / 10iters, (1.200)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.187s / 10iters, (0.819)	Loss Time 2.632s / 10iters, (0.263)	Data load 0.077s / 10iters, (0.007682)
Learning rate = [0.003368857463196588, 0.003368857463196588]	Loss = 0.78249693 (ave = 0.73154020)

2023-07-06 00:28:43,811 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28070	Time 12.088s / 10iters, (1.209)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.662s / 10iters, (0.266)	Data load 0.074s / 10iters, (0.007403)
Learning rate = [0.0033663182297050576, 0.0033663182297050576]	Loss = 0.72074163 (ave = 0.74226544)

2023-07-06 00:28:55,849 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28080	Time 12.038s / 10iters, (1.204)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.202s / 10iters, (0.820)	Loss Time 2.660s / 10iters, (0.266)	Data load 0.083s / 10iters, (0.008302)
Learning rate = [0.00336377878337804, 0.00336377878337804]	Loss = 0.66306275 (ave = 0.73835480)

2023-07-06 00:29:07,907 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28090	Time 12.058s / 10iters, (1.206)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.204s / 10iters, (0.820)	Loss Time 2.653s / 10iters, (0.265)	Data load 0.097s / 10iters, (0.009731)
Learning rate = [0.0033612391240191324, 0.0033612391240191324]	Loss = 1.12385607 (ave = 0.74804469)

2023-07-06 00:29:19,984 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28100	Time 12.077s / 10iters, (1.208)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.667s / 10iters, (0.267)	Data load 0.086s / 10iters, (0.008617)
Learning rate = [0.003358699251431589, 0.003358699251431589]	Loss = 0.66371095 (ave = 0.72240039)

2023-07-06 00:29:32,090 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28110	Time 12.106s / 10iters, (1.211)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.253s / 10iters, (0.825)	Loss Time 2.660s / 10iters, (0.266)	Data load 0.080s / 10iters, (0.007981)
Learning rate = [0.0033561591654183145, 0.0033561591654183145]	Loss = 0.81063020 (ave = 0.80446485)

2023-07-06 00:29:44,385 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28120	Time 12.296s / 10iters, (1.230)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.082s / 10iters, (0.008210)
Learning rate = [0.003353618865781869, 0.003353618865781869]	Loss = 0.72375166 (ave = 0.74989004)

2023-07-06 00:29:56,525 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28130	Time 12.139s / 10iters, (1.214)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.223s / 10iters, (0.822)	Loss Time 2.737s / 10iters, (0.274)	Data load 0.079s / 10iters, (0.007910)
Learning rate = [0.003351078352324461, 0.003351078352324461]	Loss = 0.80340999 (ave = 0.71073643)

2023-07-06 00:30:08,766 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28140	Time 12.241s / 10iters, (1.224)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.279s / 10iters, (0.828)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.097s / 10iters, (0.009689)
Learning rate = [0.003348537624847949, 0.003348537624847949]	Loss = 0.65069997 (ave = 0.71079706)

2023-07-06 00:30:21,065 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28150	Time 12.300s / 10iters, (1.230)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.328s / 10iters, (0.833)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007545)
Learning rate = [0.0033459966831538394, 0.0033459966831538394]	Loss = 0.70343435 (ave = 0.73496609)

2023-07-06 00:30:33,324 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28160	Time 12.258s / 10iters, (1.226)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.235s / 10iters, (0.823)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.106s / 10iters, (0.010630)
Learning rate = [0.003343455527043293, 0.003343455527043293]	Loss = 0.78740418 (ave = 0.70873929)

2023-07-06 00:30:45,451 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28170	Time 12.128s / 10iters, (1.213)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.698s / 10iters, (0.270)	Data load 0.085s / 10iters, (0.008516)
Learning rate = [0.003340914156317112, 0.003340914156317112]	Loss = 0.67838824 (ave = 0.75568796)

2023-07-06 00:30:57,663 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28180	Time 12.212s / 10iters, (1.221)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.262s / 10iters, (0.826)	Loss Time 2.720s / 10iters, (0.272)	Data load 0.099s / 10iters, (0.009870)
Learning rate = [0.0033383725707757457, 0.0033383725707757457]	Loss = 0.68289959 (ave = 0.71875677)

2023-07-06 00:31:09,732 INFO    [trainer_contrastive.py, 272] Train Epoch: 75	Train Iteration: 28190	Time 12.068s / 10iters, (1.207)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.166s / 10iters, (0.817)	Loss Time 2.734s / 10iters, (0.273)	Data load 0.078s / 10iters, (0.007814)
Learning rate = [0.003335830770219289, 0.003335830770219289]	Loss = 0.77873874 (ave = 0.71796150)

2023-07-06 00:31:25,047 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28200	Time 15.143s / 10iters, (1.514)	Forward Time 1.216s / 10iters, (0.122)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.747s / 10iters, (0.275)	Data load 2.878s / 10iters, (0.287789)
Learning rate = [0.0033332887544474856, 0.0033332887544474856]	Loss = 0.71923900 (ave = 0.73161408)

2023-07-06 00:31:37,264 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28210	Time 12.217s / 10iters, (1.222)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.086s / 10iters, (0.008559)
Learning rate = [0.003330746523259717, 0.003330746523259717]	Loss = 0.68800187 (ave = 0.73061661)

2023-07-06 00:31:49,303 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28220	Time 12.039s / 10iters, (1.204)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.142s / 10iters, (0.814)	Loss Time 2.719s / 10iters, (0.272)	Data load 0.088s / 10iters, (0.008780)
Learning rate = [0.0033282040764550116, 0.0033282040764550116]	Loss = 0.66091013 (ave = 0.67312325)

2023-07-06 00:32:01,436 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28230	Time 12.132s / 10iters, (1.213)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.201s / 10iters, (0.820)	Loss Time 2.749s / 10iters, (0.275)	Data load 0.079s / 10iters, (0.007866)
Learning rate = [0.0033256614138320348, 0.0033256614138320348]	Loss = 0.74511558 (ave = 0.68554372)

2023-07-06 00:32:13,448 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28240	Time 12.012s / 10iters, (1.201)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.133s / 10iters, (0.813)	Loss Time 2.696s / 10iters, (0.270)	Data load 0.083s / 10iters, (0.008309)
Learning rate = [0.003323118535189099, 0.003323118535189099]	Loss = 0.71548140 (ave = 0.71143386)

2023-07-06 00:32:25,650 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28250	Time 12.202s / 10iters, (1.220)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.223s / 10iters, (0.822)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007608)
Learning rate = [0.003320575440324152, 0.003320575440324152]	Loss = 0.75638890 (ave = 0.73813312)

2023-07-06 00:32:37,777 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28260	Time 12.126s / 10iters, (1.213)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.755s / 10iters, (0.275)	Data load 0.080s / 10iters, (0.007988)
Learning rate = [0.0033180321290347814, 0.0033180321290347814]	Loss = 0.73785293 (ave = 0.71074819)

2023-07-06 00:32:49,905 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28270	Time 12.128s / 10iters, (1.213)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.168s / 10iters, (0.817)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.086s / 10iters, (0.008560)
Learning rate = [0.0033154886011182126, 0.0033154886011182126]	Loss = 0.66008943 (ave = 0.69049364)

2023-07-06 00:33:02,054 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28280	Time 12.149s / 10iters, (1.215)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.188s / 10iters, (0.819)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.081s / 10iters, (0.008139)
Learning rate = [0.0033129448563713106, 0.0033129448563713106]	Loss = 0.62062514 (ave = 0.71685579)

2023-07-06 00:33:14,354 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28290	Time 12.300s / 10iters, (1.230)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.084s / 10iters, (0.008420)
Learning rate = [0.003310400894590573, 0.003310400894590573]	Loss = 0.90732682 (ave = 0.76179903)

2023-07-06 00:33:26,624 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28300	Time 12.270s / 10iters, (1.227)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.219s / 10iters, (0.822)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.086s / 10iters, (0.008649)
Learning rate = [0.0033078567155721333, 0.0033078567155721333]	Loss = 0.72385836 (ave = 0.79387096)

2023-07-06 00:33:38,838 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28310	Time 12.214s / 10iters, (1.221)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.083s / 10iters, (0.008308)
Learning rate = [0.0033053123191117595, 0.0033053123191117595]	Loss = 0.71591848 (ave = 0.76684968)

2023-07-06 00:33:51,032 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28320	Time 12.194s / 10iters, (1.219)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.169s / 10iters, (0.817)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.078s / 10iters, (0.007799)
Learning rate = [0.0033027677050048547, 0.0033027677050048547]	Loss = 0.76100349 (ave = 0.76366054)

2023-07-06 00:34:03,377 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28330	Time 12.344s / 10iters, (1.234)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.350s / 10iters, (0.835)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007523)
Learning rate = [0.0033002228730464513, 0.0033002228730464513]	Loss = 0.78451109 (ave = 0.75533647)

2023-07-06 00:34:15,838 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28340	Time 12.462s / 10iters, (1.246)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.387s / 10iters, (0.839)	Loss Time 2.890s / 10iters, (0.289)	Data load 0.078s / 10iters, (0.007797)
Learning rate = [0.0032976778230312132, 0.0032976778230312132]	Loss = 0.69486403 (ave = 0.72207631)

2023-07-06 00:34:28,347 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28350	Time 12.508s / 10iters, (1.251)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.487s / 10iters, (0.849)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.077s / 10iters, (0.007685)
Learning rate = [0.0032951325547534343, 0.0032951325547534343]	Loss = 0.67592168 (ave = 0.77907718)

2023-07-06 00:34:40,635 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28360	Time 12.288s / 10iters, (1.229)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.304s / 10iters, (0.830)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.087s / 10iters, (0.008712)
Learning rate = [0.003292587068007042, 0.003292587068007042]	Loss = 0.60024577 (ave = 0.70295447)

2023-07-06 00:34:52,761 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28370	Time 12.126s / 10iters, (1.213)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.208s / 10iters, (0.821)	Loss Time 2.740s / 10iters, (0.274)	Data load 0.077s / 10iters, (0.007663)
Learning rate = [0.0032900413625855857, 0.0032900413625855857]	Loss = 0.62399364 (ave = 0.68872042)

2023-07-06 00:35:05,083 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28380	Time 12.322s / 10iters, (1.232)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.085s / 10iters, (0.008455)
Learning rate = [0.0032874954382822457, 0.0032874954382822457]	Loss = 0.62589604 (ave = 0.70367861)

2023-07-06 00:35:17,368 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28390	Time 12.285s / 10iters, (1.228)	Forward Time 1.155s / 10iters, (0.116)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.086s / 10iters, (0.008562)
Learning rate = [0.0032849492948898266, 0.0032849492948898266]	Loss = 0.71313715 (ave = 0.68397307)

2023-07-06 00:35:29,691 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28400	Time 12.322s / 10iters, (1.232)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.323s / 10iters, (0.832)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.088s / 10iters, (0.008798)
Learning rate = [0.0032824029322007613, 0.0032824029322007613]	Loss = 0.69131577 (ave = 0.73309533)

2023-07-06 00:35:41,975 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28410	Time 12.284s / 10iters, (1.228)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.292s / 10iters, (0.829)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.080s / 10iters, (0.007961)
Learning rate = [0.0032798563500071047, 0.0032798563500071047]	Loss = 0.68682283 (ave = 0.70401999)

2023-07-06 00:35:54,273 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28420	Time 12.298s / 10iters, (1.230)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.080s / 10iters, (0.008021)
Learning rate = [0.0032773095481005345, 0.0032773095481005345]	Loss = 0.67471486 (ave = 0.73449185)

2023-07-06 00:36:06,615 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28430	Time 12.341s / 10iters, (1.234)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.350s / 10iters, (0.835)	Loss Time 2.808s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007604)
Learning rate = [0.00327476252627235, 0.00327476252627235]	Loss = 0.68810970 (ave = 0.77078202)

2023-07-06 00:36:18,822 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28440	Time 12.208s / 10iters, (1.221)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007523)
Learning rate = [0.0032722152843134757, 0.0032722152843134757]	Loss = 0.79509705 (ave = 0.75485617)

2023-07-06 00:36:31,100 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28450	Time 12.278s / 10iters, (1.228)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.792s / 10iters, (0.279)	Data load 0.092s / 10iters, (0.009236)
Learning rate = [0.0032696678220144526, 0.0032696678220144526]	Loss = 0.79462337 (ave = 0.72938296)

2023-07-06 00:36:43,421 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28460	Time 12.322s / 10iters, (1.232)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.332s / 10iters, (0.833)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.088s / 10iters, (0.008761)
Learning rate = [0.003267120139165442, 0.003267120139165442]	Loss = 0.72188461 (ave = 0.76258665)

2023-07-06 00:36:55,711 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28470	Time 12.289s / 10iters, (1.229)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.350s / 10iters, (0.835)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.080s / 10iters, (0.007977)
Learning rate = [0.0032645722355562224, 0.0032645722355562224]	Loss = 0.86008978 (ave = 0.75902524)

2023-07-06 00:37:07,943 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28480	Time 12.233s / 10iters, (1.223)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.734s / 10iters, (0.273)	Data load 0.088s / 10iters, (0.008824)
Learning rate = [0.003262024110976192, 0.003262024110976192]	Loss = 0.61828703 (ave = 0.70355173)

2023-07-06 00:37:20,147 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28490	Time 12.204s / 10iters, (1.220)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.740s / 10iters, (0.274)	Data load 0.086s / 10iters, (0.008561)
Learning rate = [0.0032594757652143623, 0.0032594757652143623]	Loss = 0.68303609 (ave = 0.70590139)

2023-07-06 00:37:32,535 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28500	Time 12.388s / 10iters, (1.239)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.345s / 10iters, (0.835)	Loss Time 2.868s / 10iters, (0.287)	Data load 0.076s / 10iters, (0.007600)
Learning rate = [0.0032569271980593625, 0.0032569271980593625]	Loss = 0.78099799 (ave = 0.78963140)

2023-07-06 00:37:44,875 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28510	Time 12.340s / 10iters, (1.234)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.313s / 10iters, (0.831)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.095s / 10iters, (0.009457)
Learning rate = [0.003254378409299431, 0.003254378409299431]	Loss = 0.66231197 (ave = 0.71437285)

2023-07-06 00:37:57,040 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28520	Time 12.165s / 10iters, (1.217)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.243s / 10iters, (0.824)	Loss Time 2.749s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007532)
Learning rate = [0.003251829398722427, 0.003251829398722427]	Loss = 0.64914995 (ave = 0.71406034)

2023-07-06 00:38:09,173 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28530	Time 12.132s / 10iters, (1.213)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.175s / 10iters, (0.818)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.076s / 10iters, (0.007599)
Learning rate = [0.0032492801661158145, 0.0032492801661158145]	Loss = 0.81191915 (ave = 0.70194641)

2023-07-06 00:38:21,360 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28540	Time 12.187s / 10iters, (1.219)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.236s / 10iters, (0.824)	Loss Time 2.775s / 10iters, (0.278)	Data load 0.082s / 10iters, (0.008171)
Learning rate = [0.0032467307112666716, 0.0032467307112666716]	Loss = 0.81617343 (ave = 0.75740897)

2023-07-06 00:38:33,463 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28550	Time 12.103s / 10iters, (1.210)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.183s / 10iters, (0.818)	Loss Time 2.751s / 10iters, (0.275)	Data load 0.074s / 10iters, (0.007433)
Learning rate = [0.0032441810339616847, 0.0032441810339616847]	Loss = 0.62952614 (ave = 0.69966968)

2023-07-06 00:38:45,521 INFO    [trainer_contrastive.py, 272] Train Epoch: 76	Train Iteration: 28560	Time 12.058s / 10iters, (1.206)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.169s / 10iters, (0.817)	Loss Time 2.723s / 10iters, (0.272)	Data load 0.077s / 10iters, (0.007688)
Learning rate = [0.0032416311339871526, 0.0032416311339871526]	Loss = 0.66843200 (ave = 0.74369926)

2023-07-06 00:39:00,663 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28570	Time 14.972s / 10iters, (1.497)	Forward Time 1.161s / 10iters, (0.116)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.734s / 10iters, (0.273)	Data load 2.883s / 10iters, (0.288308)
Learning rate = [0.0032390810111289775, 0.0032390810111289775]	Loss = 0.80535388 (ave = 0.74468502)

2023-07-06 00:39:13,096 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28580	Time 12.432s / 10iters, (1.243)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.483s / 10iters, (0.848)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.090s / 10iters, (0.008976)
Learning rate = [0.0032365306651726705, 0.0032365306651726705]	Loss = 0.76069790 (ave = 0.72989896)

2023-07-06 00:39:25,303 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28590	Time 12.208s / 10iters, (1.221)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.325s / 10iters, (0.833)	Loss Time 2.704s / 10iters, (0.270)	Data load 0.074s / 10iters, (0.007429)
Learning rate = [0.0032339800959033465, 0.0032339800959033465]	Loss = 0.62757540 (ave = 0.72470240)

2023-07-06 00:39:37,429 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28600	Time 12.126s / 10iters, (1.213)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.695s / 10iters, (0.269)	Data load 0.088s / 10iters, (0.008784)
Learning rate = [0.003231429303105729, 0.003231429303105729]	Loss = 0.80017471 (ave = 0.71700351)

2023-07-06 00:39:49,542 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28610	Time 12.113s / 10iters, (1.211)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.217s / 10iters, (0.822)	Loss Time 2.720s / 10iters, (0.272)	Data load 0.087s / 10iters, (0.008710)
Learning rate = [0.00322887828656414, 0.00322887828656414]	Loss = 0.57415897 (ave = 0.78460587)

2023-07-06 00:40:01,700 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28620	Time 12.159s / 10iters, (1.216)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.738s / 10iters, (0.274)	Data load 0.100s / 10iters, (0.009981)
Learning rate = [0.0032263270460625077, 0.0032263270460625077]	Loss = 0.69601548 (ave = 0.70964388)

2023-07-06 00:40:13,788 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28630	Time 12.088s / 10iters, (1.209)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.198s / 10iters, (0.820)	Loss Time 2.714s / 10iters, (0.271)	Data load 0.080s / 10iters, (0.007984)
Learning rate = [0.0032237755813843585, 0.0032237755813843585]	Loss = 0.63962317 (ave = 0.71295726)

2023-07-06 00:40:25,844 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28640	Time 12.056s / 10iters, (1.206)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.191s / 10iters, (0.819)	Loss Time 2.684s / 10iters, (0.268)	Data load 0.080s / 10iters, (0.008004)
Learning rate = [0.0032212238923128196, 0.0032212238923128196]	Loss = 0.80693412 (ave = 0.74156294)

2023-07-06 00:40:37,909 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28650	Time 12.065s / 10iters, (1.207)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.174s / 10iters, (0.817)	Loss Time 2.700s / 10iters, (0.270)	Data load 0.089s / 10iters, (0.008872)
Learning rate = [0.003218671978630621, 0.003218671978630621]	Loss = 0.67629701 (ave = 0.73376942)

2023-07-06 00:40:50,225 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28660	Time 12.315s / 10iters, (1.232)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.362s / 10iters, (0.836)	Loss Time 2.758s / 10iters, (0.276)	Data load 0.083s / 10iters, (0.008347)
Learning rate = [0.0032161198401200863, 0.0032161198401200863]	Loss = 0.77729416 (ave = 0.74441363)

2023-07-06 00:41:02,597 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28670	Time 12.373s / 10iters, (1.237)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.387s / 10iters, (0.839)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.092s / 10iters, (0.009212)
Learning rate = [0.003213567476563138, 0.003213567476563138]	Loss = 0.72990251 (ave = 0.81169652)

2023-07-06 00:41:15,093 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28680	Time 12.496s / 10iters, (1.250)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.542s / 10iters, (0.854)	Loss Time 2.747s / 10iters, (0.275)	Data load 0.086s / 10iters, (0.008571)
Learning rate = [0.0032110148877412927, 0.0032110148877412927]	Loss = 0.76716566 (ave = 0.69508702)

2023-07-06 00:41:27,510 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28690	Time 12.417s / 10iters, (1.242)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.464s / 10iters, (0.846)	Loss Time 2.740s / 10iters, (0.274)	Data load 0.083s / 10iters, (0.008292)
Learning rate = [0.003208462073435665, 0.003208462073435665]	Loss = 0.86327404 (ave = 0.70892531)

2023-07-06 00:41:39,948 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28700	Time 12.438s / 10iters, (1.244)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.489s / 10iters, (0.849)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007462)
Learning rate = [0.0032059090334269603, 0.0032059090334269603]	Loss = 0.92824054 (ave = 0.73303576)

2023-07-06 00:41:52,277 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28710	Time 12.329s / 10iters, (1.233)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.393s / 10iters, (0.839)	Loss Time 2.729s / 10iters, (0.273)	Data load 0.074s / 10iters, (0.007446)
Learning rate = [0.003203355767495477, 0.003203355767495477]	Loss = 0.84360009 (ave = 0.78971675)

2023-07-06 00:42:04,481 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28720	Time 12.204s / 10iters, (1.220)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.288s / 10iters, (0.829)	Loss Time 2.717s / 10iters, (0.272)	Data load 0.082s / 10iters, (0.008184)
Learning rate = [0.0032008022754211047, 0.0032008022754211047]	Loss = 0.79839516 (ave = 0.78862007)

2023-07-06 00:42:16,654 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28730	Time 12.173s / 10iters, (1.217)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.107s / 10iters, (0.010746)
Learning rate = [0.0031982485569833252, 0.0031982485569833252]	Loss = 0.72454697 (ave = 0.72500779)

2023-07-06 00:42:29,002 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28740	Time 12.348s / 10iters, (1.235)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.336s / 10iters, (0.834)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.080s / 10iters, (0.008047)
Learning rate = [0.003195694611961207, 0.003195694611961207]	Loss = 0.71730208 (ave = 0.74593308)

2023-07-06 00:42:41,173 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28750	Time 12.171s / 10iters, (1.217)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.076s / 10iters, (0.007607)
Learning rate = [0.003193140440133408, 0.003193140440133408]	Loss = 0.78455043 (ave = 0.75172620)

2023-07-06 00:42:53,359 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28760	Time 12.186s / 10iters, (1.219)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.744s / 10iters, (0.274)	Data load 0.079s / 10iters, (0.007855)
Learning rate = [0.0031905860412781706, 0.0031905860412781706]	Loss = 0.72534746 (ave = 0.73726620)

2023-07-06 00:43:05,573 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28770	Time 12.214s / 10iters, (1.221)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.751s / 10iters, (0.275)	Data load 0.079s / 10iters, (0.007879)
Learning rate = [0.0031880314151733276, 0.0031880314151733276]	Loss = 0.56997716 (ave = 0.67318893)

2023-07-06 00:43:17,848 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28780	Time 12.275s / 10iters, (1.228)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.279s / 10iters, (0.828)	Loss Time 2.808s / 10iters, (0.281)	Data load 0.086s / 10iters, (0.008604)
Learning rate = [0.003185476561596292, 0.003185476561596292]	Loss = 0.71436143 (ave = 0.74744132)

2023-07-06 00:43:30,152 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28790	Time 12.304s / 10iters, (1.230)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.326s / 10iters, (0.833)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.095s / 10iters, (0.009512)
Learning rate = [0.003182921480324062, 0.003182921480324062]	Loss = 0.70196122 (ave = 0.69007276)

2023-07-06 00:43:42,448 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28800	Time 12.296s / 10iters, (1.230)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.092s / 10iters, (0.009211)
Learning rate = [0.0031803661711332165, 0.0031803661711332165]	Loss = 0.78232604 (ave = 0.75528688)

2023-07-06 00:43:54,716 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28810	Time 12.268s / 10iters, (1.227)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.264s / 10iters, (0.826)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.093s / 10iters, (0.009318)
Learning rate = [0.003177810633799919, 0.003177810633799919]	Loss = 0.72490901 (ave = 0.75861107)

2023-07-06 00:44:07,058 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28820	Time 12.342s / 10iters, (1.234)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.333s / 10iters, (0.833)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.077s / 10iters, (0.007716)
Learning rate = [0.00317525486809991, 0.00317525486809991]	Loss = 0.67745084 (ave = 0.77028572)

2023-07-06 00:44:19,216 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28830	Time 12.159s / 10iters, (1.216)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.197s / 10iters, (0.820)	Loss Time 2.756s / 10iters, (0.276)	Data load 0.081s / 10iters, (0.008067)
Learning rate = [0.003172698873808509, 0.003172698873808509]	Loss = 0.65259469 (ave = 0.71851766)

2023-07-06 00:44:31,475 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28840	Time 12.259s / 10iters, (1.226)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.100s / 10iters, (0.009961)
Learning rate = [0.0031701426507006122, 0.0031701426507006122]	Loss = 0.71323037 (ave = 0.72234790)

2023-07-06 00:44:43,665 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28850	Time 12.190s / 10iters, (1.219)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.180s / 10iters, (0.818)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.085s / 10iters, (0.008541)
Learning rate = [0.0031675861985506967, 0.0031675861985506967]	Loss = 0.73010951 (ave = 0.68080839)

2023-07-06 00:44:55,977 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28860	Time 12.312s / 10iters, (1.231)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.852s / 10iters, (0.285)	Data load 0.088s / 10iters, (0.008752)
Learning rate = [0.0031650295171328103, 0.0031650295171328103]	Loss = 0.71462941 (ave = 0.67495029)

2023-07-06 00:45:08,316 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28870	Time 12.339s / 10iters, (1.234)	Forward Time 1.147s / 10iters, (0.115)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.083s / 10iters, (0.008277)
Learning rate = [0.003162472606220577, 0.003162472606220577]	Loss = 0.68889868 (ave = 0.72094134)

2023-07-06 00:45:20,706 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28880	Time 12.389s / 10iters, (1.239)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.338s / 10iters, (0.834)	Loss Time 2.835s / 10iters, (0.283)	Data load 0.092s / 10iters, (0.009185)
Learning rate = [0.0031599154655871913, 0.0031599154655871913]	Loss = 0.62344003 (ave = 0.70604189)

2023-07-06 00:45:33,050 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28890	Time 12.344s / 10iters, (1.234)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.088s / 10iters, (0.008813)
Learning rate = [0.0031573580950054235, 0.0031573580950054235]	Loss = 0.67005795 (ave = 0.70420111)

2023-07-06 00:45:45,425 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28900	Time 12.375s / 10iters, (1.238)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.314s / 10iters, (0.831)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.099s / 10iters, (0.009934)
Learning rate = [0.0031548004942476117, 0.0031548004942476117]	Loss = 0.76141530 (ave = 0.67965745)

2023-07-06 00:45:57,711 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28910	Time 12.286s / 10iters, (1.229)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.265s / 10iters, (0.827)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.079s / 10iters, (0.007918)
Learning rate = [0.0031522426630856627, 0.0031522426630856627]	Loss = 0.70541668 (ave = 0.77288227)

2023-07-06 00:46:10,091 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28920	Time 12.379s / 10iters, (1.238)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.101s / 10iters, (0.010063)
Learning rate = [0.003149684601291052, 0.003149684601291052]	Loss = 0.75074697 (ave = 0.82045569)

2023-07-06 00:46:22,421 INFO    [trainer_contrastive.py, 272] Train Epoch: 77	Train Iteration: 28930	Time 12.330s / 10iters, (1.233)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.341s / 10iters, (0.834)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.073s / 10iters, (0.007342)
Learning rate = [0.0031471263086348244, 0.0031471263086348244]	Loss = 0.73624957 (ave = 0.75803772)

2023-07-06 00:46:37,761 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 28940	Time 15.119s / 10iters, (1.512)	Forward Time 1.214s / 10iters, (0.121)	Backward Time 8.158s / 10iters, (0.816)	Loss Time 2.693s / 10iters, (0.269)	Data load 3.053s / 10iters, (0.305342)
Learning rate = [0.0031445677848875877, 0.0031445677848875877]	Loss = 0.68896031 (ave = 0.75230660)

2023-07-06 00:46:50,332 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 28950	Time 12.571s / 10iters, (1.257)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.420s / 10iters, (0.842)	Loss Time 2.917s / 10iters, (0.292)	Data load 0.106s / 10iters, (0.010607)
Learning rate = [0.0031420090298195143, 0.0031420090298195143]	Loss = 0.62617582 (ave = 0.71733444)

2023-07-06 00:47:02,761 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 28960	Time 12.429s / 10iters, (1.243)	Forward Time 1.142s / 10iters, (0.114)	Backward Time 8.313s / 10iters, (0.831)	Loss Time 2.888s / 10iters, (0.289)	Data load 0.086s / 10iters, (0.008594)
Learning rate = [0.00313945004320034, 0.00313945004320034]	Loss = 0.67074966 (ave = 0.72992452)

2023-07-06 00:47:15,125 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 28970	Time 12.364s / 10iters, (1.236)	Forward Time 1.143s / 10iters, (0.114)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.088s / 10iters, (0.008815)
Learning rate = [0.003136890824799364, 0.003136890824799364]	Loss = 0.69154328 (ave = 0.76383833)

2023-07-06 00:47:27,508 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 28980	Time 12.383s / 10iters, (1.238)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.366s / 10iters, (0.837)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007533)
Learning rate = [0.0031343313743854456, 0.0031343313743854456]	Loss = 0.79253322 (ave = 0.77341831)

2023-07-06 00:47:39,854 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 28990	Time 12.346s / 10iters, (1.235)	Forward Time 1.169s / 10iters, (0.117)	Backward Time 8.335s / 10iters, (0.834)	Loss Time 2.760s / 10iters, (0.276)	Data load 0.082s / 10iters, (0.008174)
Learning rate = [0.0031317716917270027, 0.0031317716917270027]	Loss = 0.69973439 (ave = 0.71128668)

2023-07-06 00:47:52,402 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29000	Time 12.548s / 10iters, (1.255)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.498s / 10iters, (0.850)	Loss Time 2.852s / 10iters, (0.285)	Data load 0.096s / 10iters, (0.009551)
Learning rate = [0.0031292117765920114, 0.0031292117765920114]	Loss = 0.81367099 (ave = 0.74369820)

2023-07-06 00:47:55,705 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-06 00:48:20,290 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-06 00:48:43,795 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-06 00:49:07,122 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-06 00:49:30,482 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-06 00:49:53,707 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-06 00:50:17,028 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-06 00:50:27,230 INFO    [trainer_contrastive.py, 391] Test Time 150.380s, (2.387)	Loss 0.13257368

2023-07-06 00:50:27,231 INFO    [base.py, 33] Result for seg
2023-07-06 00:50:27,232 INFO    [base.py, 49] Mean IOU: 0.7506999355224575

2023-07-06 00:50:27,232 INFO    [base.py, 50] Pixel ACC: 0.9575750734945105

2023-07-06 00:50:39,310 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29010	Time 166.908s / 10iters, (16.691)	Forward Time 1.201s / 10iters, (0.120)	Backward Time 8.186s / 10iters, (0.819)	Loss Time 2.605s / 10iters, (0.260)	Data load 154.916s / 10iters, (15.491627)
Learning rate = [0.0031266516287480075, 0.0031266516287480075]	Loss = 0.94149399 (ave = 0.78926500)

2023-07-06 00:50:51,398 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29020	Time 12.088s / 10iters, (1.209)	Forward Time 1.142s / 10iters, (0.114)	Backward Time 8.223s / 10iters, (0.822)	Loss Time 2.620s / 10iters, (0.262)	Data load 0.104s / 10iters, (0.010350)
Learning rate = [0.00312409124796208, 0.00312409124796208]	Loss = 0.73025835 (ave = 0.74248080)

2023-07-06 00:51:03,520 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29030	Time 12.122s / 10iters, (1.212)	Forward Time 1.139s / 10iters, (0.114)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.704s / 10iters, (0.270)	Data load 0.083s / 10iters, (0.008291)
Learning rate = [0.0031215306340008726, 0.0031215306340008726]	Loss = 0.92264348 (ave = 0.77670793)

2023-07-06 00:51:15,887 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29040	Time 12.368s / 10iters, (1.237)	Forward Time 1.176s / 10iters, (0.118)	Backward Time 8.319s / 10iters, (0.832)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.077s / 10iters, (0.007716)
Learning rate = [0.0031189697866305824, 0.0031189697866305824]	Loss = 0.74680793 (ave = 0.76712283)

2023-07-06 00:51:28,331 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29050	Time 12.443s / 10iters, (1.244)	Forward Time 1.153s / 10iters, (0.115)	Backward Time 8.407s / 10iters, (0.841)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.095s / 10iters, (0.009512)
Learning rate = [0.0031164087056169618, 0.0031164087056169618]	Loss = 0.66510689 (ave = 0.74677507)

2023-07-06 00:51:40,724 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29060	Time 12.393s / 10iters, (1.239)	Forward Time 1.172s / 10iters, (0.117)	Backward Time 8.425s / 10iters, (0.843)	Loss Time 2.718s / 10iters, (0.272)	Data load 0.077s / 10iters, (0.007688)
Learning rate = [0.0031138473907253083, 0.0031138473907253083]	Loss = 0.68360448 (ave = 0.74686443)

2023-07-06 00:51:52,816 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29070	Time 12.093s / 10iters, (1.209)	Forward Time 1.176s / 10iters, (0.118)	Backward Time 8.171s / 10iters, (0.817)	Loss Time 2.665s / 10iters, (0.267)	Data load 0.080s / 10iters, (0.008016)
Learning rate = [0.0031112858417204742, 0.0031112858417204742]	Loss = 0.78119546 (ave = 0.75998012)

2023-07-06 00:52:04,913 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29080	Time 12.097s / 10iters, (1.210)	Forward Time 1.155s / 10iters, (0.116)	Backward Time 8.187s / 10iters, (0.819)	Loss Time 2.662s / 10iters, (0.266)	Data load 0.093s / 10iters, (0.009287)
Learning rate = [0.0031087240583668554, 0.0031087240583668554]	Loss = 0.85003614 (ave = 0.74988136)

2023-07-06 00:52:17,005 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29090	Time 12.091s / 10iters, (1.209)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.144s / 10iters, (0.814)	Loss Time 2.709s / 10iters, (0.271)	Data load 0.135s / 10iters, (0.013474)
Learning rate = [0.0031061620404283993, 0.0031061620404283993]	Loss = 0.71178341 (ave = 0.72932082)

2023-07-06 00:52:29,515 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29100	Time 12.510s / 10iters, (1.251)	Forward Time 1.193s / 10iters, (0.119)	Backward Time 8.488s / 10iters, (0.849)	Loss Time 2.736s / 10iters, (0.274)	Data load 0.093s / 10iters, (0.009312)
Learning rate = [0.003103599787668595, 0.003103599787668595]	Loss = 0.79148656 (ave = 0.75812286)

2023-07-06 00:52:41,915 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29110	Time 12.400s / 10iters, (1.240)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.449s / 10iters, (0.845)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.083s / 10iters, (0.008283)
Learning rate = [0.0031010372998504787, 0.0031010372998504787]	Loss = 0.68770981 (ave = 0.70233039)

2023-07-06 00:52:54,133 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29120	Time 12.218s / 10iters, (1.222)	Forward Time 1.136s / 10iters, (0.114)	Backward Time 8.282s / 10iters, (0.828)	Loss Time 2.701s / 10iters, (0.270)	Data load 0.099s / 10iters, (0.009866)
Learning rate = [0.0030984745767366267, 0.0030984745767366267]	Loss = 0.74058324 (ave = 0.73817570)

2023-07-06 00:53:06,614 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29130	Time 12.480s / 10iters, (1.248)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.462s / 10iters, (0.846)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.095s / 10iters, (0.009511)
Learning rate = [0.0030959116180891617, 0.0030959116180891617]	Loss = 0.69388294 (ave = 0.73929154)

2023-07-06 00:53:18,866 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29140	Time 12.252s / 10iters, (1.225)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.312s / 10iters, (0.831)	Loss Time 2.735s / 10iters, (0.274)	Data load 0.093s / 10iters, (0.009324)
Learning rate = [0.003093348423669743, 0.003093348423669743]	Loss = 0.70309639 (ave = 0.72396239)

2023-07-06 00:53:31,265 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29150	Time 12.400s / 10iters, (1.240)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.373s / 10iters, (0.837)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.078s / 10iters, (0.007781)
Learning rate = [0.003090784993239569, 0.003090784993239569]	Loss = 0.65603340 (ave = 0.69861049)

2023-07-06 00:53:43,540 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29160	Time 12.274s / 10iters, (1.227)	Forward Time 1.135s / 10iters, (0.114)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.086s / 10iters, (0.008643)
Learning rate = [0.003088221326559378, 0.003088221326559378]	Loss = 0.64453757 (ave = 0.70763745)

2023-07-06 00:53:55,792 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29170	Time 12.252s / 10iters, (1.225)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007600)
Learning rate = [0.0030856574233894445, 0.0030856574233894445]	Loss = 0.68111002 (ave = 0.69982880)

2023-07-06 00:54:08,188 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29180	Time 12.396s / 10iters, (1.240)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.371s / 10iters, (0.837)	Loss Time 2.818s / 10iters, (0.282)	Data load 0.090s / 10iters, (0.008977)
Learning rate = [0.003083093283489577, 0.003083093283489577]	Loss = 0.84733373 (ave = 0.76919433)

2023-07-06 00:54:20,452 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29190	Time 12.264s / 10iters, (1.226)	Forward Time 1.144s / 10iters, (0.114)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.804s / 10iters, (0.280)	Data load 0.092s / 10iters, (0.009226)
Learning rate = [0.0030805289066191182, 0.0030805289066191182]	Loss = 0.70700920 (ave = 0.72115535)

2023-07-06 00:54:32,931 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29200	Time 12.479s / 10iters, (1.248)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.427s / 10iters, (0.843)	Loss Time 2.845s / 10iters, (0.284)	Data load 0.078s / 10iters, (0.007804)
Learning rate = [0.0030779642925369433, 0.0030779642925369433]	Loss = 0.78777295 (ave = 0.73622140)

2023-07-06 00:54:45,410 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29210	Time 12.479s / 10iters, (1.248)	Forward Time 1.149s / 10iters, (0.115)	Backward Time 8.377s / 10iters, (0.838)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.099s / 10iters, (0.009915)
Learning rate = [0.0030753994410014597, 0.0030753994410014597]	Loss = 0.64474434 (ave = 0.71281760)

2023-07-06 00:54:58,185 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29220	Time 12.774s / 10iters, (1.277)	Forward Time 1.155s / 10iters, (0.116)	Backward Time 8.564s / 10iters, (0.856)	Loss Time 2.960s / 10iters, (0.296)	Data load 0.094s / 10iters, (0.009449)
Learning rate = [0.0030728343517706035, 0.0030728343517706035]	Loss = 0.67380428 (ave = 0.71583413)

2023-07-06 00:55:10,914 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29230	Time 12.730s / 10iters, (1.273)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.582s / 10iters, (0.858)	Loss Time 2.945s / 10iters, (0.295)	Data load 0.075s / 10iters, (0.007541)
Learning rate = [0.0030702690246018393, 0.0030702690246018393]	Loss = 0.72980714 (ave = 0.73571470)

2023-07-06 00:55:23,475 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29240	Time 12.560s / 10iters, (1.256)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.443s / 10iters, (0.844)	Loss Time 2.909s / 10iters, (0.291)	Data load 0.096s / 10iters, (0.009554)
Learning rate = [0.0030677034592521586, 0.0030677034592521586]	Loss = 0.75251698 (ave = 0.71709744)

2023-07-06 00:55:36,013 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29250	Time 12.538s / 10iters, (1.254)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.409s / 10iters, (0.841)	Loss Time 2.934s / 10iters, (0.293)	Data load 0.084s / 10iters, (0.008421)
Learning rate = [0.0030651376554780806, 0.0030651376554780806]	Loss = 0.66025281 (ave = 0.70771767)

2023-07-06 00:55:48,448 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29260	Time 12.435s / 10iters, (1.243)	Forward Time 1.164s / 10iters, (0.116)	Backward Time 8.315s / 10iters, (0.831)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.080s / 10iters, (0.007972)
Learning rate = [0.0030625716130356466, 0.0030625716130356466]	Loss = 0.79399955 (ave = 0.73037586)

2023-07-06 00:56:00,840 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29270	Time 12.393s / 10iters, (1.239)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.279s / 10iters, (0.828)	Loss Time 2.886s / 10iters, (0.289)	Data load 0.096s / 10iters, (0.009632)
Learning rate = [0.003060005331680422, 0.003060005331680422]	Loss = 0.75854647 (ave = 0.76596887)

2023-07-06 00:56:13,148 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29280	Time 12.307s / 10iters, (1.231)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.107s / 10iters, (0.010732)
Learning rate = [0.003057438811167493, 0.003057438811167493]	Loss = 0.75232583 (ave = 0.72668756)

2023-07-06 00:56:25,448 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29290	Time 12.301s / 10iters, (1.230)	Forward Time 1.151s / 10iters, (0.115)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.765s / 10iters, (0.277)	Data load 0.089s / 10iters, (0.008943)
Learning rate = [0.0030548720512514668, 0.0030548720512514668]	Loss = 0.68444800 (ave = 0.69894955)

2023-07-06 00:56:37,612 INFO    [trainer_contrastive.py, 272] Train Epoch: 78	Train Iteration: 29300	Time 12.163s / 10iters, (1.216)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.217s / 10iters, (0.822)	Loss Time 2.764s / 10iters, (0.276)	Data load 0.078s / 10iters, (0.007786)
Learning rate = [0.0030523050516864697, 0.0030523050516864697]	Loss = 0.78779817 (ave = 0.76949559)

2023-07-06 00:56:52,278 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29310	Time 14.443s / 10iters, (1.444)	Forward Time 1.229s / 10iters, (0.123)	Backward Time 8.136s / 10iters, (0.814)	Loss Time 2.736s / 10iters, (0.274)	Data load 2.341s / 10iters, (0.234117)
Learning rate = [0.0030497378122261456, 0.0030497378122261456]	Loss = 0.70221168 (ave = 0.74918191)

2023-07-06 00:57:04,655 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29320	Time 12.377s / 10iters, (1.238)	Forward Time 1.187s / 10iters, (0.119)	Backward Time 8.368s / 10iters, (0.837)	Loss Time 2.723s / 10iters, (0.272)	Data load 0.099s / 10iters, (0.009918)
Learning rate = [0.003047170332623651, 0.003047170332623651]	Loss = 0.71740776 (ave = 0.73306053)

2023-07-06 00:57:16,952 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29330	Time 12.297s / 10iters, (1.230)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.327s / 10iters, (0.833)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.088s / 10iters, (0.008817)
Learning rate = [0.0030446026126316633, 0.0030446026126316633]	Loss = 0.66839600 (ave = 0.70878747)

2023-07-06 00:57:29,271 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29340	Time 12.319s / 10iters, (1.232)	Forward Time 1.140s / 10iters, (0.114)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.084s / 10iters, (0.008369)
Learning rate = [0.003042034652002369, 0.003042034652002369]	Loss = 0.69878465 (ave = 0.68856543)

2023-07-06 00:57:41,843 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29350	Time 12.572s / 10iters, (1.257)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.485s / 10iters, (0.848)	Loss Time 2.877s / 10iters, (0.288)	Data load 0.082s / 10iters, (0.008175)
Learning rate = [0.0030394664504874666, 0.0030394664504874666]	Loss = 0.81253076 (ave = 0.70722610)

2023-07-06 00:57:54,169 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29360	Time 12.326s / 10iters, (1.233)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.299s / 10iters, (0.830)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.079s / 10iters, (0.007920)
Learning rate = [0.0030368980078381647, 0.0030368980078381647]	Loss = 0.77551639 (ave = 0.72761219)

2023-07-06 00:58:06,654 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29370	Time 12.486s / 10iters, (1.249)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.463s / 10iters, (0.846)	Loss Time 2.818s / 10iters, (0.282)	Data load 0.084s / 10iters, (0.008407)
Learning rate = [0.0030343293238051837, 0.0030343293238051837]	Loss = 0.77237922 (ave = 0.72051844)

2023-07-06 00:58:18,931 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29380	Time 12.277s / 10iters, (1.228)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.270s / 10iters, (0.827)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.093s / 10iters, (0.009316)
Learning rate = [0.00303176039813875, 0.00303176039813875]	Loss = 0.72970456 (ave = 0.75125005)

2023-07-06 00:58:31,403 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29390	Time 12.471s / 10iters, (1.247)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.356s / 10iters, (0.836)	Loss Time 2.881s / 10iters, (0.288)	Data load 0.109s / 10iters, (0.010943)
Learning rate = [0.0030291912305885943, 0.0030291912305885943]	Loss = 0.72022080 (ave = 0.73368086)

2023-07-06 00:58:43,748 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29400	Time 12.345s / 10iters, (1.234)	Forward Time 1.169s / 10iters, (0.117)	Backward Time 8.281s / 10iters, (0.828)	Loss Time 2.809s / 10iters, (0.281)	Data load 0.086s / 10iters, (0.008629)
Learning rate = [0.003026621820903953, 0.003026621820903953]	Loss = 0.79895002 (ave = 0.70436846)

2023-07-06 00:58:56,216 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29410	Time 12.468s / 10iters, (1.247)	Forward Time 1.138s / 10iters, (0.114)	Backward Time 8.368s / 10iters, (0.837)	Loss Time 2.886s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007549)
Learning rate = [0.0030240521688335693, 0.0030240521688335693]	Loss = 0.75382876 (ave = 0.76634799)

2023-07-06 00:59:08,466 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29420	Time 12.250s / 10iters, (1.225)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.219s / 10iters, (0.822)	Loss Time 2.825s / 10iters, (0.283)	Data load 0.081s / 10iters, (0.008122)
Learning rate = [0.003021482274125682, 0.003021482274125682]	Loss = 0.69204122 (ave = 0.70318889)

2023-07-06 00:59:20,839 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29430	Time 12.373s / 10iters, (1.237)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.285s / 10iters, (0.828)	Loss Time 2.888s / 10iters, (0.289)	Data load 0.083s / 10iters, (0.008293)
Learning rate = [0.0030189121365280353, 0.0030189121365280353]	Loss = 0.66905081 (ave = 0.74882088)

2023-07-06 00:59:33,224 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29440	Time 12.384s / 10iters, (1.238)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.098s / 10iters, (0.009842)
Learning rate = [0.003016341755787868, 0.003016341755787868]	Loss = 0.73126823 (ave = 0.72291683)

2023-07-06 00:59:45,477 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29450	Time 12.254s / 10iters, (1.225)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.188s / 10iters, (0.819)	Loss Time 2.886s / 10iters, (0.289)	Data load 0.077s / 10iters, (0.007660)
Learning rate = [0.0030137711316519213, 0.0030137711316519213]	Loss = 0.66154426 (ave = 0.76256706)

2023-07-06 00:59:57,810 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29460	Time 12.332s / 10iters, (1.233)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.894s / 10iters, (0.289)	Data load 0.086s / 10iters, (0.008563)
Learning rate = [0.003011200263866428, 0.003011200263866428]	Loss = 0.69408870 (ave = 0.71577575)

2023-07-06 01:00:10,246 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29470	Time 12.437s / 10iters, (1.244)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.307s / 10iters, (0.831)	Loss Time 2.937s / 10iters, (0.294)	Data load 0.084s / 10iters, (0.008429)
Learning rate = [0.003008629152177118, 0.003008629152177118]	Loss = 0.80785763 (ave = 0.76355544)

2023-07-06 01:00:22,602 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29480	Time 12.356s / 10iters, (1.236)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.921s / 10iters, (0.292)	Data load 0.096s / 10iters, (0.009645)
Learning rate = [0.0030060577963292104, 0.0030060577963292104]	Loss = 0.77690923 (ave = 0.74939813)

2023-07-06 01:00:34,921 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29490	Time 12.319s / 10iters, (1.232)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.888s / 10iters, (0.289)	Data load 0.081s / 10iters, (0.008115)
Learning rate = [0.0030034861960674215, 0.0030034861960674215]	Loss = 0.66436148 (ave = 0.76709445)

2023-07-06 01:00:47,266 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29500	Time 12.344s / 10iters, (1.234)	Forward Time 1.141s / 10iters, (0.114)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.865s / 10iters, (0.287)	Data load 0.087s / 10iters, (0.008662)
Learning rate = [0.0030009143511359527, 0.0030009143511359527]	Loss = 0.85694617 (ave = 0.77000843)

2023-07-06 01:00:59,843 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29510	Time 12.578s / 10iters, (1.258)	Forward Time 1.137s / 10iters, (0.114)	Backward Time 8.474s / 10iters, (0.847)	Loss Time 2.866s / 10iters, (0.287)	Data load 0.101s / 10iters, (0.010068)
Learning rate = [0.002998342261278496, 0.002998342261278496]	Loss = 0.76757550 (ave = 0.71741347)

2023-07-06 01:01:12,038 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29520	Time 12.195s / 10iters, (1.219)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.088s / 10iters, (0.008834)
Learning rate = [0.0029957699262382286, 0.0029957699262382286]	Loss = 0.77282274 (ave = 0.72589498)

2023-07-06 01:01:24,499 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29530	Time 12.460s / 10iters, (1.246)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.403s / 10iters, (0.840)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.095s / 10iters, (0.009520)
Learning rate = [0.0029931973457578164, 0.0029931973457578164]	Loss = 0.72825164 (ave = 0.71233287)

2023-07-06 01:01:36,783 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29540	Time 12.284s / 10iters, (1.228)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.275s / 10iters, (0.828)	Loss Time 2.795s / 10iters, (0.279)	Data load 0.091s / 10iters, (0.009061)
Learning rate = [0.0029906245195794067, 0.0029906245195794067]	Loss = 0.68610597 (ave = 0.68967482)

2023-07-06 01:01:49,027 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29550	Time 12.244s / 10iters, (1.224)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007578)
Learning rate = [0.0029880514474446285, 0.0029880514474446285]	Loss = 0.86618674 (ave = 0.69368890)

2023-07-06 01:02:01,325 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29560	Time 12.298s / 10iters, (1.230)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.095s / 10iters, (0.009537)
Learning rate = [0.002985478129094592, 0.002985478129094592]	Loss = 0.76311743 (ave = 0.73637122)

2023-07-06 01:02:13,707 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29570	Time 12.382s / 10iters, (1.238)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.306s / 10iters, (0.831)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.077s / 10iters, (0.007660)
Learning rate = [0.0029829045642698893, 0.0029829045642698893]	Loss = 0.70956236 (ave = 0.72964275)

2023-07-06 01:02:26,215 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29580	Time 12.508s / 10iters, (1.251)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.362s / 10iters, (0.836)	Loss Time 2.927s / 10iters, (0.293)	Data load 0.112s / 10iters, (0.011210)
Learning rate = [0.0029803307527105877, 0.0029803307527105877]	Loss = 0.72260785 (ave = 0.78227654)

2023-07-06 01:02:38,603 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29590	Time 12.388s / 10iters, (1.239)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.279s / 10iters, (0.828)	Loss Time 2.908s / 10iters, (0.291)	Data load 0.088s / 10iters, (0.008814)
Learning rate = [0.002977756694156231, 0.002977756694156231]	Loss = 0.71310270 (ave = 0.74014788)

2023-07-06 01:02:51,020 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29600	Time 12.416s / 10iters, (1.242)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.333s / 10iters, (0.833)	Loss Time 2.887s / 10iters, (0.289)	Data load 0.090s / 10iters, (0.009015)
Learning rate = [0.0029751823883458367, 0.0029751823883458367]	Loss = 1.07255745 (ave = 0.76949511)

2023-07-06 01:03:03,426 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29610	Time 12.407s / 10iters, (1.241)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.297s / 10iters, (0.830)	Loss Time 2.885s / 10iters, (0.288)	Data load 0.098s / 10iters, (0.009797)
Learning rate = [0.0029726078350178985, 0.0029726078350178985]	Loss = 0.70248300 (ave = 0.70360868)

2023-07-06 01:03:15,808 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29620	Time 12.381s / 10iters, (1.238)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.870s / 10iters, (0.287)	Data load 0.080s / 10iters, (0.008015)
Learning rate = [0.0029700330339103792, 0.0029700330339103792]	Loss = 0.74561530 (ave = 0.73480756)

2023-07-06 01:03:28,114 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29630	Time 12.306s / 10iters, (1.231)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.795s / 10iters, (0.279)	Data load 0.095s / 10iters, (0.009456)
Learning rate = [0.0029674579847607106, 0.0029674579847607106]	Loss = 0.71395856 (ave = 0.72825193)

2023-07-06 01:03:40,479 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29640	Time 12.365s / 10iters, (1.237)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.864s / 10iters, (0.286)	Data load 0.092s / 10iters, (0.009245)
Learning rate = [0.0029648826873057937, 0.0029648826873057937]	Loss = 0.70830357 (ave = 0.73646398)

2023-07-06 01:03:52,782 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29650	Time 12.303s / 10iters, (1.230)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.096s / 10iters, (0.009633)
Learning rate = [0.002962307141281999, 0.002962307141281999]	Loss = 0.69822824 (ave = 0.73562089)

2023-07-06 01:04:04,976 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29660	Time 12.194s / 10iters, (1.219)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.178s / 10iters, (0.818)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.085s / 10iters, (0.008493)
Learning rate = [0.0029597313464251587, 0.0029597313464251587]	Loss = 0.75005281 (ave = 0.72146195)

2023-07-06 01:04:17,286 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29670	Time 12.309s / 10iters, (1.231)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.304s / 10iters, (0.830)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.077s / 10iters, (0.007736)
Learning rate = [0.0029571553024705685, 0.0029571553024705685]	Loss = 0.63926542 (ave = 0.69820804)

2023-07-06 01:04:29,485 INFO    [trainer_contrastive.py, 272] Train Epoch: 79	Train Iteration: 29680	Time 12.200s / 10iters, (1.220)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.077s / 10iters, (0.007714)
Learning rate = [0.0029545790091529867, 0.0029545790091529867]	Loss = 0.74458569 (ave = 0.75636699)

2023-07-06 01:04:45,429 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29690	Time 15.795s / 10iters, (1.580)	Forward Time 1.208s / 10iters, (0.121)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.704s / 10iters, (0.270)	Data load 3.669s / 10iters, (0.366883)
Learning rate = [0.002952002466206634, 0.002952002466206634]	Loss = 0.90867001 (ave = 0.71439781)

2023-07-06 01:04:57,730 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29700	Time 12.302s / 10iters, (1.230)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.337s / 10iters, (0.834)	Loss Time 2.743s / 10iters, (0.274)	Data load 0.107s / 10iters, (0.010705)
Learning rate = [0.0029494256733651877, 0.0029494256733651877]	Loss = 0.68618393 (ave = 0.72995102)

2023-07-06 01:05:09,886 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29710	Time 12.156s / 10iters, (1.216)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.236s / 10iters, (0.824)	Loss Time 2.733s / 10iters, (0.273)	Data load 0.076s / 10iters, (0.007637)
Learning rate = [0.0029468486303617816, 0.0029468486303617816]	Loss = 0.79539919 (ave = 0.78190467)

2023-07-06 01:05:22,243 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29720	Time 12.357s / 10iters, (1.236)	Forward Time 1.166s / 10iters, (0.117)	Backward Time 8.376s / 10iters, (0.838)	Loss Time 2.740s / 10iters, (0.274)	Data load 0.075s / 10iters, (0.007522)
Learning rate = [0.0029442713369290047, 0.0029442713369290047]	Loss = 0.77978379 (ave = 0.72691273)

2023-07-06 01:05:34,587 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29730	Time 12.344s / 10iters, (1.234)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.379s / 10iters, (0.838)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.080s / 10iters, (0.007982)
Learning rate = [0.002941693792798903, 0.002941693792798903]	Loss = 0.65327680 (ave = 0.71213764)

2023-07-06 01:05:47,106 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29740	Time 12.518s / 10iters, (1.252)	Forward Time 1.154s / 10iters, (0.115)	Backward Time 8.508s / 10iters, (0.851)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.079s / 10iters, (0.007854)
Learning rate = [0.002939115997702972, 0.002939115997702972]	Loss = 0.75518435 (ave = 0.74968129)

2023-07-06 01:05:59,651 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29750	Time 12.546s / 10iters, (1.255)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.534s / 10iters, (0.853)	Loss Time 2.805s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007494)
Learning rate = [0.0029365379513721568, 0.0029365379513721568]	Loss = 0.73023725 (ave = 0.67485060)

2023-07-06 01:06:12,196 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29760	Time 12.545s / 10iters, (1.254)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.515s / 10iters, (0.852)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007379)
Learning rate = [0.002933959653536853, 0.002933959653536853]	Loss = 0.78456122 (ave = 0.68981662)

2023-07-06 01:06:24,771 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29770	Time 12.575s / 10iters, (1.258)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.547s / 10iters, (0.855)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.085s / 10iters, (0.008469)
Learning rate = [0.0029313811039269034, 0.0029313811039269034]	Loss = 0.62713099 (ave = 0.72382811)

2023-07-06 01:06:37,084 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29780	Time 12.313s / 10iters, (1.231)	Forward Time 1.143s / 10iters, (0.114)	Backward Time 8.314s / 10iters, (0.831)	Loss Time 2.764s / 10iters, (0.276)	Data load 0.091s / 10iters, (0.009144)
Learning rate = [0.0029288023022715952, 0.0029288023022715952]	Loss = 0.61150968 (ave = 0.65710300)

2023-07-06 01:06:49,298 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29790	Time 12.214s / 10iters, (1.221)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.230s / 10iters, (0.823)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.082s / 10iters, (0.008164)
Learning rate = [0.0029262232482996607, 0.0029262232482996607]	Loss = 0.78166634 (ave = 0.69367160)

2023-07-06 01:07:01,547 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29800	Time 12.249s / 10iters, (1.225)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.298s / 10iters, (0.830)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.084s / 10iters, (0.008425)
Learning rate = [0.0029236439417392717, 0.0029236439417392717]	Loss = 0.75022209 (ave = 0.75739117)

2023-07-06 01:07:13,829 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29810	Time 12.282s / 10iters, (1.228)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.343s / 10iters, (0.834)	Loss Time 2.762s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007436)
Learning rate = [0.0029210643823180445, 0.0029210643823180445]	Loss = 0.82613325 (ave = 0.72161543)

2023-07-06 01:07:26,154 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29820	Time 12.325s / 10iters, (1.232)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.315s / 10iters, (0.831)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.084s / 10iters, (0.008385)
Learning rate = [0.0029184845697630304, 0.0029184845697630304]	Loss = 0.80132920 (ave = 0.72281201)

2023-07-06 01:07:38,354 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29830	Time 12.200s / 10iters, (1.220)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.233s / 10iters, (0.823)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.087s / 10iters, (0.008730)
Learning rate = [0.0029159045038007194, 0.0029159045038007194]	Loss = 0.72181499 (ave = 0.72234549)

2023-07-06 01:07:50,671 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29840	Time 12.317s / 10iters, (1.232)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.081s / 10iters, (0.008100)
Learning rate = [0.002913324184157035, 0.002913324184157035]	Loss = 0.64859456 (ave = 0.73072795)

2023-07-06 01:08:03,058 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29850	Time 12.387s / 10iters, (1.239)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.398s / 10iters, (0.840)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.086s / 10iters, (0.008561)
Learning rate = [0.0029107436105573373, 0.0029107436105573373]	Loss = 0.95422029 (ave = 0.74705586)

2023-07-06 01:08:15,337 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29860	Time 12.279s / 10iters, (1.228)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.345s / 10iters, (0.834)	Loss Time 2.729s / 10iters, (0.273)	Data load 0.074s / 10iters, (0.007406)
Learning rate = [0.0029081627827264164, 0.0029081627827264164]	Loss = 0.80908912 (ave = 0.70854799)

2023-07-06 01:08:27,488 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29870	Time 12.151s / 10iters, (1.215)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.725s / 10iters, (0.273)	Data load 0.087s / 10iters, (0.008659)
Learning rate = [0.0029055817003884915, 0.0029055817003884915]	Loss = 0.74005699 (ave = 0.70808739)

2023-07-06 01:08:39,625 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29880	Time 12.137s / 10iters, (1.214)	Forward Time 1.137s / 10iters, (0.114)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.687s / 10iters, (0.269)	Data load 0.078s / 10iters, (0.007816)
Learning rate = [0.0029030003632672125, 0.0029030003632672125]	Loss = 0.75055444 (ave = 0.70497026)

2023-07-06 01:08:51,979 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29890	Time 12.354s / 10iters, (1.235)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.335s / 10iters, (0.834)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.078s / 10iters, (0.007788)
Learning rate = [0.002900418771085652, 0.002900418771085652]	Loss = 0.78137988 (ave = 0.74259008)

2023-07-06 01:09:04,231 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29900	Time 12.252s / 10iters, (1.225)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.082s / 10iters, (0.008152)
Learning rate = [0.0028978369235663137, 0.0028978369235663137]	Loss = 0.61000407 (ave = 0.71823083)

2023-07-06 01:09:16,508 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29910	Time 12.277s / 10iters, (1.228)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.286s / 10iters, (0.829)	Loss Time 2.808s / 10iters, (0.281)	Data load 0.078s / 10iters, (0.007808)
Learning rate = [0.0028952548204311183, 0.0028952548204311183]	Loss = 0.79237700 (ave = 0.75550572)

2023-07-06 01:09:28,778 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29920	Time 12.270s / 10iters, (1.227)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.089s / 10iters, (0.008948)
Learning rate = [0.002892672461401411, 0.002892672461401411]	Loss = 0.78405368 (ave = 0.73174099)

2023-07-06 01:09:41,058 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29930	Time 12.280s / 10iters, (1.228)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.265s / 10iters, (0.827)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007539)
Learning rate = [0.0028900898461979535, 0.0028900898461979535]	Loss = 0.83779132 (ave = 0.70122384)

2023-07-06 01:09:53,434 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29940	Time 12.376s / 10iters, (1.238)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.101s / 10iters, (0.010148)
Learning rate = [0.0028875069745409303, 0.0028875069745409303]	Loss = 0.63472277 (ave = 0.72463275)

2023-07-06 01:10:05,788 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29950	Time 12.354s / 10iters, (1.235)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.079s / 10iters, (0.007859)
Learning rate = [0.0028849238461499376, 0.0028849238461499376]	Loss = 0.69148183 (ave = 0.68422039)

2023-07-06 01:10:18,115 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29960	Time 12.327s / 10iters, (1.233)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.855s / 10iters, (0.286)	Data load 0.089s / 10iters, (0.008910)
Learning rate = [0.002882340460743987, 0.002882340460743987]	Loss = 0.63761044 (ave = 0.72812013)

2023-07-06 01:10:30,483 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29970	Time 12.368s / 10iters, (1.237)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.305s / 10iters, (0.830)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.083s / 10iters, (0.008308)
Learning rate = [0.0028797568180415007, 0.0028797568180415007]	Loss = 0.64950037 (ave = 0.73410066)

2023-07-06 01:10:42,806 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29980	Time 12.322s / 10iters, (1.232)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.286s / 10iters, (0.829)	Loss Time 2.857s / 10iters, (0.286)	Data load 0.083s / 10iters, (0.008266)
Learning rate = [0.002877172917760315, 0.002877172917760315]	Loss = 0.89327753 (ave = 0.76705917)

2023-07-06 01:10:55,170 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 29990	Time 12.365s / 10iters, (1.236)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.920s / 10iters, (0.292)	Data load 0.075s / 10iters, (0.007456)
Learning rate = [0.0028745887596176734, 0.0028745887596176734]	Loss = 0.70506924 (ave = 0.70554829)

2023-07-06 01:11:07,627 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 30000	Time 12.456s / 10iters, (1.246)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.369s / 10iters, (0.837)	Loss Time 2.901s / 10iters, (0.290)	Data load 0.081s / 10iters, (0.008147)
Learning rate = [0.002872004343330224, 0.002872004343330224]	Loss = 0.91414380 (ave = 0.77466708)

2023-07-06 01:11:11,658 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-06 01:11:35,797 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-06 01:11:59,117 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-06 01:12:22,424 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-06 01:12:45,794 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-06 01:13:08,942 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-06 01:13:31,668 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-06 01:13:40,334 INFO    [trainer_contrastive.py, 391] Test Time 149.683s, (2.376)	Loss 0.13719995

2023-07-06 01:13:40,334 INFO    [base.py, 33] Result for seg
2023-07-06 01:13:40,335 INFO    [base.py, 49] Mean IOU: 0.7538083363065078

2023-07-06 01:13:40,335 INFO    [base.py, 50] Pixel ACC: 0.9560911012340559

2023-07-06 01:13:52,532 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 30010	Time 164.905s / 10iters, (16.491)	Forward Time 1.136s / 10iters, (0.114)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.734s / 10iters, (0.273)	Data load 152.828s / 10iters, (15.282820)
Learning rate = [0.0028694196686140216, 0.0028694196686140216]	Loss = 0.73438811 (ave = 0.73861543)

2023-07-06 01:14:04,883 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 30020	Time 12.351s / 10iters, (1.235)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.355s / 10iters, (0.835)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.097s / 10iters, (0.009729)
Learning rate = [0.002866834735184526, 0.002866834735184526]	Loss = 0.68738812 (ave = 0.70029837)

2023-07-06 01:14:17,048 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 30030	Time 12.164s / 10iters, (1.216)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.085s / 10iters, (0.008527)
Learning rate = [0.0028642495427565946, 0.0028642495427565946]	Loss = 0.69168258 (ave = 0.70704600)

2023-07-06 01:14:29,033 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 30040	Time 11.986s / 10iters, (1.199)	Forward Time 1.083s / 10iters, (0.108)	Backward Time 8.079s / 10iters, (0.808)	Loss Time 2.750s / 10iters, (0.275)	Data load 0.074s / 10iters, (0.007429)
Learning rate = [0.0028616640910444874, 0.0028616640910444874]	Loss = 0.68397266 (ave = 0.67800314)

2023-07-06 01:14:40,889 INFO    [trainer_contrastive.py, 272] Train Epoch: 80	Train Iteration: 30050	Time 11.856s / 10iters, (1.186)	Forward Time 1.073s / 10iters, (0.107)	Backward Time 8.030s / 10iters, (0.803)	Loss Time 2.676s / 10iters, (0.268)	Data load 0.077s / 10iters, (0.007718)
Learning rate = [0.0028590783797618584, 0.0028590783797618584]	Loss = 0.72355217 (ave = 0.73085893)

2023-07-06 01:14:55,911 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30060	Time 14.802s / 10iters, (1.480)	Forward Time 1.354s / 10iters, (0.135)	Backward Time 8.192s / 10iters, (0.819)	Loss Time 2.656s / 10iters, (0.266)	Data load 2.600s / 10iters, (0.259970)
Learning rate = [0.002856492408621763, 0.002856492408621763]	Loss = 0.69375813 (ave = 0.73941727)

2023-07-06 01:15:08,158 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30070	Time 12.247s / 10iters, (1.225)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.726s / 10iters, (0.273)	Data load 0.075s / 10iters, (0.007461)
Learning rate = [0.0028539061773366447, 0.0028539061773366447]	Loss = 0.60851026 (ave = 0.71286098)

2023-07-06 01:15:20,434 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30080	Time 12.276s / 10iters, (1.228)	Forward Time 1.144s / 10iters, (0.114)	Backward Time 8.397s / 10iters, (0.840)	Loss Time 2.660s / 10iters, (0.266)	Data load 0.076s / 10iters, (0.007564)
Learning rate = [0.0028513196856183413, 0.0028513196856183413]	Loss = 0.84076047 (ave = 0.75879955)

2023-07-06 01:15:32,793 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30090	Time 12.359s / 10iters, (1.236)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.457s / 10iters, (0.846)	Loss Time 2.689s / 10iters, (0.269)	Data load 0.102s / 10iters, (0.010205)
Learning rate = [0.0028487329331780805, 0.0028487329331780805]	Loss = 0.71057850 (ave = 0.71006334)

2023-07-06 01:15:45,166 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30100	Time 12.373s / 10iters, (1.237)	Forward Time 1.196s / 10iters, (0.120)	Backward Time 8.459s / 10iters, (0.846)	Loss Time 2.642s / 10iters, (0.264)	Data load 0.076s / 10iters, (0.007627)
Learning rate = [0.002846145919726479, 0.002846145919726479]	Loss = 0.78682005 (ave = 0.69584828)

2023-07-06 01:15:57,473 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30110	Time 12.307s / 10iters, (1.231)	Forward Time 1.176s / 10iters, (0.118)	Backward Time 8.335s / 10iters, (0.834)	Loss Time 2.720s / 10iters, (0.272)	Data load 0.076s / 10iters, (0.007608)
Learning rate = [0.002843558644973538, 0.002843558644973538]	Loss = 0.65925592 (ave = 0.67125897)

2023-07-06 01:16:09,886 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30120	Time 12.413s / 10iters, (1.241)	Forward Time 1.137s / 10iters, (0.114)	Backward Time 8.349s / 10iters, (0.835)	Loss Time 2.833s / 10iters, (0.283)	Data load 0.094s / 10iters, (0.009366)
Learning rate = [0.0028409711086286437, 0.0028409711086286437]	Loss = 0.67012936 (ave = 0.74103013)

2023-07-06 01:16:22,113 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30130	Time 12.227s / 10iters, (1.223)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.756s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007461)
Learning rate = [0.0028383833104005636, 0.0028383833104005636]	Loss = 0.68456906 (ave = 0.70692918)

2023-07-06 01:16:34,547 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30140	Time 12.434s / 10iters, (1.243)	Forward Time 1.164s / 10iters, (0.116)	Backward Time 8.397s / 10iters, (0.840)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.079s / 10iters, (0.007916)
Learning rate = [0.002835795249997449, 0.002835795249997449]	Loss = 0.73561382 (ave = 0.70871966)

2023-07-06 01:16:46,976 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30150	Time 12.430s / 10iters, (1.243)	Forward Time 1.147s / 10iters, (0.115)	Backward Time 8.370s / 10iters, (0.837)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.085s / 10iters, (0.008532)
Learning rate = [0.002833206927126826, 0.002833206927126826]	Loss = 0.70220196 (ave = 0.74656007)

2023-07-06 01:16:59,248 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30160	Time 12.272s / 10iters, (1.227)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.089s / 10iters, (0.008933)
Learning rate = [0.002830618341495598, 0.002830618341495598]	Loss = 0.73096889 (ave = 0.79978201)

2023-07-06 01:17:11,489 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30170	Time 12.241s / 10iters, (1.224)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.082s / 10iters, (0.008224)
Learning rate = [0.002828029492810043, 0.002828029492810043]	Loss = 0.66982752 (ave = 0.70366113)

2023-07-06 01:17:23,784 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30180	Time 12.295s / 10iters, (1.230)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.305s / 10iters, (0.830)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.083s / 10iters, (0.008278)
Learning rate = [0.002825440380775814, 0.002825440380775814]	Loss = 0.70144784 (ave = 0.75837203)

2023-07-06 01:17:36,186 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30190	Time 12.402s / 10iters, (1.240)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.394s / 10iters, (0.839)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.087s / 10iters, (0.008734)
Learning rate = [0.0028228510050979307, 0.0028228510050979307]	Loss = 0.72576159 (ave = 0.72859145)

2023-07-06 01:17:48,538 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30200	Time 12.352s / 10iters, (1.235)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.079s / 10iters, (0.007945)
Learning rate = [0.002820261365480784, 0.002820261365480784]	Loss = 0.71983457 (ave = 0.72067857)

2023-07-06 01:18:00,732 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30210	Time 12.194s / 10iters, (1.219)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.228s / 10iters, (0.823)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.096s / 10iters, (0.009553)
Learning rate = [0.0028176714616281297, 0.0028176714616281297]	Loss = 0.70957613 (ave = 0.69001606)

2023-07-06 01:18:13,002 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30220	Time 12.270s / 10iters, (1.227)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.098s / 10iters, (0.009787)
Learning rate = [0.0028150812932430896, 0.0028150812932430896]	Loss = 0.82737261 (ave = 0.74349179)

2023-07-06 01:18:25,282 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30230	Time 12.281s / 10iters, (1.228)	Forward Time 1.136s / 10iters, (0.114)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.775s / 10iters, (0.278)	Data load 0.085s / 10iters, (0.008470)
Learning rate = [0.0028124908600281485, 0.0028124908600281485]	Loss = 0.59064746 (ave = 0.67320251)

2023-07-06 01:18:37,539 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30240	Time 12.257s / 10iters, (1.226)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.077s / 10iters, (0.007662)
Learning rate = [0.0028099001616851494, 0.0028099001616851494]	Loss = 0.60980660 (ave = 0.66797219)

2023-07-06 01:18:49,982 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30250	Time 12.443s / 10iters, (1.244)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.479s / 10iters, (0.848)	Loss Time 2.755s / 10iters, (0.275)	Data load 0.084s / 10iters, (0.008361)
Learning rate = [0.0028073091979152944, 0.0028073091979152944]	Loss = 0.72633177 (ave = 0.72640579)

2023-07-06 01:19:02,086 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30260	Time 12.104s / 10iters, (1.210)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.689s / 10iters, (0.269)	Data load 0.082s / 10iters, (0.008211)
Learning rate = [0.0028047179684191448, 0.0028047179684191448]	Loss = 0.78846925 (ave = 0.77270417)

2023-07-06 01:19:14,301 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30270	Time 12.215s / 10iters, (1.221)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.711s / 10iters, (0.271)	Data load 0.086s / 10iters, (0.008588)
Learning rate = [0.002802126472896613, 0.002802126472896613]	Loss = 0.77705598 (ave = 0.73723857)

2023-07-06 01:19:26,547 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30280	Time 12.246s / 10iters, (1.225)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.341s / 10iters, (0.834)	Loss Time 2.714s / 10iters, (0.271)	Data load 0.087s / 10iters, (0.008726)
Learning rate = [0.0027995347110469668, 0.0027995347110469668]	Loss = 0.65027720 (ave = 0.72791053)

2023-07-06 01:19:38,803 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30290	Time 12.257s / 10iters, (1.226)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007611)
Learning rate = [0.0027969426825688194, 0.0027969426825688194]	Loss = 0.71424425 (ave = 0.70976607)

2023-07-06 01:19:51,030 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30300	Time 12.227s / 10iters, (1.223)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.083s / 10iters, (0.008253)
Learning rate = [0.0027943503871601383, 0.0027943503871601383]	Loss = 0.64461815 (ave = 0.72355577)

2023-07-06 01:20:03,449 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30310	Time 12.418s / 10iters, (1.242)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.370s / 10iters, (0.837)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.106s / 10iters, (0.010568)
Learning rate = [0.0027917578245182334, 0.0027917578245182334]	Loss = 0.69303948 (ave = 0.71565902)

2023-07-06 01:20:15,755 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30320	Time 12.306s / 10iters, (1.231)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.305s / 10iters, (0.831)	Loss Time 2.804s / 10iters, (0.280)	Data load 0.095s / 10iters, (0.009515)
Learning rate = [0.0027891649943397596, 0.0027891649943397596]	Loss = 0.70167911 (ave = 0.68152416)

2023-07-06 01:20:28,084 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30330	Time 12.329s / 10iters, (1.233)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.331s / 10iters, (0.833)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.085s / 10iters, (0.008476)
Learning rate = [0.002786571896320712, 0.002786571896320712]	Loss = 0.63263017 (ave = 0.69161823)

2023-07-06 01:20:40,421 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30340	Time 12.337s / 10iters, (1.234)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.342s / 10iters, (0.834)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.095s / 10iters, (0.009521)
Learning rate = [0.0027839785301564304, 0.0027839785301564304]	Loss = 0.70311117 (ave = 0.71772285)

2023-07-06 01:20:52,633 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30350	Time 12.212s / 10iters, (1.221)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.737s / 10iters, (0.274)	Data load 0.093s / 10iters, (0.009287)
Learning rate = [0.002781384895541587, 0.002781384895541587]	Loss = 0.59557182 (ave = 0.69866271)

2023-07-06 01:21:04,918 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30360	Time 12.285s / 10iters, (1.228)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.307s / 10iters, (0.831)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.078s / 10iters, (0.007793)
Learning rate = [0.002778790992170192, 0.002778790992170192]	Loss = 0.78120947 (ave = 0.71178002)

2023-07-06 01:21:17,235 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30370	Time 12.317s / 10iters, (1.232)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.275s / 10iters, (0.828)	Loss Time 2.868s / 10iters, (0.287)	Data load 0.079s / 10iters, (0.007928)
Learning rate = [0.002776196819735588, 0.002776196819735588]	Loss = 0.80364704 (ave = 0.76588844)

2023-07-06 01:21:29,413 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30380	Time 12.178s / 10iters, (1.218)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.178s / 10iters, (0.818)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.083s / 10iters, (0.008299)
Learning rate = [0.002773602377930452, 0.002773602377930452]	Loss = 0.54925555 (ave = 0.69696748)

2023-07-06 01:21:41,772 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30390	Time 12.359s / 10iters, (1.236)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.874s / 10iters, (0.287)	Data load 0.082s / 10iters, (0.008228)
Learning rate = [0.002771007666446786, 0.002771007666446786]	Loss = 0.77758193 (ave = 0.71718896)

2023-07-06 01:21:54,127 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30400	Time 12.356s / 10iters, (1.236)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.275s / 10iters, (0.828)	Loss Time 2.893s / 10iters, (0.289)	Data load 0.077s / 10iters, (0.007706)
Learning rate = [0.0027684126849759215, 0.0027684126849759215]	Loss = 0.71691114 (ave = 0.69035855)

2023-07-06 01:22:06,292 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30410	Time 12.165s / 10iters, (1.216)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007381)
Learning rate = [0.0027658174332085127, 0.0027658174332085127]	Loss = 0.73810750 (ave = 0.74482910)

2023-07-06 01:22:18,351 INFO    [trainer_contrastive.py, 272] Train Epoch: 81	Train Iteration: 30420	Time 12.059s / 10iters, (1.206)	Forward Time 1.082s / 10iters, (0.108)	Backward Time 8.160s / 10iters, (0.816)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.078s / 10iters, (0.007781)
Learning rate = [0.0027632219108345408, 0.0027632219108345408]	Loss = 0.75330085 (ave = 0.71897809)

2023-07-06 01:22:33,608 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30430	Time 15.069s / 10iters, (1.507)	Forward Time 1.275s / 10iters, (0.128)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.703s / 10iters, (0.270)	Data load 2.802s / 10iters, (0.280205)
Learning rate = [0.0027606261175433027, 0.0027606261175433027]	Loss = 0.71019548 (ave = 0.68515526)

2023-07-06 01:22:45,925 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30440	Time 12.317s / 10iters, (1.232)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.298s / 10iters, (0.830)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.085s / 10iters, (0.008521)
Learning rate = [0.002758030053023416, 0.002758030053023416]	Loss = 0.59804618 (ave = 0.73307043)

2023-07-06 01:22:58,303 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30450	Time 12.378s / 10iters, (1.238)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.329s / 10iters, (0.833)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.088s / 10iters, (0.008794)
Learning rate = [0.0027554337169628114, 0.0027554337169628114]	Loss = 0.64286757 (ave = 0.69372063)

2023-07-06 01:23:10,646 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30460	Time 12.343s / 10iters, (1.234)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.092s / 10iters, (0.009244)
Learning rate = [0.00275283710904874, 0.00275283710904874]	Loss = 0.69844347 (ave = 0.71833761)

2023-07-06 01:23:22,848 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30470	Time 12.202s / 10iters, (1.220)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.199s / 10iters, (0.820)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007581)
Learning rate = [0.002750240228967757, 0.002750240228967757]	Loss = 0.78656644 (ave = 0.70837143)

2023-07-06 01:23:35,129 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30480	Time 12.281s / 10iters, (1.228)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.091s / 10iters, (0.009131)
Learning rate = [0.0027476430764057313, 0.0027476430764057313]	Loss = 0.74913603 (ave = 0.72354549)

2023-07-06 01:23:47,541 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30490	Time 12.412s / 10iters, (1.241)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.903s / 10iters, (0.290)	Data load 0.078s / 10iters, (0.007796)
Learning rate = [0.0027450456510478365, 0.0027450456510478365]	Loss = 0.69793946 (ave = 0.75344334)

2023-07-06 01:23:59,853 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30500	Time 12.312s / 10iters, (1.231)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.203s / 10iters, (0.820)	Loss Time 2.857s / 10iters, (0.286)	Data load 0.117s / 10iters, (0.011710)
Learning rate = [0.002742447952578555, 0.002742447952578555]	Loss = 0.67679119 (ave = 0.71884608)

2023-07-06 01:24:12,266 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30510	Time 12.413s / 10iters, (1.241)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.901s / 10iters, (0.290)	Data load 0.086s / 10iters, (0.008588)
Learning rate = [0.002739849980681667, 0.002739849980681667]	Loss = 0.92624342 (ave = 0.73859497)

2023-07-06 01:24:24,750 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30520	Time 12.484s / 10iters, (1.248)	Forward Time 1.140s / 10iters, (0.114)	Backward Time 8.383s / 10iters, (0.838)	Loss Time 2.870s / 10iters, (0.287)	Data load 0.091s / 10iters, (0.009074)
Learning rate = [0.002737251735040256, 0.002737251735040256]	Loss = 0.66171473 (ave = 0.70076984)

2023-07-06 01:24:37,042 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30530	Time 12.291s / 10iters, (1.229)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.281s / 10iters, (0.828)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.079s / 10iters, (0.007868)
Learning rate = [0.002734653215336701, 0.002734653215336701]	Loss = 0.76236403 (ave = 0.74665807)

2023-07-06 01:24:49,179 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30540	Time 12.137s / 10iters, (1.214)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.740s / 10iters, (0.274)	Data load 0.080s / 10iters, (0.007974)
Learning rate = [0.0027320544212526806, 0.0027320544212526806]	Loss = 0.73930824 (ave = 0.72732240)

2023-07-06 01:25:01,314 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30550	Time 12.135s / 10iters, (1.213)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.745s / 10iters, (0.275)	Data load 0.081s / 10iters, (0.008142)
Learning rate = [0.002729455352469163, 0.002729455352469163]	Loss = 0.77015567 (ave = 0.75362657)

2023-07-06 01:25:13,568 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30560	Time 12.255s / 10iters, (1.225)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.088s / 10iters, (0.008847)
Learning rate = [0.0027268560086664098, 0.0027268560086664098]	Loss = 0.73567277 (ave = 0.72427254)

2023-07-06 01:25:25,895 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30570	Time 12.326s / 10iters, (1.233)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.319s / 10iters, (0.832)	Loss Time 2.809s / 10iters, (0.281)	Data load 0.095s / 10iters, (0.009535)
Learning rate = [0.0027242563895239686, 0.0027242563895239686]	Loss = 0.86251259 (ave = 0.76975476)

2023-07-06 01:25:38,136 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30580	Time 12.242s / 10iters, (1.224)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.228s / 10iters, (0.823)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.085s / 10iters, (0.008463)
Learning rate = [0.0027216564947206783, 0.0027216564947206783]	Loss = 0.80292511 (ave = 0.70376785)

2023-07-06 01:25:50,386 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30590	Time 12.249s / 10iters, (1.225)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.816s / 10iters, (0.282)	Data load 0.088s / 10iters, (0.008843)
Learning rate = [0.0027190563239346574, 0.0027190563239346574]	Loss = 0.65453476 (ave = 0.67533702)

2023-07-06 01:26:02,599 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30600	Time 12.213s / 10iters, (1.221)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.083s / 10iters, (0.008259)
Learning rate = [0.002716455876843307, 0.002716455876843307]	Loss = 0.77971458 (ave = 0.68393196)

2023-07-06 01:26:14,851 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30610	Time 12.252s / 10iters, (1.225)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.227s / 10iters, (0.823)	Loss Time 2.848s / 10iters, (0.285)	Data load 0.084s / 10iters, (0.008372)
Learning rate = [0.0027138551531233086, 0.0027138551531233086]	Loss = 0.75180328 (ave = 0.69910358)

2023-07-06 01:26:27,112 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30620	Time 12.262s / 10iters, (1.226)	Forward Time 1.152s / 10iters, (0.115)	Backward Time 8.242s / 10iters, (0.824)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.080s / 10iters, (0.007983)
Learning rate = [0.002711254152450621, 0.002711254152450621]	Loss = 0.71265334 (ave = 0.70739372)

2023-07-06 01:26:39,329 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30630	Time 12.217s / 10iters, (1.222)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.219s / 10iters, (0.822)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.100s / 10iters, (0.009988)
Learning rate = [0.002708652874500476, 0.002708652874500476]	Loss = 0.68424273 (ave = 0.67572145)

2023-07-06 01:26:51,620 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30640	Time 12.290s / 10iters, (1.229)	Forward Time 1.148s / 10iters, (0.115)	Backward Time 8.312s / 10iters, (0.831)	Loss Time 2.732s / 10iters, (0.273)	Data load 0.099s / 10iters, (0.009852)
Learning rate = [0.002706051318947379, 0.002706051318947379]	Loss = 0.60807371 (ave = 0.70000763)

2023-07-06 01:27:04,034 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30650	Time 12.414s / 10iters, (1.241)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.379s / 10iters, (0.838)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.077s / 10iters, (0.007742)
Learning rate = [0.0027034494854651027, 0.0027034494854651027]	Loss = 0.74791360 (ave = 0.70818023)

2023-07-06 01:27:16,373 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30660	Time 12.340s / 10iters, (1.234)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.357s / 10iters, (0.836)	Loss Time 2.804s / 10iters, (0.280)	Data load 0.078s / 10iters, (0.007848)
Learning rate = [0.0027008473737266912, 0.0027008473737266912]	Loss = 0.68433690 (ave = 0.68331333)

2023-07-06 01:27:28,713 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30670	Time 12.340s / 10iters, (1.234)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.314s / 10iters, (0.831)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.096s / 10iters, (0.009620)
Learning rate = [0.002698244983404451, 0.002698244983404451]	Loss = 0.66208827 (ave = 0.68006194)

2023-07-06 01:27:41,068 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30680	Time 12.355s / 10iters, (1.236)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.286s / 10iters, (0.829)	Loss Time 2.845s / 10iters, (0.285)	Data load 0.095s / 10iters, (0.009535)
Learning rate = [0.00269564231416995, 0.00269564231416995]	Loss = 0.75282282 (ave = 0.69302022)

2023-07-06 01:27:53,464 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30690	Time 12.396s / 10iters, (1.240)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.333s / 10iters, (0.833)	Loss Time 2.872s / 10iters, (0.287)	Data load 0.089s / 10iters, (0.008932)
Learning rate = [0.002693039365694017, 0.002693039365694017]	Loss = 0.70184720 (ave = 0.75320362)

2023-07-06 01:28:05,873 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30700	Time 12.409s / 10iters, (1.241)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.326s / 10iters, (0.833)	Loss Time 2.884s / 10iters, (0.288)	Data load 0.089s / 10iters, (0.008915)
Learning rate = [0.0026904361376467417, 0.0026904361376467417]	Loss = 0.71962017 (ave = 0.69938320)

2023-07-06 01:28:18,291 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30710	Time 12.417s / 10iters, (1.242)	Forward Time 1.171s / 10iters, (0.117)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.856s / 10iters, (0.286)	Data load 0.088s / 10iters, (0.008771)
Learning rate = [0.0026878326296974637, 0.0026878326296974637]	Loss = 0.72882301 (ave = 0.68082228)

2023-07-06 01:28:30,675 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30720	Time 12.385s / 10iters, (1.238)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.915s / 10iters, (0.291)	Data load 0.095s / 10iters, (0.009482)
Learning rate = [0.002685228841514778, 0.002685228841514778]	Loss = 0.65755451 (ave = 0.69196251)

2023-07-06 01:28:43,084 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30730	Time 12.409s / 10iters, (1.241)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.330s / 10iters, (0.833)	Loss Time 2.901s / 10iters, (0.290)	Data load 0.080s / 10iters, (0.007968)
Learning rate = [0.002682624772766528, 0.002682624772766528]	Loss = 0.64892590 (ave = 0.70621995)

2023-07-06 01:28:55,418 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30740	Time 12.334s / 10iters, (1.233)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.250s / 10iters, (0.825)	Loss Time 2.899s / 10iters, (0.290)	Data load 0.081s / 10iters, (0.008103)
Learning rate = [0.0026800204231198083, 0.0026800204231198083]	Loss = 0.70031762 (ave = 0.67341246)

2023-07-06 01:29:07,866 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30750	Time 12.448s / 10iters, (1.245)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.323s / 10iters, (0.832)	Loss Time 2.934s / 10iters, (0.293)	Data load 0.076s / 10iters, (0.007575)
Learning rate = [0.002677415792240955, 0.002677415792240955]	Loss = 0.73147970 (ave = 0.77010462)

2023-07-06 01:29:20,242 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30760	Time 12.375s / 10iters, (1.238)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.908s / 10iters, (0.291)	Data load 0.083s / 10iters, (0.008327)
Learning rate = [0.0026748108797955473, 0.0026748108797955473]	Loss = 0.76923668 (ave = 0.73717463)

2023-07-06 01:29:32,602 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30770	Time 12.360s / 10iters, (1.236)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.857s / 10iters, (0.286)	Data load 0.089s / 10iters, (0.008882)
Learning rate = [0.0026722056854484037, 0.0026722056854484037]	Loss = 0.60404849 (ave = 0.73143662)

2023-07-06 01:29:44,870 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30780	Time 12.268s / 10iters, (1.227)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.093s / 10iters, (0.009289)
Learning rate = [0.0026696002088635847, 0.0026696002088635847]	Loss = 0.80527610 (ave = 0.70963041)

2023-07-06 01:29:56,961 INFO    [trainer_contrastive.py, 272] Train Epoch: 82	Train Iteration: 30790	Time 12.091s / 10iters, (1.209)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.179s / 10iters, (0.818)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.073s / 10iters, (0.007292)
Learning rate = [0.00266699444970438, 0.00266699444970438]	Loss = 0.77283800 (ave = 0.75244142)

2023-07-06 01:30:12,459 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30800	Time 15.313s / 10iters, (1.531)	Forward Time 1.201s / 10iters, (0.120)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.833s / 10iters, (0.283)	Data load 3.016s / 10iters, (0.301640)
Learning rate = [0.002664388407633314, 0.002664388407633314]	Loss = 0.71285647 (ave = 0.75773324)

2023-07-06 01:30:24,762 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30810	Time 12.303s / 10iters, (1.230)	Forward Time 1.137s / 10iters, (0.114)	Backward Time 8.255s / 10iters, (0.825)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.087s / 10iters, (0.008711)
Learning rate = [0.0026617820823121407, 0.0026617820823121407]	Loss = 0.67236948 (ave = 0.72772073)

2023-07-06 01:30:36,996 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30820	Time 12.234s / 10iters, (1.223)	Forward Time 1.198s / 10iters, (0.120)	Backward Time 8.230s / 10iters, (0.823)	Loss Time 2.721s / 10iters, (0.272)	Data load 0.085s / 10iters, (0.008481)
Learning rate = [0.002659175473401843, 0.002659175473401843]	Loss = 0.70155859 (ave = 0.74071220)

2023-07-06 01:30:49,419 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30830	Time 12.423s / 10iters, (1.242)	Forward Time 1.135s / 10iters, (0.114)	Backward Time 8.354s / 10iters, (0.835)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.085s / 10iters, (0.008461)
Learning rate = [0.0026565685805626255, 0.0026565685805626255]	Loss = 0.67052376 (ave = 0.70333276)

2023-07-06 01:31:01,661 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30840	Time 12.242s / 10iters, (1.224)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.777s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007421)
Learning rate = [0.0026539614034539155, 0.0026539614034539155]	Loss = 0.82911098 (ave = 0.74354577)

2023-07-06 01:31:14,073 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30850	Time 12.412s / 10iters, (1.241)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.378s / 10iters, (0.838)	Loss Time 2.856s / 10iters, (0.286)	Data load 0.081s / 10iters, (0.008054)
Learning rate = [0.002651353941734359, 0.002651353941734359]	Loss = 0.73902541 (ave = 0.73175203)

2023-07-06 01:31:26,439 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30860	Time 12.367s / 10iters, (1.237)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.333s / 10iters, (0.833)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007567)
Learning rate = [0.0026487461950618217, 0.0026487461950618217]	Loss = 0.80021954 (ave = 0.75089399)

2023-07-06 01:31:38,917 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30870	Time 12.477s / 10iters, (1.248)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.397s / 10iters, (0.840)	Loss Time 2.895s / 10iters, (0.289)	Data load 0.084s / 10iters, (0.008357)
Learning rate = [0.0026461381630933796, 0.0026461381630933796]	Loss = 0.79195291 (ave = 0.73110972)

2023-07-06 01:31:51,406 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30880	Time 12.489s / 10iters, (1.249)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.389s / 10iters, (0.839)	Loss Time 2.914s / 10iters, (0.291)	Data load 0.085s / 10iters, (0.008507)
Learning rate = [0.002643529845485322, 0.002643529845485322]	Loss = 0.71861225 (ave = 0.69187862)

2023-07-06 01:32:03,784 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30890	Time 12.378s / 10iters, (1.238)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.893s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007467)
Learning rate = [0.002640921241893144, 0.002640921241893144]	Loss = 0.67135441 (ave = 0.69193497)

2023-07-06 01:32:16,240 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30900	Time 12.456s / 10iters, (1.246)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.365s / 10iters, (0.836)	Loss Time 2.892s / 10iters, (0.289)	Data load 0.085s / 10iters, (0.008466)
Learning rate = [0.002638312351971552, 0.002638312351971552]	Loss = 0.60945958 (ave = 0.69380671)

2023-07-06 01:32:28,781 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30910	Time 12.541s / 10iters, (1.254)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.387s / 10iters, (0.839)	Loss Time 2.926s / 10iters, (0.293)	Data load 0.103s / 10iters, (0.010275)
Learning rate = [0.0026357031753744507, 0.0026357031753744507]	Loss = 0.66961497 (ave = 0.69873402)

2023-07-06 01:32:41,257 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30920	Time 12.476s / 10iters, (1.248)	Forward Time 1.152s / 10iters, (0.115)	Backward Time 8.402s / 10iters, (0.840)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.090s / 10iters, (0.009029)
Learning rate = [0.0026330937117549475, 0.0026330937117549475]	Loss = 0.74849498 (ave = 0.72866988)

2023-07-06 01:32:53,622 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30930	Time 12.366s / 10iters, (1.237)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.319s / 10iters, (0.832)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.113s / 10iters, (0.011285)
Learning rate = [0.0026304839607653456, 0.0026304839607653456]	Loss = 0.72031224 (ave = 0.75396927)

2023-07-06 01:33:05,940 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30940	Time 12.317s / 10iters, (1.232)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007529)
Learning rate = [0.002627873922057147, 0.002627873922057147]	Loss = 0.79039127 (ave = 0.74261382)

2023-07-06 01:33:18,322 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30950	Time 12.382s / 10iters, (1.238)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.092s / 10iters, (0.009155)
Learning rate = [0.002625263595281042, 0.002625263595281042]	Loss = 0.67012137 (ave = 0.68434410)

2023-07-06 01:33:30,709 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30960	Time 12.387s / 10iters, (1.239)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.370s / 10iters, (0.837)	Loss Time 2.805s / 10iters, (0.281)	Data load 0.083s / 10iters, (0.008321)
Learning rate = [0.002622652980086913, 0.002622652980086913]	Loss = 0.73986149 (ave = 0.70291735)

2023-07-06 01:33:43,140 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30970	Time 12.431s / 10iters, (1.243)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.376s / 10iters, (0.838)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.100s / 10iters, (0.009993)
Learning rate = [0.0026200420761238264, 0.0026200420761238264]	Loss = 0.71024764 (ave = 0.69876610)

2023-07-06 01:33:55,499 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30980	Time 12.359s / 10iters, (1.236)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.380s / 10iters, (0.838)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.090s / 10iters, (0.008981)
Learning rate = [0.002617430883040036, 0.002617430883040036]	Loss = 0.74948633 (ave = 0.71117166)

2023-07-06 01:34:07,797 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 30990	Time 12.298s / 10iters, (1.230)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.312s / 10iters, (0.831)	Loss Time 2.764s / 10iters, (0.276)	Data load 0.105s / 10iters, (0.010517)
Learning rate = [0.002614819400482975, 0.002614819400482975]	Loss = 0.70749277 (ave = 0.72523650)

2023-07-06 01:34:20,070 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 31000	Time 12.273s / 10iters, (1.227)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.762s / 10iters, (0.276)	Data load 0.091s / 10iters, (0.009063)
Learning rate = [0.0026122076280992545, 0.0026122076280992545]	Loss = 0.70735872 (ave = 0.74163435)

2023-07-06 01:34:25,140 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-06 01:34:48,895 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-06 01:35:12,500 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-06 01:35:36,339 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-06 01:35:59,811 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-06 01:36:23,027 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-06 01:36:45,812 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-06 01:36:54,465 INFO    [trainer_contrastive.py, 391] Test Time 151.417s, (2.403)	Loss 0.13948295

2023-07-06 01:36:54,466 INFO    [base.py, 33] Result for seg
2023-07-06 01:36:54,467 INFO    [base.py, 49] Mean IOU: 0.7507929887768425

2023-07-06 01:36:54,467 INFO    [base.py, 50] Pixel ACC: 0.9538850988205103

2023-07-06 01:37:06,566 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 31010	Time 166.495s / 10iters, (16.650)	Forward Time 1.154s / 10iters, (0.115)	Backward Time 8.180s / 10iters, (0.818)	Loss Time 2.681s / 10iters, (0.268)	Data load 154.481s / 10iters, (15.448066)
Learning rate = [0.0026095955655346596, 0.0026095955655346596]	Loss = 0.75836670 (ave = 0.70945737)

2023-07-06 01:37:18,629 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 31020	Time 12.064s / 10iters, (1.206)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.139s / 10iters, (0.814)	Loss Time 2.713s / 10iters, (0.271)	Data load 0.104s / 10iters, (0.010400)
Learning rate = [0.002606983212434153, 0.002606983212434153]	Loss = 0.70272011 (ave = 0.69137973)

2023-07-06 01:37:30,929 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 31030	Time 12.299s / 10iters, (1.230)	Forward Time 1.160s / 10iters, (0.116)	Backward Time 8.278s / 10iters, (0.828)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.080s / 10iters, (0.008025)
Learning rate = [0.002604370568441862, 0.002604370568441862]	Loss = 0.73556399 (ave = 0.72950853)

2023-07-06 01:37:43,104 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 31040	Time 12.175s / 10iters, (1.218)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.217s / 10iters, (0.822)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.074s / 10iters, (0.007414)
Learning rate = [0.002601757633201084, 0.002601757633201084]	Loss = 0.61288577 (ave = 0.72456488)

2023-07-06 01:37:55,302 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 31050	Time 12.198s / 10iters, (1.220)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.219s / 10iters, (0.822)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.095s / 10iters, (0.009457)
Learning rate = [0.0025991444063542773, 0.0025991444063542773]	Loss = 0.69343185 (ave = 0.71725446)

2023-07-06 01:38:07,578 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 31060	Time 12.276s / 10iters, (1.228)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.262s / 10iters, (0.826)	Loss Time 2.792s / 10iters, (0.279)	Data load 0.091s / 10iters, (0.009086)
Learning rate = [0.002596530887543066, 0.002596530887543066]	Loss = 0.74389428 (ave = 0.75824615)

2023-07-06 01:38:19,921 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 31070	Time 12.343s / 10iters, (1.234)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.328s / 10iters, (0.833)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.095s / 10iters, (0.009503)
Learning rate = [0.0025939170764082285, 0.0025939170764082285]	Loss = 0.69055456 (ave = 0.75058646)

2023-07-06 01:38:32,179 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 31080	Time 12.257s / 10iters, (1.226)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.082s / 10iters, (0.008241)
Learning rate = [0.0025913029725896995, 0.0025913029725896995]	Loss = 0.72563368 (ave = 0.72499229)

2023-07-06 01:38:44,357 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 31090	Time 12.178s / 10iters, (1.218)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.177s / 10iters, (0.818)	Loss Time 2.797s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007546)
Learning rate = [0.0025886885757265654, 0.0025886885757265654]	Loss = 0.65706104 (ave = 0.71287941)

2023-07-06 01:38:56,654 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 31100	Time 12.297s / 10iters, (1.230)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007503)
Learning rate = [0.002586073885457065, 0.002586073885457065]	Loss = 0.68254465 (ave = 0.71740239)

2023-07-06 01:39:08,890 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 31110	Time 12.236s / 10iters, (1.224)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.825s / 10iters, (0.283)	Data load 0.093s / 10iters, (0.009335)
Learning rate = [0.0025834589014185807, 0.0025834589014185807]	Loss = 0.66755897 (ave = 0.69584600)

2023-07-06 01:39:21,176 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 31120	Time 12.287s / 10iters, (1.229)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.809s / 10iters, (0.281)	Data load 0.086s / 10iters, (0.008599)
Learning rate = [0.0025808436232476377, 0.0025808436232476377]	Loss = 0.69649327 (ave = 0.74805514)

2023-07-06 01:39:33,396 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 31130	Time 12.219s / 10iters, (1.222)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.215s / 10iters, (0.822)	Loss Time 2.804s / 10iters, (0.280)	Data load 0.080s / 10iters, (0.007966)
Learning rate = [0.002578228050579905, 0.002578228050579905]	Loss = 0.64427531 (ave = 0.73800213)

2023-07-06 01:39:45,563 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 31140	Time 12.167s / 10iters, (1.217)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.195s / 10iters, (0.820)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.077s / 10iters, (0.007749)
Learning rate = [0.002575612183050185, 0.002575612183050185]	Loss = 0.67730844 (ave = 0.75819534)

2023-07-06 01:39:57,784 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 31150	Time 12.221s / 10iters, (1.222)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.225s / 10iters, (0.823)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007475)
Learning rate = [0.00257299602029242, 0.00257299602029242]	Loss = 0.61777139 (ave = 0.74527875)

2023-07-06 01:40:09,821 INFO    [trainer_contrastive.py, 272] Train Epoch: 83	Train Iteration: 31160	Time 12.037s / 10iters, (1.204)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.153s / 10iters, (0.815)	Loss Time 2.731s / 10iters, (0.273)	Data load 0.073s / 10iters, (0.007276)
Learning rate = [0.002570379561939677, 0.002570379561939677]	Loss = 0.65084285 (ave = 0.68598580)

2023-07-06 01:40:24,852 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31170	Time 14.826s / 10iters, (1.483)	Forward Time 1.227s / 10iters, (0.123)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.696s / 10iters, (0.270)	Data load 2.626s / 10iters, (0.262594)
Learning rate = [0.002567762807624157, 0.002567762807624157]	Loss = 0.65193647 (ave = 0.71050907)

2023-07-06 01:40:37,163 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31180	Time 12.310s / 10iters, (1.231)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.335s / 10iters, (0.833)	Loss Time 2.750s / 10iters, (0.275)	Data load 0.097s / 10iters, (0.009656)
Learning rate = [0.0025651457569771823, 0.0025651457569771823]	Loss = 0.79750365 (ave = 0.72995102)

2023-07-06 01:40:49,748 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31190	Time 12.585s / 10iters, (1.259)	Forward Time 1.140s / 10iters, (0.114)	Backward Time 8.537s / 10iters, (0.854)	Loss Time 2.833s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007556)
Learning rate = [0.002562528409629202, 0.002562528409629202]	Loss = 0.60916102 (ave = 0.69058923)

2023-07-06 01:41:02,505 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31200	Time 12.757s / 10iters, (1.276)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.650s / 10iters, (0.865)	Loss Time 2.895s / 10iters, (0.289)	Data load 0.090s / 10iters, (0.009011)
Learning rate = [0.0025599107652097804, 0.0025599107652097804]	Loss = 0.77147233 (ave = 0.72804707)

2023-07-06 01:41:15,228 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31210	Time 12.723s / 10iters, (1.272)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.653s / 10iters, (0.865)	Loss Time 2.866s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007470)
Learning rate = [0.0025572928233475985, 0.0025572928233475985]	Loss = 0.82120728 (ave = 0.72148023)

2023-07-06 01:41:27,612 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31220	Time 12.383s / 10iters, (1.238)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.388s / 10iters, (0.839)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007514)
Learning rate = [0.00255467458367045, 0.00255467458367045]	Loss = 0.66716588 (ave = 0.72007322)

2023-07-06 01:41:39,940 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31230	Time 12.329s / 10iters, (1.233)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.097s / 10iters, (0.009694)
Learning rate = [0.002552056045805242, 0.002552056045805242]	Loss = 0.67296791 (ave = 0.71649073)

2023-07-06 01:41:52,324 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31240	Time 12.384s / 10iters, (1.238)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.408s / 10iters, (0.841)	Loss Time 2.805s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007455)
Learning rate = [0.0025494372093779845, 0.0025494372093779845]	Loss = 0.76945436 (ave = 0.70866960)

2023-07-06 01:42:04,501 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31250	Time 12.176s / 10iters, (1.218)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007409)
Learning rate = [0.0025468180740137914, 0.0025468180740137914]	Loss = 0.65458721 (ave = 0.70965008)

2023-07-06 01:42:16,749 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31260	Time 12.248s / 10iters, (1.225)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.275s / 10iters, (0.827)	Loss Time 2.762s / 10iters, (0.276)	Data load 0.091s / 10iters, (0.009063)
Learning rate = [0.0025441986393368765, 0.0025441986393368765]	Loss = 0.83520895 (ave = 0.71364405)

2023-07-06 01:42:29,000 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31270	Time 12.251s / 10iters, (1.225)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.082s / 10iters, (0.008164)
Learning rate = [0.002541578904970555, 0.002541578904970555]	Loss = 0.68100095 (ave = 0.73783160)

2023-07-06 01:42:41,125 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31280	Time 12.126s / 10iters, (1.213)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.186s / 10iters, (0.819)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007475)
Learning rate = [0.002538958870537231, 0.002538958870537231]	Loss = 0.66182965 (ave = 0.68937010)

2023-07-06 01:42:53,256 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31290	Time 12.131s / 10iters, (1.213)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007370)
Learning rate = [0.002536338535658401, 0.002536338535658401]	Loss = 0.66283739 (ave = 0.69531940)

2023-07-06 01:43:05,497 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31300	Time 12.242s / 10iters, (1.224)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.833s / 10iters, (0.283)	Data load 0.082s / 10iters, (0.008197)
Learning rate = [0.0025337178999546473, 0.0025337178999546473]	Loss = 0.66084433 (ave = 0.72375892)

2023-07-06 01:43:17,674 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31310	Time 12.176s / 10iters, (1.218)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.194s / 10iters, (0.819)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007408)
Learning rate = [0.002531096963045642, 0.002531096963045642]	Loss = 0.64407933 (ave = 0.67472718)

2023-07-06 01:43:29,847 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31320	Time 12.173s / 10iters, (1.217)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.187s / 10iters, (0.819)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007384)
Learning rate = [0.0025284757245501335, 0.0025284757245501335]	Loss = 0.67689157 (ave = 0.71811250)

2023-07-06 01:43:42,070 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31330	Time 12.223s / 10iters, (1.222)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.201s / 10iters, (0.820)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007437)
Learning rate = [0.0025258541840859467, 0.0025258541840859467]	Loss = 0.77453345 (ave = 0.73606887)

2023-07-06 01:43:54,283 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31340	Time 12.213s / 10iters, (1.221)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.243s / 10iters, (0.824)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007403)
Learning rate = [0.002523232341269984, 0.002523232341269984]	Loss = 0.76762390 (ave = 0.73707667)

2023-07-06 01:44:06,426 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31350	Time 12.143s / 10iters, (1.214)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.177s / 10iters, (0.818)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.088s / 10iters, (0.008774)
Learning rate = [0.0025206101957182185, 0.0025206101957182185]	Loss = 1.08559346 (ave = 0.77544710)

2023-07-06 01:44:18,641 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31360	Time 12.214s / 10iters, (1.221)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.076s / 10iters, (0.007648)
Learning rate = [0.00251798774704569, 0.00251798774704569]	Loss = 0.66051042 (ave = 0.67003762)

2023-07-06 01:44:30,994 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31370	Time 12.354s / 10iters, (1.235)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.085s / 10iters, (0.008470)
Learning rate = [0.0025153649948665025, 0.0025153649948665025]	Loss = 0.73249441 (ave = 0.70216854)

2023-07-06 01:44:43,364 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31380	Time 12.370s / 10iters, (1.237)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.304s / 10iters, (0.830)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.086s / 10iters, (0.008628)
Learning rate = [0.002512741938793821, 0.002512741938793821]	Loss = 0.51435268 (ave = 0.67419476)

2023-07-06 01:44:55,759 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31390	Time 12.395s / 10iters, (1.239)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.334s / 10iters, (0.833)	Loss Time 2.864s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007402)
Learning rate = [0.002510118578439871, 0.002510118578439871]	Loss = 0.66298103 (ave = 0.70612574)

2023-07-06 01:45:08,030 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31400	Time 12.271s / 10iters, (1.227)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.856s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007456)
Learning rate = [0.0025074949134159283, 0.0025074949134159283]	Loss = 0.64151835 (ave = 0.72164149)

2023-07-06 01:45:20,482 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31410	Time 12.452s / 10iters, (1.245)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.417s / 10iters, (0.842)	Loss Time 2.825s / 10iters, (0.283)	Data load 0.091s / 10iters, (0.009137)
Learning rate = [0.0025048709433323213, 0.0025048709433323213]	Loss = 0.66697305 (ave = 0.71039663)

2023-07-06 01:45:32,893 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31420	Time 12.411s / 10iters, (1.241)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.332s / 10iters, (0.833)	Loss Time 2.856s / 10iters, (0.286)	Data load 0.095s / 10iters, (0.009519)
Learning rate = [0.002502246667798425, 0.002502246667798425]	Loss = 0.72985303 (ave = 0.69462578)

2023-07-06 01:45:45,454 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31430	Time 12.561s / 10iters, (1.256)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.408s / 10iters, (0.841)	Loss Time 2.955s / 10iters, (0.295)	Data load 0.078s / 10iters, (0.007758)
Learning rate = [0.002499622086422661, 0.002499622086422661]	Loss = 0.70773178 (ave = 0.71338016)

2023-07-06 01:45:57,862 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31440	Time 12.408s / 10iters, (1.241)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.343s / 10iters, (0.834)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.077s / 10iters, (0.007716)
Learning rate = [0.0024969971988124885, 0.0024969971988124885]	Loss = 0.70352918 (ave = 0.71625182)

2023-07-06 01:46:10,112 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31450	Time 12.250s / 10iters, (1.225)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007444)
Learning rate = [0.0024943720045744046, 0.0024943720045744046]	Loss = 0.66399819 (ave = 0.70017489)

2023-07-06 01:46:22,340 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31460	Time 12.228s / 10iters, (1.223)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.717s / 10iters, (0.272)	Data load 0.091s / 10iters, (0.009127)
Learning rate = [0.002491746503313939, 0.002491746503313939]	Loss = 0.55878454 (ave = 0.68539807)

2023-07-06 01:46:34,502 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31470	Time 12.162s / 10iters, (1.216)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.702s / 10iters, (0.270)	Data load 0.082s / 10iters, (0.008222)
Learning rate = [0.0024891206946356555, 0.0024891206946356555]	Loss = 0.65990829 (ave = 0.69897246)

2023-07-06 01:46:46,684 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31480	Time 12.182s / 10iters, (1.218)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.270s / 10iters, (0.827)	Loss Time 2.740s / 10iters, (0.274)	Data load 0.074s / 10iters, (0.007416)
Learning rate = [0.00248649457814314, 0.00248649457814314]	Loss = 0.63313216 (ave = 0.67911037)

2023-07-06 01:46:58,826 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31490	Time 12.141s / 10iters, (1.214)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.228s / 10iters, (0.823)	Loss Time 2.719s / 10iters, (0.272)	Data load 0.075s / 10iters, (0.007515)
Learning rate = [0.0024838681534390026, 0.0024838681534390026]	Loss = 0.65234673 (ave = 0.72961957)

2023-07-06 01:47:11,080 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31500	Time 12.254s / 10iters, (1.225)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.760s / 10iters, (0.276)	Data load 0.089s / 10iters, (0.008852)
Learning rate = [0.002481241420124872, 0.002481241420124872]	Loss = 0.64933974 (ave = 0.70750996)

2023-07-06 01:47:23,363 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31510	Time 12.283s / 10iters, (1.228)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.078s / 10iters, (0.007805)
Learning rate = [0.0024786143778013966, 0.0024786143778013966]	Loss = 0.68052703 (ave = 0.71093288)

2023-07-06 01:47:35,641 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31520	Time 12.278s / 10iters, (1.228)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.328s / 10iters, (0.833)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.084s / 10iters, (0.008441)
Learning rate = [0.002475987026068233, 0.002475987026068233]	Loss = 0.67340779 (ave = 0.73248735)

2023-07-06 01:47:47,652 INFO    [trainer_contrastive.py, 272] Train Epoch: 84	Train Iteration: 31530	Time 12.012s / 10iters, (1.201)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.162s / 10iters, (0.816)	Loss Time 2.680s / 10iters, (0.268)	Data load 0.078s / 10iters, (0.007838)
Learning rate = [0.0024733593645240477, 0.0024733593645240477]	Loss = 0.74924290 (ave = 0.69552262)

2023-07-06 01:48:02,874 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31540	Time 15.008s / 10iters, (1.501)	Forward Time 1.279s / 10iters, (0.128)	Backward Time 8.177s / 10iters, (0.818)	Loss Time 2.588s / 10iters, (0.259)	Data load 2.964s / 10iters, (0.296420)
Learning rate = [0.002470731392766511, 0.002470731392766511]	Loss = 0.67669600 (ave = 0.70870141)

2023-07-06 01:48:15,010 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31550	Time 12.136s / 10iters, (1.214)	Forward Time 1.251s / 10iters, (0.125)	Backward Time 8.253s / 10iters, (0.825)	Loss Time 2.555s / 10iters, (0.255)	Data load 0.076s / 10iters, (0.007636)
Learning rate = [0.0024681031103922983, 0.0024681031103922983]	Loss = 0.65418518 (ave = 0.63963591)

2023-07-06 01:48:27,234 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31560	Time 12.224s / 10iters, (1.222)	Forward Time 1.136s / 10iters, (0.114)	Backward Time 8.264s / 10iters, (0.826)	Loss Time 2.744s / 10iters, (0.274)	Data load 0.080s / 10iters, (0.008040)
Learning rate = [0.0024654745169970793, 0.0024654745169970793]	Loss = 0.81718320 (ave = 0.77124976)

2023-07-06 01:48:39,458 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31570	Time 12.224s / 10iters, (1.222)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.083s / 10iters, (0.008344)
Learning rate = [0.0024628456121755186, 0.0024628456121755186]	Loss = 0.73707682 (ave = 0.70846059)

2023-07-06 01:48:51,747 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31580	Time 12.289s / 10iters, (1.229)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.201s / 10iters, (0.820)	Loss Time 2.904s / 10iters, (0.290)	Data load 0.080s / 10iters, (0.007958)
Learning rate = [0.0024602163955212697, 0.0024602163955212697]	Loss = 0.62620598 (ave = 0.71065405)

2023-07-06 01:49:04,044 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31590	Time 12.297s / 10iters, (1.230)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.870s / 10iters, (0.287)	Data load 0.077s / 10iters, (0.007733)
Learning rate = [0.0024575868666269767, 0.0024575868666269767]	Loss = 0.72192121 (ave = 0.73279458)

2023-07-06 01:49:16,340 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31600	Time 12.296s / 10iters, (1.230)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.094s / 10iters, (0.009437)
Learning rate = [0.002454957025084264, 0.002454957025084264]	Loss = 0.75206375 (ave = 0.69245785)

2023-07-06 01:49:28,764 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31610	Time 12.424s / 10iters, (1.242)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.353s / 10iters, (0.835)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.076s / 10iters, (0.007617)
Learning rate = [0.002452326870483733, 0.002452326870483733]	Loss = 0.67240548 (ave = 0.68370014)

2023-07-06 01:49:41,083 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31620	Time 12.320s / 10iters, (1.232)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.295s / 10iters, (0.829)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007469)
Learning rate = [0.0024496964024149637, 0.0024496964024149637]	Loss = 0.70631349 (ave = 0.73051513)

2023-07-06 01:49:53,324 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31630	Time 12.240s / 10iters, (1.224)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.086s / 10iters, (0.008603)
Learning rate = [0.0024470656204665076, 0.0024470656204665076]	Loss = 0.64079058 (ave = 0.66933429)

2023-07-06 01:50:05,595 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31640	Time 12.272s / 10iters, (1.227)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.272s / 10iters, (0.827)	Loss Time 2.815s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007416)
Learning rate = [0.0024444345242258824, 0.0024444345242258824]	Loss = 0.70922673 (ave = 0.70040245)

2023-07-06 01:50:17,989 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31650	Time 12.394s / 10iters, (1.239)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.353s / 10iters, (0.835)	Loss Time 2.848s / 10iters, (0.285)	Data load 0.085s / 10iters, (0.008530)
Learning rate = [0.0024418031132795704, 0.0024418031132795704]	Loss = 0.98402369 (ave = 0.78304979)

2023-07-06 01:50:30,362 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31660	Time 12.373s / 10iters, (1.237)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.885s / 10iters, (0.288)	Data load 0.098s / 10iters, (0.009810)
Learning rate = [0.0024391713872130125, 0.0024391713872130125]	Loss = 0.76468408 (ave = 0.74289091)

2023-07-06 01:50:42,627 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31670	Time 12.265s / 10iters, (1.227)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007456)
Learning rate = [0.0024365393456106093, 0.0024365393456106093]	Loss = 0.72563899 (ave = 0.69161214)

2023-07-06 01:50:54,843 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31680	Time 12.216s / 10iters, (1.222)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007541)
Learning rate = [0.002433906988055711, 0.002433906988055711]	Loss = 0.63554555 (ave = 0.68544934)

2023-07-06 01:51:07,081 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31690	Time 12.237s / 10iters, (1.224)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.235s / 10iters, (0.823)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007411)
Learning rate = [0.0024312743141306167, 0.0024312743141306167]	Loss = 0.79632050 (ave = 0.73245360)

2023-07-06 01:51:19,421 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31700	Time 12.340s / 10iters, (1.234)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.089s / 10iters, (0.008911)
Learning rate = [0.0024286413234165683, 0.0024286413234165683]	Loss = 0.74742365 (ave = 0.73329513)

2023-07-06 01:51:31,799 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31710	Time 12.378s / 10iters, (1.238)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.323s / 10iters, (0.832)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.094s / 10iters, (0.009429)
Learning rate = [0.002426008015493753, 0.002426008015493753]	Loss = 0.77771688 (ave = 0.70823214)

2023-07-06 01:51:44,055 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31720	Time 12.256s / 10iters, (1.226)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007460)
Learning rate = [0.002423374389941291, 0.002423374389941291]	Loss = 0.82364810 (ave = 0.71075917)

2023-07-06 01:51:56,249 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31730	Time 12.194s / 10iters, (1.219)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.199s / 10iters, (0.820)	Loss Time 2.795s / 10iters, (0.279)	Data load 0.085s / 10iters, (0.008507)
Learning rate = [0.0024207404463372348, 0.0024207404463372348]	Loss = 0.69017351 (ave = 0.74092958)

2023-07-06 01:52:08,568 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31740	Time 12.320s / 10iters, (1.232)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.105s / 10iters, (0.010483)
Learning rate = [0.002418106184258566, 0.002418106184258566]	Loss = 0.64735109 (ave = 0.72107426)

2023-07-06 01:52:21,047 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31750	Time 12.478s / 10iters, (1.248)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.356s / 10iters, (0.836)	Loss Time 2.932s / 10iters, (0.293)	Data load 0.083s / 10iters, (0.008293)
Learning rate = [0.002415471603281194, 0.002415471603281194]	Loss = 0.74073088 (ave = 0.75734080)

2023-07-06 01:52:33,372 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31760	Time 12.326s / 10iters, (1.233)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.084s / 10iters, (0.008444)
Learning rate = [0.002412836702979944, 0.002412836702979944]	Loss = 1.08518505 (ave = 0.75330243)

2023-07-06 01:52:45,618 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31770	Time 12.246s / 10iters, (1.225)	Forward Time 1.141s / 10iters, (0.114)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.818s / 10iters, (0.282)	Data load 0.081s / 10iters, (0.008107)
Learning rate = [0.0024102014829285603, 0.0024102014829285603]	Loss = 0.71760595 (ave = 0.67917265)

2023-07-06 01:52:58,032 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31780	Time 12.414s / 10iters, (1.241)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.380s / 10iters, (0.838)	Loss Time 2.857s / 10iters, (0.286)	Data load 0.083s / 10iters, (0.008273)
Learning rate = [0.002407565942699698, 0.002407565942699698]	Loss = 0.62015539 (ave = 0.71923693)

2023-07-06 01:53:10,280 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31790	Time 12.249s / 10iters, (1.225)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.095s / 10iters, (0.009459)
Learning rate = [0.002404930081864924, 0.002404930081864924]	Loss = 0.61920512 (ave = 0.69578608)

2023-07-06 01:53:22,545 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31800	Time 12.264s / 10iters, (1.226)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.255s / 10iters, (0.825)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007558)
Learning rate = [0.0024022938999947057, 0.0024022938999947057]	Loss = 0.90030909 (ave = 0.69519175)

2023-07-06 01:53:34,767 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31810	Time 12.222s / 10iters, (1.222)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.225s / 10iters, (0.823)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.086s / 10iters, (0.008587)
Learning rate = [0.0023996573966584113, 0.0023996573966584113]	Loss = 0.66315132 (ave = 0.68902217)

2023-07-06 01:53:47,140 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31820	Time 12.373s / 10iters, (1.237)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.343s / 10iters, (0.834)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.085s / 10iters, (0.008451)
Learning rate = [0.0023970205714243056, 0.0023970205714243056]	Loss = 0.64465570 (ave = 0.71573480)

2023-07-06 01:53:59,384 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31830	Time 12.244s / 10iters, (1.224)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.820s / 10iters, (0.282)	Data load 0.091s / 10iters, (0.009116)
Learning rate = [0.002394383423859546, 0.002394383423859546]	Loss = 0.69638443 (ave = 0.71410980)

2023-07-06 01:54:11,573 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31840	Time 12.189s / 10iters, (1.219)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.098s / 10iters, (0.009811)
Learning rate = [0.002391745953530175, 0.002391745953530175]	Loss = 0.74665433 (ave = 0.75667667)

2023-07-06 01:54:23,793 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31850	Time 12.220s / 10iters, (1.222)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007512)
Learning rate = [0.002389108160001121, 0.002389108160001121]	Loss = 0.58631945 (ave = 0.74587033)

2023-07-06 01:54:36,181 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31860	Time 12.387s / 10iters, (1.239)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.874s / 10iters, (0.287)	Data load 0.086s / 10iters, (0.008572)
Learning rate = [0.002386470042836188, 0.002386470042836188]	Loss = 0.69279289 (ave = 0.71736966)

2023-07-06 01:54:48,568 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31870	Time 12.387s / 10iters, (1.239)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.330s / 10iters, (0.833)	Loss Time 2.850s / 10iters, (0.285)	Data load 0.087s / 10iters, (0.008747)
Learning rate = [0.0023838316015980594, 0.0023838316015980594]	Loss = 0.71167284 (ave = 0.72253193)

2023-07-06 01:55:01,254 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31880	Time 12.686s / 10iters, (1.269)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.541s / 10iters, (0.854)	Loss Time 2.947s / 10iters, (0.295)	Data load 0.075s / 10iters, (0.007478)
Learning rate = [0.0023811928358482854, 0.0023811928358482854]	Loss = 0.63275200 (ave = 0.71990975)

2023-07-06 01:55:13,873 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31890	Time 12.619s / 10iters, (1.262)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.466s / 10iters, (0.847)	Loss Time 2.943s / 10iters, (0.294)	Data load 0.080s / 10iters, (0.008003)
Learning rate = [0.002378553745147283, 0.002378553745147283]	Loss = 0.74270976 (ave = 0.73775834)

2023-07-06 01:55:26,257 INFO    [trainer_contrastive.py, 272] Train Epoch: 85	Train Iteration: 31900	Time 12.384s / 10iters, (1.238)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.361s / 10iters, (0.836)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007493)
Learning rate = [0.0023759143290543313, 0.0023759143290543313]	Loss = 0.67779207 (ave = 0.71098989)

2023-07-06 01:55:41,534 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 31910	Time 15.058s / 10iters, (1.506)	Forward Time 1.268s / 10iters, (0.127)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.711s / 10iters, (0.271)	Data load 2.821s / 10iters, (0.282051)
Learning rate = [0.0023732745871275687, 0.0023732745871275687]	Loss = 0.66744226 (ave = 0.69822695)

2023-07-06 01:55:53,774 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 31920	Time 12.240s / 10iters, (1.224)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.755s / 10iters, (0.276)	Data load 0.094s / 10iters, (0.009408)
Learning rate = [0.002370634518923984, 0.002370634518923984]	Loss = 0.64013344 (ave = 0.68531812)

2023-07-06 01:56:05,954 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 31930	Time 12.180s / 10iters, (1.218)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.232s / 10iters, (0.823)	Loss Time 2.730s / 10iters, (0.273)	Data load 0.096s / 10iters, (0.009597)
Learning rate = [0.0023679941239994158, 0.0023679941239994158]	Loss = 0.67253530 (ave = 0.67178132)

2023-07-06 01:56:18,308 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 31940	Time 12.355s / 10iters, (1.235)	Forward Time 1.144s / 10iters, (0.114)	Backward Time 8.367s / 10iters, (0.837)	Loss Time 2.765s / 10iters, (0.276)	Data load 0.079s / 10iters, (0.007894)
Learning rate = [0.0023653534019085457, 0.0023653534019085457]	Loss = 0.71472615 (ave = 0.69737459)

2023-07-06 01:56:30,721 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 31950	Time 12.412s / 10iters, (1.241)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.423s / 10iters, (0.842)	Loss Time 2.777s / 10iters, (0.278)	Data load 0.083s / 10iters, (0.008279)
Learning rate = [0.0023627123522048984, 0.0023627123522048984]	Loss = 0.75615335 (ave = 0.68072594)

2023-07-06 01:56:43,139 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 31960	Time 12.418s / 10iters, (1.242)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.429s / 10iters, (0.843)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.076s / 10iters, (0.007581)
Learning rate = [0.0023600709744408307, 0.0023600709744408307]	Loss = 0.72915077 (ave = 0.70070178)

2023-07-06 01:56:55,512 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 31970	Time 12.373s / 10iters, (1.237)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.398s / 10iters, (0.840)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.077s / 10iters, (0.007665)
Learning rate = [0.002357429268167532, 0.002357429268167532]	Loss = 0.64427918 (ave = 0.71234035)

2023-07-06 01:57:08,016 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 31980	Time 12.504s / 10iters, (1.250)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.467s / 10iters, (0.847)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007437)
Learning rate = [0.002354787232935015, 0.002354787232935015]	Loss = 0.77601129 (ave = 0.69931943)

2023-07-06 01:57:20,480 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 31990	Time 12.464s / 10iters, (1.246)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.422s / 10iters, (0.842)	Loss Time 2.838s / 10iters, (0.284)	Data load 0.087s / 10iters, (0.008687)
Learning rate = [0.0023521448682921205, 0.0023521448682921205]	Loss = 0.75123477 (ave = 0.71396948)

2023-07-06 01:57:32,792 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32000	Time 12.313s / 10iters, (1.231)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.084s / 10iters, (0.008378)
Learning rate = [0.0023495021737865007, 0.0023495021737865007]	Loss = 0.61887437 (ave = 0.71699098)

2023-07-06 01:57:37,279 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-06 01:58:01,216 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-06 01:58:24,446 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-06 01:58:47,688 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-06 01:59:10,822 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-06 01:59:33,831 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-06 01:59:56,388 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-06 02:00:02,206 INFO    [base.py, 84] Performance 0.7588134374009878 -> 0.7664567661860565
2023-07-06 02:00:07,796 INFO    [trainer_contrastive.py, 391] Test Time 149.206s, (2.368)	Loss 0.12638697

2023-07-06 02:00:07,797 INFO    [base.py, 33] Result for seg
2023-07-06 02:00:07,798 INFO    [base.py, 49] Mean IOU: 0.7664567661860565

2023-07-06 02:00:07,799 INFO    [base.py, 50] Pixel ACC: 0.9583034721124364

2023-07-06 02:00:20,002 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32010	Time 167.209s / 10iters, (16.721)	Forward Time 1.182s / 10iters, (0.118)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.656s / 10iters, (0.266)	Data load 155.104s / 10iters, (15.510383)
Learning rate = [0.0023468591489646225, 0.0023468591489646225]	Loss = 0.68374884 (ave = 0.68559527)

2023-07-06 02:00:32,001 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32020	Time 12.000s / 10iters, (1.200)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.149s / 10iters, (0.815)	Loss Time 2.635s / 10iters, (0.264)	Data load 0.098s / 10iters, (0.009811)
Learning rate = [0.00234421579337176, 0.00234421579337176]	Loss = 0.73905361 (ave = 0.67408627)

2023-07-06 02:00:44,061 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32030	Time 12.059s / 10iters, (1.206)	Forward Time 1.164s / 10iters, (0.116)	Backward Time 8.185s / 10iters, (0.819)	Loss Time 2.622s / 10iters, (0.262)	Data load 0.088s / 10iters, (0.008815)
Learning rate = [0.002341572106551993, 0.002341572106551993]	Loss = 0.67008120 (ave = 0.71186635)

2023-07-06 02:00:56,170 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32040	Time 12.109s / 10iters, (1.211)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.195s / 10iters, (0.820)	Loss Time 2.699s / 10iters, (0.270)	Data load 0.098s / 10iters, (0.009763)
Learning rate = [0.0023389280880481986, 0.0023389280880481986]	Loss = 0.67877579 (ave = 0.72655262)

2023-07-06 02:01:08,299 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32050	Time 12.130s / 10iters, (1.213)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.692s / 10iters, (0.269)	Data load 0.105s / 10iters, (0.010465)
Learning rate = [0.002336283737402047, 0.002336283737402047]	Loss = 0.57785517 (ave = 0.67847728)

2023-07-06 02:01:20,490 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32060	Time 12.191s / 10iters, (1.219)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.223s / 10iters, (0.822)	Loss Time 2.745s / 10iters, (0.275)	Data load 0.102s / 10iters, (0.010216)
Learning rate = [0.0023336390541539988, 0.0023336390541539988]	Loss = 0.59335506 (ave = 0.68962770)

2023-07-06 02:01:32,575 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32070	Time 12.085s / 10iters, (1.209)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.107s / 10iters, (0.811)	Loss Time 2.765s / 10iters, (0.277)	Data load 0.080s / 10iters, (0.008046)
Learning rate = [0.0023309940378433004, 0.0023309940378433004]	Loss = 0.71095896 (ave = 0.71212512)

2023-07-06 02:01:44,864 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32080	Time 12.289s / 10iters, (1.229)	Forward Time 1.134s / 10iters, (0.113)	Backward Time 8.286s / 10iters, (0.829)	Loss Time 2.793s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007544)
Learning rate = [0.002328348688007977, 0.002328348688007977]	Loss = 0.68340558 (ave = 0.69794879)

2023-07-06 02:01:57,118 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32090	Time 12.254s / 10iters, (1.225)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.084s / 10iters, (0.008447)
Learning rate = [0.002325703004184828, 0.002325703004184828]	Loss = 0.65508515 (ave = 0.70659227)

2023-07-06 02:02:09,567 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32100	Time 12.449s / 10iters, (1.245)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.362s / 10iters, (0.836)	Loss Time 2.881s / 10iters, (0.288)	Data load 0.088s / 10iters, (0.008786)
Learning rate = [0.0023230569859094235, 0.0023230569859094235]	Loss = 0.64085549 (ave = 0.70177172)

2023-07-06 02:02:21,952 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32110	Time 12.384s / 10iters, (1.238)	Forward Time 1.144s / 10iters, (0.114)	Backward Time 8.352s / 10iters, (0.835)	Loss Time 2.799s / 10iters, (0.280)	Data load 0.090s / 10iters, (0.008972)
Learning rate = [0.002320410632716102, 0.002320410632716102]	Loss = 0.77532405 (ave = 0.71895180)

2023-07-06 02:02:34,187 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32120	Time 12.236s / 10iters, (1.224)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.292s / 10iters, (0.829)	Loss Time 2.733s / 10iters, (0.273)	Data load 0.086s / 10iters, (0.008614)
Learning rate = [0.002317763944137959, 0.002317763944137959]	Loss = 0.71610796 (ave = 0.70003203)

2023-07-06 02:02:46,469 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32130	Time 12.281s / 10iters, (1.228)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.352s / 10iters, (0.835)	Loss Time 2.701s / 10iters, (0.270)	Data load 0.097s / 10iters, (0.009700)
Learning rate = [0.0023151169197068466, 0.0023151169197068466]	Loss = 0.68868279 (ave = 0.67110054)

2023-07-06 02:02:58,673 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32140	Time 12.205s / 10iters, (1.220)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.715s / 10iters, (0.272)	Data load 0.103s / 10iters, (0.010257)
Learning rate = [0.0023124695589533686, 0.0023124695589533686]	Loss = 0.64315504 (ave = 0.66694470)

2023-07-06 02:03:10,882 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32150	Time 12.208s / 10iters, (1.221)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.755s / 10iters, (0.275)	Data load 0.076s / 10iters, (0.007600)
Learning rate = [0.0023098218614068756, 0.0023098218614068756]	Loss = 0.74209285 (ave = 0.68982275)

2023-07-06 02:03:23,169 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32160	Time 12.288s / 10iters, (1.229)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.320s / 10iters, (0.832)	Loss Time 2.719s / 10iters, (0.272)	Data load 0.121s / 10iters, (0.012149)
Learning rate = [0.0023071738265954575, 0.0023071738265954575]	Loss = 0.68170589 (ave = 0.67887679)

2023-07-06 02:03:35,386 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32170	Time 12.217s / 10iters, (1.222)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.292s / 10iters, (0.829)	Loss Time 2.722s / 10iters, (0.272)	Data load 0.075s / 10iters, (0.007488)
Learning rate = [0.002304525454045941, 0.002304525454045941]	Loss = 0.64917535 (ave = 0.67192113)

2023-07-06 02:03:47,537 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32180	Time 12.150s / 10iters, (1.215)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.721s / 10iters, (0.272)	Data load 0.081s / 10iters, (0.008058)
Learning rate = [0.0023018767432838824, 0.0023018767432838824]	Loss = 0.60233915 (ave = 0.69982957)

2023-07-06 02:03:59,742 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32190	Time 12.205s / 10iters, (1.221)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.238s / 10iters, (0.824)	Loss Time 2.786s / 10iters, (0.279)	Data load 0.085s / 10iters, (0.008522)
Learning rate = [0.0022992276938335675, 0.0022992276938335675]	Loss = 0.72493976 (ave = 0.70404324)

2023-07-06 02:04:12,259 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32200	Time 12.517s / 10iters, (1.252)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.482s / 10iters, (0.848)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007588)
Learning rate = [0.0022965783052180003, 0.0022965783052180003]	Loss = 0.58831513 (ave = 0.72162645)

2023-07-06 02:04:24,732 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32210	Time 12.473s / 10iters, (1.247)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.442s / 10iters, (0.844)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007454)
Learning rate = [0.0022939285769589006, 0.0022939285769589006]	Loss = 0.64130342 (ave = 0.70176982)

2023-07-06 02:04:36,976 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32220	Time 12.244s / 10iters, (1.224)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.809s / 10iters, (0.281)	Data load 0.082s / 10iters, (0.008194)
Learning rate = [0.0022912785085766984, 0.0022912785085766984]	Loss = 0.70474201 (ave = 0.72049542)

2023-07-06 02:04:49,280 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32230	Time 12.304s / 10iters, (1.230)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.285s / 10iters, (0.828)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.082s / 10iters, (0.008241)
Learning rate = [0.0022886280995905333, 0.0022886280995905333]	Loss = 0.73241675 (ave = 0.73294088)

2023-07-06 02:05:01,563 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32240	Time 12.283s / 10iters, (1.228)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.833s / 10iters, (0.283)	Data load 0.088s / 10iters, (0.008773)
Learning rate = [0.0022859773495182405, 0.0022859773495182405]	Loss = 0.75679195 (ave = 0.69485556)

2023-07-06 02:05:13,869 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32250	Time 12.305s / 10iters, (1.231)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.816s / 10iters, (0.282)	Data load 0.084s / 10iters, (0.008401)
Learning rate = [0.0022833262578763535, 0.0022833262578763535]	Loss = 0.72333699 (ave = 0.73044853)

2023-07-06 02:05:26,211 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32260	Time 12.343s / 10iters, (1.234)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.857s / 10iters, (0.286)	Data load 0.081s / 10iters, (0.008135)
Learning rate = [0.0022806748241800934, 0.0022806748241800934]	Loss = 0.65745294 (ave = 0.70351022)

2023-07-06 02:05:38,172 INFO    [trainer_contrastive.py, 272] Train Epoch: 86	Train Iteration: 32270	Time 11.961s / 10iters, (1.196)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.091s / 10iters, (0.809)	Loss Time 2.709s / 10iters, (0.271)	Data load 0.074s / 10iters, (0.007370)
Learning rate = [0.00227802304794337, 0.00227802304794337]	Loss = 0.70690984 (ave = 0.71597483)

2023-07-06 02:05:53,275 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32280	Time 14.879s / 10iters, (1.488)	Forward Time 1.169s / 10iters, (0.117)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.775s / 10iters, (0.278)	Data load 2.722s / 10iters, (0.272178)
Learning rate = [0.002275370928678768, 0.002275370928678768]	Loss = 0.66518581 (ave = 0.69799394)

2023-07-06 02:06:05,903 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32290	Time 12.628s / 10iters, (1.263)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.544s / 10iters, (0.854)	Loss Time 2.880s / 10iters, (0.288)	Data load 0.089s / 10iters, (0.008929)
Learning rate = [0.00227271846589755, 0.00227271846589755]	Loss = 0.71499723 (ave = 0.70237354)

2023-07-06 02:06:18,455 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32300	Time 12.553s / 10iters, (1.255)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.489s / 10iters, (0.849)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.076s / 10iters, (0.007560)
Learning rate = [0.002270065659109644, 0.002270065659109644]	Loss = 0.58904719 (ave = 0.66994551)

2023-07-06 02:06:31,020 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32310	Time 12.565s / 10iters, (1.256)	Forward Time 1.186s / 10iters, (0.119)	Backward Time 8.507s / 10iters, (0.851)	Loss Time 2.795s / 10iters, (0.279)	Data load 0.077s / 10iters, (0.007663)
Learning rate = [0.0022674125078236454, 0.0022674125078236454]	Loss = 0.66489595 (ave = 0.66492810)

2023-07-06 02:06:43,637 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32320	Time 12.617s / 10iters, (1.262)	Forward Time 1.146s / 10iters, (0.115)	Backward Time 8.553s / 10iters, (0.855)	Loss Time 2.835s / 10iters, (0.283)	Data load 0.084s / 10iters, (0.008364)
Learning rate = [0.002264759011546806, 0.002264759011546806]	Loss = 0.65884900 (ave = 0.67499037)

2023-07-06 02:06:55,863 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32330	Time 12.227s / 10iters, (1.223)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.270s / 10iters, (0.827)	Loss Time 2.752s / 10iters, (0.275)	Data load 0.093s / 10iters, (0.009300)
Learning rate = [0.002262105169785029, 0.002262105169785029]	Loss = 0.79826713 (ave = 0.72298211)

2023-07-06 02:07:08,181 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32340	Time 12.318s / 10iters, (1.232)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.362s / 10iters, (0.836)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.085s / 10iters, (0.008546)
Learning rate = [0.002259450982042865, 0.002259450982042865]	Loss = 0.63932335 (ave = 0.69129347)

2023-07-06 02:07:20,315 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32350	Time 12.134s / 10iters, (1.213)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.208s / 10iters, (0.821)	Loss Time 2.756s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007550)
Learning rate = [0.00225679644782351, 0.00225679644782351]	Loss = 0.70652956 (ave = 0.71472942)

2023-07-06 02:07:32,475 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32360	Time 12.160s / 10iters, (1.216)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.187s / 10iters, (0.819)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007434)
Learning rate = [0.0022541415666287932, 0.0022541415666287932]	Loss = 0.77118629 (ave = 0.73194913)

2023-07-06 02:07:44,830 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32370	Time 12.354s / 10iters, (1.235)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.349s / 10iters, (0.835)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007595)
Learning rate = [0.0022514863379591746, 0.0022514863379591746]	Loss = 1.12665892 (ave = 0.74158154)

2023-07-06 02:07:57,020 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32380	Time 12.191s / 10iters, (1.219)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007540)
Learning rate = [0.0022488307613137398, 0.0022488307613137398]	Loss = 0.68706411 (ave = 0.70090014)

2023-07-06 02:08:09,102 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32390	Time 12.082s / 10iters, (1.208)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.175s / 10iters, (0.817)	Loss Time 2.742s / 10iters, (0.274)	Data load 0.075s / 10iters, (0.007453)
Learning rate = [0.0022461748361901936, 0.0022461748361901936]	Loss = 0.64265454 (ave = 0.69718398)

2023-07-06 02:08:21,283 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32400	Time 12.181s / 10iters, (1.218)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.756s / 10iters, (0.276)	Data load 0.084s / 10iters, (0.008431)
Learning rate = [0.002243518562084857, 0.002243518562084857]	Loss = 0.75555891 (ave = 0.66321415)

2023-07-06 02:08:33,520 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32410	Time 12.237s / 10iters, (1.224)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.287s / 10iters, (0.829)	Loss Time 2.777s / 10iters, (0.278)	Data load 0.076s / 10iters, (0.007628)
Learning rate = [0.0022408619384926567, 0.0022408619384926567]	Loss = 0.78771490 (ave = 0.69067752)

2023-07-06 02:08:45,762 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32420	Time 12.242s / 10iters, (1.224)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.083s / 10iters, (0.008335)
Learning rate = [0.0022382049649071235, 0.0022382049649071235]	Loss = 0.67474371 (ave = 0.67973310)

2023-07-06 02:08:57,948 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32430	Time 12.186s / 10iters, (1.219)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.762s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007537)
Learning rate = [0.002235547640820384, 0.002235547640820384]	Loss = 0.76596189 (ave = 0.69975066)

2023-07-06 02:09:10,138 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32440	Time 12.190s / 10iters, (1.219)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.087s / 10iters, (0.008722)
Learning rate = [0.0022328899657231573, 0.0022328899657231573]	Loss = 0.66562110 (ave = 0.74423440)

2023-07-06 02:09:22,375 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32450	Time 12.236s / 10iters, (1.224)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.298s / 10iters, (0.830)	Loss Time 2.766s / 10iters, (0.277)	Data load 0.077s / 10iters, (0.007672)
Learning rate = [0.0022302319391047476, 0.0022302319391047476]	Loss = 0.70017415 (ave = 0.70557092)

2023-07-06 02:09:34,554 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32460	Time 12.179s / 10iters, (1.218)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.265s / 10iters, (0.826)	Loss Time 2.743s / 10iters, (0.274)	Data load 0.075s / 10iters, (0.007501)
Learning rate = [0.002227573560453038, 0.002227573560453038]	Loss = 0.66057998 (ave = 0.63046267)

2023-07-06 02:09:46,755 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32470	Time 12.201s / 10iters, (1.220)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.222s / 10iters, (0.822)	Loss Time 2.803s / 10iters, (0.280)	Data load 0.077s / 10iters, (0.007684)
Learning rate = [0.002224914829254485, 0.002224914829254485]	Loss = 0.74775767 (ave = 0.70798686)

2023-07-06 02:09:59,024 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32480	Time 12.269s / 10iters, (1.227)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.279s / 10iters, (0.828)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.077s / 10iters, (0.007677)
Learning rate = [0.0022222557449941157, 0.0022222557449941157]	Loss = 0.76801741 (ave = 0.72101722)

2023-07-06 02:10:11,208 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32490	Time 12.184s / 10iters, (1.218)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007468)
Learning rate = [0.002219596307155516, 0.002219596307155516]	Loss = 0.73759741 (ave = 0.69963936)

2023-07-06 02:10:23,370 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32500	Time 12.161s / 10iters, (1.216)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.219s / 10iters, (0.822)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007582)
Learning rate = [0.00221693651522083, 0.00221693651522083]	Loss = 0.64724761 (ave = 0.68481973)

2023-07-06 02:10:35,551 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32510	Time 12.181s / 10iters, (1.218)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.227s / 10iters, (0.823)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.078s / 10iters, (0.007770)
Learning rate = [0.002214276368670749, 0.002214276368670749]	Loss = 0.69642770 (ave = 0.68029999)

2023-07-06 02:10:47,712 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32520	Time 12.161s / 10iters, (1.216)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.195s / 10iters, (0.820)	Loss Time 2.785s / 10iters, (0.279)	Data load 0.077s / 10iters, (0.007700)
Learning rate = [0.002211615866984514, 0.002211615866984514]	Loss = 0.62922382 (ave = 0.69633914)

2023-07-06 02:10:59,963 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32530	Time 12.251s / 10iters, (1.225)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.765s / 10iters, (0.276)	Data load 0.077s / 10iters, (0.007706)
Learning rate = [0.002208955009639898, 0.002208955009639898]	Loss = 0.69688702 (ave = 0.71596892)

2023-07-06 02:11:12,173 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32540	Time 12.210s / 10iters, (1.221)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.727s / 10iters, (0.273)	Data load 0.074s / 10iters, (0.007434)
Learning rate = [0.0022062937961132094, 0.0022062937961132094]	Loss = 0.67428863 (ave = 0.69095256)

2023-07-06 02:11:24,339 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32550	Time 12.166s / 10iters, (1.217)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.262s / 10iters, (0.826)	Loss Time 2.734s / 10iters, (0.273)	Data load 0.075s / 10iters, (0.007539)
Learning rate = [0.0022036322258792806, 0.0022036322258792806]	Loss = 0.82329583 (ave = 0.69788728)

2023-07-06 02:11:36,533 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32560	Time 12.194s / 10iters, (1.219)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.756s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007495)
Learning rate = [0.002200970298411466, 0.002200970298411466]	Loss = 0.65359932 (ave = 0.73900032)

2023-07-06 02:11:48,845 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32570	Time 12.312s / 10iters, (1.231)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.345s / 10iters, (0.834)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.084s / 10iters, (0.008399)
Learning rate = [0.002198308013181633, 0.002198308013181633]	Loss = 0.65667766 (ave = 0.71377295)

2023-07-06 02:12:00,953 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32580	Time 12.108s / 10iters, (1.211)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.216s / 10iters, (0.822)	Loss Time 2.730s / 10iters, (0.273)	Data load 0.075s / 10iters, (0.007511)
Learning rate = [0.002195645369660154, 0.002195645369660154]	Loss = 0.67026639 (ave = 0.73750186)

2023-07-06 02:12:13,147 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32590	Time 12.194s / 10iters, (1.219)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.738s / 10iters, (0.274)	Data load 0.105s / 10iters, (0.010498)
Learning rate = [0.0021929823673159043, 0.0021929823673159043]	Loss = 0.74127394 (ave = 0.69214854)

2023-07-06 02:12:25,342 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32600	Time 12.195s / 10iters, (1.220)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.082s / 10iters, (0.008203)
Learning rate = [0.002190319005616256, 0.002190319005616256]	Loss = 0.71380383 (ave = 0.68822228)

2023-07-06 02:12:37,413 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32610	Time 12.071s / 10iters, (1.207)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.142s / 10iters, (0.814)	Loss Time 2.755s / 10iters, (0.276)	Data load 0.076s / 10iters, (0.007595)
Learning rate = [0.002187655284027067, 0.002187655284027067]	Loss = 0.61562794 (ave = 0.64606974)

2023-07-06 02:12:49,594 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32620	Time 12.181s / 10iters, (1.218)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.208s / 10iters, (0.821)	Loss Time 2.803s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007441)
Learning rate = [0.002184991202012678, 0.002184991202012678]	Loss = 0.72400475 (ave = 0.71355453)

2023-07-06 02:13:01,772 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32630	Time 12.178s / 10iters, (1.218)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.219s / 10iters, (0.822)	Loss Time 2.795s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007384)
Learning rate = [0.002182326759035906, 0.002182326759035906]	Loss = 0.70962691 (ave = 0.69869632)

2023-07-06 02:13:13,807 INFO    [trainer_contrastive.py, 272] Train Epoch: 87	Train Iteration: 32640	Time 12.036s / 10iters, (1.204)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.123s / 10iters, (0.812)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.091s / 10iters, (0.009111)
Learning rate = [0.002179661954558038, 0.002179661954558038]	Loss = 0.73185766 (ave = 0.71088181)

2023-07-06 02:13:28,932 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32650	Time 14.983s / 10iters, (1.498)	Forward Time 1.144s / 10iters, (0.114)	Backward Time 8.120s / 10iters, (0.812)	Loss Time 2.717s / 10iters, (0.272)	Data load 3.002s / 10iters, (0.300184)
Learning rate = [0.002176996788038823, 0.002176996788038823]	Loss = 0.66757250 (ave = 0.68977922)

2023-07-06 02:13:41,048 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32660	Time 12.116s / 10iters, (1.212)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.726s / 10iters, (0.273)	Data load 0.088s / 10iters, (0.008796)
Learning rate = [0.002174331258936467, 0.002174331258936467]	Loss = 0.72586685 (ave = 0.68781673)

2023-07-06 02:13:53,223 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32670	Time 12.175s / 10iters, (1.218)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.726s / 10iters, (0.273)	Data load 0.097s / 10iters, (0.009714)
Learning rate = [0.002171665366707625, 0.002171665366707625]	Loss = 0.65636671 (ave = 0.68914197)

2023-07-06 02:14:05,583 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32680	Time 12.360s / 10iters, (1.236)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.369s / 10iters, (0.837)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007510)
Learning rate = [0.0021689991108073984, 0.0021689991108073984]	Loss = 0.77104425 (ave = 0.71656228)

2023-07-06 02:14:17,723 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32690	Time 12.140s / 10iters, (1.214)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.199s / 10iters, (0.820)	Loss Time 2.762s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007428)
Learning rate = [0.002166332490689322, 0.002166332490689322]	Loss = 0.76886994 (ave = 0.72788259)

2023-07-06 02:14:29,991 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32700	Time 12.268s / 10iters, (1.227)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.777s / 10iters, (0.278)	Data load 0.084s / 10iters, (0.008438)
Learning rate = [0.0021636655058053633, 0.0021636655058053633]	Loss = 0.68570203 (ave = 0.77533870)

2023-07-06 02:14:42,163 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32710	Time 12.172s / 10iters, (1.217)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.731s / 10iters, (0.273)	Data load 0.080s / 10iters, (0.007984)
Learning rate = [0.0021609981556059104, 0.0021609981556059104]	Loss = 0.64469141 (ave = 0.74663676)

2023-07-06 02:14:54,317 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32720	Time 12.154s / 10iters, (1.215)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.155s / 10iters, (0.815)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.085s / 10iters, (0.008487)
Learning rate = [0.002158330439539772, 0.002158330439539772]	Loss = 0.72294390 (ave = 0.70635760)

2023-07-06 02:15:06,657 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32730	Time 12.340s / 10iters, (1.234)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.861s / 10iters, (0.286)	Data load 0.078s / 10iters, (0.007795)
Learning rate = [0.0021556623570541658, 0.0021556623570541658]	Loss = 0.71348345 (ave = 0.72619330)

2023-07-06 02:15:18,988 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32740	Time 12.331s / 10iters, (1.233)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.297s / 10iters, (0.830)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.078s / 10iters, (0.007769)
Learning rate = [0.002152993907594711, 0.002152993907594711]	Loss = 0.69600850 (ave = 0.71034528)

2023-07-06 02:15:31,235 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32750	Time 12.246s / 10iters, (1.225)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.085s / 10iters, (0.008496)
Learning rate = [0.0021503250906054236, 0.0021503250906054236]	Loss = 0.73890746 (ave = 0.66599252)

2023-07-06 02:15:43,395 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32760	Time 12.160s / 10iters, (1.216)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.203s / 10iters, (0.820)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.079s / 10iters, (0.007903)
Learning rate = [0.0021476559055287124, 0.0021476559055287124]	Loss = 0.79620636 (ave = 0.70407413)

2023-07-06 02:15:55,539 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32770	Time 12.144s / 10iters, (1.214)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.189s / 10iters, (0.819)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007485)
Learning rate = [0.002144986351805366, 0.002144986351805366]	Loss = 0.71168494 (ave = 0.72028324)

2023-07-06 02:16:07,607 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32780	Time 12.068s / 10iters, (1.207)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.113s / 10iters, (0.811)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.076s / 10iters, (0.007612)
Learning rate = [0.002142316428874549, 0.002142316428874549]	Loss = 0.71674842 (ave = 0.67379678)

2023-07-06 02:16:19,879 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32790	Time 12.272s / 10iters, (1.227)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.095s / 10iters, (0.009517)
Learning rate = [0.0021396461361737956, 0.0021396461361737956]	Loss = 0.77835536 (ave = 0.70811938)

2023-07-06 02:16:32,165 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32800	Time 12.286s / 10iters, (1.229)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.238s / 10iters, (0.824)	Loss Time 2.869s / 10iters, (0.287)	Data load 0.078s / 10iters, (0.007780)
Learning rate = [0.002136975473139003, 0.002136975473139003]	Loss = 0.51326954 (ave = 0.72623550)

2023-07-06 02:16:44,335 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32810	Time 12.170s / 10iters, (1.217)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.138s / 10iters, (0.814)	Loss Time 2.855s / 10iters, (0.285)	Data load 0.077s / 10iters, (0.007722)
Learning rate = [0.002134304439204421, 0.002134304439204421]	Loss = 0.72723418 (ave = 0.69711963)

2023-07-06 02:16:56,576 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32820	Time 12.240s / 10iters, (1.224)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.850s / 10iters, (0.285)	Data load 0.077s / 10iters, (0.007691)
Learning rate = [0.0021316330338026486, 0.0021316330338026486]	Loss = 0.83754343 (ave = 0.71882531)

2023-07-06 02:17:08,870 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32830	Time 12.294s / 10iters, (1.229)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.890s / 10iters, (0.289)	Data load 0.077s / 10iters, (0.007709)
Learning rate = [0.002128961256364624, 0.002128961256364624]	Loss = 0.64333951 (ave = 0.70447215)

2023-07-06 02:17:21,068 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32840	Time 12.198s / 10iters, (1.220)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.180s / 10iters, (0.818)	Loss Time 2.838s / 10iters, (0.284)	Data load 0.077s / 10iters, (0.007715)
Learning rate = [0.002126289106319621, 0.002126289106319621]	Loss = 0.68790102 (ave = 0.74484707)

2023-07-06 02:17:33,238 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32850	Time 12.170s / 10iters, (1.217)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.184s / 10iters, (0.818)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.080s / 10iters, (0.008001)
Learning rate = [0.002123616583095238, 0.002123616583095238]	Loss = 0.69287020 (ave = 0.70912343)

2023-07-06 02:17:45,391 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32860	Time 12.153s / 10iters, (1.215)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.185s / 10iters, (0.819)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.080s / 10iters, (0.008034)
Learning rate = [0.0021209436861173918, 0.0021209436861173918]	Loss = 0.81527835 (ave = 0.76659148)

2023-07-06 02:17:57,479 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32870	Time 12.088s / 10iters, (1.209)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.183s / 10iters, (0.818)	Loss Time 2.730s / 10iters, (0.273)	Data load 0.075s / 10iters, (0.007531)
Learning rate = [0.0021182704148103118, 0.0021182704148103118]	Loss = 0.76567024 (ave = 0.69024292)

2023-07-06 02:18:09,628 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32880	Time 12.149s / 10iters, (1.215)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.226s / 10iters, (0.823)	Loss Time 2.727s / 10iters, (0.273)	Data load 0.075s / 10iters, (0.007513)
Learning rate = [0.0021155967685965323, 0.0021155967685965323]	Loss = 0.69963872 (ave = 0.66212992)

2023-07-06 02:18:21,764 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32890	Time 12.136s / 10iters, (1.214)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.077s / 10iters, (0.007651)
Learning rate = [0.0021129227468968843, 0.0021129227468968843]	Loss = 0.71437937 (ave = 0.69460562)

2023-07-06 02:18:33,970 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32900	Time 12.206s / 10iters, (1.221)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.730s / 10iters, (0.273)	Data load 0.085s / 10iters, (0.008486)
Learning rate = [0.002110248349130487, 0.002110248349130487]	Loss = 0.63025534 (ave = 0.70649861)

2023-07-06 02:18:46,203 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32910	Time 12.233s / 10iters, (1.223)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.079s / 10iters, (0.007888)
Learning rate = [0.002107573574714741, 0.002107573574714741]	Loss = 0.75109875 (ave = 0.73681247)

2023-07-06 02:18:58,369 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32920	Time 12.166s / 10iters, (1.217)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.760s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007455)
Learning rate = [0.0021048984230653254, 0.0021048984230653254]	Loss = 0.64868742 (ave = 0.71797975)

2023-07-06 02:19:10,600 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32930	Time 12.231s / 10iters, (1.223)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007559)
Learning rate = [0.0021022228935961827, 0.0021022228935961827]	Loss = 0.57189578 (ave = 0.66229334)

2023-07-06 02:19:22,958 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32940	Time 12.358s / 10iters, (1.236)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.369s / 10iters, (0.837)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.082s / 10iters, (0.008213)
Learning rate = [0.0020995469857195154, 0.0020995469857195154]	Loss = 0.83728033 (ave = 0.72132269)

2023-07-06 02:19:35,448 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32950	Time 12.490s / 10iters, (1.249)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.448s / 10iters, (0.845)	Loss Time 2.850s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007427)
Learning rate = [0.002096870698845777, 0.002096870698845777]	Loss = 0.70872724 (ave = 0.73568350)

2023-07-06 02:19:47,758 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32960	Time 12.309s / 10iters, (1.231)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.816s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007411)
Learning rate = [0.0020941940323836693, 0.0020941940323836693]	Loss = 0.84215319 (ave = 0.70207023)

2023-07-06 02:19:59,904 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32970	Time 12.146s / 10iters, (1.215)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.752s / 10iters, (0.275)	Data load 0.074s / 10iters, (0.007409)
Learning rate = [0.0020915169857401244, 0.0020915169857401244]	Loss = 0.70701718 (ave = 0.71289045)

2023-07-06 02:20:12,038 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32980	Time 12.134s / 10iters, (1.213)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.242s / 10iters, (0.824)	Loss Time 2.730s / 10iters, (0.273)	Data load 0.075s / 10iters, (0.007475)
Learning rate = [0.002088839558320307, 0.002088839558320307]	Loss = 0.74199486 (ave = 0.70996210)

2023-07-06 02:20:24,473 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 32990	Time 12.435s / 10iters, (1.243)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.433s / 10iters, (0.843)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.082s / 10iters, (0.008198)
Learning rate = [0.0020861617495275997, 0.0020861617495275997]	Loss = 0.85527754 (ave = 0.71487775)

2023-07-06 02:20:36,922 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 33000	Time 12.449s / 10iters, (1.245)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.415s / 10iters, (0.842)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007512)
Learning rate = [0.0020834835587636015, 0.0020834835587636015]	Loss = 0.77716511 (ave = 0.71335690)

2023-07-06 02:20:41,103 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-06 02:21:04,412 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-06 02:21:27,166 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-06 02:21:50,189 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-06 02:22:13,324 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-06 02:22:36,033 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-06 02:22:58,409 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-06 02:23:06,921 INFO    [trainer_contrastive.py, 391] Test Time 147.051s, (2.334)	Loss 0.12764804

2023-07-06 02:23:06,922 INFO    [base.py, 33] Result for seg
2023-07-06 02:23:06,923 INFO    [base.py, 49] Mean IOU: 0.758843671700919

2023-07-06 02:23:06,923 INFO    [base.py, 50] Pixel ACC: 0.9583462858620727

2023-07-06 02:23:18,863 INFO    [trainer_contrastive.py, 272] Train Epoch: 88	Train Iteration: 33010	Time 161.940s / 10iters, (16.194)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.033s / 10iters, (0.803)	Loss Time 2.709s / 10iters, (0.271)	Data load 150.084s / 10iters, (15.008425)
Learning rate = [0.002080804985428113, 0.002080804985428113]	Loss = 0.66959918 (ave = 0.70553564)

2023-07-06 02:23:33,683 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33020	Time 14.678s / 10iters, (1.468)	Forward Time 1.182s / 10iters, (0.118)	Backward Time 8.134s / 10iters, (0.813)	Loss Time 2.701s / 10iters, (0.270)	Data load 2.661s / 10iters, (0.266073)
Learning rate = [0.002078126028919134, 0.002078126028919134]	Loss = 0.80880952 (ave = 0.72855784)

2023-07-06 02:23:46,126 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33030	Time 12.443s / 10iters, (1.244)	Forward Time 1.254s / 10iters, (0.125)	Backward Time 8.494s / 10iters, (0.849)	Loss Time 2.612s / 10iters, (0.261)	Data load 0.083s / 10iters, (0.008337)
Learning rate = [0.0020754466886328503, 0.0020754466886328503]	Loss = 0.64566094 (ave = 0.68875317)

2023-07-06 02:23:58,484 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33040	Time 12.358s / 10iters, (1.236)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.440s / 10iters, (0.844)	Loss Time 2.724s / 10iters, (0.272)	Data load 0.081s / 10iters, (0.008064)
Learning rate = [0.0020727669639636326, 0.0020727669639636326]	Loss = 0.65802127 (ave = 0.69010397)

2023-07-06 02:24:10,543 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33050	Time 12.060s / 10iters, (1.206)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.661s / 10iters, (0.266)	Data load 0.099s / 10iters, (0.009873)
Learning rate = [0.0020700868543040217, 0.0020700868543040217]	Loss = 0.90354180 (ave = 0.70265363)

2023-07-06 02:24:22,692 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33060	Time 12.148s / 10iters, (1.215)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.242s / 10iters, (0.824)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.076s / 10iters, (0.007573)
Learning rate = [0.002067406359044724, 0.002067406359044724]	Loss = 0.68542808 (ave = 0.68114741)

2023-07-06 02:24:34,872 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33070	Time 12.180s / 10iters, (1.218)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.763s / 10iters, (0.276)	Data load 0.084s / 10iters, (0.008423)
Learning rate = [0.0020647254775746004, 0.0020647254775746004]	Loss = 0.77814114 (ave = 0.68797976)

2023-07-06 02:24:47,077 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33080	Time 12.205s / 10iters, (1.221)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.250s / 10iters, (0.825)	Loss Time 2.792s / 10iters, (0.279)	Data load 0.076s / 10iters, (0.007560)
Learning rate = [0.002062044209280664, 0.002062044209280664]	Loss = 0.79468501 (ave = 0.71259293)

2023-07-06 02:24:59,287 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33090	Time 12.210s / 10iters, (1.221)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.797s / 10iters, (0.280)	Data load 0.077s / 10iters, (0.007695)
Learning rate = [0.002059362553548064, 0.002059362553548064]	Loss = 0.66544259 (ave = 0.68448219)

2023-07-06 02:25:11,499 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33100	Time 12.211s / 10iters, (1.221)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007565)
Learning rate = [0.0020566805097600835, 0.0020566805097600835]	Loss = 0.56932521 (ave = 0.64930053)

2023-07-06 02:25:23,663 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33110	Time 12.164s / 10iters, (1.216)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.228s / 10iters, (0.823)	Loss Time 2.751s / 10iters, (0.275)	Data load 0.092s / 10iters, (0.009235)
Learning rate = [0.002053998077298126, 0.002053998077298126]	Loss = 0.77821320 (ave = 0.70873486)

2023-07-06 02:25:35,873 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33120	Time 12.210s / 10iters, (1.221)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.333s / 10iters, (0.833)	Loss Time 2.686s / 10iters, (0.269)	Data load 0.080s / 10iters, (0.007953)
Learning rate = [0.002051315255541714, 0.002051315255541714]	Loss = 0.72806525 (ave = 0.68350151)

2023-07-06 02:25:48,319 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33130	Time 12.447s / 10iters, (1.245)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.485s / 10iters, (0.849)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.078s / 10iters, (0.007834)
Learning rate = [0.0020486320438684725, 0.0020486320438684725]	Loss = 0.74468863 (ave = 0.68751890)

2023-07-06 02:26:00,546 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33140	Time 12.226s / 10iters, (1.223)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.272s / 10iters, (0.827)	Loss Time 2.742s / 10iters, (0.274)	Data load 0.090s / 10iters, (0.008990)
Learning rate = [0.0020459484416541266, 0.0020459484416541266]	Loss = 0.83400309 (ave = 0.68374900)

2023-07-06 02:26:12,755 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33150	Time 12.209s / 10iters, (1.221)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.238s / 10iters, (0.824)	Loss Time 2.789s / 10iters, (0.279)	Data load 0.091s / 10iters, (0.009147)
Learning rate = [0.002043264448272487, 0.002043264448272487]	Loss = 0.67986977 (ave = 0.69683741)

2023-07-06 02:26:25,028 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33160	Time 12.274s / 10iters, (1.227)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.332s / 10iters, (0.833)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.093s / 10iters, (0.009288)
Learning rate = [0.00204058006309545, 0.00204058006309545]	Loss = 0.70701599 (ave = 0.69173062)

2023-07-06 02:26:37,247 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33170	Time 12.219s / 10iters, (1.222)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.089s / 10iters, (0.008948)
Learning rate = [0.00203789528549298, 0.00203789528549298]	Loss = 0.74149513 (ave = 0.72078483)

2023-07-06 02:26:49,439 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33180	Time 12.192s / 10iters, (1.219)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.755s / 10iters, (0.275)	Data load 0.074s / 10iters, (0.007409)
Learning rate = [0.002035210114833105, 0.002035210114833105]	Loss = 0.67306000 (ave = 0.68891463)

2023-07-06 02:27:01,606 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33190	Time 12.166s / 10iters, (1.217)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.723s / 10iters, (0.272)	Data load 0.074s / 10iters, (0.007414)
Learning rate = [0.002032524550481906, 0.002032524550481906]	Loss = 0.68448049 (ave = 0.66598004)

2023-07-06 02:27:13,751 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33200	Time 12.145s / 10iters, (1.215)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.270s / 10iters, (0.827)	Loss Time 2.694s / 10iters, (0.269)	Data load 0.084s / 10iters, (0.008377)
Learning rate = [0.0020298385918035137, 0.0020298385918035137]	Loss = 0.56244409 (ave = 0.65213740)

2023-07-06 02:27:25,890 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33210	Time 12.140s / 10iters, (1.214)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.723s / 10iters, (0.272)	Data load 0.094s / 10iters, (0.009418)
Learning rate = [0.002027152238160091, 0.002027152238160091]	Loss = 0.68573785 (ave = 0.71799333)

2023-07-06 02:27:38,137 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33220	Time 12.246s / 10iters, (1.225)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.309s / 10iters, (0.831)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007639)
Learning rate = [0.002024465488911829, 0.002024465488911829]	Loss = 0.76905102 (ave = 0.70601569)

2023-07-06 02:27:50,465 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33230	Time 12.329s / 10iters, (1.233)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.379s / 10iters, (0.838)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007351)
Learning rate = [0.002021778343416938, 0.002021778343416938]	Loss = 0.78455794 (ave = 0.68063134)

2023-07-06 02:28:02,905 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33240	Time 12.440s / 10iters, (1.244)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.462s / 10iters, (0.846)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.088s / 10iters, (0.008812)
Learning rate = [0.002019090801031638, 0.002019090801031638]	Loss = 0.68570727 (ave = 0.70261561)

2023-07-06 02:28:15,164 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33250	Time 12.259s / 10iters, (1.226)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.306s / 10iters, (0.831)	Loss Time 2.746s / 10iters, (0.275)	Data load 0.086s / 10iters, (0.008578)
Learning rate = [0.002016402861110149, 0.002016402861110149]	Loss = 0.73198885 (ave = 0.73550603)

2023-07-06 02:28:27,385 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33260	Time 12.220s / 10iters, (1.222)	Forward Time 1.132s / 10iters, (0.113)	Backward Time 8.314s / 10iters, (0.831)	Loss Time 2.686s / 10iters, (0.269)	Data load 0.089s / 10iters, (0.008930)
Learning rate = [0.002013714523004681, 0.002013714523004681]	Loss = 0.68827808 (ave = 0.69601661)

2023-07-06 02:28:39,562 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33270	Time 12.178s / 10iters, (1.218)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.077s / 10iters, (0.007657)
Learning rate = [0.002011025786065426, 0.002011025786065426]	Loss = 0.64265120 (ave = 0.68039467)

2023-07-06 02:28:51,874 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33280	Time 12.312s / 10iters, (1.231)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.363s / 10iters, (0.836)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.086s / 10iters, (0.008609)
Learning rate = [0.0020083366496405504, 0.0020083366496405504]	Loss = 0.75013417 (ave = 0.69073264)

2023-07-06 02:29:04,155 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33290	Time 12.280s / 10iters, (1.228)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007451)
Learning rate = [0.0020056471130761823, 0.0020056471130761823]	Loss = 0.55783296 (ave = 0.65030465)

2023-07-06 02:29:16,332 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33300	Time 12.177s / 10iters, (1.218)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.198s / 10iters, (0.820)	Loss Time 2.795s / 10iters, (0.280)	Data load 0.087s / 10iters, (0.008683)
Learning rate = [0.0020029571757164033, 0.0020029571757164033]	Loss = 0.71840686 (ave = 0.67406784)

2023-07-06 02:29:28,542 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33310	Time 12.211s / 10iters, (1.221)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.236s / 10iters, (0.824)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007397)
Learning rate = [0.0020002668369032387, 0.0020002668369032387]	Loss = 0.73400891 (ave = 0.70174876)

2023-07-06 02:29:40,686 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33320	Time 12.144s / 10iters, (1.214)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.154s / 10iters, (0.815)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007416)
Learning rate = [0.0019975760959766516, 0.0019975760959766516]	Loss = 0.70092404 (ave = 0.70060738)

2023-07-06 02:29:52,905 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33330	Time 12.219s / 10iters, (1.222)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.833s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007370)
Learning rate = [0.0019948849522745276, 0.0019948849522745276]	Loss = 0.71316099 (ave = 0.70279856)

2023-07-06 02:30:05,068 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33340	Time 12.163s / 10iters, (1.216)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.795s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007441)
Learning rate = [0.001992193405132668, 0.001992193405132668]	Loss = 0.66894597 (ave = 0.70411497)

2023-07-06 02:30:17,224 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33350	Time 12.157s / 10iters, (1.216)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.178s / 10iters, (0.818)	Loss Time 2.809s / 10iters, (0.281)	Data load 0.083s / 10iters, (0.008335)
Learning rate = [0.001989501453884779, 0.001989501453884779]	Loss = 0.64712787 (ave = 0.70310099)

2023-07-06 02:30:29,415 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33360	Time 12.191s / 10iters, (1.219)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007386)
Learning rate = [0.0019868090978624672, 0.0019868090978624672]	Loss = 0.66347426 (ave = 0.67611687)

2023-07-06 02:30:41,711 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33370	Time 12.296s / 10iters, (1.230)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007399)
Learning rate = [0.0019841163363952213, 0.0019841163363952213]	Loss = 0.65180671 (ave = 0.70893897)

2023-07-06 02:30:53,746 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33380	Time 12.035s / 10iters, (1.204)	Forward Time 1.081s / 10iters, (0.108)	Backward Time 8.138s / 10iters, (0.814)	Loss Time 2.743s / 10iters, (0.274)	Data load 0.073s / 10iters, (0.007322)
Learning rate = [0.0019814231688104074, 0.0019814231688104074]	Loss = 0.65600538 (ave = 0.64809027)

2023-07-06 02:31:05,735 INFO    [trainer_contrastive.py, 272] Train Epoch: 89	Train Iteration: 33390	Time 11.989s / 10iters, (1.199)	Forward Time 1.078s / 10iters, (0.108)	Backward Time 8.119s / 10iters, (0.812)	Loss Time 2.714s / 10iters, (0.271)	Data load 0.077s / 10iters, (0.007730)
Learning rate = [0.001978729594433257, 0.001978729594433257]	Loss = 0.74807811 (ave = 0.70561370)

2023-07-06 02:31:20,844 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33400	Time 14.959s / 10iters, (1.496)	Forward Time 1.309s / 10iters, (0.131)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.698s / 10iters, (0.270)	Data load 2.700s / 10iters, (0.269965)
Learning rate = [0.0019760356125868624, 0.0019760356125868624]	Loss = 0.66708797 (ave = 0.71963833)

2023-07-06 02:31:33,013 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33410	Time 12.169s / 10iters, (1.217)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007455)
Learning rate = [0.001973341222592157, 0.001973341222592157]	Loss = 0.63316441 (ave = 0.70153270)

2023-07-06 02:31:45,228 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33420	Time 12.215s / 10iters, (1.222)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.087s / 10iters, (0.008729)
Learning rate = [0.0019706464237679126, 0.0019706464237679126]	Loss = 0.79446566 (ave = 0.68100914)

2023-07-06 02:31:57,443 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33430	Time 12.215s / 10iters, (1.221)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.238s / 10iters, (0.824)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007572)
Learning rate = [0.0019679512154307265, 0.0019679512154307265]	Loss = 0.59414679 (ave = 0.65636111)

2023-07-06 02:32:09,741 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33440	Time 12.298s / 10iters, (1.230)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007519)
Learning rate = [0.001965255596895014, 0.001965255596895014]	Loss = 0.67991483 (ave = 0.69384978)

2023-07-06 02:32:22,031 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33450	Time 12.290s / 10iters, (1.229)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.828s / 10iters, (0.283)	Data load 0.095s / 10iters, (0.009458)
Learning rate = [0.001962559567472993, 0.001962559567472993]	Loss = 0.74689621 (ave = 0.66009625)

2023-07-06 02:32:34,192 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33460	Time 12.161s / 10iters, (1.216)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.204s / 10iters, (0.820)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007440)
Learning rate = [0.0019598631264746776, 0.0019598631264746776]	Loss = 0.64998049 (ave = 0.65747481)

2023-07-06 02:32:46,404 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33470	Time 12.211s / 10iters, (1.221)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.209s / 10iters, (0.821)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007586)
Learning rate = [0.001957166273207865, 0.001957166273207865]	Loss = 0.69003987 (ave = 0.70064911)

2023-07-06 02:32:58,614 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33480	Time 12.210s / 10iters, (1.221)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007474)
Learning rate = [0.001954469006978131, 0.001954469006978131]	Loss = 0.77095139 (ave = 0.68106642)

2023-07-06 02:33:10,902 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33490	Time 12.288s / 10iters, (1.229)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.855s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007528)
Learning rate = [0.0019517713270888108, 0.0019517713270888108]	Loss = 0.84320301 (ave = 0.71339836)

2023-07-06 02:33:23,080 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33500	Time 12.178s / 10iters, (1.218)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.166s / 10iters, (0.817)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007393)
Learning rate = [0.0019490732328409927, 0.0019490732328409927]	Loss = 0.69042259 (ave = 0.70340055)

2023-07-06 02:33:35,361 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33510	Time 12.281s / 10iters, (1.228)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.077s / 10iters, (0.007690)
Learning rate = [0.0019463747235335073, 0.0019463747235335073]	Loss = 0.55266654 (ave = 0.66115708)

2023-07-06 02:33:47,701 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33520	Time 12.340s / 10iters, (1.234)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.307s / 10iters, (0.831)	Loss Time 2.866s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007519)
Learning rate = [0.0019436757984629197, 0.0019436757984629197]	Loss = 0.78679693 (ave = 0.71925631)

2023-07-06 02:33:59,853 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33530	Time 12.152s / 10iters, (1.215)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.777s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007438)
Learning rate = [0.0019409764569235117, 0.0019409764569235117]	Loss = 0.61481041 (ave = 0.66257370)

2023-07-06 02:34:12,103 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33540	Time 12.250s / 10iters, (1.225)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.789s / 10iters, (0.279)	Data load 0.077s / 10iters, (0.007734)
Learning rate = [0.0019382766982072761, 0.0019382766982072761]	Loss = 0.66144097 (ave = 0.69860390)

2023-07-06 02:34:24,283 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33550	Time 12.179s / 10iters, (1.218)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.747s / 10iters, (0.275)	Data load 0.074s / 10iters, (0.007436)
Learning rate = [0.0019355765216039033, 0.0019355765216039033]	Loss = 0.66272569 (ave = 0.68509725)

2023-07-06 02:34:36,498 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33560	Time 12.215s / 10iters, (1.222)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.756s / 10iters, (0.276)	Data load 0.076s / 10iters, (0.007627)
Learning rate = [0.0019328759264007748, 0.0019328759264007748]	Loss = 0.66436619 (ave = 0.66998304)

2023-07-06 02:34:48,854 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33570	Time 12.356s / 10iters, (1.236)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.389s / 10iters, (0.839)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.086s / 10iters, (0.008561)
Learning rate = [0.0019301749118829442, 0.0019301749118829442]	Loss = 0.65107656 (ave = 0.64772213)

2023-07-06 02:35:01,293 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33580	Time 12.439s / 10iters, (1.244)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.476s / 10iters, (0.848)	Loss Time 2.757s / 10iters, (0.276)	Data load 0.076s / 10iters, (0.007557)
Learning rate = [0.0019274734773331325, 0.0019274734773331325]	Loss = 0.65899938 (ave = 0.66489437)

2023-07-06 02:35:13,436 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33590	Time 12.143s / 10iters, (1.214)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.735s / 10iters, (0.273)	Data load 0.076s / 10iters, (0.007607)
Learning rate = [0.001924771622031713, 0.001924771622031713]	Loss = 0.61479056 (ave = 0.65839193)

2023-07-06 02:35:25,695 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33600	Time 12.259s / 10iters, (1.226)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.341s / 10iters, (0.834)	Loss Time 2.750s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007451)
Learning rate = [0.0019220693452567047, 0.0019220693452567047]	Loss = 0.76026678 (ave = 0.72554324)

2023-07-06 02:35:38,026 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33610	Time 12.331s / 10iters, (1.233)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.380s / 10iters, (0.838)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.082s / 10iters, (0.008222)
Learning rate = [0.0019193666462837553, 0.0019193666462837553]	Loss = 0.73421067 (ave = 0.68626108)

2023-07-06 02:35:50,367 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33620	Time 12.341s / 10iters, (1.234)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.390s / 10iters, (0.839)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007602)
Learning rate = [0.0019166635243861325, 0.0019166635243861325]	Loss = 0.74991536 (ave = 0.74087703)

2023-07-06 02:36:02,579 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33630	Time 12.212s / 10iters, (1.221)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.721s / 10iters, (0.272)	Data load 0.075s / 10iters, (0.007463)
Learning rate = [0.0019139599788347123, 0.0019139599788347123]	Loss = 0.62053996 (ave = 0.67528245)

2023-07-06 02:36:14,837 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33640	Time 12.258s / 10iters, (1.226)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.331s / 10iters, (0.833)	Loss Time 2.735s / 10iters, (0.273)	Data load 0.090s / 10iters, (0.008988)
Learning rate = [0.001911256008897966, 0.001911256008897966]	Loss = 0.68518066 (ave = 0.68624985)

2023-07-06 02:36:27,001 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33650	Time 12.164s / 10iters, (1.216)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.697s / 10iters, (0.270)	Data load 0.077s / 10iters, (0.007716)
Learning rate = [0.0019085516138419535, 0.0019085516138419535]	Loss = 0.98130339 (ave = 0.73609758)

2023-07-06 02:36:39,268 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33660	Time 12.267s / 10iters, (1.227)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.320s / 10iters, (0.832)	Loss Time 2.760s / 10iters, (0.276)	Data load 0.085s / 10iters, (0.008478)
Learning rate = [0.001905846792930304, 0.001905846792930304]	Loss = 0.61108840 (ave = 0.68732544)

2023-07-06 02:36:51,524 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33670	Time 12.256s / 10iters, (1.226)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.281s / 10iters, (0.828)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.078s / 10iters, (0.007777)
Learning rate = [0.0019031415454242085, 0.0019031415454242085]	Loss = 0.75638944 (ave = 0.69378445)

2023-07-06 02:37:03,824 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33680	Time 12.301s / 10iters, (1.230)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.088s / 10iters, (0.008821)
Learning rate = [0.0019004358705824065, 0.0019004358705824065]	Loss = 0.78486013 (ave = 0.67791419)

2023-07-06 02:37:16,013 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33690	Time 12.189s / 10iters, (1.219)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.170s / 10iters, (0.817)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.083s / 10iters, (0.008324)
Learning rate = [0.0018977297676611785, 0.0018977297676611785]	Loss = 0.65082312 (ave = 0.67928916)

2023-07-06 02:37:28,378 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33700	Time 12.365s / 10iters, (1.236)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.309s / 10iters, (0.831)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.083s / 10iters, (0.008256)
Learning rate = [0.0018950232359143256, 0.0018950232359143256]	Loss = 0.70843548 (ave = 0.70600117)

2023-07-06 02:37:40,744 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33710	Time 12.367s / 10iters, (1.237)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.098s / 10iters, (0.009803)
Learning rate = [0.0018923162745931638, 0.0018923162745931638]	Loss = 0.88342857 (ave = 0.68778084)

2023-07-06 02:37:53,115 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33720	Time 12.371s / 10iters, (1.237)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.328s / 10iters, (0.833)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.090s / 10iters, (0.008951)
Learning rate = [0.001889608882946508, 0.001889608882946508]	Loss = 0.67381072 (ave = 0.66190192)

2023-07-06 02:38:05,628 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33730	Time 12.513s / 10iters, (1.251)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.411s / 10iters, (0.841)	Loss Time 2.900s / 10iters, (0.290)	Data load 0.080s / 10iters, (0.008002)
Learning rate = [0.001886901060220665, 0.001886901060220665]	Loss = 0.67954087 (ave = 0.70937529)

2023-07-06 02:38:18,025 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33740	Time 12.397s / 10iters, (1.240)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.911s / 10iters, (0.291)	Data load 0.078s / 10iters, (0.007770)
Learning rate = [0.001884192805659414, 0.001884192805659414]	Loss = 0.67048407 (ave = 0.71119507)

2023-07-06 02:38:30,257 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33750	Time 12.232s / 10iters, (1.223)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.217s / 10iters, (0.822)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007447)
Learning rate = [0.001881484118503999, 0.001881484118503999]	Loss = 0.65615761 (ave = 0.70281192)

2023-07-06 02:38:42,270 INFO    [trainer_contrastive.py, 272] Train Epoch: 90	Train Iteration: 33760	Time 12.013s / 10iters, (1.201)	Forward Time 1.079s / 10iters, (0.108)	Backward Time 8.116s / 10iters, (0.812)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.077s / 10iters, (0.007680)
Learning rate = [0.0018787749979931132, 0.0018787749979931132]	Loss = 0.67877483 (ave = 0.72425772)

2023-07-06 02:38:57,287 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33770	Time 14.824s / 10iters, (1.482)	Forward Time 1.221s / 10iters, (0.122)	Backward Time 8.325s / 10iters, (0.832)	Loss Time 2.699s / 10iters, (0.270)	Data load 2.579s / 10iters, (0.257926)
Learning rate = [0.0018760654433628919, 0.0018760654433628919]	Loss = 0.64813602 (ave = 0.70252131)

2023-07-06 02:39:09,442 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33780	Time 12.155s / 10iters, (1.216)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.250s / 10iters, (0.825)	Loss Time 2.719s / 10iters, (0.272)	Data load 0.093s / 10iters, (0.009328)
Learning rate = [0.001873355453846891, 0.001873355453846891]	Loss = 0.66514558 (ave = 0.68452458)

2023-07-06 02:39:21,705 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33790	Time 12.263s / 10iters, (1.226)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.306s / 10iters, (0.831)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.077s / 10iters, (0.007682)
Learning rate = [0.0018706450286760823, 0.0018706450286760823]	Loss = 0.71665907 (ave = 0.68194928)

2023-07-06 02:39:33,916 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33800	Time 12.211s / 10iters, (1.221)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007377)
Learning rate = [0.0018679341670788338, 0.0018679341670788338]	Loss = 0.53722024 (ave = 0.69921790)

2023-07-06 02:39:46,193 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33810	Time 12.277s / 10iters, (1.228)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.346s / 10iters, (0.835)	Loss Time 2.744s / 10iters, (0.274)	Data load 0.075s / 10iters, (0.007474)
Learning rate = [0.0018652228682809052, 0.0018652228682809052]	Loss = 0.68523550 (ave = 0.69388818)

2023-07-06 02:39:58,465 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33820	Time 12.271s / 10iters, (1.227)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.089s / 10iters, (0.008921)
Learning rate = [0.0018625111315054255, 0.0018625111315054255]	Loss = 0.78634244 (ave = 0.67351817)

2023-07-06 02:40:10,764 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33830	Time 12.299s / 10iters, (1.230)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007410)
Learning rate = [0.0018597989559728852, 0.0018597989559728852]	Loss = 0.64716667 (ave = 0.69919133)

2023-07-06 02:40:23,059 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33840	Time 12.295s / 10iters, (1.230)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.085s / 10iters, (0.008518)
Learning rate = [0.0018570863409011215, 0.0018570863409011215]	Loss = 0.71752167 (ave = 0.68495691)

2023-07-06 02:40:35,322 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33850	Time 12.263s / 10iters, (1.226)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.216s / 10iters, (0.822)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007488)
Learning rate = [0.0018543732855053079, 0.0018543732855053079]	Loss = 0.78330624 (ave = 0.70469809)

2023-07-06 02:40:47,605 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33860	Time 12.283s / 10iters, (1.228)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.845s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007547)
Learning rate = [0.0018516597889979348, 0.0018516597889979348]	Loss = 0.72517693 (ave = 0.66112093)

2023-07-06 02:40:59,917 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33870	Time 12.313s / 10iters, (1.231)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.275s / 10iters, (0.828)	Loss Time 2.857s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007525)
Learning rate = [0.0018489458505888013, 0.0018489458505888013]	Loss = 0.68078965 (ave = 0.72225893)

2023-07-06 02:41:12,247 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33880	Time 12.329s / 10iters, (1.233)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.904s / 10iters, (0.290)	Data load 0.076s / 10iters, (0.007588)
Learning rate = [0.0018462314694849978, 0.0018462314694849978]	Loss = 0.65403104 (ave = 0.66642187)

2023-07-06 02:41:24,619 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33890	Time 12.373s / 10iters, (1.237)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.322s / 10iters, (0.832)	Loss Time 2.881s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007491)
Learning rate = [0.001843516644890898, 0.001843516644890898]	Loss = 0.78269005 (ave = 0.66350921)

2023-07-06 02:41:36,931 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33900	Time 12.312s / 10iters, (1.231)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.877s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007483)
Learning rate = [0.0018408013760081376, 0.0018408013760081376]	Loss = 0.66656631 (ave = 0.73120413)

2023-07-06 02:41:49,281 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33910	Time 12.350s / 10iters, (1.235)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.278s / 10iters, (0.828)	Loss Time 2.899s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007518)
Learning rate = [0.0018380856620356057, 0.0018380856620356057]	Loss = 0.72073090 (ave = 0.69917829)

2023-07-06 02:42:01,719 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33920	Time 12.437s / 10iters, (1.244)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.367s / 10iters, (0.837)	Loss Time 2.893s / 10iters, (0.289)	Data load 0.082s / 10iters, (0.008197)
Learning rate = [0.001835369502169427, 0.001835369502169427]	Loss = 0.69138122 (ave = 0.66711301)

2023-07-06 02:42:14,075 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33930	Time 12.356s / 10iters, (1.236)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.285s / 10iters, (0.829)	Loss Time 2.899s / 10iters, (0.290)	Data load 0.076s / 10iters, (0.007577)
Learning rate = [0.001832652895602954, 0.001832652895602954]	Loss = 0.66489786 (ave = 0.69113280)

2023-07-06 02:42:26,298 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33940	Time 12.223s / 10iters, (1.222)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.194s / 10iters, (0.819)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007470)
Learning rate = [0.0018299358415267454, 0.0018299358415267454]	Loss = 0.66178375 (ave = 0.70663200)

2023-07-06 02:42:38,604 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33950	Time 12.307s / 10iters, (1.231)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.235s / 10iters, (0.824)	Loss Time 2.896s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007498)
Learning rate = [0.001827218339128556, 0.001827218339128556]	Loss = 0.66024321 (ave = 0.67119232)

2023-07-06 02:42:50,988 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33960	Time 12.383s / 10iters, (1.238)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.921s / 10iters, (0.292)	Data load 0.101s / 10iters, (0.010127)
Learning rate = [0.0018245003875933205, 0.0018245003875933205]	Loss = 0.64030015 (ave = 0.68195720)

2023-07-06 02:43:03,256 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33970	Time 12.268s / 10iters, (1.227)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.225s / 10iters, (0.823)	Loss Time 2.874s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007463)
Learning rate = [0.0018217819861031431, 0.0018217819861031431]	Loss = 0.62943941 (ave = 0.63614792)

2023-07-06 02:43:15,543 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33980	Time 12.287s / 10iters, (1.229)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.897s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007529)
Learning rate = [0.001819063133837277, 0.001819063133837277]	Loss = 0.64271516 (ave = 0.66062946)

2023-07-06 02:43:28,073 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 33990	Time 12.531s / 10iters, (1.253)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.407s / 10iters, (0.841)	Loss Time 2.925s / 10iters, (0.293)	Data load 0.078s / 10iters, (0.007838)
Learning rate = [0.001816343829972113, 0.001816343829972113]	Loss = 0.77430743 (ave = 0.65850904)

2023-07-06 02:43:40,278 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 34000	Time 12.205s / 10iters, (1.220)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.185s / 10iters, (0.819)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007519)
Learning rate = [0.0018136240736811638, 0.0018136240736811638]	Loss = 0.63238090 (ave = 0.65922093)

2023-07-06 02:43:43,774 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-06 02:44:07,323 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-06 02:44:30,259 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-06 02:44:52,950 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-06 02:45:16,037 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-06 02:45:38,689 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-06 02:46:01,094 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-06 02:46:06,903 INFO    [base.py, 84] Performance 0.7664567661860565 -> 0.7682762208938888
2023-07-06 02:46:12,709 INFO    [trainer_contrastive.py, 391] Test Time 146.434s, (2.324)	Loss 0.12383018

2023-07-06 02:46:12,709 INFO    [base.py, 33] Result for seg
2023-07-06 02:46:12,711 INFO    [base.py, 49] Mean IOU: 0.7682762208938888

2023-07-06 02:46:12,712 INFO    [base.py, 50] Pixel ACC: 0.9608967218980468

2023-07-06 02:46:24,989 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 34010	Time 164.711s / 10iters, (16.471)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.769s / 10iters, (0.277)	Data load 152.525s / 10iters, (15.252453)
Learning rate = [0.0018109038641350526, 0.0018109038641350526]	Loss = 0.69655013 (ave = 0.69543997)

2023-07-06 02:46:37,142 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 34020	Time 12.153s / 10iters, (1.215)	Forward Time 1.081s / 10iters, (0.108)	Backward Time 8.230s / 10iters, (0.823)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.074s / 10iters, (0.007362)
Learning rate = [0.0018081832005014918, 0.0018081832005014918]	Loss = 0.71542180 (ave = 0.73404213)

2023-07-06 02:46:49,334 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 34030	Time 12.192s / 10iters, (1.219)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007518)
Learning rate = [0.0018054620819452727, 0.0018054620819452727]	Loss = 0.67216301 (ave = 0.68334691)

2023-07-06 02:47:01,513 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 34040	Time 12.179s / 10iters, (1.218)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.082s / 10iters, (0.008183)
Learning rate = [0.0018027405076282473, 0.0018027405076282473]	Loss = 0.72846150 (ave = 0.69361509)

2023-07-06 02:47:13,801 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 34050	Time 12.288s / 10iters, (1.229)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.286s / 10iters, (0.829)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.084s / 10iters, (0.008360)
Learning rate = [0.001800018476709319, 0.001800018476709319]	Loss = 0.60329825 (ave = 0.67303637)

2023-07-06 02:47:26,062 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 34060	Time 12.261s / 10iters, (1.226)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.265s / 10iters, (0.826)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007515)
Learning rate = [0.0017972959883444184, 0.0017972959883444184]	Loss = 0.68139362 (ave = 0.67974802)

2023-07-06 02:47:38,269 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 34070	Time 12.206s / 10iters, (1.221)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.086s / 10iters, (0.008576)
Learning rate = [0.001794573041686494, 0.001794573041686494]	Loss = 0.62147331 (ave = 0.71106113)

2023-07-06 02:47:50,461 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 34080	Time 12.193s / 10iters, (1.219)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.757s / 10iters, (0.276)	Data load 0.086s / 10iters, (0.008559)
Learning rate = [0.001791849635885493, 0.001791849635885493]	Loss = 0.66930777 (ave = 0.71085266)

2023-07-06 02:48:02,588 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 34090	Time 12.127s / 10iters, (1.213)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.233s / 10iters, (0.823)	Loss Time 2.726s / 10iters, (0.273)	Data load 0.075s / 10iters, (0.007512)
Learning rate = [0.0017891257700883524, 0.0017891257700883524]	Loss = 0.64364344 (ave = 0.66860823)

2023-07-06 02:48:14,857 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 34100	Time 12.269s / 10iters, (1.227)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.314s / 10iters, (0.831)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007631)
Learning rate = [0.001786401443438973, 0.001786401443438973]	Loss = 0.71430600 (ave = 0.67726542)

2023-07-06 02:48:27,043 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 34110	Time 12.185s / 10iters, (1.219)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.282s / 10iters, (0.828)	Loss Time 2.737s / 10iters, (0.274)	Data load 0.077s / 10iters, (0.007744)
Learning rate = [0.0017836766550782116, 0.0017836766550782116]	Loss = 1.00800204 (ave = 0.71363872)

2023-07-06 02:48:39,264 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 34120	Time 12.221s / 10iters, (1.222)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.305s / 10iters, (0.831)	Loss Time 2.755s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007398)
Learning rate = [0.0017809514041438592, 0.0017809514041438592]	Loss = 0.64445353 (ave = 0.68461950)

2023-07-06 02:48:51,226 INFO    [trainer_contrastive.py, 272] Train Epoch: 91	Train Iteration: 34130	Time 11.962s / 10iters, (1.196)	Forward Time 1.078s / 10iters, (0.108)	Backward Time 8.126s / 10iters, (0.813)	Loss Time 2.681s / 10iters, (0.268)	Data load 0.077s / 10iters, (0.007670)
Learning rate = [0.001778225689770633, 0.001778225689770633]	Loss = 0.68295777 (ave = 0.71179205)

2023-07-06 02:49:06,328 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34140	Time 14.878s / 10iters, (1.488)	Forward Time 1.254s / 10iters, (0.125)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.771s / 10iters, (0.277)	Data load 2.552s / 10iters, (0.255247)
Learning rate = [0.0017754995110901498, 0.0017754995110901498]	Loss = 0.71607208 (ave = 0.71720545)

2023-07-06 02:49:18,548 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34150	Time 12.221s / 10iters, (1.222)	Forward Time 1.085s / 10iters, (0.109)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.088s / 10iters, (0.008805)
Learning rate = [0.001772772867230917, 0.001772772867230917]	Loss = 0.60193026 (ave = 0.69753855)

2023-07-06 02:49:30,769 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34160	Time 12.221s / 10iters, (1.222)	Forward Time 1.084s / 10iters, (0.108)	Backward Time 8.223s / 10iters, (0.822)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007445)
Learning rate = [0.001770045757318312, 0.001770045757318312]	Loss = 0.72219872 (ave = 0.66151688)

2023-07-06 02:49:43,002 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34170	Time 12.233s / 10iters, (1.223)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.205s / 10iters, (0.821)	Loss Time 2.869s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007386)
Learning rate = [0.0017673181804745714, 0.0017673181804745714]	Loss = 0.85781401 (ave = 0.66885801)

2023-07-06 02:49:55,244 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34180	Time 12.241s / 10iters, (1.224)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.835s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007441)
Learning rate = [0.0017645901358187665, 0.0017645901358187665]	Loss = 0.77286720 (ave = 0.67363688)

2023-07-06 02:50:07,485 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34190	Time 12.241s / 10iters, (1.224)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007512)
Learning rate = [0.0017618616224667914, 0.0017618616224667914]	Loss = 0.69755059 (ave = 0.69192625)

2023-07-06 02:50:19,718 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34200	Time 12.234s / 10iters, (1.223)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.083s / 10iters, (0.008268)
Learning rate = [0.001759132639531344, 0.001759132639531344]	Loss = 0.79334146 (ave = 0.69127858)

2023-07-06 02:50:31,836 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34210	Time 12.117s / 10iters, (1.212)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.174s / 10iters, (0.817)	Loss Time 2.766s / 10iters, (0.277)	Data load 0.083s / 10iters, (0.008272)
Learning rate = [0.001756403186121913, 0.001756403186121913]	Loss = 0.82504481 (ave = 0.66704398)

2023-07-06 02:50:44,028 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34220	Time 12.192s / 10iters, (1.219)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.762s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007391)
Learning rate = [0.0017536732613447545, 0.0017536732613447545]	Loss = 0.64096272 (ave = 0.67186039)

2023-07-06 02:50:56,205 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34230	Time 12.177s / 10iters, (1.218)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.742s / 10iters, (0.274)	Data load 0.082s / 10iters, (0.008188)
Learning rate = [0.0017509428643028783, 0.0017509428643028783]	Loss = 0.63447183 (ave = 0.66839215)

2023-07-06 02:51:08,321 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34240	Time 12.116s / 10iters, (1.212)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.219s / 10iters, (0.822)	Loss Time 2.724s / 10iters, (0.272)	Data load 0.077s / 10iters, (0.007710)
Learning rate = [0.001748211994096029, 0.001748211994096029]	Loss = 0.70220459 (ave = 0.64843796)

2023-07-06 02:51:20,550 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34250	Time 12.229s / 10iters, (1.223)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007429)
Learning rate = [0.001745480649820673, 0.001745480649820673]	Loss = 0.61373752 (ave = 0.66751862)

2023-07-06 02:51:32,734 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34260	Time 12.183s / 10iters, (1.218)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.086s / 10iters, (0.008614)
Learning rate = [0.0017427488305699734, 0.0017427488305699734]	Loss = 0.62836438 (ave = 0.69522943)

2023-07-06 02:51:44,945 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34270	Time 12.211s / 10iters, (1.221)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007423)
Learning rate = [0.0017400165354337768, 0.0017400165354337768]	Loss = 0.73536122 (ave = 0.69282024)

2023-07-06 02:51:57,148 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34280	Time 12.203s / 10iters, (1.220)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.179s / 10iters, (0.818)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007441)
Learning rate = [0.001737283763498594, 0.001737283763498594]	Loss = 0.75481498 (ave = 0.70389177)

2023-07-06 02:52:09,283 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34290	Time 12.136s / 10iters, (1.214)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.188s / 10iters, (0.819)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007446)
Learning rate = [0.001734550513847585, 0.001734550513847585]	Loss = 0.62428629 (ave = 0.69366770)

2023-07-06 02:52:21,508 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34300	Time 12.225s / 10iters, (1.222)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.083s / 10iters, (0.008289)
Learning rate = [0.0017318167855605354, 0.0017318167855605354]	Loss = 0.65060276 (ave = 0.73088505)

2023-07-06 02:52:33,626 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34310	Time 12.118s / 10iters, (1.212)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.192s / 10iters, (0.819)	Loss Time 2.764s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007380)
Learning rate = [0.0017290825777138417, 0.0017290825777138417]	Loss = 0.70437992 (ave = 0.66111273)

2023-07-06 02:52:45,806 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34320	Time 12.181s / 10iters, (1.218)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007415)
Learning rate = [0.00172634788938049, 0.00172634788938049]	Loss = 0.65050060 (ave = 0.72209968)

2023-07-06 02:52:57,863 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34330	Time 12.056s / 10iters, (1.206)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.155s / 10iters, (0.815)	Loss Time 2.738s / 10iters, (0.274)	Data load 0.075s / 10iters, (0.007452)
Learning rate = [0.001723612719630045, 0.001723612719630045]	Loss = 0.76656997 (ave = 0.71283768)

2023-07-06 02:53:10,074 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34340	Time 12.211s / 10iters, (1.221)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007367)
Learning rate = [0.0017208770675286194, 0.0017208770675286194]	Loss = 0.61735684 (ave = 0.66809266)

2023-07-06 02:53:22,333 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34350	Time 12.259s / 10iters, (1.226)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.869s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007434)
Learning rate = [0.001718140932138865, 0.001718140932138865]	Loss = 0.72170877 (ave = 0.68630520)

2023-07-06 02:53:34,542 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34360	Time 12.209s / 10iters, (1.221)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.188s / 10iters, (0.819)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.074s / 10iters, (0.007365)
Learning rate = [0.0017154043125199468, 0.0017154043125199468]	Loss = 0.51357216 (ave = 0.63268641)

2023-07-06 02:53:46,656 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34370	Time 12.114s / 10iters, (1.211)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.074s / 10iters, (0.007445)
Learning rate = [0.0017126672077275313, 0.0017126672077275313]	Loss = 0.65714836 (ave = 0.65320445)

2023-07-06 02:53:58,816 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34380	Time 12.160s / 10iters, (1.216)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.185s / 10iters, (0.818)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007432)
Learning rate = [0.0017099296168137598, 0.0017099296168137598]	Loss = 0.76032060 (ave = 0.66154313)

2023-07-06 02:54:11,072 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34390	Time 12.256s / 10iters, (1.226)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007367)
Learning rate = [0.0017071915388272327, 0.0017071915388272327]	Loss = 0.68577528 (ave = 0.72014270)

2023-07-06 02:54:23,245 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34400	Time 12.173s / 10iters, (1.217)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.187s / 10iters, (0.819)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007417)
Learning rate = [0.0017044529728129881, 0.0017044529728129881]	Loss = 0.61987275 (ave = 0.67334898)

2023-07-06 02:54:35,492 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34410	Time 12.246s / 10iters, (1.225)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.868s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007470)
Learning rate = [0.0017017139178124873, 0.0017017139178124873]	Loss = 0.67884433 (ave = 0.73765765)

2023-07-06 02:54:47,729 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34420	Time 12.237s / 10iters, (1.224)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.187s / 10iters, (0.819)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007411)
Learning rate = [0.0016989743728635877, 0.0016989743728635877]	Loss = 0.94131416 (ave = 0.72147515)

2023-07-06 02:54:59,958 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34430	Time 12.229s / 10iters, (1.223)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.182s / 10iters, (0.818)	Loss Time 2.881s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007377)
Learning rate = [0.0016962343370005254, 0.0016962343370005254]	Loss = 0.63444746 (ave = 0.67003772)

2023-07-06 02:55:12,217 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34440	Time 12.259s / 10iters, (1.226)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007426)
Learning rate = [0.0016934938092538969, 0.0016934938092538969]	Loss = 0.67509377 (ave = 0.68411485)

2023-07-06 02:55:24,465 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34450	Time 12.248s / 10iters, (1.225)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007427)
Learning rate = [0.0016907527886506396, 0.0016907527886506396]	Loss = 0.67632264 (ave = 0.68990291)

2023-07-06 02:55:36,774 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34460	Time 12.309s / 10iters, (1.231)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.235s / 10iters, (0.823)	Loss Time 2.909s / 10iters, (0.291)	Data load 0.074s / 10iters, (0.007395)
Learning rate = [0.0016880112742140064, 0.0016880112742140064]	Loss = 0.57713181 (ave = 0.68778595)

2023-07-06 02:55:49,013 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34470	Time 12.239s / 10iters, (1.224)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.169s / 10iters, (0.817)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.079s / 10iters, (0.007876)
Learning rate = [0.0016852692649635492, 0.0016852692649635492]	Loss = 0.58447874 (ave = 0.70806865)

2023-07-06 02:56:01,380 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34480	Time 12.366s / 10iters, (1.237)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.928s / 10iters, (0.293)	Data load 0.075s / 10iters, (0.007478)
Learning rate = [0.0016825267599150959, 0.0016825267599150959]	Loss = 0.55330122 (ave = 0.69432060)

2023-07-06 02:56:13,586 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34490	Time 12.206s / 10iters, (1.221)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.084s / 10iters, (0.008422)
Learning rate = [0.0016797837580807338, 0.0016797837580807338]	Loss = 0.74029642 (ave = 0.69077739)

2023-07-06 02:56:25,491 INFO    [trainer_contrastive.py, 272] Train Epoch: 92	Train Iteration: 34500	Time 11.905s / 10iters, (1.191)	Forward Time 1.077s / 10iters, (0.108)	Backward Time 8.063s / 10iters, (0.806)	Loss Time 2.688s / 10iters, (0.269)	Data load 0.077s / 10iters, (0.007680)
Learning rate = [0.0016770402584687823, 0.0016770402584687823]	Loss = 0.69557256 (ave = 0.66898274)

2023-07-06 02:56:41,003 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34510	Time 15.301s / 10iters, (1.530)	Forward Time 1.164s / 10iters, (0.116)	Backward Time 8.287s / 10iters, (0.829)	Loss Time 2.831s / 10iters, (0.283)	Data load 3.019s / 10iters, (0.301925)
Learning rate = [0.0016742962600837753, 0.0016742962600837753]	Loss = 0.66837329 (ave = 0.67922711)

2023-07-06 02:56:53,450 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34520	Time 12.446s / 10iters, (1.245)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.380s / 10iters, (0.838)	Loss Time 2.892s / 10iters, (0.289)	Data load 0.077s / 10iters, (0.007678)
Learning rate = [0.001671551761926438, 0.001671551761926438]	Loss = 0.66827410 (ave = 0.68828050)

2023-07-06 02:57:05,705 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34530	Time 12.255s / 10iters, (1.225)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.815s / 10iters, (0.281)	Data load 0.083s / 10iters, (0.008253)
Learning rate = [0.0016688067629936718, 0.0016688067629936718]	Loss = 0.62911987 (ave = 0.68635584)

2023-07-06 02:57:17,983 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34540	Time 12.278s / 10iters, (1.228)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.835s / 10iters, (0.283)	Data load 0.086s / 10iters, (0.008581)
Learning rate = [0.0016660612622785215, 0.0016660612622785215]	Loss = 0.65496373 (ave = 0.73484533)

2023-07-06 02:57:30,241 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34550	Time 12.258s / 10iters, (1.226)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.820s / 10iters, (0.282)	Data load 0.083s / 10iters, (0.008299)
Learning rate = [0.0016633152587701623, 0.0016633152587701623]	Loss = 0.86727983 (ave = 0.72162842)

2023-07-06 02:57:42,614 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34560	Time 12.373s / 10iters, (1.237)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.324s / 10iters, (0.832)	Loss Time 2.875s / 10iters, (0.287)	Data load 0.077s / 10iters, (0.007691)
Learning rate = [0.0016605687514538723, 0.0016605687514538723]	Loss = 0.76966727 (ave = 0.72330303)

2023-07-06 02:57:54,830 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34570	Time 12.216s / 10iters, (1.222)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.209s / 10iters, (0.821)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.088s / 10iters, (0.008790)
Learning rate = [0.0016578217393110176, 0.0016578217393110176]	Loss = 0.92055321 (ave = 0.67219943)

2023-07-06 02:58:07,196 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34580	Time 12.366s / 10iters, (1.237)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.328s / 10iters, (0.833)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.086s / 10iters, (0.008600)
Learning rate = [0.0016550742213190211, 0.0016550742213190211]	Loss = 0.70711517 (ave = 0.66474980)

2023-07-06 02:58:19,645 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34590	Time 12.449s / 10iters, (1.245)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.396s / 10iters, (0.840)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.077s / 10iters, (0.007672)
Learning rate = [0.0016523261964513454, 0.0016523261964513454]	Loss = 0.67370141 (ave = 0.66331152)

2023-07-06 02:58:31,872 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34600	Time 12.227s / 10iters, (1.223)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.795s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007501)
Learning rate = [0.0016495776636774667, 0.0016495776636774667]	Loss = 0.70296752 (ave = 0.63940604)

2023-07-06 02:58:44,001 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34610	Time 12.128s / 10iters, (1.213)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.184s / 10iters, (0.818)	Loss Time 2.775s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007512)
Learning rate = [0.001646828621962859, 0.001646828621962859]	Loss = 0.68941307 (ave = 0.67345907)

2023-07-06 02:58:56,112 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34620	Time 12.112s / 10iters, (1.211)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.198s / 10iters, (0.820)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.076s / 10iters, (0.007598)
Learning rate = [0.0016440790702689611, 0.0016440790702689611]	Loss = 0.66688257 (ave = 0.70851555)

2023-07-06 02:59:08,235 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34630	Time 12.122s / 10iters, (1.212)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.219s / 10iters, (0.822)	Loss Time 2.731s / 10iters, (0.273)	Data load 0.075s / 10iters, (0.007488)
Learning rate = [0.001641329007553161, 0.001641329007553161]	Loss = 0.79159230 (ave = 0.71934470)

2023-07-06 02:59:20,417 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34640	Time 12.183s / 10iters, (1.218)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.090s / 10iters, (0.009026)
Learning rate = [0.0016385784327687667, 0.0016385784327687667]	Loss = 0.80804157 (ave = 0.66147610)

2023-07-06 02:59:32,479 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34650	Time 12.062s / 10iters, (1.206)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.158s / 10iters, (0.816)	Loss Time 2.735s / 10iters, (0.273)	Data load 0.076s / 10iters, (0.007583)
Learning rate = [0.0016358273448649908, 0.0016358273448649908]	Loss = 0.69195259 (ave = 0.68238251)

2023-07-06 02:59:44,593 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34660	Time 12.114s / 10iters, (1.211)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.187s / 10iters, (0.819)	Loss Time 2.749s / 10iters, (0.275)	Data load 0.084s / 10iters, (0.008394)
Learning rate = [0.0016330757427869178, 0.0016330757427869178]	Loss = 0.80346835 (ave = 0.68949679)

2023-07-06 02:59:56,778 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34670	Time 12.184s / 10iters, (1.218)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.243s / 10iters, (0.824)	Loss Time 2.775s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007462)
Learning rate = [0.001630323625475485, 0.001630323625475485]	Loss = 0.61228698 (ave = 0.67177510)

2023-07-06 03:00:08,993 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34680	Time 12.215s / 10iters, (1.221)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.242s / 10iters, (0.824)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007517)
Learning rate = [0.001627570991867456, 0.001627570991867456]	Loss = 0.72672999 (ave = 0.68262682)

2023-07-06 03:00:21,180 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34690	Time 12.188s / 10iters, (1.219)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.198s / 10iters, (0.820)	Loss Time 2.815s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007527)
Learning rate = [0.0016248178408954023, 0.0016248178408954023]	Loss = 0.86423635 (ave = 0.70010160)

2023-07-06 03:00:33,352 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34700	Time 12.171s / 10iters, (1.217)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007519)
Learning rate = [0.0016220641714876697, 0.0016220641714876697]	Loss = 0.59233129 (ave = 0.67512795)

2023-07-06 03:00:45,807 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34710	Time 12.455s / 10iters, (1.245)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.383s / 10iters, (0.838)	Loss Time 2.879s / 10iters, (0.288)	Data load 0.076s / 10iters, (0.007560)
Learning rate = [0.00161930998256836, 0.00161930998256836]	Loss = 0.65802473 (ave = 0.67089283)

2023-07-06 03:00:58,273 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34720	Time 12.466s / 10iters, (1.247)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.381s / 10iters, (0.838)	Loss Time 2.877s / 10iters, (0.288)	Data load 0.084s / 10iters, (0.008393)
Learning rate = [0.0016165552730573027, 0.0016165552730573027]	Loss = 0.72455835 (ave = 0.68541517)

2023-07-06 03:01:10,543 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34730	Time 12.270s / 10iters, (1.227)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007618)
Learning rate = [0.001613800041870036, 0.001613800041870036]	Loss = 0.75614333 (ave = 0.70941809)

2023-07-06 03:01:22,811 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34740	Time 12.269s / 10iters, (1.227)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.250s / 10iters, (0.825)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007573)
Learning rate = [0.0016110442879177726, 0.0016110442879177726]	Loss = 0.56048918 (ave = 0.67314396)

2023-07-06 03:01:35,107 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34750	Time 12.296s / 10iters, (1.230)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007437)
Learning rate = [0.0016082880101073805, 0.0016082880101073805]	Loss = 0.78800070 (ave = 0.70021182)

2023-07-06 03:01:47,358 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34760	Time 12.250s / 10iters, (1.225)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007612)
Learning rate = [0.0016055312073413538, 0.0016055312073413538]	Loss = 0.65439796 (ave = 0.66698845)

2023-07-06 03:01:59,588 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34770	Time 12.230s / 10iters, (1.223)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.235s / 10iters, (0.824)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007456)
Learning rate = [0.0016027738785177933, 0.0016027738785177933]	Loss = 0.74264896 (ave = 0.73175156)

2023-07-06 03:02:11,857 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34780	Time 12.269s / 10iters, (1.227)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.079s / 10iters, (0.007865)
Learning rate = [0.001600016022530371, 0.001600016022530371]	Loss = 0.67703545 (ave = 0.69322821)

2023-07-06 03:02:24,140 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34790	Time 12.283s / 10iters, (1.228)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007511)
Learning rate = [0.00159725763826831, 0.00159725763826831]	Loss = 0.67678821 (ave = 0.69327517)

2023-07-06 03:02:36,373 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34800	Time 12.232s / 10iters, (1.223)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.204s / 10iters, (0.820)	Loss Time 2.845s / 10iters, (0.285)	Data load 0.081s / 10iters, (0.008146)
Learning rate = [0.0015944987246163565, 0.0015944987246163565]	Loss = 0.55515063 (ave = 0.67318125)

2023-07-06 03:02:48,596 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34810	Time 12.224s / 10iters, (1.222)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.082s / 10iters, (0.008199)
Learning rate = [0.001591739280454755, 0.001591739280454755]	Loss = 0.67426056 (ave = 0.71186876)

2023-07-06 03:03:00,827 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34820	Time 12.231s / 10iters, (1.223)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.844s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007465)
Learning rate = [0.0015889793046592175, 0.0015889793046592175]	Loss = 0.67569339 (ave = 0.68280699)

2023-07-06 03:03:13,106 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34830	Time 12.279s / 10iters, (1.228)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.245s / 10iters, (0.824)	Loss Time 2.852s / 10iters, (0.285)	Data load 0.086s / 10iters, (0.008603)
Learning rate = [0.0015862187961008989, 0.0015862187961008989]	Loss = 0.74896777 (ave = 0.66252365)

2023-07-06 03:03:25,461 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34840	Time 12.355s / 10iters, (1.236)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.868s / 10iters, (0.287)	Data load 0.078s / 10iters, (0.007805)
Learning rate = [0.001583457753646369, 0.001583457753646369]	Loss = 0.65506309 (ave = 0.64859211)

2023-07-06 03:03:37,694 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34850	Time 12.232s / 10iters, (1.223)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.204s / 10iters, (0.820)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007482)
Learning rate = [0.0015806961761575876, 0.0015806961761575876]	Loss = 0.89885640 (ave = 0.71731523)

2023-07-06 03:03:49,925 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34860	Time 12.232s / 10iters, (1.223)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.825s / 10iters, (0.283)	Data load 0.082s / 10iters, (0.008205)
Learning rate = [0.0015779340624918715, 0.0015779340624918715]	Loss = 0.65726840 (ave = 0.72213781)

2023-07-06 03:04:02,130 INFO    [trainer_contrastive.py, 272] Train Epoch: 93	Train Iteration: 34870	Time 12.205s / 10iters, (1.220)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.073s / 10iters, (0.007294)
Learning rate = [0.0015751714115018705, 0.0015751714115018705]	Loss = 0.68073571 (ave = 0.72400466)

2023-07-06 03:04:17,343 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 34880	Time 15.017s / 10iters, (1.502)	Forward Time 1.168s / 10iters, (0.117)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.746s / 10iters, (0.275)	Data load 2.812s / 10iters, (0.281247)
Learning rate = [0.0015724082220355384, 0.0015724082220355384]	Loss = 0.64742678 (ave = 0.70088205)

2023-07-06 03:04:29,656 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 34890	Time 12.313s / 10iters, (1.231)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.362s / 10iters, (0.836)	Loss Time 2.760s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007516)
Learning rate = [0.0015696444929361026, 0.0015696444929361026]	Loss = 0.80166471 (ave = 0.68754666)

2023-07-06 03:04:41,919 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 34900	Time 12.263s / 10iters, (1.226)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.306s / 10iters, (0.831)	Loss Time 2.775s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007474)
Learning rate = [0.0015668802230420407, 0.0015668802230420407]	Loss = 0.61410022 (ave = 0.69622287)

2023-07-06 03:04:54,120 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 34910	Time 12.201s / 10iters, (1.220)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.193s / 10iters, (0.819)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.098s / 10iters, (0.009801)
Learning rate = [0.0015641154111870445, 0.0015641154111870445]	Loss = 0.66289049 (ave = 0.66935079)

2023-07-06 03:05:06,251 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 34920	Time 12.131s / 10iters, (1.213)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.186s / 10iters, (0.819)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007489)
Learning rate = [0.001561350056199996, 0.001561350056199996]	Loss = 0.73204261 (ave = 0.67229748)

2023-07-06 03:05:18,452 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 34930	Time 12.201s / 10iters, (1.220)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.815s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007542)
Learning rate = [0.0015585841569049348, 0.0015585841569049348]	Loss = 0.57776231 (ave = 0.62894473)

2023-07-06 03:05:30,728 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 34940	Time 12.276s / 10iters, (1.228)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007483)
Learning rate = [0.0015558177121210335, 0.0015558177121210335]	Loss = 0.66337931 (ave = 0.66263086)

2023-07-06 03:05:43,136 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 34950	Time 12.408s / 10iters, (1.241)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.389s / 10iters, (0.839)	Loss Time 2.848s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007526)
Learning rate = [0.0015530507206625616, 0.0015530507206625616]	Loss = 0.72637677 (ave = 0.70067003)

2023-07-06 03:05:55,520 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 34960	Time 12.384s / 10iters, (1.238)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.336s / 10iters, (0.834)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007454)
Learning rate = [0.001550283181338859, 0.001550283181338859]	Loss = 0.63936746 (ave = 0.72947879)

2023-07-06 03:06:07,755 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 34970	Time 12.235s / 10iters, (1.224)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.808s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007490)
Learning rate = [0.001547515092954304, 0.001547515092954304]	Loss = 0.64979404 (ave = 0.74933780)

2023-07-06 03:06:20,128 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 34980	Time 12.373s / 10iters, (1.237)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.328s / 10iters, (0.833)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007500)
Learning rate = [0.001544746454308287, 0.001544746454308287]	Loss = 0.65456671 (ave = 0.73332788)

2023-07-06 03:06:32,379 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 34990	Time 12.251s / 10iters, (1.225)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007603)
Learning rate = [0.0015419772641951737, 0.0015419772641951737]	Loss = 0.83856201 (ave = 0.68858567)

2023-07-06 03:06:44,606 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35000	Time 12.227s / 10iters, (1.223)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.808s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007513)
Learning rate = [0.0015392075214042766, 0.0015392075214042766]	Loss = 0.73758471 (ave = 0.66413965)

2023-07-06 03:06:48,079 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-06 03:07:11,572 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-06 03:07:34,590 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-06 03:07:57,580 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-06 03:08:20,679 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-06 03:08:43,180 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-06 03:09:05,411 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-06 03:09:15,325 INFO    [trainer_contrastive.py, 391] Test Time 146.347s, (2.323)	Loss 0.12132512

2023-07-06 03:09:15,325 INFO    [base.py, 33] Result for seg
2023-07-06 03:09:15,327 INFO    [base.py, 49] Mean IOU: 0.7660366965546082

2023-07-06 03:09:15,327 INFO    [base.py, 50] Pixel ACC: 0.9601484196465313

2023-07-06 03:09:27,401 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35010	Time 162.795s / 10iters, (16.280)	Forward Time 1.172s / 10iters, (0.117)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.619s / 10iters, (0.262)	Data load 150.808s / 10iters, (15.080811)
Learning rate = [0.0015364372247198238, 0.0015364372247198238]	Loss = 0.66771364 (ave = 0.69830468)

2023-07-06 03:09:39,539 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35020	Time 12.138s / 10iters, (1.214)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.660s / 10iters, (0.266)	Data load 0.095s / 10iters, (0.009530)
Learning rate = [0.0015336663729209304, 0.0015336663729209304]	Loss = 0.66049278 (ave = 0.67636265)

2023-07-06 03:09:51,630 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35030	Time 12.090s / 10iters, (1.209)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.624s / 10iters, (0.262)	Data load 0.110s / 10iters, (0.011026)
Learning rate = [0.0015308949647815603, 0.0015308949647815603]	Loss = 0.70300210 (ave = 0.68415026)

2023-07-06 03:10:03,865 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35040	Time 12.235s / 10iters, (1.224)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.363s / 10iters, (0.836)	Loss Time 2.694s / 10iters, (0.269)	Data load 0.078s / 10iters, (0.007766)
Learning rate = [0.0015281229990704989, 0.0015281229990704989]	Loss = 0.66896611 (ave = 0.67958370)

2023-07-06 03:10:15,909 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35050	Time 12.043s / 10iters, (1.204)	Forward Time 1.083s / 10iters, (0.108)	Backward Time 8.218s / 10iters, (0.822)	Loss Time 2.657s / 10iters, (0.266)	Data load 0.084s / 10iters, (0.008415)
Learning rate = [0.0015253504745513175, 0.0015253504745513175]	Loss = 0.75424922 (ave = 0.66450816)

2023-07-06 03:10:28,193 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35060	Time 12.284s / 10iters, (1.228)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.354s / 10iters, (0.835)	Loss Time 2.754s / 10iters, (0.275)	Data load 0.074s / 10iters, (0.007429)
Learning rate = [0.0015225773899823461, 0.0015225773899823461]	Loss = 0.68037498 (ave = 0.71796307)

2023-07-06 03:10:40,495 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35070	Time 12.303s / 10iters, (1.230)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.307s / 10iters, (0.831)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.093s / 10iters, (0.009340)
Learning rate = [0.0015198037441166343, 0.0015198037441166343]	Loss = 0.65518320 (ave = 0.65581198)

2023-07-06 03:10:52,782 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35080	Time 12.286s / 10iters, (1.229)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007512)
Learning rate = [0.001517029535701921, 0.001517029535701921]	Loss = 0.78316957 (ave = 0.66533473)

2023-07-06 03:11:04,975 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35090	Time 12.193s / 10iters, (1.219)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.083s / 10iters, (0.008289)
Learning rate = [0.0015142547634805993, 0.0015142547634805993]	Loss = 0.81379533 (ave = 0.69787091)

2023-07-06 03:11:17,285 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35100	Time 12.311s / 10iters, (1.231)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.322s / 10iters, (0.832)	Loss Time 2.775s / 10iters, (0.277)	Data load 0.084s / 10iters, (0.008385)
Learning rate = [0.0015114794261896877, 0.0015114794261896877]	Loss = 0.73968893 (ave = 0.69549747)

2023-07-06 03:11:29,551 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35110	Time 12.266s / 10iters, (1.227)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.076s / 10iters, (0.007612)
Learning rate = [0.00150870352256079, 0.00150870352256079]	Loss = 0.68539786 (ave = 0.68012634)

2023-07-06 03:11:41,794 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35120	Time 12.243s / 10iters, (1.224)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.786s / 10iters, (0.279)	Data load 0.078s / 10iters, (0.007821)
Learning rate = [0.001505927051320063, 0.001505927051320063]	Loss = 0.69402587 (ave = 0.66938013)

2023-07-06 03:11:54,021 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35130	Time 12.227s / 10iters, (1.223)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.262s / 10iters, (0.826)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.088s / 10iters, (0.008838)
Learning rate = [0.0015031500111881819, 0.0015031500111881819]	Loss = 0.66893733 (ave = 0.68758386)

2023-07-06 03:12:06,260 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35140	Time 12.239s / 10iters, (1.224)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.077s / 10iters, (0.007703)
Learning rate = [0.0015003724008803099, 0.0015003724008803099]	Loss = 0.76196355 (ave = 0.64062952)

2023-07-06 03:12:18,492 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35150	Time 12.232s / 10iters, (1.223)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.232s / 10iters, (0.823)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.078s / 10iters, (0.007776)
Learning rate = [0.0014975942191060546, 0.0014975942191060546]	Loss = 0.64022714 (ave = 0.67064322)

2023-07-06 03:12:30,788 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35160	Time 12.296s / 10iters, (1.230)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.285s / 10iters, (0.828)	Loss Time 2.831s / 10iters, (0.283)	Data load 0.084s / 10iters, (0.008439)
Learning rate = [0.0014948154645694387, 0.0014948154645694387]	Loss = 0.56542361 (ave = 0.66421514)

2023-07-06 03:12:43,048 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35170	Time 12.260s / 10iters, (1.226)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.090s / 10iters, (0.009035)
Learning rate = [0.001492036135968861, 0.001492036135968861]	Loss = 0.70484030 (ave = 0.67689475)

2023-07-06 03:12:55,343 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35180	Time 12.295s / 10iters, (1.230)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.286s / 10iters, (0.829)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007571)
Learning rate = [0.0014892562319970648, 0.0014892562319970648]	Loss = 0.66974324 (ave = 0.70603737)

2023-07-06 03:13:07,528 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35190	Time 12.185s / 10iters, (1.218)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.760s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007469)
Learning rate = [0.001486475751341096, 0.001486475751341096]	Loss = 0.73404276 (ave = 0.67309270)

2023-07-06 03:13:19,830 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35200	Time 12.302s / 10iters, (1.230)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.330s / 10iters, (0.833)	Loss Time 2.795s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007474)
Learning rate = [0.0014836946926822692, 0.0014836946926822692]	Loss = 0.72081864 (ave = 0.69499347)

2023-07-06 03:13:32,022 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35210	Time 12.192s / 10iters, (1.219)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.086s / 10iters, (0.008611)
Learning rate = [0.0014809130546961295, 0.0014809130546961295]	Loss = 0.81002438 (ave = 0.73023978)

2023-07-06 03:13:44,355 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35220	Time 12.333s / 10iters, (1.233)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.320s / 10iters, (0.832)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007535)
Learning rate = [0.001478130836052419, 0.001478130836052419]	Loss = 0.73743057 (ave = 0.70145116)

2023-07-06 03:13:56,586 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35230	Time 12.230s / 10iters, (1.223)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.216s / 10iters, (0.822)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007419)
Learning rate = [0.0014753480354150336, 0.0014753480354150336]	Loss = 0.75410581 (ave = 0.68830202)

2023-07-06 03:14:08,517 INFO    [trainer_contrastive.py, 272] Train Epoch: 94	Train Iteration: 35240	Time 11.932s / 10iters, (1.193)	Forward Time 1.082s / 10iters, (0.108)	Backward Time 8.079s / 10iters, (0.808)	Loss Time 2.697s / 10iters, (0.270)	Data load 0.073s / 10iters, (0.007322)
Learning rate = [0.001472564651441988, 0.001472564651441988]	Loss = 0.67663378 (ave = 0.65914857)

2023-07-06 03:14:23,927 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35250	Time 15.215s / 10iters, (1.522)	Forward Time 1.286s / 10iters, (0.129)	Backward Time 8.278s / 10iters, (0.828)	Loss Time 2.702s / 10iters, (0.270)	Data load 2.949s / 10iters, (0.294922)
Learning rate = [0.001469780682785376, 0.001469780682785376]	Loss = 0.72159576 (ave = 0.65124846)

2023-07-06 03:14:36,076 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35260	Time 12.149s / 10iters, (1.215)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.731s / 10iters, (0.273)	Data load 0.075s / 10iters, (0.007467)
Learning rate = [0.0014669961280913365, 0.0014669961280913365]	Loss = 0.85955119 (ave = 0.70681002)

2023-07-06 03:14:48,304 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35270	Time 12.228s / 10iters, (1.223)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.074s / 10iters, (0.007428)
Learning rate = [0.0014642109860000074, 0.0014642109860000074]	Loss = 0.67770541 (ave = 0.68963651)

2023-07-06 03:15:00,498 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35280	Time 12.194s / 10iters, (1.219)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.745s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007504)
Learning rate = [0.0014614252551454906, 0.0014614252551454906]	Loss = 0.64637780 (ave = 0.65056251)

2023-07-06 03:15:12,670 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35290	Time 12.172s / 10iters, (1.217)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.243s / 10iters, (0.824)	Loss Time 2.737s / 10iters, (0.274)	Data load 0.082s / 10iters, (0.008246)
Learning rate = [0.001458638934155811, 0.001458638934155811]	Loss = 0.79986548 (ave = 0.69897950)

2023-07-06 03:15:24,848 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35300	Time 12.178s / 10iters, (1.218)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.219s / 10iters, (0.822)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007504)
Learning rate = [0.0014558520216528795, 0.0014558520216528795]	Loss = 0.69336945 (ave = 0.70626072)

2023-07-06 03:15:37,024 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35310	Time 12.176s / 10iters, (1.218)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.205s / 10iters, (0.821)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007638)
Learning rate = [0.0014530645162524483, 0.0014530645162524483]	Loss = 0.73245847 (ave = 0.68539725)

2023-07-06 03:15:49,228 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35320	Time 12.204s / 10iters, (1.220)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.224s / 10iters, (0.822)	Loss Time 2.805s / 10iters, (0.280)	Data load 0.078s / 10iters, (0.007779)
Learning rate = [0.0014502764165640716, 0.0014502764165640716]	Loss = 0.75090671 (ave = 0.69490402)

2023-07-06 03:16:01,474 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35330	Time 12.246s / 10iters, (1.225)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.226s / 10iters, (0.823)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007499)
Learning rate = [0.001447487721191065, 0.001447487721191065]	Loss = 0.70106369 (ave = 0.67228426)

2023-07-06 03:16:13,703 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35340	Time 12.229s / 10iters, (1.223)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007558)
Learning rate = [0.0014446984287304677, 0.0014446984287304677]	Loss = 0.61651814 (ave = 0.67768540)

2023-07-06 03:16:25,901 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35350	Time 12.199s / 10iters, (1.220)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007455)
Learning rate = [0.0014419085377729926, 0.0014419085377729926]	Loss = 0.66286778 (ave = 0.67085825)

2023-07-06 03:16:38,014 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35360	Time 12.113s / 10iters, (1.211)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.184s / 10iters, (0.818)	Loss Time 2.755s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007475)
Learning rate = [0.0014391180469029913, 0.0014391180469029913]	Loss = 0.62066782 (ave = 0.66130834)

2023-07-06 03:16:50,478 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35370	Time 12.463s / 10iters, (1.246)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.443s / 10iters, (0.844)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007437)
Learning rate = [0.001436326954698407, 0.001436326954698407]	Loss = 0.68293333 (ave = 0.67633001)

2023-07-06 03:17:02,665 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35380	Time 12.187s / 10iters, (1.219)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.709s / 10iters, (0.271)	Data load 0.074s / 10iters, (0.007403)
Learning rate = [0.0014335352597307377, 0.0014335352597307377]	Loss = 0.66301352 (ave = 0.71795531)

2023-07-06 03:17:14,858 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35390	Time 12.193s / 10iters, (1.219)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.255s / 10iters, (0.825)	Loss Time 2.744s / 10iters, (0.274)	Data load 0.089s / 10iters, (0.008934)
Learning rate = [0.0014307429605649846, 0.0014307429605649846]	Loss = 0.58230412 (ave = 0.67539910)

2023-07-06 03:17:27,236 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35400	Time 12.378s / 10iters, (1.238)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.385s / 10iters, (0.839)	Loss Time 2.805s / 10iters, (0.281)	Data load 0.084s / 10iters, (0.008436)
Learning rate = [0.0014279500557596151, 0.0014279500557596151]	Loss = 0.78716701 (ave = 0.66630295)

2023-07-06 03:17:39,407 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35410	Time 12.171s / 10iters, (1.217)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.749s / 10iters, (0.275)	Data load 0.085s / 10iters, (0.008541)
Learning rate = [0.0014251565438665138, 0.0014251565438665138]	Loss = 0.69542384 (ave = 0.69499484)

2023-07-06 03:17:51,638 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35420	Time 12.231s / 10iters, (1.223)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.752s / 10iters, (0.275)	Data load 0.085s / 10iters, (0.008461)
Learning rate = [0.0014223624234309452, 0.0014223624234309452]	Loss = 0.59683728 (ave = 0.66523720)

2023-07-06 03:18:03,763 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35430	Time 12.125s / 10iters, (1.212)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.077s / 10iters, (0.007741)
Learning rate = [0.0014195676929915002, 0.0014195676929915002]	Loss = 0.79085350 (ave = 0.68498583)

2023-07-06 03:18:15,866 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35440	Time 12.103s / 10iters, (1.210)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.203s / 10iters, (0.820)	Loss Time 2.731s / 10iters, (0.273)	Data load 0.080s / 10iters, (0.008036)
Learning rate = [0.0014167723510800567, 0.0014167723510800567]	Loss = 0.64189696 (ave = 0.67914774)

2023-07-06 03:18:28,106 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35450	Time 12.240s / 10iters, (1.224)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.311s / 10iters, (0.831)	Loss Time 2.735s / 10iters, (0.273)	Data load 0.074s / 10iters, (0.007428)
Learning rate = [0.0014139763962217312, 0.0014139763962217312]	Loss = 0.79366255 (ave = 0.71880093)

2023-07-06 03:18:40,588 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35460	Time 12.482s / 10iters, (1.248)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.460s / 10iters, (0.846)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.085s / 10iters, (0.008539)
Learning rate = [0.0014111798269348362, 0.0014111798269348362]	Loss = 0.67736101 (ave = 0.67346572)

2023-07-06 03:18:52,845 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35470	Time 12.257s / 10iters, (1.226)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.305s / 10iters, (0.830)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.084s / 10iters, (0.008430)
Learning rate = [0.0014083826417308285, 0.0014083826417308285]	Loss = 0.72172463 (ave = 0.71605915)

2023-07-06 03:19:05,027 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35480	Time 12.182s / 10iters, (1.218)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.745s / 10iters, (0.275)	Data load 0.085s / 10iters, (0.008545)
Learning rate = [0.0014055848391142667, 0.0014055848391142667]	Loss = 0.72042966 (ave = 0.72115899)

2023-07-06 03:19:17,134 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35490	Time 12.107s / 10iters, (1.211)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.230s / 10iters, (0.823)	Loss Time 2.690s / 10iters, (0.269)	Data load 0.091s / 10iters, (0.009143)
Learning rate = [0.0014027864175827603, 0.0014027864175827603]	Loss = 0.64331907 (ave = 0.67595032)

2023-07-06 03:19:29,307 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35500	Time 12.173s / 10iters, (1.217)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.085s / 10iters, (0.008478)
Learning rate = [0.0013999873756269283, 0.0013999873756269283]	Loss = 0.76843870 (ave = 0.71164466)

2023-07-06 03:19:41,345 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35510	Time 12.038s / 10iters, (1.204)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.649s / 10iters, (0.265)	Data load 0.089s / 10iters, (0.008933)
Learning rate = [0.0013971877117303425, 0.0013971877117303425]	Loss = 0.74792820 (ave = 0.72035391)

2023-07-06 03:19:53,547 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35520	Time 12.202s / 10iters, (1.220)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.319s / 10iters, (0.832)	Loss Time 2.715s / 10iters, (0.271)	Data load 0.075s / 10iters, (0.007464)
Learning rate = [0.0013943874243694846, 0.0013943874243694846]	Loss = 0.62939465 (ave = 0.66100110)

2023-07-06 03:20:05,679 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35530	Time 12.132s / 10iters, (1.213)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.675s / 10iters, (0.267)	Data load 0.086s / 10iters, (0.008641)
Learning rate = [0.0013915865120136936, 0.0013915865120136936]	Loss = 0.76511782 (ave = 0.67063698)

2023-07-06 03:20:17,806 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35540	Time 12.127s / 10iters, (1.213)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.285s / 10iters, (0.828)	Loss Time 2.659s / 10iters, (0.266)	Data load 0.078s / 10iters, (0.007785)
Learning rate = [0.0013887849731251233, 0.0013887849731251233]	Loss = 0.62990350 (ave = 0.67587687)

2023-07-06 03:20:29,866 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35550	Time 12.060s / 10iters, (1.206)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.663s / 10iters, (0.266)	Data load 0.085s / 10iters, (0.008518)
Learning rate = [0.001385982806158683, 0.001385982806158683]	Loss = 0.68010318 (ave = 0.64688451)

2023-07-06 03:20:41,962 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35560	Time 12.096s / 10iters, (1.210)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.250s / 10iters, (0.825)	Loss Time 2.665s / 10iters, (0.267)	Data load 0.082s / 10iters, (0.008212)
Learning rate = [0.0013831800095619917, 0.0013831800095619917]	Loss = 0.65961897 (ave = 0.68243986)

2023-07-06 03:20:54,062 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35570	Time 12.100s / 10iters, (1.210)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.678s / 10iters, (0.268)	Data load 0.075s / 10iters, (0.007534)
Learning rate = [0.001380376581775327, 0.001380376581775327]	Loss = 0.82441473 (ave = 0.70384179)

2023-07-06 03:21:06,244 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35580	Time 12.182s / 10iters, (1.218)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.705s / 10iters, (0.271)	Data load 0.090s / 10iters, (0.009024)
Learning rate = [0.0013775725212315764, 0.0013775725212315764]	Loss = 0.65216780 (ave = 0.68254601)

2023-07-06 03:21:18,582 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35590	Time 12.338s / 10iters, (1.234)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.396s / 10iters, (0.840)	Loss Time 2.721s / 10iters, (0.272)	Data load 0.094s / 10iters, (0.009390)
Learning rate = [0.0013747678263561797, 0.0013747678263561797]	Loss = 0.57731295 (ave = 0.65682465)

2023-07-06 03:21:30,675 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35600	Time 12.093s / 10iters, (1.209)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.683s / 10iters, (0.268)	Data load 0.077s / 10iters, (0.007729)
Learning rate = [0.00137196249556708, 0.00137196249556708]	Loss = 0.73756361 (ave = 0.68821557)

2023-07-06 03:21:42,787 INFO    [trainer_contrastive.py, 272] Train Epoch: 95	Train Iteration: 35610	Time 12.111s / 10iters, (1.211)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.205s / 10iters, (0.820)	Loss Time 2.732s / 10iters, (0.273)	Data load 0.077s / 10iters, (0.007685)
Learning rate = [0.00136915652727467, 0.00136915652727467]	Loss = 0.63416487 (ave = 0.66096837)

2023-07-06 03:21:58,218 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35620	Time 15.155s / 10iters, (1.515)	Forward Time 1.195s / 10iters, (0.120)	Backward Time 8.191s / 10iters, (0.819)	Loss Time 2.739s / 10iters, (0.274)	Data load 3.029s / 10iters, (0.302939)
Learning rate = [0.0013663499198817428, 0.0013663499198817428]	Loss = 0.62724495 (ave = 0.67576913)

2023-07-06 03:22:10,555 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35630	Time 12.337s / 10iters, (1.234)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.412s / 10iters, (0.841)	Loss Time 2.722s / 10iters, (0.272)	Data load 0.085s / 10iters, (0.008502)
Learning rate = [0.0013635426717834298, 0.0013635426717834298]	Loss = 0.73667288 (ave = 0.65499985)

2023-07-06 03:22:22,832 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35640	Time 12.278s / 10iters, (1.228)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.342s / 10iters, (0.834)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.084s / 10iters, (0.008400)
Learning rate = [0.001360734781367154, 0.001360734781367154]	Loss = 0.69544715 (ave = 0.70302982)

2023-07-06 03:22:35,151 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35650	Time 12.318s / 10iters, (1.232)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.402s / 10iters, (0.840)	Loss Time 2.731s / 10iters, (0.273)	Data load 0.080s / 10iters, (0.007994)
Learning rate = [0.00135792624701257, 0.00135792624701257]	Loss = 0.60094720 (ave = 0.64717811)

2023-07-06 03:22:47,528 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35660	Time 12.377s / 10iters, (1.238)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.441s / 10iters, (0.844)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.088s / 10iters, (0.008831)
Learning rate = [0.0013551170670915147, 0.0013551170670915147]	Loss = 0.64730644 (ave = 0.69184011)

2023-07-06 03:22:59,924 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35670	Time 12.396s / 10iters, (1.240)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.428s / 10iters, (0.843)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.076s / 10iters, (0.007563)
Learning rate = [0.001352307239967944, 0.001352307239967944]	Loss = 0.59931946 (ave = 0.66236272)

2023-07-06 03:23:12,164 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35680	Time 12.241s / 10iters, (1.224)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.083s / 10iters, (0.008321)
Learning rate = [0.0013494967639978814, 0.0013494967639978814]	Loss = 0.85682541 (ave = 0.70939875)

2023-07-06 03:23:24,613 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35690	Time 12.449s / 10iters, (1.245)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.505s / 10iters, (0.851)	Loss Time 2.760s / 10iters, (0.276)	Data load 0.076s / 10iters, (0.007615)
Learning rate = [0.0013466856375293585, 0.0013466856375293585]	Loss = 0.63861156 (ave = 0.65766026)

2023-07-06 03:23:36,871 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35700	Time 12.258s / 10iters, (1.226)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.795s / 10iters, (0.280)	Data load 0.084s / 10iters, (0.008372)
Learning rate = [0.0013438738589023628, 0.0013438738589023628]	Loss = 0.76087302 (ave = 0.69290427)

2023-07-06 03:23:49,206 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35710	Time 12.335s / 10iters, (1.234)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.286s / 10iters, (0.829)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.091s / 10iters, (0.009062)
Learning rate = [0.0013410614264487714, 0.0013410614264487714]	Loss = 0.73454684 (ave = 0.70234086)

2023-07-06 03:24:01,532 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35720	Time 12.326s / 10iters, (1.233)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.865s / 10iters, (0.287)	Data load 0.084s / 10iters, (0.008362)
Learning rate = [0.001338248338492298, 0.001338248338492298]	Loss = 0.66539669 (ave = 0.69510003)

2023-07-06 03:24:14,124 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35730	Time 12.592s / 10iters, (1.259)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.514s / 10iters, (0.851)	Loss Time 2.899s / 10iters, (0.290)	Data load 0.076s / 10iters, (0.007609)
Learning rate = [0.001335434593348432, 0.001335434593348432]	Loss = 0.80219012 (ave = 0.68068967)

2023-07-06 03:24:26,423 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35740	Time 12.298s / 10iters, (1.230)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.873s / 10iters, (0.287)	Data load 0.076s / 10iters, (0.007556)
Learning rate = [0.0013326201893243818, 0.0013326201893243818]	Loss = 0.63990211 (ave = 0.67299052)

2023-07-06 03:24:38,786 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35750	Time 12.364s / 10iters, (1.236)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.332s / 10iters, (0.833)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007492)
Learning rate = [0.0013298051247190093, 0.0013298051247190093]	Loss = 0.66122043 (ave = 0.68124554)

2023-07-06 03:24:51,143 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35760	Time 12.357s / 10iters, (1.236)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.356s / 10iters, (0.836)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.084s / 10iters, (0.008435)
Learning rate = [0.0013269893978227725, 0.0013269893978227725]	Loss = 0.79924428 (ave = 0.65584269)

2023-07-06 03:25:03,430 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35770	Time 12.287s / 10iters, (1.229)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.838s / 10iters, (0.284)	Data load 0.092s / 10iters, (0.009237)
Learning rate = [0.001324173006917662, 0.001324173006917662]	Loss = 0.74299878 (ave = 0.70608757)

2023-07-06 03:25:15,867 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35780	Time 12.437s / 10iters, (1.244)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.358s / 10iters, (0.836)	Loss Time 2.901s / 10iters, (0.290)	Data load 0.074s / 10iters, (0.007372)
Learning rate = [0.0013213559502771445, 0.0013213559502771445]	Loss = 0.68836606 (ave = 0.65845139)

2023-07-06 03:25:28,156 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35790	Time 12.289s / 10iters, (1.229)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.865s / 10iters, (0.287)	Data load 0.076s / 10iters, (0.007643)
Learning rate = [0.0013185382261660915, 0.0013185382261660915]	Loss = 0.60470605 (ave = 0.65965554)

2023-07-06 03:25:40,575 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35800	Time 12.419s / 10iters, (1.242)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.904s / 10iters, (0.290)	Data load 0.074s / 10iters, (0.007439)
Learning rate = [0.001315719832840722, 0.001315719832840722]	Loss = 0.62925196 (ave = 0.68390816)

2023-07-06 03:25:52,949 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35810	Time 12.374s / 10iters, (1.237)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.895s / 10iters, (0.289)	Data load 0.086s / 10iters, (0.008574)
Learning rate = [0.0013129007685485363, 0.0013129007685485363]	Loss = 0.68464983 (ave = 0.67237490)

2023-07-06 03:26:05,315 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35820	Time 12.366s / 10iters, (1.237)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.342s / 10iters, (0.834)	Loss Time 2.838s / 10iters, (0.284)	Data load 0.079s / 10iters, (0.007914)
Learning rate = [0.0013100810315282555, 0.0013100810315282555]	Loss = 0.73021454 (ave = 0.69144699)

2023-07-06 03:26:17,695 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35830	Time 12.380s / 10iters, (1.238)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.314s / 10iters, (0.831)	Loss Time 2.879s / 10iters, (0.288)	Data load 0.085s / 10iters, (0.008472)
Learning rate = [0.0013072606200097495, 0.0013072606200097495]	Loss = 0.76244467 (ave = 0.69556069)

2023-07-06 03:26:30,033 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35840	Time 12.338s / 10iters, (1.234)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.292s / 10iters, (0.829)	Loss Time 2.862s / 10iters, (0.286)	Data load 0.091s / 10iters, (0.009061)
Learning rate = [0.0013044395322139764, 0.0013044395322139764]	Loss = 0.78962100 (ave = 0.66262380)

2023-07-06 03:26:42,306 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35850	Time 12.273s / 10iters, (1.227)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.873s / 10iters, (0.287)	Data load 0.076s / 10iters, (0.007626)
Learning rate = [0.0013016177663529133, 0.0013016177663529133]	Loss = 0.57524818 (ave = 0.65242147)

2023-07-06 03:26:54,585 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35860	Time 12.279s / 10iters, (1.228)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.239s / 10iters, (0.824)	Loss Time 2.850s / 10iters, (0.285)	Data load 0.094s / 10iters, (0.009447)
Learning rate = [0.0012987953206294942, 0.0012987953206294942]	Loss = 0.72493708 (ave = 0.66429595)

2023-07-06 03:27:06,882 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35870	Time 12.297s / 10iters, (1.230)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.076s / 10iters, (0.007611)
Learning rate = [0.0012959721932375348, 0.0012959721932375348]	Loss = 0.63819242 (ave = 0.67768909)

2023-07-06 03:27:19,261 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35880	Time 12.379s / 10iters, (1.238)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.881s / 10iters, (0.288)	Data load 0.084s / 10iters, (0.008447)
Learning rate = [0.0012931483823616697, 0.0012931483823616697]	Loss = 0.65261340 (ave = 0.68408483)

2023-07-06 03:27:31,579 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35890	Time 12.318s / 10iters, (1.232)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.878s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007548)
Learning rate = [0.0012903238861772795, 0.0012903238861772795]	Loss = 0.69675589 (ave = 0.71289576)

2023-07-06 03:27:43,933 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35900	Time 12.354s / 10iters, (1.235)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.325s / 10iters, (0.833)	Loss Time 2.833s / 10iters, (0.283)	Data load 0.082s / 10iters, (0.008196)
Learning rate = [0.001287498702850427, 0.001287498702850427]	Loss = 0.58097899 (ave = 0.65309536)

2023-07-06 03:27:56,218 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35910	Time 12.285s / 10iters, (1.228)	Forward Time 1.139s / 10iters, (0.114)	Backward Time 8.250s / 10iters, (0.825)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.085s / 10iters, (0.008491)
Learning rate = [0.0012846728305377798, 0.0012846728305377798]	Loss = 0.74964750 (ave = 0.65113904)

2023-07-06 03:28:08,408 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35920	Time 12.190s / 10iters, (1.219)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.223s / 10iters, (0.822)	Loss Time 2.785s / 10iters, (0.279)	Data load 0.079s / 10iters, (0.007948)
Learning rate = [0.0012818462673865418, 0.0012818462673865418]	Loss = 0.73959839 (ave = 0.70648465)

2023-07-06 03:28:20,819 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35930	Time 12.411s / 10iters, (1.241)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.399s / 10iters, (0.840)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007567)
Learning rate = [0.001279019011534382, 0.001279019011534382]	Loss = 0.66130185 (ave = 0.72143636)

2023-07-06 03:28:33,170 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35940	Time 12.351s / 10iters, (1.235)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.356s / 10iters, (0.836)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.081s / 10iters, (0.008071)
Learning rate = [0.0012761910611093642, 0.0012761910611093642]	Loss = 0.69597936 (ave = 0.66375731)

2023-07-06 03:28:45,491 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35950	Time 12.321s / 10iters, (1.232)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.329s / 10iters, (0.833)	Loss Time 2.804s / 10iters, (0.280)	Data load 0.079s / 10iters, (0.007922)
Learning rate = [0.0012733624142298673, 0.0012733624142298673]	Loss = 0.72406590 (ave = 0.67917293)

2023-07-06 03:28:57,777 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35960	Time 12.286s / 10iters, (1.229)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.324s / 10iters, (0.832)	Loss Time 2.792s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007452)
Learning rate = [0.0012705330690045164, 0.0012705330690045164]	Loss = 0.60169417 (ave = 0.66364115)

2023-07-06 03:29:09,982 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35970	Time 12.205s / 10iters, (1.221)	Forward Time 1.150s / 10iters, (0.115)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.746s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007497)
Learning rate = [0.0012677030235321047, 0.0012677030235321047]	Loss = 0.73086333 (ave = 0.69806545)

2023-07-06 03:29:22,269 INFO    [trainer_contrastive.py, 272] Train Epoch: 96	Train Iteration: 35980	Time 12.287s / 10iters, (1.229)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007399)
Learning rate = [0.0012648722759015239, 0.0012648722759015239]	Loss = 0.73446608 (ave = 0.71787750)

2023-07-06 03:29:37,790 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 35990	Time 15.270s / 10iters, (1.527)	Forward Time 1.163s / 10iters, (0.116)	Backward Time 8.288s / 10iters, (0.829)	Loss Time 2.731s / 10iters, (0.273)	Data load 3.087s / 10iters, (0.308729)
Learning rate = [0.0012620408241916792, 0.0012620408241916792]	Loss = 0.51507127 (ave = 0.71176199)

2023-07-06 03:29:50,148 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36000	Time 12.358s / 10iters, (1.236)	Forward Time 1.141s / 10iters, (0.114)	Backward Time 8.412s / 10iters, (0.841)	Loss Time 2.705s / 10iters, (0.270)	Data load 0.100s / 10iters, (0.009987)
Learning rate = [0.0012592086664714181, 0.0012592086664714181]	Loss = 0.76429754 (ave = 0.67826529)

2023-07-06 03:29:54,902 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-06 03:30:17,980 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-06 03:30:40,918 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-06 03:31:03,788 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-06 03:31:26,909 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-06 03:31:49,690 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-06 03:32:12,699 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-06 03:32:21,232 INFO    [trainer_contrastive.py, 391] Test Time 148.121s, (2.351)	Loss 0.12185003

2023-07-06 03:32:21,232 INFO    [base.py, 33] Result for seg
2023-07-06 03:32:21,233 INFO    [base.py, 49] Mean IOU: 0.7556377841184065

2023-07-06 03:32:21,233 INFO    [base.py, 50] Pixel ACC: 0.9610134839931237

2023-07-06 03:32:33,272 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36010	Time 163.124s / 10iters, (16.312)	Forward Time 1.182s / 10iters, (0.118)	Backward Time 8.090s / 10iters, (0.809)	Loss Time 2.657s / 10iters, (0.266)	Data load 151.194s / 10iters, (15.119433)
Learning rate = [0.0012563758007994492, 0.0012563758007994492]	Loss = 0.64831042 (ave = 0.68788803)

2023-07-06 03:32:45,274 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36020	Time 12.001s / 10iters, (1.200)	Forward Time 1.194s / 10iters, (0.119)	Backward Time 8.174s / 10iters, (0.817)	Loss Time 2.544s / 10iters, (0.254)	Data load 0.089s / 10iters, (0.008938)
Learning rate = [0.0012535422252242688, 0.0012535422252242688]	Loss = 0.68188757 (ave = 0.65827262)

2023-07-06 03:32:57,369 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36030	Time 12.095s / 10iters, (1.210)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.227s / 10iters, (0.823)	Loss Time 2.691s / 10iters, (0.269)	Data load 0.077s / 10iters, (0.007709)
Learning rate = [0.001250707937784074, 0.001250707937784074]	Loss = 0.89095426 (ave = 0.68898530)

2023-07-06 03:33:09,637 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36040	Time 12.268s / 10iters, (1.227)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.353s / 10iters, (0.835)	Loss Time 2.715s / 10iters, (0.271)	Data load 0.092s / 10iters, (0.009194)
Learning rate = [0.001247872936506687, 0.001247872936506687]	Loss = 0.61255592 (ave = 0.64204731)

2023-07-06 03:33:21,792 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36050	Time 12.155s / 10iters, (1.216)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.722s / 10iters, (0.272)	Data load 0.088s / 10iters, (0.008775)
Learning rate = [0.0012450372194094722, 0.0012450372194094722]	Loss = 0.67065895 (ave = 0.65701536)

2023-07-06 03:33:33,878 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36060	Time 12.086s / 10iters, (1.209)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.227s / 10iters, (0.823)	Loss Time 2.648s / 10iters, (0.265)	Data load 0.087s / 10iters, (0.008693)
Learning rate = [0.0012422007844992572, 0.0012422007844992572]	Loss = 0.62727386 (ave = 0.65056465)

2023-07-06 03:33:46,163 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36070	Time 12.284s / 10iters, (1.228)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.412s / 10iters, (0.841)	Loss Time 2.708s / 10iters, (0.271)	Data load 0.077s / 10iters, (0.007718)
Learning rate = [0.0012393636297722442, 0.0012393636297722442]	Loss = 0.60009772 (ave = 0.67964965)

2023-07-06 03:33:58,435 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36080	Time 12.273s / 10iters, (1.227)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.344s / 10iters, (0.834)	Loss Time 2.730s / 10iters, (0.273)	Data load 0.098s / 10iters, (0.009793)
Learning rate = [0.0012365257532139314, 0.0012365257532139314]	Loss = 0.62261552 (ave = 0.69863384)

2023-07-06 03:34:10,675 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36090	Time 12.239s / 10iters, (1.224)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.787s / 10iters, (0.279)	Data load 0.078s / 10iters, (0.007846)
Learning rate = [0.001233687152799024, 0.001233687152799024]	Loss = 0.72865760 (ave = 0.70257261)

2023-07-06 03:34:22,917 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36100	Time 12.242s / 10iters, (1.224)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.300s / 10iters, (0.830)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.080s / 10iters, (0.008003)
Learning rate = [0.0012308478264913556, 0.0012308478264913556]	Loss = 0.76022124 (ave = 0.67637936)

2023-07-06 03:34:35,176 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36110	Time 12.259s / 10iters, (1.226)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.270s / 10iters, (0.827)	Loss Time 2.795s / 10iters, (0.279)	Data load 0.095s / 10iters, (0.009496)
Learning rate = [0.0012280077722437927, 0.0012280077722437927]	Loss = 0.62631154 (ave = 0.69564054)

2023-07-06 03:34:47,509 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36120	Time 12.332s / 10iters, (1.233)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.312s / 10iters, (0.831)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.078s / 10iters, (0.007773)
Learning rate = [0.001225166987998154, 0.001225166987998154]	Loss = 0.64321995 (ave = 0.67802739)

2023-07-06 03:34:59,860 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36130	Time 12.351s / 10iters, (1.235)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.270s / 10iters, (0.827)	Loss Time 2.905s / 10iters, (0.291)	Data load 0.077s / 10iters, (0.007695)
Learning rate = [0.001222325471685119, 0.001222325471685119]	Loss = 0.68656927 (ave = 0.66848685)

2023-07-06 03:35:12,168 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36140	Time 12.308s / 10iters, (1.231)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.233s / 10iters, (0.823)	Loss Time 2.878s / 10iters, (0.288)	Data load 0.093s / 10iters, (0.009327)
Learning rate = [0.0012194832212241388, 0.0012194832212241388]	Loss = 0.59902745 (ave = 0.65444469)

2023-07-06 03:35:24,419 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36150	Time 12.251s / 10iters, (1.225)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.264s / 10iters, (0.826)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.081s / 10iters, (0.008149)
Learning rate = [0.001216640234523351, 0.001216640234523351]	Loss = 0.68417573 (ave = 0.64919477)

2023-07-06 03:35:36,706 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36160	Time 12.287s / 10iters, (1.229)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.352s / 10iters, (0.835)	Loss Time 2.752s / 10iters, (0.275)	Data load 0.085s / 10iters, (0.008547)
Learning rate = [0.0012137965094794806, 0.0012137965094794806]	Loss = 0.71413898 (ave = 0.69189646)

2023-07-06 03:35:49,005 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36170	Time 12.299s / 10iters, (1.230)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.351s / 10iters, (0.835)	Loss Time 2.745s / 10iters, (0.275)	Data load 0.083s / 10iters, (0.008253)
Learning rate = [0.0012109520439777528, 0.0012109520439777528]	Loss = 0.67644024 (ave = 0.67446111)

2023-07-06 03:36:01,340 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36180	Time 12.335s / 10iters, (1.234)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.392s / 10iters, (0.839)	Loss Time 2.763s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007478)
Learning rate = [0.0012081068358917976, 0.0012081068358917976]	Loss = 0.63913858 (ave = 0.65781655)

2023-07-06 03:36:13,591 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36190	Time 12.251s / 10iters, (1.225)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.322s / 10iters, (0.832)	Loss Time 2.760s / 10iters, (0.276)	Data load 0.077s / 10iters, (0.007665)
Learning rate = [0.0012052608830835615, 0.0012052608830835615]	Loss = 0.64673328 (ave = 0.70211138)

2023-07-06 03:36:25,884 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36200	Time 12.293s / 10iters, (1.229)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.316s / 10iters, (0.832)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.084s / 10iters, (0.008399)
Learning rate = [0.0012024141834032027, 0.0012024141834032027]	Loss = 0.59404278 (ave = 0.66922486)

2023-07-06 03:36:38,208 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36210	Time 12.324s / 10iters, (1.232)	Forward Time 1.144s / 10iters, (0.114)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.094s / 10iters, (0.009413)
Learning rate = [0.0011995667346890032, 0.0011995667346890032]	Loss = 0.67553967 (ave = 0.68791648)

2023-07-06 03:36:50,559 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36220	Time 12.351s / 10iters, (1.235)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.324s / 10iters, (0.832)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007505)
Learning rate = [0.0011967185347672663, 0.0011967185347672663]	Loss = 0.65532881 (ave = 0.66805639)

2023-07-06 03:37:02,932 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36230	Time 12.373s / 10iters, (1.237)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.317s / 10iters, (0.832)	Loss Time 2.884s / 10iters, (0.288)	Data load 0.079s / 10iters, (0.007921)
Learning rate = [0.001193869581452225, 0.001193869581452225]	Loss = 0.62938553 (ave = 0.64443824)

2023-07-06 03:37:15,278 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36240	Time 12.346s / 10iters, (1.235)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.282s / 10iters, (0.828)	Loss Time 2.872s / 10iters, (0.287)	Data load 0.082s / 10iters, (0.008151)
Learning rate = [0.0011910198725459348, 0.0011910198725459348]	Loss = 0.67135924 (ave = 0.66703252)

2023-07-06 03:37:27,641 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36250	Time 12.363s / 10iters, (1.236)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.305s / 10iters, (0.830)	Loss Time 2.870s / 10iters, (0.287)	Data load 0.090s / 10iters, (0.008989)
Learning rate = [0.0011881694058381777, 0.0011881694058381777]	Loss = 0.68678927 (ave = 0.71007419)

2023-07-06 03:37:39,908 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36260	Time 12.267s / 10iters, (1.227)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.083s / 10iters, (0.008266)
Learning rate = [0.0011853181791063594, 0.0011853181791063594]	Loss = 0.71378344 (ave = 0.70152401)

2023-07-06 03:37:52,188 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36270	Time 12.281s / 10iters, (1.228)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.835s / 10iters, (0.283)	Data load 0.093s / 10iters, (0.009332)
Learning rate = [0.0011824661901154111, 0.0011824661901154111]	Loss = 0.68817443 (ave = 0.70327191)

2023-07-06 03:38:04,539 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36280	Time 12.351s / 10iters, (1.235)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.378s / 10iters, (0.838)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007466)
Learning rate = [0.0011796134366176784, 0.0011796134366176784]	Loss = 0.60906851 (ave = 0.66887332)

2023-07-06 03:38:16,865 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36290	Time 12.326s / 10iters, (1.233)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.350s / 10iters, (0.835)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007639)
Learning rate = [0.001176759916352821, 0.001176759916352821]	Loss = 0.66906995 (ave = 0.68742145)

2023-07-06 03:38:29,106 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36300	Time 12.240s / 10iters, (1.224)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.085s / 10iters, (0.008472)
Learning rate = [0.0011739056270477053, 0.0011739056270477053]	Loss = 0.63623238 (ave = 0.63025064)

2023-07-06 03:38:41,381 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36310	Time 12.276s / 10iters, (1.228)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.275s / 10iters, (0.827)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007616)
Learning rate = [0.001171050566416301, 0.001171050566416301]	Loss = 0.74451083 (ave = 0.68245958)

2023-07-06 03:38:53,717 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36320	Time 12.335s / 10iters, (1.234)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.325s / 10iters, (0.833)	Loss Time 2.800s / 10iters, (0.280)	Data load 0.088s / 10iters, (0.008757)
Learning rate = [0.0011681947321595665, 0.0011681947321595665]	Loss = 0.61919844 (ave = 0.69473911)

2023-07-06 03:39:05,988 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36330	Time 12.271s / 10iters, (1.227)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.297s / 10iters, (0.830)	Loss Time 2.781s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007486)
Learning rate = [0.0011653381219653431, 0.0011653381219653431]	Loss = 0.62039697 (ave = 0.66898156)

2023-07-06 03:39:18,271 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36340	Time 12.283s / 10iters, (1.228)	Forward Time 1.130s / 10iters, (0.113)	Backward Time 8.307s / 10iters, (0.831)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.084s / 10iters, (0.008417)
Learning rate = [0.0011624807335082422, 0.0011624807335082422]	Loss = 0.72032231 (ave = 0.65376438)

2023-07-06 03:39:30,263 INFO    [trainer_contrastive.py, 272] Train Epoch: 97	Train Iteration: 36350	Time 11.992s / 10iters, (1.199)	Forward Time 1.079s / 10iters, (0.108)	Backward Time 8.119s / 10iters, (0.812)	Loss Time 2.720s / 10iters, (0.272)	Data load 0.074s / 10iters, (0.007376)
Learning rate = [0.0011596225644495387, 0.0011596225644495387]	Loss = 0.67745036 (ave = 0.65626814)

2023-07-06 03:39:45,572 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36360	Time 15.092s / 10iters, (1.509)	Forward Time 1.228s / 10iters, (0.123)	Backward Time 8.210s / 10iters, (0.821)	Loss Time 2.705s / 10iters, (0.270)	Data load 2.949s / 10iters, (0.294903)
Learning rate = [0.00115676361243705, 0.00115676361243705]	Loss = 0.67084134 (ave = 0.68843158)

2023-07-06 03:39:57,670 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36370	Time 12.098s / 10iters, (1.210)	Forward Time 1.145s / 10iters, (0.115)	Backward Time 8.250s / 10iters, (0.825)	Loss Time 2.618s / 10iters, (0.262)	Data load 0.085s / 10iters, (0.008493)
Learning rate = [0.0011539038751050255, 0.0011539038751050255]	Loss = 0.64221138 (ave = 0.65319943)

2023-07-06 03:40:09,896 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36380	Time 12.225s / 10iters, (1.223)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.372s / 10iters, (0.837)	Loss Time 2.678s / 10iters, (0.268)	Data load 0.083s / 10iters, (0.008261)
Learning rate = [0.00115104335007403, 0.00115104335007403]	Loss = 0.68986416 (ave = 0.69684741)

2023-07-06 03:40:21,959 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36390	Time 12.063s / 10iters, (1.206)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.220s / 10iters, (0.822)	Loss Time 2.647s / 10iters, (0.265)	Data load 0.080s / 10iters, (0.007960)
Learning rate = [0.0011481820349508298, 0.0011481820349508298]	Loss = 0.66046858 (ave = 0.63673144)

2023-07-06 03:40:34,198 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36400	Time 12.239s / 10iters, (1.224)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.361s / 10iters, (0.836)	Loss Time 2.702s / 10iters, (0.270)	Data load 0.076s / 10iters, (0.007650)
Learning rate = [0.001145319927328268, 0.001145319927328268]	Loss = 0.84943420 (ave = 0.69300223)

2023-07-06 03:40:46,478 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36410	Time 12.279s / 10iters, (1.228)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.340s / 10iters, (0.834)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.078s / 10iters, (0.007772)
Learning rate = [0.0011424570247851487, 0.0011424570247851487]	Loss = 0.68216825 (ave = 0.65792359)

2023-07-06 03:40:58,765 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36420	Time 12.287s / 10iters, (1.229)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.359s / 10iters, (0.836)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.081s / 10iters, (0.008140)
Learning rate = [0.0011395933248861136, 0.0011395933248861136]	Loss = 0.60527337 (ave = 0.67679198)

2023-07-06 03:41:10,967 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36430	Time 12.202s / 10iters, (1.220)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.256s / 10iters, (0.826)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.082s / 10iters, (0.008204)
Learning rate = [0.0011367288251815252, 0.0011367288251815252]	Loss = 0.67452615 (ave = 0.68656097)

2023-07-06 03:41:23,232 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36440	Time 12.265s / 10iters, (1.227)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007565)
Learning rate = [0.0011338635232073335, 0.0011338635232073335]	Loss = 0.73950547 (ave = 0.67617015)

2023-07-06 03:41:35,553 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36450	Time 12.321s / 10iters, (1.232)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.299s / 10iters, (0.830)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.080s / 10iters, (0.007983)
Learning rate = [0.0011309974164849578, 0.0011309974164849578]	Loss = 0.63020915 (ave = 0.65124449)

2023-07-06 03:41:47,908 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36460	Time 12.355s / 10iters, (1.236)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.305s / 10iters, (0.831)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.097s / 10iters, (0.009736)
Learning rate = [0.001128130502521155, 0.001128130502521155]	Loss = 0.76998645 (ave = 0.69385756)

2023-07-06 03:42:00,366 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36470	Time 12.458s / 10iters, (1.246)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.384s / 10iters, (0.838)	Loss Time 2.864s / 10iters, (0.286)	Data load 0.097s / 10iters, (0.009711)
Learning rate = [0.0011252627788078983, 0.0011252627788078983]	Loss = 0.55581915 (ave = 0.72037756)

2023-07-06 03:42:12,944 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36480	Time 12.578s / 10iters, (1.258)	Forward Time 1.125s / 10iters, (0.112)	Backward Time 8.504s / 10iters, (0.850)	Loss Time 2.873s / 10iters, (0.287)	Data load 0.076s / 10iters, (0.007613)
Learning rate = [0.0011223942428222383, 0.0011223942428222383]	Loss = 0.70088661 (ave = 0.65791335)

2023-07-06 03:42:25,286 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36490	Time 12.341s / 10iters, (1.234)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.279s / 10iters, (0.828)	Loss Time 2.873s / 10iters, (0.287)	Data load 0.085s / 10iters, (0.008474)
Learning rate = [0.0011195248920261773, 0.0011195248920261773]	Loss = 0.65078199 (ave = 0.66327683)

2023-07-06 03:42:37,727 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36500	Time 12.442s / 10iters, (1.244)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.342s / 10iters, (0.834)	Loss Time 2.911s / 10iters, (0.291)	Data load 0.076s / 10iters, (0.007589)
Learning rate = [0.0011166547238665343, 0.0011166547238665343]	Loss = 0.66923654 (ave = 0.65918130)

2023-07-06 03:42:49,970 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36510	Time 12.243s / 10iters, (1.224)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.215s / 10iters, (0.822)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.077s / 10iters, (0.007731)
Learning rate = [0.0011137837357748147, 0.0011137837357748147]	Loss = 0.64967269 (ave = 0.69346586)

2023-07-06 03:43:02,448 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36520	Time 12.478s / 10iters, (1.248)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.377s / 10iters, (0.838)	Loss Time 2.879s / 10iters, (0.288)	Data load 0.089s / 10iters, (0.008890)
Learning rate = [0.0011109119251670673, 0.0011109119251670673]	Loss = 0.66088563 (ave = 0.70649436)

2023-07-06 03:43:14,738 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36530	Time 12.290s / 10iters, (1.229)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.255s / 10iters, (0.826)	Loss Time 2.862s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007495)
Learning rate = [0.0011080392894437512, 0.0011080392894437512]	Loss = 0.60382867 (ave = 0.66668306)

2023-07-06 03:43:26,916 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36540	Time 12.178s / 10iters, (1.218)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.084s / 10iters, (0.008359)
Learning rate = [0.001105165825989595, 0.001105165825989595]	Loss = 0.69583338 (ave = 0.71085024)

2023-07-06 03:43:39,150 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36550	Time 12.234s / 10iters, (1.223)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.077s / 10iters, (0.007686)
Learning rate = [0.0011022915321734596, 0.0011022915321734596]	Loss = 0.60465699 (ave = 0.66131826)

2023-07-06 03:43:51,508 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36560	Time 12.358s / 10iters, (1.236)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.367s / 10iters, (0.837)	Loss Time 2.796s / 10iters, (0.280)	Data load 0.077s / 10iters, (0.007667)
Learning rate = [0.0010994164053481895, 0.0010994164053481895]	Loss = 0.67743409 (ave = 0.65607064)

2023-07-06 03:44:03,783 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36570	Time 12.275s / 10iters, (1.227)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.326s / 10iters, (0.833)	Loss Time 2.758s / 10iters, (0.276)	Data load 0.084s / 10iters, (0.008410)
Learning rate = [0.0010965404428504718, 0.0010965404428504718]	Loss = 0.84948713 (ave = 0.68138067)

2023-07-06 03:44:16,185 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36580	Time 12.402s / 10iters, (1.240)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.442s / 10iters, (0.844)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007617)
Learning rate = [0.0010936636420006897, 0.0010936636420006897]	Loss = 0.60059106 (ave = 0.66653541)

2023-07-06 03:44:28,560 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36590	Time 12.375s / 10iters, (1.238)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.415s / 10iters, (0.842)	Loss Time 2.785s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007494)
Learning rate = [0.0010907860001027779, 0.0010907860001027779]	Loss = 0.56127512 (ave = 0.68245835)

2023-07-06 03:44:40,810 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36600	Time 12.250s / 10iters, (1.225)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.288s / 10iters, (0.829)	Loss Time 2.763s / 10iters, (0.276)	Data load 0.096s / 10iters, (0.009634)
Learning rate = [0.0010879075144440667, 0.0010879075144440667]	Loss = 0.60085815 (ave = 0.63824636)

2023-07-06 03:44:53,196 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36610	Time 12.386s / 10iters, (1.239)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.418s / 10iters, (0.842)	Loss Time 2.779s / 10iters, (0.278)	Data load 0.077s / 10iters, (0.007707)
Learning rate = [0.0010850281822951354, 0.0010850281822951354]	Loss = 0.65887398 (ave = 0.65206107)

2023-07-06 03:45:05,605 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36620	Time 12.409s / 10iters, (1.241)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.389s / 10iters, (0.839)	Loss Time 2.827s / 10iters, (0.283)	Data load 0.084s / 10iters, (0.008351)
Learning rate = [0.0010821480009096565, 0.0010821480009096565]	Loss = 0.60407430 (ave = 0.66767610)

2023-07-06 03:45:17,911 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36630	Time 12.306s / 10iters, (1.231)	Forward Time 1.129s / 10iters, (0.113)	Backward Time 8.303s / 10iters, (0.830)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.076s / 10iters, (0.007564)
Learning rate = [0.0010792669675242453, 0.0010792669675242453]	Loss = 0.62766290 (ave = 0.64923289)

2023-07-06 03:45:30,258 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36640	Time 12.346s / 10iters, (1.235)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.360s / 10iters, (0.836)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.077s / 10iters, (0.007733)
Learning rate = [0.0010763850793582966, 0.0010763850793582966]	Loss = 0.72615945 (ave = 0.69156829)

2023-07-06 03:45:42,555 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36650	Time 12.297s / 10iters, (1.230)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.313s / 10iters, (0.831)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007503)
Learning rate = [0.0010735023336138302, 0.0010735023336138302]	Loss = 0.60324115 (ave = 0.66196179)

2023-07-06 03:45:54,929 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36660	Time 12.374s / 10iters, (1.237)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.105s / 10iters, (0.010524)
Learning rate = [0.0010706187274753267, 0.0010706187274753267]	Loss = 0.76551932 (ave = 0.70385983)

2023-07-06 03:46:07,351 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36670	Time 12.422s / 10iters, (1.242)	Forward Time 1.137s / 10iters, (0.114)	Backward Time 8.354s / 10iters, (0.835)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.081s / 10iters, (0.008122)
Learning rate = [0.0010677342581095713, 0.0010677342581095713]	Loss = 0.64220715 (ave = 0.65358596)

2023-07-06 03:46:19,866 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36680	Time 12.515s / 10iters, (1.252)	Forward Time 1.156s / 10iters, (0.116)	Backward Time 8.417s / 10iters, (0.842)	Loss Time 2.865s / 10iters, (0.287)	Data load 0.077s / 10iters, (0.007704)
Learning rate = [0.0010648489226654813, 0.0010648489226654813]	Loss = 0.66221666 (ave = 0.68315623)

2023-07-06 03:46:32,264 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36690	Time 12.398s / 10iters, (1.240)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.370s / 10iters, (0.837)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007640)
Learning rate = [0.0010619627182739432, 0.0010619627182739432]	Loss = 0.70621175 (ave = 0.70868969)

2023-07-06 03:46:44,630 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36700	Time 12.366s / 10iters, (1.237)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.386s / 10iters, (0.839)	Loss Time 2.803s / 10iters, (0.280)	Data load 0.081s / 10iters, (0.008099)
Learning rate = [0.0010590756420476425, 0.0010590756420476425]	Loss = 0.66129601 (ave = 0.70535845)

2023-07-06 03:46:56,847 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36710	Time 12.216s / 10iters, (1.222)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.278s / 10iters, (0.828)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.085s / 10iters, (0.008452)
Learning rate = [0.001056187691080897, 0.001056187691080897]	Loss = 0.56945342 (ave = 0.64749256)

2023-07-06 03:47:08,863 INFO    [trainer_contrastive.py, 272] Train Epoch: 98	Train Iteration: 36720	Time 12.017s / 10iters, (1.202)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.115s / 10iters, (0.812)	Loss Time 2.721s / 10iters, (0.272)	Data load 0.075s / 10iters, (0.007474)
Learning rate = [0.0010532988624494773, 0.0010532988624494773]	Loss = 0.75440842 (ave = 0.65154814)

2023-07-06 03:47:23,803 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36730	Time 14.746s / 10iters, (1.475)	Forward Time 1.157s / 10iters, (0.116)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.765s / 10iters, (0.276)	Data load 2.591s / 10iters, (0.259110)
Learning rate = [0.0010504091532104348, 0.0010504091532104348]	Loss = 0.70944476 (ave = 0.70250233)

2023-07-06 03:47:36,049 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36740	Time 12.247s / 10iters, (1.225)	Forward Time 1.128s / 10iters, (0.113)	Backward Time 8.268s / 10iters, (0.827)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.112s / 10iters, (0.011151)
Learning rate = [0.0010475185604019233, 0.0010475185604019233]	Loss = 0.76222408 (ave = 0.65338501)

2023-07-06 03:47:48,331 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36750	Time 12.281s / 10iters, (1.228)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.077s / 10iters, (0.007691)
Learning rate = [0.0010446270810430243, 0.0010446270810430243]	Loss = 0.70376354 (ave = 0.63757818)

2023-07-06 03:48:00,508 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36760	Time 12.178s / 10iters, (1.218)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.173s / 10iters, (0.817)	Loss Time 2.815s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007540)
Learning rate = [0.0010417347121335562, 0.0010417347121335562]	Loss = 0.76550287 (ave = 0.67172799)

2023-07-06 03:48:12,996 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36770	Time 12.488s / 10iters, (1.249)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.454s / 10iters, (0.845)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.077s / 10iters, (0.007703)
Learning rate = [0.0010388414506538963, 0.0010388414506538963]	Loss = 0.72216517 (ave = 0.67346384)

2023-07-06 03:48:25,325 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36780	Time 12.329s / 10iters, (1.233)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.334s / 10iters, (0.833)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.083s / 10iters, (0.008312)
Learning rate = [0.0010359472935647918, 0.0010359472935647918]	Loss = 0.73334289 (ave = 0.65486907)

2023-07-06 03:48:37,744 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36790	Time 12.419s / 10iters, (1.242)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.425s / 10iters, (0.843)	Loss Time 2.810s / 10iters, (0.281)	Data load 0.088s / 10iters, (0.008753)
Learning rate = [0.0010330522378071746, 0.0010330522378071746]	Loss = 0.79028827 (ave = 0.65963712)

2023-07-06 03:48:50,019 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36800	Time 12.276s / 10iters, (1.228)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.347s / 10iters, (0.835)	Loss Time 2.745s / 10iters, (0.274)	Data load 0.078s / 10iters, (0.007848)
Learning rate = [0.0010301562803019643, 0.0010301562803019643]	Loss = 0.66518366 (ave = 0.66106244)

2023-07-06 03:49:02,371 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36810	Time 12.352s / 10iters, (1.235)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.430s / 10iters, (0.843)	Loss Time 2.721s / 10iters, (0.272)	Data load 0.084s / 10iters, (0.008369)
Learning rate = [0.0010272594179498772, 0.0010272594179498772]	Loss = 0.56119931 (ave = 0.67230908)

2023-07-06 03:49:14,622 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36820	Time 12.251s / 10iters, (1.225)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.334s / 10iters, (0.833)	Loss Time 2.700s / 10iters, (0.270)	Data load 0.090s / 10iters, (0.008989)
Learning rate = [0.0010243616476312294, 0.0010243616476312294]	Loss = 0.69054580 (ave = 0.70633776)

2023-07-06 03:49:27,105 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36830	Time 12.483s / 10iters, (1.248)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.507s / 10iters, (0.851)	Loss Time 2.749s / 10iters, (0.275)	Data load 0.112s / 10iters, (0.011218)
Learning rate = [0.001021462966205742, 0.001021462966205742]	Loss = 0.61021918 (ave = 0.65840744)

2023-07-06 03:49:39,212 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36840	Time 12.108s / 10iters, (1.211)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.245s / 10iters, (0.824)	Loss Time 2.661s / 10iters, (0.266)	Data load 0.075s / 10iters, (0.007519)
Learning rate = [0.0010185633705123325, 0.0010185633705123325]	Loss = 0.64163387 (ave = 0.65827948)

2023-07-06 03:49:51,507 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36850	Time 12.295s / 10iters, (1.230)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.436s / 10iters, (0.844)	Loss Time 2.673s / 10iters, (0.267)	Data load 0.077s / 10iters, (0.007666)
Learning rate = [0.0010156628573689157, 0.0010156628573689157]	Loss = 0.61965740 (ave = 0.64012045)

2023-07-06 03:50:03,850 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36860	Time 12.342s / 10iters, (1.234)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.426s / 10iters, (0.843)	Loss Time 2.732s / 10iters, (0.273)	Data load 0.075s / 10iters, (0.007500)
Learning rate = [0.0010127614235721943, 0.0010127614235721943]	Loss = 0.59196323 (ave = 0.65809680)

2023-07-06 03:50:16,140 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36870	Time 12.290s / 10iters, (1.229)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.382s / 10iters, (0.838)	Loss Time 2.718s / 10iters, (0.272)	Data load 0.083s / 10iters, (0.008346)
Learning rate = [0.001009859065897455, 0.001009859065897455]	Loss = 0.70497757 (ave = 0.65088703)

2023-07-06 03:50:28,438 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36880	Time 12.298s / 10iters, (1.230)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.352s / 10iters, (0.835)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007452)
Learning rate = [0.001006955781098348, 0.001006955781098348]	Loss = 0.66718805 (ave = 0.65689227)

2023-07-06 03:50:40,596 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36890	Time 12.157s / 10iters, (1.216)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.238s / 10iters, (0.824)	Loss Time 2.720s / 10iters, (0.272)	Data load 0.074s / 10iters, (0.007389)
Learning rate = [0.0010040515659066787, 0.0010040515659066787]	Loss = 0.66191363 (ave = 0.64982325)

2023-07-06 03:50:53,044 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36900	Time 12.449s / 10iters, (1.245)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.413s / 10iters, (0.841)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.084s / 10iters, (0.008382)
Learning rate = [0.0010011464170321858, 0.0010011464170321858]	Loss = 0.67336994 (ave = 0.68374030)

2023-07-06 03:51:05,342 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36910	Time 12.297s / 10iters, (1.230)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.319s / 10iters, (0.832)	Loss Time 2.808s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007491)
Learning rate = [0.0009982403311623268, 0.0009982403311623268]	Loss = 0.64631432 (ave = 0.65490239)

2023-07-06 03:51:17,684 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36920	Time 12.342s / 10iters, (1.234)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.325s / 10iters, (0.833)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007483)
Learning rate = [0.0009953333049620458, 0.0009953333049620458]	Loss = 0.61651450 (ave = 0.64824498)

2023-07-06 03:51:29,995 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36930	Time 12.311s / 10iters, (1.231)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.285s / 10iters, (0.828)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007535)
Learning rate = [0.0009924253350735537, 0.0009924253350735537]	Loss = 0.76782358 (ave = 0.68074864)

2023-07-06 03:51:42,348 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36940	Time 12.353s / 10iters, (1.235)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.333s / 10iters, (0.833)	Loss Time 2.832s / 10iters, (0.283)	Data load 0.092s / 10iters, (0.009156)
Learning rate = [0.0009895164181160942, 0.0009895164181160942]	Loss = 0.61423451 (ave = 0.62577546)

2023-07-06 03:51:54,584 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36950	Time 12.236s / 10iters, (1.224)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.091s / 10iters, (0.009066)
Learning rate = [0.000986606550685718, 0.000986606550685718]	Loss = 0.66985297 (ave = 0.66980199)

2023-07-06 03:52:06,877 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36960	Time 12.293s / 10iters, (1.229)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.328s / 10iters, (0.833)	Loss Time 2.763s / 10iters, (0.276)	Data load 0.076s / 10iters, (0.007621)
Learning rate = [0.0009836957293550387, 0.0009836957293550387]	Loss = 0.69358528 (ave = 0.67793298)

2023-07-06 03:52:19,176 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36970	Time 12.299s / 10iters, (1.230)	Forward Time 1.126s / 10iters, (0.113)	Backward Time 8.333s / 10iters, (0.833)	Loss Time 2.765s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007439)
Learning rate = [0.000980783950672998, 0.000980783950672998]	Loss = 0.70285702 (ave = 0.66478807)

2023-07-06 03:52:31,336 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36980	Time 12.160s / 10iters, (1.216)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.230s / 10iters, (0.823)	Loss Time 2.747s / 10iters, (0.275)	Data load 0.074s / 10iters, (0.007435)
Learning rate = [0.0009778712111646228, 0.0009778712111646228]	Loss = 0.58393699 (ave = 0.65750865)

2023-07-06 03:52:43,768 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 36990	Time 12.432s / 10iters, (1.243)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.459s / 10iters, (0.846)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007447)
Learning rate = [0.0009749575073307834, 0.0009749575073307834]	Loss = 0.68419343 (ave = 0.67074668)

2023-07-06 03:52:56,254 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 37000	Time 12.485s / 10iters, (1.249)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.469s / 10iters, (0.847)	Loss Time 2.833s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007460)
Learning rate = [0.0009720428356479383, 0.0009720428356479383]	Loss = 0.74163973 (ave = 0.68550463)

2023-07-06 03:53:00,893 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-06 03:53:24,101 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-06 03:53:47,054 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-06 03:54:09,967 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-06 03:54:33,187 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-06 03:54:55,821 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-06 03:55:18,037 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-06 03:55:23,733 INFO    [base.py, 84] Performance 0.7682762208938888 -> 0.7885630323893416
2023-07-06 03:55:29,363 INFO    [trainer_contrastive.py, 391] Test Time 147.304s, (2.338)	Loss 0.12107799

2023-07-06 03:55:29,364 INFO    [base.py, 33] Result for seg
2023-07-06 03:55:29,365 INFO    [base.py, 49] Mean IOU: 0.7885630323893416

2023-07-06 03:55:29,368 INFO    [base.py, 50] Pixel ACC: 0.9616484341135242

2023-07-06 03:55:41,555 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 37010	Time 165.301s / 10iters, (16.530)	Forward Time 1.147s / 10iters, (0.115)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.643s / 10iters, (0.264)	Data load 153.217s / 10iters, (15.321665)
Learning rate = [0.0009691271925678858, 0.0009691271925678858]	Loss = 0.80375457 (ave = 0.65739217)

2023-07-06 03:55:53,681 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 37020	Time 12.126s / 10iters, (1.213)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.672s / 10iters, (0.267)	Data load 0.091s / 10iters, (0.009116)
Learning rate = [0.0009662105745175068, 0.0009662105745175068]	Loss = 0.74028563 (ave = 0.68280439)

2023-07-06 03:56:05,714 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 37030	Time 12.033s / 10iters, (1.203)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.649s / 10iters, (0.265)	Data load 0.082s / 10iters, (0.008239)
Learning rate = [0.0009632929778985106, 0.0009632929778985106]	Loss = 0.63723487 (ave = 0.64640727)

2023-07-06 03:56:17,944 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 37040	Time 12.230s / 10iters, (1.223)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.328s / 10iters, (0.833)	Loss Time 2.700s / 10iters, (0.270)	Data load 0.086s / 10iters, (0.008551)
Learning rate = [0.000960374399087164, 0.000960374399087164]	Loss = 0.73812580 (ave = 0.68796858)

2023-07-06 03:56:30,145 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 37050	Time 12.201s / 10iters, (1.220)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.699s / 10iters, (0.270)	Data load 0.087s / 10iters, (0.008664)
Learning rate = [0.0009574548344340305, 0.0009574548344340305]	Loss = 0.68394190 (ave = 0.70055412)

2023-07-06 03:56:42,203 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 37060	Time 12.058s / 10iters, (1.206)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.204s / 10iters, (0.820)	Loss Time 2.656s / 10iters, (0.266)	Data load 0.097s / 10iters, (0.009738)
Learning rate = [0.0009545342802636974, 0.0009545342802636974]	Loss = 0.55983329 (ave = 0.66172692)

2023-07-06 03:56:54,305 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 37070	Time 12.102s / 10iters, (1.210)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.675s / 10iters, (0.268)	Data load 0.087s / 10iters, (0.008697)
Learning rate = [0.0009516127328745076, 0.0009516127328745076]	Loss = 0.69377232 (ave = 0.73347199)

2023-07-06 03:57:06,573 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 37080	Time 12.268s / 10iters, (1.227)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.396s / 10iters, (0.840)	Loss Time 2.686s / 10iters, (0.269)	Data load 0.077s / 10iters, (0.007676)
Learning rate = [0.0009486901885382734, 0.0009486901885382734]	Loss = 0.73894405 (ave = 0.68559577)

2023-07-06 03:57:18,471 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 37090	Time 11.898s / 10iters, (1.190)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.067s / 10iters, (0.807)	Loss Time 2.641s / 10iters, (0.264)	Data load 0.089s / 10iters, (0.008910)
Learning rate = [0.000945766643500001, 0.000945766643500001]	Loss = 0.71484005 (ave = 0.68937060)

2023-07-06 03:57:30,318 INFO    [trainer_contrastive.py, 272] Train Epoch: 99	Train Iteration: 37100	Time 11.846s / 10iters, (1.185)	Forward Time 1.073s / 10iters, (0.107)	Backward Time 8.063s / 10iters, (0.806)	Loss Time 2.634s / 10iters, (0.263)	Data load 0.077s / 10iters, (0.007671)
Learning rate = [0.0009428420939776016, 0.0009428420939776016]	Loss = 0.71616304 (ave = 0.71137198)

2023-07-06 03:57:45,437 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37110	Time 14.947s / 10iters, (1.495)	Forward Time 1.279s / 10iters, (0.128)	Backward Time 8.341s / 10iters, (0.834)	Loss Time 2.706s / 10iters, (0.271)	Data load 2.620s / 10iters, (0.262032)
Learning rate = [0.000939916536161607, 0.000939916536161607]	Loss = 0.57643026 (ave = 0.63756767)

2023-07-06 03:57:57,714 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37120	Time 12.277s / 10iters, (1.228)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.281s / 10iters, (0.828)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.076s / 10iters, (0.007560)
Learning rate = [0.0009369899662148692, 0.0009369899662148692]	Loss = 0.62377024 (ave = 0.65722464)

2023-07-06 03:58:09,736 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37130	Time 12.022s / 10iters, (1.202)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.159s / 10iters, (0.816)	Loss Time 2.686s / 10iters, (0.269)	Data load 0.083s / 10iters, (0.008311)
Learning rate = [0.0009340623802722665, 0.0009340623802722665]	Loss = 0.58157402 (ave = 0.64632909)

2023-07-06 03:58:21,846 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37140	Time 12.110s / 10iters, (1.211)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.228s / 10iters, (0.823)	Loss Time 2.716s / 10iters, (0.272)	Data load 0.074s / 10iters, (0.007440)
Learning rate = [0.0009311337744403994, 0.0009311337744403994]	Loss = 0.61178875 (ave = 0.63576703)

2023-07-06 03:58:33,960 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37150	Time 12.114s / 10iters, (1.211)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007462)
Learning rate = [0.0009282041447972892, 0.0009282041447972892]	Loss = 0.62183446 (ave = 0.66994219)

2023-07-06 03:58:46,164 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37160	Time 12.203s / 10iters, (1.220)	Forward Time 1.085s / 10iters, (0.109)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.074s / 10iters, (0.007446)
Learning rate = [0.0009252734873920598, 0.0009252734873920598]	Loss = 0.70225966 (ave = 0.68187395)

2023-07-06 03:58:58,307 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37170	Time 12.143s / 10iters, (1.214)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.187s / 10iters, (0.819)	Loss Time 2.798s / 10iters, (0.280)	Data load 0.074s / 10iters, (0.007401)
Learning rate = [0.0009223417982446261, 0.0009223417982446261]	Loss = 0.64980167 (ave = 0.65291935)

2023-07-06 03:59:10,534 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37180	Time 12.227s / 10iters, (1.223)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007442)
Learning rate = [0.0009194090733453738, 0.0009194090733453738]	Loss = 0.69105524 (ave = 0.66879524)

2023-07-06 03:59:22,719 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37190	Time 12.185s / 10iters, (1.219)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.191s / 10iters, (0.819)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.080s / 10iters, (0.008050)
Learning rate = [0.0009164753086548377, 0.0009164753086548377]	Loss = 0.65389973 (ave = 0.64102299)

2023-07-06 03:59:34,983 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37200	Time 12.264s / 10iters, (1.226)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.847s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007533)
Learning rate = [0.0009135405001033667, 0.0009135405001033667]	Loss = 0.74208790 (ave = 0.68541410)

2023-07-06 03:59:47,201 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37210	Time 12.218s / 10iters, (1.222)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.860s / 10iters, (0.286)	Data load 0.076s / 10iters, (0.007583)
Learning rate = [0.000910604643590793, 0.000910604643590793]	Loss = 0.71869558 (ave = 0.63048025)

2023-07-06 03:59:59,401 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37220	Time 12.200s / 10iters, (1.220)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.178s / 10iters, (0.818)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.076s / 10iters, (0.007598)
Learning rate = [0.000907667734986092, 0.000907667734986092]	Loss = 0.59909362 (ave = 0.66750771)

2023-07-06 04:00:11,601 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37230	Time 12.200s / 10iters, (1.220)	Forward Time 1.085s / 10iters, (0.108)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007397)
Learning rate = [0.0009047297701270423, 0.0009047297701270423]	Loss = 0.66254711 (ave = 0.67786830)

2023-07-06 04:00:23,905 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37240	Time 12.304s / 10iters, (1.230)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.289s / 10iters, (0.829)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007398)
Learning rate = [0.0009017907448198698, 0.0009017907448198698]	Loss = 0.66112077 (ave = 0.68072215)

2023-07-06 04:00:36,164 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37250	Time 12.259s / 10iters, (1.226)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.895s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007488)
Learning rate = [0.0008988506548388979, 0.0008988506548388979]	Loss = 0.69302273 (ave = 0.66384870)

2023-07-06 04:00:48,469 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37260	Time 12.305s / 10iters, (1.231)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.243s / 10iters, (0.824)	Loss Time 2.901s / 10iters, (0.290)	Data load 0.074s / 10iters, (0.007404)
Learning rate = [0.0008959094959261856, 0.0008959094959261856]	Loss = 0.75609255 (ave = 0.67347978)

2023-07-06 04:01:00,769 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37270	Time 12.300s / 10iters, (1.230)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.243s / 10iters, (0.824)	Loss Time 2.890s / 10iters, (0.289)	Data load 0.076s / 10iters, (0.007584)
Learning rate = [0.0008929672637911676, 0.0008929672637911676]	Loss = 0.71640939 (ave = 0.65554398)

2023-07-06 04:01:12,980 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37280	Time 12.211s / 10iters, (1.221)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.186s / 10iters, (0.819)	Loss Time 2.855s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007500)
Learning rate = [0.0008900239541102764, 0.0008900239541102764]	Loss = 0.72588420 (ave = 0.64263637)

2023-07-06 04:01:25,247 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37290	Time 12.267s / 10iters, (1.227)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.201s / 10iters, (0.820)	Loss Time 2.899s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007522)
Learning rate = [0.0008870795625265711, 0.0008870795625265711]	Loss = 0.71408069 (ave = 0.65798515)

2023-07-06 04:01:37,499 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37300	Time 12.252s / 10iters, (1.225)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.194s / 10iters, (0.819)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007477)
Learning rate = [0.000884134084649353, 0.000884134084649353]	Loss = 0.67672360 (ave = 0.64806879)

2023-07-06 04:01:49,780 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37310	Time 12.281s / 10iters, (1.228)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.894s / 10iters, (0.289)	Data load 0.083s / 10iters, (0.008345)
Learning rate = [0.000881187516053784, 0.000881187516053784]	Loss = 0.70581037 (ave = 0.69585400)

2023-07-06 04:02:02,067 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37320	Time 12.287s / 10iters, (1.229)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.881s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007450)
Learning rate = [0.0008782398522804843, 0.0008782398522804843]	Loss = 0.60357529 (ave = 0.66252016)

2023-07-06 04:02:14,362 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37330	Time 12.295s / 10iters, (1.229)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.901s / 10iters, (0.290)	Data load 0.074s / 10iters, (0.007423)
Learning rate = [0.0008752910888351397, 0.0008752910888351397]	Loss = 0.68645984 (ave = 0.66077537)

2023-07-06 04:02:26,733 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37340	Time 12.371s / 10iters, (1.237)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.912s / 10iters, (0.291)	Data load 0.092s / 10iters, (0.009177)
Learning rate = [0.0008723412211880916, 0.0008723412211880916]	Loss = 0.68985403 (ave = 0.68727677)

2023-07-06 04:02:39,076 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37350	Time 12.343s / 10iters, (1.234)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.281s / 10iters, (0.828)	Loss Time 2.897s / 10iters, (0.290)	Data load 0.075s / 10iters, (0.007545)
Learning rate = [0.0008693902447739318, 0.0008693902447739318]	Loss = 0.60235280 (ave = 0.63599846)

2023-07-06 04:02:51,389 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37360	Time 12.313s / 10iters, (1.231)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.900s / 10iters, (0.290)	Data load 0.074s / 10iters, (0.007437)
Learning rate = [0.0008664381549910757, 0.0008664381549910757]	Loss = 0.65536547 (ave = 0.64967846)

2023-07-06 04:03:03,667 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37370	Time 12.278s / 10iters, (1.228)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.893s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007472)
Learning rate = [0.0008634849472013439, 0.0008634849472013439]	Loss = 0.67233068 (ave = 0.72685501)

2023-07-06 04:03:16,033 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37380	Time 12.366s / 10iters, (1.237)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.352s / 10iters, (0.835)	Loss Time 2.817s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007630)
Learning rate = [0.0008605306167295283, 0.0008605306167295283]	Loss = 0.61138022 (ave = 0.66107646)

2023-07-06 04:03:28,536 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37390	Time 12.503s / 10iters, (1.250)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.428s / 10iters, (0.843)	Loss Time 2.884s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007499)
Learning rate = [0.0008575751588629534, 0.0008575751588629534]	Loss = 0.74334335 (ave = 0.67580367)

2023-07-06 04:03:40,855 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37400	Time 12.319s / 10iters, (1.232)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.327s / 10iters, (0.833)	Loss Time 2.820s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007483)
Learning rate = [0.0008546185688510363, 0.0008546185688510363]	Loss = 0.78848946 (ave = 0.66277740)

2023-07-06 04:03:53,141 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37410	Time 12.286s / 10iters, (1.229)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.281s / 10iters, (0.828)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007542)
Learning rate = [0.0008516608419048278, 0.0008516608419048278]	Loss = 0.62976122 (ave = 0.68030636)

2023-07-06 04:04:05,354 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37420	Time 12.213s / 10iters, (1.221)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.243s / 10iters, (0.824)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.077s / 10iters, (0.007658)
Learning rate = [0.0008487019731965575, 0.0008487019731965575]	Loss = 0.58962590 (ave = 0.68884820)

2023-07-06 04:04:17,585 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37430	Time 12.231s / 10iters, (1.223)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.191s / 10iters, (0.819)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.089s / 10iters, (0.008872)
Learning rate = [0.0008457419578591655, 0.0008457419578591655]	Loss = 0.59387374 (ave = 0.68837299)

2023-07-06 04:04:29,859 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37440	Time 12.274s / 10iters, (1.227)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.074s / 10iters, (0.007406)
Learning rate = [0.0008427807909858327, 0.0008427807909858327]	Loss = 0.76170355 (ave = 0.66050275)

2023-07-06 04:04:42,232 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37450	Time 12.373s / 10iters, (1.237)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.329s / 10iters, (0.833)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.078s / 10iters, (0.007776)
Learning rate = [0.0008398184676294936, 0.0008398184676294936]	Loss = 0.76182294 (ave = 0.69726133)

2023-07-06 04:04:54,690 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37460	Time 12.458s / 10iters, (1.246)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.412s / 10iters, (0.841)	Loss Time 2.856s / 10iters, (0.286)	Data load 0.078s / 10iters, (0.007774)
Learning rate = [0.0008368549828023502, 0.0008368549828023502]	Loss = 0.64780313 (ave = 0.66550986)

2023-07-06 04:05:06,920 INFO    [trainer_contrastive.py, 272] Train Epoch: 100	Train Iteration: 37470	Time 12.231s / 10iters, (1.223)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.279s / 10iters, (0.828)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.074s / 10iters, (0.007353)
Learning rate = [0.0008338903314753736, 0.0008338903314753736]	Loss = 0.59127331 (ave = 0.68477863)

2023-07-06 04:05:21,967 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37480	Time 14.836s / 10iters, (1.484)	Forward Time 1.273s / 10iters, (0.127)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.734s / 10iters, (0.273)	Data load 2.560s / 10iters, (0.256008)
Learning rate = [0.000830924508577804, 0.000830924508577804]	Loss = 0.58121079 (ave = 0.65612238)

2023-07-06 04:05:34,312 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37490	Time 12.345s / 10iters, (1.234)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.279s / 10iters, (0.828)	Loss Time 2.881s / 10iters, (0.288)	Data load 0.083s / 10iters, (0.008258)
Learning rate = [0.0008279575089966293, 0.0008279575089966293]	Loss = 0.69544333 (ave = 0.64721968)

2023-07-06 04:05:46,637 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37500	Time 12.325s / 10iters, (1.233)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.924s / 10iters, (0.292)	Data load 0.076s / 10iters, (0.007640)
Learning rate = [0.0008249893275760685, 0.0008249893275760685]	Loss = 0.75767970 (ave = 0.67890556)

2023-07-06 04:05:58,890 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37510	Time 12.253s / 10iters, (1.225)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.178s / 10iters, (0.818)	Loss Time 2.878s / 10iters, (0.288)	Data load 0.082s / 10iters, (0.008196)
Learning rate = [0.0008220199591170394, 0.0008220199591170394]	Loss = 0.67909282 (ave = 0.69673863)

2023-07-06 04:06:11,141 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37520	Time 12.250s / 10iters, (1.225)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.207s / 10iters, (0.821)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.083s / 10iters, (0.008335)
Learning rate = [0.0008190493983766241, 0.0008190493983766241]	Loss = 0.65953320 (ave = 0.65172796)

2023-07-06 04:06:23,369 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37530	Time 12.228s / 10iters, (1.223)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.202s / 10iters, (0.820)	Loss Time 2.821s / 10iters, (0.282)	Data load 0.088s / 10iters, (0.008844)
Learning rate = [0.0008160776400675139, 0.0008160776400675139]	Loss = 0.73770112 (ave = 0.66421420)

2023-07-06 04:06:35,570 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37540	Time 12.202s / 10iters, (1.220)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.178s / 10iters, (0.818)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.100s / 10iters, (0.009963)
Learning rate = [0.0008131046788574577, 0.0008131046788574577]	Loss = 0.70768160 (ave = 0.66806848)

2023-07-06 04:06:47,873 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37550	Time 12.302s / 10iters, (1.230)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.080s / 10iters, (0.007967)
Learning rate = [0.000810130509368692, 0.000810130509368692]	Loss = 0.67280018 (ave = 0.67964491)

2023-07-06 04:07:00,109 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37560	Time 12.236s / 10iters, (1.224)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.820s / 10iters, (0.282)	Data load 0.078s / 10iters, (0.007796)
Learning rate = [0.0008071551261773718, 0.0008071551261773718]	Loss = 0.62395144 (ave = 0.66458580)

2023-07-06 04:07:12,238 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37570	Time 12.129s / 10iters, (1.213)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.194s / 10iters, (0.819)	Loss Time 2.762s / 10iters, (0.276)	Data load 0.077s / 10iters, (0.007726)
Learning rate = [0.0008041785238129762, 0.0008041785238129762]	Loss = 0.76344115 (ave = 0.64254212)

2023-07-06 04:07:24,360 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37580	Time 12.122s / 10iters, (1.212)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.191s / 10iters, (0.819)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.077s / 10iters, (0.007728)
Learning rate = [0.0008012006967577193, 0.0008012006967577193]	Loss = 0.74174231 (ave = 0.60343924)

2023-07-06 04:07:36,618 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37590	Time 12.258s / 10iters, (1.226)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.788s / 10iters, (0.279)	Data load 0.082s / 10iters, (0.008179)
Learning rate = [0.0007982216394459413, 0.0007982216394459413]	Loss = 0.72691751 (ave = 0.64024990)

2023-07-06 04:07:48,884 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37600	Time 12.265s / 10iters, (1.227)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.086s / 10iters, (0.008635)
Learning rate = [0.0007952413462634991, 0.0007952413462634991]	Loss = 0.70725501 (ave = 0.66220059)

2023-07-06 04:08:01,192 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37610	Time 12.309s / 10iters, (1.231)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.325s / 10iters, (0.833)	Loss Time 2.813s / 10iters, (0.281)	Data load 0.077s / 10iters, (0.007676)
Learning rate = [0.0007922598115471314, 0.0007922598115471314]	Loss = 0.68421990 (ave = 0.66283426)

2023-07-06 04:08:13,424 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37620	Time 12.231s / 10iters, (1.223)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.219s / 10iters, (0.822)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.085s / 10iters, (0.008549)
Learning rate = [0.0007892770295838269, 0.0007892770295838269]	Loss = 0.66961884 (ave = 0.64520210)

2023-07-06 04:08:25,653 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37630	Time 12.229s / 10iters, (1.223)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.226s / 10iters, (0.823)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.079s / 10iters, (0.007871)
Learning rate = [0.0007862929946101752, 0.0007862929946101752]	Loss = 0.64351261 (ave = 0.68445602)

2023-07-06 04:08:37,916 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37640	Time 12.263s / 10iters, (1.226)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.272s / 10iters, (0.827)	Loss Time 2.825s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007497)
Learning rate = [0.0007833077008117111, 0.0007833077008117111]	Loss = 0.74101210 (ave = 0.70426245)

2023-07-06 04:08:50,196 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37650	Time 12.280s / 10iters, (1.228)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.851s / 10iters, (0.285)	Data load 0.078s / 10iters, (0.007831)
Learning rate = [0.0007803211423222376, 0.0007803211423222376]	Loss = 0.75377357 (ave = 0.70404057)

2023-07-06 04:09:02,516 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37660	Time 12.319s / 10iters, (1.232)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.086s / 10iters, (0.008625)
Learning rate = [0.000777333313223148, 0.000777333313223148]	Loss = 0.73928100 (ave = 0.67116234)

2023-07-06 04:09:14,868 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37670	Time 12.352s / 10iters, (1.235)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.272s / 10iters, (0.827)	Loss Time 2.903s / 10iters, (0.290)	Data load 0.077s / 10iters, (0.007668)
Learning rate = [0.0007743442075427297, 0.0007743442075427297]	Loss = 0.71398646 (ave = 0.66726997)

2023-07-06 04:09:27,219 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37680	Time 12.351s / 10iters, (1.235)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.286s / 10iters, (0.829)	Loss Time 2.881s / 10iters, (0.288)	Data load 0.078s / 10iters, (0.007800)
Learning rate = [0.0007713538192554629, 0.0007713538192554629]	Loss = 0.69154602 (ave = 0.67401469)

2023-07-06 04:09:39,539 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37690	Time 12.320s / 10iters, (1.232)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007518)
Learning rate = [0.0007683621422812934, 0.0007683621422812934]	Loss = 0.61270779 (ave = 0.66475241)

2023-07-06 04:09:51,877 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37700	Time 12.338s / 10iters, (1.234)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.272s / 10iters, (0.827)	Loss Time 2.873s / 10iters, (0.287)	Data load 0.095s / 10iters, (0.009543)
Learning rate = [0.0007653691704849068, 0.0007653691704849068]	Loss = 0.69500518 (ave = 0.68718240)

2023-07-06 04:10:04,127 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37710	Time 12.250s / 10iters, (1.225)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.205s / 10iters, (0.821)	Loss Time 2.878s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007494)
Learning rate = [0.000762374897674981, 0.000762374897674981]	Loss = 0.62509757 (ave = 0.65365255)

2023-07-06 04:10:16,458 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37720	Time 12.331s / 10iters, (1.233)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.079s / 10iters, (0.007903)
Learning rate = [0.0007593793176034333, 0.0007593793176034333]	Loss = 0.55861998 (ave = 0.64128651)

2023-07-06 04:10:28,804 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37730	Time 12.346s / 10iters, (1.235)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.888s / 10iters, (0.289)	Data load 0.078s / 10iters, (0.007814)
Learning rate = [0.000756382423964641, 0.000756382423964641]	Loss = 0.78103495 (ave = 0.68522316)

2023-07-06 04:10:41,042 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37740	Time 12.238s / 10iters, (1.224)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007509)
Learning rate = [0.0007533842103946608, 0.0007533842103946608]	Loss = 0.66098994 (ave = 0.65355021)

2023-07-06 04:10:53,247 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37750	Time 12.205s / 10iters, (1.220)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.209s / 10iters, (0.821)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.094s / 10iters, (0.009409)
Learning rate = [0.0007503846704704273, 0.0007503846704704273]	Loss = 0.68439829 (ave = 0.67559416)

2023-07-06 04:11:05,457 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37760	Time 12.209s / 10iters, (1.221)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.202s / 10iters, (0.820)	Loss Time 2.823s / 10iters, (0.282)	Data load 0.085s / 10iters, (0.008467)
Learning rate = [0.0007473837977089424, 0.0007473837977089424]	Loss = 0.68924677 (ave = 0.64477639)

2023-07-06 04:11:17,748 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37770	Time 12.292s / 10iters, (1.229)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.078s / 10iters, (0.007813)
Learning rate = [0.0007443815855664396, 0.0007443815855664396]	Loss = 0.72542155 (ave = 0.66732069)

2023-07-06 04:11:30,009 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37780	Time 12.261s / 10iters, (1.226)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.207s / 10iters, (0.821)	Loss Time 2.869s / 10iters, (0.287)	Data load 0.079s / 10iters, (0.007857)
Learning rate = [0.0007413780274375436, 0.0007413780274375436]	Loss = 0.83964276 (ave = 0.71202487)

2023-07-06 04:11:42,555 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37790	Time 12.546s / 10iters, (1.255)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.411s / 10iters, (0.841)	Loss Time 2.931s / 10iters, (0.293)	Data load 0.077s / 10iters, (0.007659)
Learning rate = [0.0007383731166544078, 0.0007383731166544078]	Loss = 0.66732788 (ave = 0.63149645)

2023-07-06 04:11:55,063 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37800	Time 12.508s / 10iters, (1.251)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.391s / 10iters, (0.839)	Loss Time 2.926s / 10iters, (0.293)	Data load 0.087s / 10iters, (0.008694)
Learning rate = [0.000735366846485844, 0.000735366846485844]	Loss = 0.71613973 (ave = 0.68752766)

2023-07-06 04:12:07,436 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37810	Time 12.373s / 10iters, (1.237)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.869s / 10iters, (0.287)	Data load 0.084s / 10iters, (0.008441)
Learning rate = [0.0007323592101364216, 0.0007323592101364216]	Loss = 0.83861017 (ave = 0.69481552)

2023-07-06 04:12:19,771 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37820	Time 12.336s / 10iters, (1.234)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.241s / 10iters, (0.824)	Loss Time 2.920s / 10iters, (0.292)	Data load 0.081s / 10iters, (0.008093)
Learning rate = [0.0007293502007455641, 0.0007293502007455641]	Loss = 0.62321794 (ave = 0.63034533)

2023-07-06 04:12:31,996 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37830	Time 12.225s / 10iters, (1.222)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.077s / 10iters, (0.007685)
Learning rate = [0.0007263398113866195, 0.0007263398113866195]	Loss = 0.65427166 (ave = 0.66995093)

2023-07-06 04:12:44,003 INFO    [trainer_contrastive.py, 272] Train Epoch: 101	Train Iteration: 37840	Time 12.007s / 10iters, (1.201)	Forward Time 1.080s / 10iters, (0.108)	Backward Time 8.130s / 10iters, (0.813)	Loss Time 2.723s / 10iters, (0.272)	Data load 0.074s / 10iters, (0.007394)
Learning rate = [0.0007233280350659227, 0.0007233280350659227]	Loss = 0.78644228 (ave = 0.62943567)

2023-07-06 04:12:59,263 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 37850	Time 15.099s / 10iters, (1.510)	Forward Time 1.177s / 10iters, (0.118)	Backward Time 8.186s / 10iters, (0.819)	Loss Time 2.732s / 10iters, (0.273)	Data load 3.003s / 10iters, (0.300302)
Learning rate = [0.0007203148647218259, 0.0007203148647218259]	Loss = 0.62569690 (ave = 0.69183657)

2023-07-06 04:13:11,376 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 37860	Time 12.113s / 10iters, (1.211)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.190s / 10iters, (0.819)	Loss Time 2.756s / 10iters, (0.276)	Data load 0.076s / 10iters, (0.007584)
Learning rate = [0.0007173002932237232, 0.0007173002932237232]	Loss = 0.65755141 (ave = 0.64087065)

2023-07-06 04:13:23,450 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 37870	Time 12.074s / 10iters, (1.207)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.188s / 10iters, (0.819)	Loss Time 2.708s / 10iters, (0.271)	Data load 0.078s / 10iters, (0.007758)
Learning rate = [0.0007142843133710504, 0.0007142843133710504]	Loss = 0.75037402 (ave = 0.61368371)

2023-07-06 04:13:35,574 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 37880	Time 12.124s / 10iters, (1.212)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.216s / 10iters, (0.822)	Loss Time 2.720s / 10iters, (0.272)	Data load 0.076s / 10iters, (0.007561)
Learning rate = [0.0007112669178922711, 0.0007112669178922711]	Loss = 0.62377328 (ave = 0.64136413)

2023-07-06 04:13:47,742 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 37890	Time 12.168s / 10iters, (1.217)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.272s / 10iters, (0.827)	Loss Time 2.726s / 10iters, (0.273)	Data load 0.076s / 10iters, (0.007560)
Learning rate = [0.000708248099443832, 0.000708248099443832]	Loss = 0.74086750 (ave = 0.66168525)

2023-07-06 04:13:59,949 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 37900	Time 12.207s / 10iters, (1.221)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.765s / 10iters, (0.276)	Data load 0.094s / 10iters, (0.009439)
Learning rate = [0.0007052278506091101, 0.0007052278506091101]	Loss = 0.64316213 (ave = 0.66517757)

2023-07-06 04:14:12,126 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 37910	Time 12.178s / 10iters, (1.218)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.196s / 10iters, (0.820)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007515)
Learning rate = [0.0007022061638973316, 0.0007022061638973316]	Loss = 0.74833167 (ave = 0.64798378)

2023-07-06 04:14:24,404 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 37920	Time 12.278s / 10iters, (1.228)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.217s / 10iters, (0.822)	Loss Time 2.892s / 10iters, (0.289)	Data load 0.074s / 10iters, (0.007380)
Learning rate = [0.0006991830317424781, 0.0006991830317424781]	Loss = 0.68950278 (ave = 0.65248960)

2023-07-06 04:14:36,650 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 37930	Time 12.246s / 10iters, (1.225)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.855s / 10iters, (0.286)	Data load 0.077s / 10iters, (0.007651)
Learning rate = [0.0006961584465021564, 0.0006961584465021564]	Loss = 0.69839603 (ave = 0.70622467)

2023-07-06 04:14:48,987 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 37940	Time 12.336s / 10iters, (1.234)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.243s / 10iters, (0.824)	Loss Time 2.919s / 10iters, (0.292)	Data load 0.080s / 10iters, (0.008001)
Learning rate = [0.0006931324004564616, 0.0006931324004564616]	Loss = 0.71728122 (ave = 0.65223825)

2023-07-06 04:15:01,243 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 37950	Time 12.257s / 10iters, (1.226)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.879s / 10iters, (0.288)	Data load 0.075s / 10iters, (0.007472)
Learning rate = [0.0006901048858068068, 0.0006901048858068068]	Loss = 0.64192563 (ave = 0.64826190)

2023-07-06 04:15:13,384 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 37960	Time 12.141s / 10iters, (1.214)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.180s / 10iters, (0.818)	Loss Time 2.791s / 10iters, (0.279)	Data load 0.076s / 10iters, (0.007560)
Learning rate = [0.0006870758946747404, 0.0006870758946747404]	Loss = 0.79288960 (ave = 0.67302012)

2023-07-06 04:15:25,555 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 37970	Time 12.171s / 10iters, (1.217)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.182s / 10iters, (0.818)	Loss Time 2.816s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007489)
Learning rate = [0.000684045419100724, 0.000684045419100724]	Loss = 0.57024854 (ave = 0.66070441)

2023-07-06 04:15:37,884 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 37980	Time 12.329s / 10iters, (1.233)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.875s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007434)
Learning rate = [0.0006810134510428991, 0.0006810134510428991]	Loss = 0.57050741 (ave = 0.65161377)

2023-07-06 04:15:50,053 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 37990	Time 12.169s / 10iters, (1.217)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.163s / 10iters, (0.816)	Loss Time 2.835s / 10iters, (0.283)	Data load 0.076s / 10iters, (0.007579)
Learning rate = [0.0006779799823758227, 0.0006779799823758227]	Loss = 0.50253499 (ave = 0.64904093)

2023-07-06 04:16:02,322 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38000	Time 12.270s / 10iters, (1.227)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.237s / 10iters, (0.824)	Loss Time 2.867s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007445)
Learning rate = [0.0006749450048891831, 0.0006749450048891831]	Loss = 0.65773141 (ave = 0.67418382)

2023-07-06 04:16:05,663 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-06 04:16:29,120 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-06 04:16:51,918 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-06 04:17:14,693 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-06 04:17:37,521 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-06 04:18:00,177 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-06 04:18:22,427 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-06 04:18:28,164 INFO    [base.py, 84] Performance 0.7885630323893416 -> 0.7934902142283347
2023-07-06 04:18:33,886 INFO    [trainer_contrastive.py, 391] Test Time 145.636s, (2.312)	Loss 0.11598886

2023-07-06 04:18:33,887 INFO    [base.py, 33] Result for seg
2023-07-06 04:18:33,888 INFO    [base.py, 49] Mean IOU: 0.7934902142283347

2023-07-06 04:18:33,890 INFO    [base.py, 50] Pixel ACC: 0.9630358248970922

2023-07-06 04:18:46,025 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38010	Time 163.702s / 10iters, (16.370)	Forward Time 1.143s / 10iters, (0.114)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.685s / 10iters, (0.268)	Data load 151.662s / 10iters, (15.166158)
Learning rate = [0.0006719085102864766, 0.0006719085102864766]	Loss = 0.68408799 (ave = 0.65035883)

2023-07-06 04:18:58,120 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38020	Time 12.095s / 10iters, (1.210)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.667s / 10iters, (0.267)	Data load 0.078s / 10iters, (0.007842)
Learning rate = [0.000668870490183671, 0.000668870490183671]	Loss = 0.61998135 (ave = 0.62752921)

2023-07-06 04:19:10,159 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38030	Time 12.039s / 10iters, (1.204)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.150s / 10iters, (0.815)	Loss Time 2.699s / 10iters, (0.270)	Data load 0.092s / 10iters, (0.009160)
Learning rate = [0.0006658309361078324, 0.0006658309361078324]	Loss = 0.71537149 (ave = 0.68633828)

2023-07-06 04:19:22,241 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38040	Time 12.082s / 10iters, (1.208)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.185s / 10iters, (0.818)	Loss Time 2.720s / 10iters, (0.272)	Data load 0.082s / 10iters, (0.008158)
Learning rate = [0.0006627898394957319, 0.0006627898394957319]	Loss = 0.75476503 (ave = 0.67496092)

2023-07-06 04:19:34,358 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38050	Time 12.117s / 10iters, (1.212)	Forward Time 1.084s / 10iters, (0.108)	Backward Time 8.206s / 10iters, (0.821)	Loss Time 2.732s / 10iters, (0.273)	Data load 0.094s / 10iters, (0.009438)
Learning rate = [0.0006597471916924105, 0.0006597471916924105]	Loss = 0.64238214 (ave = 0.65315223)

2023-07-06 04:19:46,376 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38060	Time 12.018s / 10iters, (1.202)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.174s / 10iters, (0.817)	Loss Time 2.676s / 10iters, (0.268)	Data load 0.076s / 10iters, (0.007620)
Learning rate = [0.0006567029839497249, 0.0006567029839497249]	Loss = 0.56968355 (ave = 0.64593281)

2023-07-06 04:19:58,555 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38070	Time 12.179s / 10iters, (1.218)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.217s / 10iters, (0.822)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.086s / 10iters, (0.008557)
Learning rate = [0.0006536572074248585, 0.0006536572074248585]	Loss = 0.68274438 (ave = 0.70360332)

2023-07-06 04:20:10,829 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38080	Time 12.275s / 10iters, (1.227)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.806s / 10iters, (0.281)	Data load 0.081s / 10iters, (0.008137)
Learning rate = [0.0006506098531788046, 0.0006506098531788046]	Loss = 0.64804262 (ave = 0.63322506)

2023-07-06 04:20:22,957 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38090	Time 12.128s / 10iters, (1.213)	Forward Time 1.086s / 10iters, (0.109)	Backward Time 8.203s / 10iters, (0.820)	Loss Time 2.763s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007516)
Learning rate = [0.0006475609121748062, 0.0006475609121748062]	Loss = 0.62396234 (ave = 0.65474775)

2023-07-06 04:20:35,086 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38100	Time 12.129s / 10iters, (1.213)	Forward Time 1.083s / 10iters, (0.108)	Backward Time 8.203s / 10iters, (0.820)	Loss Time 2.764s / 10iters, (0.276)	Data load 0.079s / 10iters, (0.007872)
Learning rate = [0.0006445103752767753, 0.0006445103752767753]	Loss = 0.62201440 (ave = 0.69161355)

2023-07-06 04:20:47,272 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38110	Time 12.186s / 10iters, (1.219)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.221s / 10iters, (0.822)	Loss Time 2.766s / 10iters, (0.277)	Data load 0.108s / 10iters, (0.010779)
Learning rate = [0.0006414582332476702, 0.0006414582332476702]	Loss = 0.73952317 (ave = 0.69605011)

2023-07-06 04:20:59,495 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38120	Time 12.223s / 10iters, (1.222)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.245s / 10iters, (0.825)	Loss Time 2.780s / 10iters, (0.278)	Data load 0.093s / 10iters, (0.009320)
Learning rate = [0.0006384044767478448, 0.0006384044767478448]	Loss = 0.80367535 (ave = 0.65592803)

2023-07-06 04:21:11,664 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38130	Time 12.169s / 10iters, (1.217)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.210s / 10iters, (0.821)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.094s / 10iters, (0.009423)
Learning rate = [0.0006353490963333502, 0.0006353490963333502]	Loss = 0.61063713 (ave = 0.66718001)

2023-07-06 04:21:23,805 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38140	Time 12.141s / 10iters, (1.214)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.763s / 10iters, (0.276)	Data load 0.074s / 10iters, (0.007396)
Learning rate = [0.0006322920824542093, 0.0006322920824542093]	Loss = 0.68991500 (ave = 0.66650403)

2023-07-06 04:21:36,046 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38150	Time 12.241s / 10iters, (1.224)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.279s / 10iters, (0.828)	Loss Time 2.763s / 10iters, (0.276)	Data load 0.086s / 10iters, (0.008649)
Learning rate = [0.0006292334254526502, 0.0006292334254526502]	Loss = 0.64943850 (ave = 0.64924933)

2023-07-06 04:21:48,159 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38160	Time 12.112s / 10iters, (1.211)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.253s / 10iters, (0.825)	Loss Time 2.676s / 10iters, (0.268)	Data load 0.076s / 10iters, (0.007587)
Learning rate = [0.0006261731155613037, 0.0006261731155613037]	Loss = 0.64647496 (ave = 0.66297904)

2023-07-06 04:22:00,391 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38170	Time 12.233s / 10iters, (1.223)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.294s / 10iters, (0.829)	Loss Time 2.755s / 10iters, (0.276)	Data load 0.092s / 10iters, (0.009241)
Learning rate = [0.0006231111429013497, 0.0006231111429013497]	Loss = 0.65850472 (ave = 0.65189235)

2023-07-06 04:22:12,519 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38180	Time 12.128s / 10iters, (1.213)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.240s / 10iters, (0.824)	Loss Time 2.723s / 10iters, (0.272)	Data load 0.078s / 10iters, (0.007838)
Learning rate = [0.0006200474974806354, 0.0006200474974806354]	Loss = 0.68300581 (ave = 0.64782845)

2023-07-06 04:22:24,705 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38190	Time 12.185s / 10iters, (1.219)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.283s / 10iters, (0.828)	Loss Time 2.734s / 10iters, (0.273)	Data load 0.074s / 10iters, (0.007421)
Learning rate = [0.0006169821691917428, 0.0006169821691917428]	Loss = 0.65094006 (ave = 0.66322672)

2023-07-06 04:22:36,860 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38200	Time 12.156s / 10iters, (1.216)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.243s / 10iters, (0.824)	Loss Time 2.746s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007468)
Learning rate = [0.0006139151478100199, 0.0006139151478100199]	Loss = 0.58829677 (ave = 0.64789137)

2023-07-06 04:22:48,801 INFO    [trainer_contrastive.py, 272] Train Epoch: 102	Train Iteration: 38210	Time 11.941s / 10iters, (1.194)	Forward Time 1.081s / 10iters, (0.108)	Backward Time 8.084s / 10iters, (0.808)	Loss Time 2.700s / 10iters, (0.270)	Data load 0.076s / 10iters, (0.007646)
Learning rate = [0.0006108464229915543, 0.0006108464229915543]	Loss = 0.67852080 (ave = 0.65849549)

2023-07-06 04:23:04,001 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38220	Time 14.992s / 10iters, (1.499)	Forward Time 1.275s / 10iters, (0.128)	Backward Time 8.380s / 10iters, (0.838)	Loss Time 2.681s / 10iters, (0.268)	Data load 2.656s / 10iters, (0.265596)
Learning rate = [0.0006077759842711142, 0.0006077759842711142]	Loss = 0.71573281 (ave = 0.64979536)

2023-07-06 04:23:16,220 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38230	Time 12.219s / 10iters, (1.222)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.250s / 10iters, (0.825)	Loss Time 2.789s / 10iters, (0.279)	Data load 0.076s / 10iters, (0.007550)
Learning rate = [0.0006047038210600326, 0.0006047038210600326]	Loss = 0.59324914 (ave = 0.65881639)

2023-07-06 04:23:28,524 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38240	Time 12.304s / 10iters, (1.230)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.365s / 10iters, (0.837)	Loss Time 2.753s / 10iters, (0.275)	Data load 0.083s / 10iters, (0.008344)
Learning rate = [0.0006016299226440522, 0.0006016299226440522]	Loss = 0.59480119 (ave = 0.65761397)

2023-07-06 04:23:40,715 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38250	Time 12.190s / 10iters, (1.219)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.212s / 10iters, (0.821)	Loss Time 2.777s / 10iters, (0.278)	Data load 0.086s / 10iters, (0.008581)
Learning rate = [0.000598554278181105, 0.000598554278181105]	Loss = 0.80733788 (ave = 0.64263824)

2023-07-06 04:23:53,036 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38260	Time 12.322s / 10iters, (1.232)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.861s / 10iters, (0.286)	Data load 0.092s / 10iters, (0.009208)
Learning rate = [0.0005954768766990551, 0.0005954768766990551]	Loss = 0.59130883 (ave = 0.65812037)

2023-07-06 04:24:05,337 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38270	Time 12.301s / 10iters, (1.230)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.288s / 10iters, (0.829)	Loss Time 2.834s / 10iters, (0.283)	Data load 0.074s / 10iters, (0.007412)
Learning rate = [0.0005923977070933781, 0.0005923977070933781]	Loss = 0.65462238 (ave = 0.64737359)

2023-07-06 04:24:17,762 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38280	Time 12.425s / 10iters, (1.242)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.319s / 10iters, (0.832)	Loss Time 2.914s / 10iters, (0.291)	Data load 0.077s / 10iters, (0.007709)
Learning rate = [0.0005893167581247965, 0.0005893167581247965]	Loss = 0.63882917 (ave = 0.63726695)

2023-07-06 04:24:30,314 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38290	Time 12.553s / 10iters, (1.255)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.408s / 10iters, (0.841)	Loss Time 2.944s / 10iters, (0.294)	Data load 0.075s / 10iters, (0.007520)
Learning rate = [0.0005862340184168418, 0.0005862340184168418]	Loss = 0.59542811 (ave = 0.61122772)

2023-07-06 04:24:42,942 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38300	Time 12.628s / 10iters, (1.263)	Forward Time 1.122s / 10iters, (0.112)	Backward Time 8.462s / 10iters, (0.846)	Loss Time 2.967s / 10iters, (0.297)	Data load 0.076s / 10iters, (0.007590)
Learning rate = [0.000583149476453375, 0.000583149476453375]	Loss = 0.65593445 (ave = 0.65382620)

2023-07-06 04:24:55,646 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38310	Time 12.705s / 10iters, (1.270)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.533s / 10iters, (0.853)	Loss Time 2.979s / 10iters, (0.298)	Data load 0.075s / 10iters, (0.007515)
Learning rate = [0.0005800631205760365, 0.0005800631205760365]	Loss = 0.64267462 (ave = 0.66769332)

2023-07-06 04:25:08,207 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38320	Time 12.561s / 10iters, (1.256)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.467s / 10iters, (0.847)	Loss Time 2.902s / 10iters, (0.290)	Data load 0.074s / 10iters, (0.007401)
Learning rate = [0.0005769749389816441, 0.0005769749389816441]	Loss = 0.71250188 (ave = 0.66243467)

2023-07-06 04:25:20,649 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38330	Time 12.441s / 10iters, (1.244)	Forward Time 1.148s / 10iters, (0.115)	Backward Time 8.360s / 10iters, (0.836)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007547)
Learning rate = [0.0005738849197195134, 0.0005738849197195134]	Loss = 0.69767416 (ave = 0.64992698)

2023-07-06 04:25:33,135 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38340	Time 12.487s / 10iters, (1.249)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.397s / 10iters, (0.840)	Loss Time 2.896s / 10iters, (0.290)	Data load 0.074s / 10iters, (0.007395)
Learning rate = [0.0005707930506887252, 0.0005707930506887252]	Loss = 0.70832884 (ave = 0.65888118)

2023-07-06 04:25:45,646 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38350	Time 12.510s / 10iters, (1.251)	Forward Time 1.185s / 10iters, (0.118)	Backward Time 8.381s / 10iters, (0.838)	Loss Time 2.869s / 10iters, (0.287)	Data load 0.075s / 10iters, (0.007534)
Learning rate = [0.0005676993196353187, 0.0005676993196353187]	Loss = 0.65061599 (ave = 0.64979759)

2023-07-06 04:25:57,982 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38360	Time 12.336s / 10iters, (1.234)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.288s / 10iters, (0.829)	Loss Time 2.849s / 10iters, (0.285)	Data load 0.090s / 10iters, (0.009037)
Learning rate = [0.000564603714149422, 0.000564603714149422]	Loss = 0.70522910 (ave = 0.66314248)

2023-07-06 04:26:10,386 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38370	Time 12.404s / 10iters, (1.240)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.364s / 10iters, (0.836)	Loss Time 2.856s / 10iters, (0.286)	Data load 0.076s / 10iters, (0.007607)
Learning rate = [0.0005615062216622978, 0.0005615062216622978]	Loss = 0.70821601 (ave = 0.70120710)

2023-07-06 04:26:22,698 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38380	Time 12.312s / 10iters, (1.231)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.368s / 10iters, (0.837)	Loss Time 2.763s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007524)
Learning rate = [0.0005584068294433285, 0.0005584068294433285]	Loss = 0.84247303 (ave = 0.67757483)

2023-07-06 04:26:34,958 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38390	Time 12.260s / 10iters, (1.226)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.320s / 10iters, (0.832)	Loss Time 2.746s / 10iters, (0.275)	Data load 0.079s / 10iters, (0.007936)
Learning rate = [0.0005553055245969161, 0.0005553055245969161]	Loss = 0.68305516 (ave = 0.68459787)

2023-07-06 04:26:47,215 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38400	Time 12.256s / 10iters, (1.226)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.332s / 10iters, (0.833)	Loss Time 2.708s / 10iters, (0.271)	Data load 0.106s / 10iters, (0.010625)
Learning rate = [0.0005522022940593127, 0.0005522022940593127]	Loss = 0.60401368 (ave = 0.61744457)

2023-07-06 04:26:59,293 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38410	Time 12.079s / 10iters, (1.208)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.188s / 10iters, (0.819)	Loss Time 2.718s / 10iters, (0.272)	Data load 0.078s / 10iters, (0.007804)
Learning rate = [0.0005490971245953546, 0.0005490971245953546]	Loss = 0.62019140 (ave = 0.65123508)

2023-07-06 04:27:11,526 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38420	Time 12.232s / 10iters, (1.223)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.304s / 10iters, (0.830)	Loss Time 2.754s / 10iters, (0.275)	Data load 0.076s / 10iters, (0.007590)
Learning rate = [0.0005459900027951272, 0.0005459900027951272]	Loss = 0.67586392 (ave = 0.67679488)

2023-07-06 04:27:23,840 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38430	Time 12.315s / 10iters, (1.231)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.382s / 10iters, (0.838)	Loss Time 2.751s / 10iters, (0.275)	Data load 0.084s / 10iters, (0.008417)
Learning rate = [0.0005428809150705341, 0.0005428809150705341]	Loss = 0.64125812 (ave = 0.66899580)

2023-07-06 04:27:36,110 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38440	Time 12.270s / 10iters, (1.227)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.328s / 10iters, (0.833)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007488)
Learning rate = [0.0005397698476517863, 0.0005397698476517863]	Loss = 0.65358877 (ave = 0.65598947)

2023-07-06 04:27:48,313 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38450	Time 12.203s / 10iters, (1.220)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.735s / 10iters, (0.274)	Data load 0.076s / 10iters, (0.007555)
Learning rate = [0.0005366567865837832, 0.0005366567865837832]	Loss = 0.63435429 (ave = 0.63850570)

2023-07-06 04:28:00,584 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38460	Time 12.271s / 10iters, (1.227)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.309s / 10iters, (0.831)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.094s / 10iters, (0.009418)
Learning rate = [0.0005335417177224138, 0.0005335417177224138]	Loss = 0.70590675 (ave = 0.64217865)

2023-07-06 04:28:12,889 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38470	Time 12.305s / 10iters, (1.231)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.317s / 10iters, (0.832)	Loss Time 2.771s / 10iters, (0.277)	Data load 0.102s / 10iters, (0.010176)
Learning rate = [0.0005304246267307502, 0.0005304246267307502]	Loss = 0.56733966 (ave = 0.63328391)

2023-07-06 04:28:25,083 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38480	Time 12.194s / 10iters, (1.219)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.744s / 10iters, (0.274)	Data load 0.075s / 10iters, (0.007518)
Learning rate = [0.0005273054990751475, 0.0005273054990751475]	Loss = 0.64966375 (ave = 0.64726312)

2023-07-06 04:28:37,306 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38490	Time 12.223s / 10iters, (1.222)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.748s / 10iters, (0.275)	Data load 0.075s / 10iters, (0.007485)
Learning rate = [0.0005241843200212244, 0.0005241843200212244]	Loss = 0.54385829 (ave = 0.62515134)

2023-07-06 04:28:49,542 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38500	Time 12.236s / 10iters, (1.224)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.320s / 10iters, (0.832)	Loss Time 2.737s / 10iters, (0.274)	Data load 0.083s / 10iters, (0.008258)
Learning rate = [0.0005210610746297496, 0.0005210610746297496]	Loss = 0.72559339 (ave = 0.64673480)

2023-07-06 04:29:01,797 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38510	Time 12.255s / 10iters, (1.226)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.357s / 10iters, (0.836)	Loss Time 2.719s / 10iters, (0.272)	Data load 0.074s / 10iters, (0.007351)
Learning rate = [0.0005179357477524061, 0.0005179357477524061]	Loss = 0.64203358 (ave = 0.66069797)

2023-07-06 04:29:14,126 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38520	Time 12.329s / 10iters, (1.233)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.406s / 10iters, (0.841)	Loss Time 2.741s / 10iters, (0.274)	Data load 0.082s / 10iters, (0.008247)
Learning rate = [0.0005148083240274481, 0.0005148083240274481]	Loss = 0.75583196 (ave = 0.65906076)

2023-07-06 04:29:26,303 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38530	Time 12.177s / 10iters, (1.218)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.302s / 10iters, (0.830)	Loss Time 2.711s / 10iters, (0.271)	Data load 0.074s / 10iters, (0.007404)
Learning rate = [0.0005116787878752239, 0.0005116787878752239]	Loss = 0.63699144 (ave = 0.64999085)

2023-07-06 04:29:38,536 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38540	Time 12.233s / 10iters, (1.223)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.360s / 10iters, (0.836)	Loss Time 2.708s / 10iters, (0.271)	Data load 0.074s / 10iters, (0.007384)
Learning rate = [0.0005085471234935876, 0.0005085471234935876]	Loss = 0.59172267 (ave = 0.65449398)

2023-07-06 04:29:50,794 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38550	Time 12.258s / 10iters, (1.226)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.379s / 10iters, (0.838)	Loss Time 2.704s / 10iters, (0.270)	Data load 0.075s / 10iters, (0.007534)
Learning rate = [0.0005054133148531729, 0.0005054133148531729]	Loss = 0.71686459 (ave = 0.67512897)

2023-07-06 04:30:03,099 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38560	Time 12.304s / 10iters, (1.230)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.352s / 10iters, (0.835)	Loss Time 2.769s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007456)
Learning rate = [0.000502277345692543, 0.000502277345692543]	Loss = 0.63947374 (ave = 0.67219785)

2023-07-06 04:30:15,356 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38570	Time 12.257s / 10iters, (1.226)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.337s / 10iters, (0.834)	Loss Time 2.746s / 10iters, (0.275)	Data load 0.074s / 10iters, (0.007430)
Learning rate = [0.0004991391995131881, 0.0004991391995131881]	Loss = 0.63540864 (ave = 0.66080888)

2023-07-06 04:30:27,379 INFO    [trainer_contrastive.py, 272] Train Epoch: 103	Train Iteration: 38580	Time 12.023s / 10iters, (1.202)	Forward Time 1.085s / 10iters, (0.109)	Backward Time 8.139s / 10iters, (0.814)	Loss Time 2.722s / 10iters, (0.272)	Data load 0.077s / 10iters, (0.007653)
Learning rate = [0.0004959988595743926, 0.0004959988595743926]	Loss = 0.63498938 (ave = 0.63237175)

2023-07-06 04:30:42,614 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38590	Time 15.037s / 10iters, (1.504)	Forward Time 1.250s / 10iters, (0.125)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.693s / 10iters, (0.269)	Data load 2.786s / 10iters, (0.278561)
Learning rate = [0.0004928563088879466, 0.0004928563088879466]	Loss = 0.64581245 (ave = 0.66991269)

2023-07-06 04:30:54,861 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38600	Time 12.247s / 10iters, (1.225)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.344s / 10iters, (0.834)	Loss Time 2.680s / 10iters, (0.268)	Data load 0.092s / 10iters, (0.009202)
Learning rate = [0.0004897115302127124, 0.0004897115302127124]	Loss = 0.82458508 (ave = 0.62230135)

2023-07-06 04:31:07,049 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38610	Time 12.189s / 10iters, (1.219)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.726s / 10iters, (0.273)	Data load 0.076s / 10iters, (0.007594)
Learning rate = [0.0004865645060490163, 0.0004865645060490163]	Loss = 0.66535592 (ave = 0.67036924)

2023-07-06 04:31:19,330 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38620	Time 12.281s / 10iters, (1.228)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.326s / 10iters, (0.833)	Loss Time 2.792s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007519)
Learning rate = [0.00048341521863289164, 0.00048341521863289164]	Loss = 0.72552264 (ave = 0.68613421)

2023-07-06 04:31:31,613 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38630	Time 12.283s / 10iters, (1.228)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.074s / 10iters, (0.007424)
Learning rate = [0.0004802636499301408, 0.0004802636499301408]	Loss = 0.66235960 (ave = 0.65135905)

2023-07-06 04:31:43,859 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38640	Time 12.247s / 10iters, (1.225)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.082s / 10iters, (0.008210)
Learning rate = [0.00047710978163022244, 0.00047710978163022244]	Loss = 0.65529323 (ave = 0.64335390)

2023-07-06 04:31:56,144 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38650	Time 12.285s / 10iters, (1.228)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.264s / 10iters, (0.826)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007470)
Learning rate = [0.0004739535951399591, 0.0004739535951399591]	Loss = 0.71378666 (ave = 0.67219645)

2023-07-06 04:32:08,485 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38660	Time 12.341s / 10iters, (1.234)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.307s / 10iters, (0.831)	Loss Time 2.862s / 10iters, (0.286)	Data load 0.083s / 10iters, (0.008250)
Learning rate = [0.0004707950715770417, 0.0004707950715770417]	Loss = 0.66439247 (ave = 0.67583447)

2023-07-06 04:32:20,762 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38670	Time 12.278s / 10iters, (1.228)	Forward Time 1.088s / 10iters, (0.109)	Backward Time 8.234s / 10iters, (0.823)	Loss Time 2.881s / 10iters, (0.288)	Data load 0.074s / 10iters, (0.007403)
Learning rate = [0.00046763419176334774, 0.00046763419176334774]	Loss = 0.56040955 (ave = 0.64669904)

2023-07-06 04:32:33,135 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38680	Time 12.373s / 10iters, (1.237)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.907s / 10iters, (0.291)	Data load 0.076s / 10iters, (0.007555)
Learning rate = [0.0004644709362180466, 0.0004644709362180466]	Loss = 0.66871744 (ave = 0.65819367)

2023-07-06 04:32:45,324 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38690	Time 12.189s / 10iters, (1.219)	Forward Time 1.091s / 10iters, (0.109)	Backward Time 8.242s / 10iters, (0.824)	Loss Time 2.782s / 10iters, (0.278)	Data load 0.074s / 10iters, (0.007397)
Learning rate = [0.00046130528515049823, 0.00046130528515049823]	Loss = 0.63011730 (ave = 0.65433354)

2023-07-06 04:32:57,506 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38700	Time 12.182s / 10iters, (1.218)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.759s / 10iters, (0.276)	Data load 0.075s / 10iters, (0.007470)
Learning rate = [0.0004581372184529156, 0.0004581372184529156]	Loss = 0.60321099 (ave = 0.62476913)

2023-07-06 04:33:09,768 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38710	Time 12.262s / 10iters, (1.226)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.279s / 10iters, (0.828)	Loss Time 2.818s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007402)
Learning rate = [0.00045496671569281096, 0.00045496671569281096]	Loss = 0.68460447 (ave = 0.65256085)

2023-07-06 04:33:22,116 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38720	Time 12.348s / 10iters, (1.235)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.330s / 10iters, (0.833)	Loss Time 2.839s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007552)
Learning rate = [0.0004517937561051922, 0.0004517937561051922]	Loss = 0.66333842 (ave = 0.64647065)

2023-07-06 04:33:34,346 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38730	Time 12.231s / 10iters, (1.223)	Forward Time 1.087s / 10iters, (0.109)	Backward Time 8.280s / 10iters, (0.828)	Loss Time 2.789s / 10iters, (0.279)	Data load 0.074s / 10iters, (0.007419)
Learning rate = [0.00044861831858451865, 0.00044861831858451865]	Loss = 0.71922785 (ave = 0.62851374)

2023-07-06 04:33:46,634 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38740	Time 12.288s / 10iters, (1.229)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.291s / 10iters, (0.829)	Loss Time 2.805s / 10iters, (0.281)	Data load 0.093s / 10iters, (0.009289)
Learning rate = [0.00044544038167638295, 0.00044544038167638295]	Loss = 0.68557984 (ave = 0.64562562)

2023-07-06 04:33:58,894 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38750	Time 12.260s / 10iters, (1.226)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.245s / 10iters, (0.825)	Loss Time 2.825s / 10iters, (0.283)	Data load 0.083s / 10iters, (0.008297)
Learning rate = [0.0004422599235689367, 0.0004422599235689367]	Loss = 0.60391068 (ave = 0.67076034)

2023-07-06 04:34:11,092 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38760	Time 12.198s / 10iters, (1.220)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.213s / 10iters, (0.821)	Loss Time 2.808s / 10iters, (0.281)	Data load 0.081s / 10iters, (0.008136)
Learning rate = [0.00043907692208402615, 0.00043907692208402615]	Loss = 0.68861079 (ave = 0.64226319)

2023-07-06 04:34:23,348 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38770	Time 12.256s / 10iters, (1.226)	Forward Time 1.089s / 10iters, (0.109)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007446)
Learning rate = [0.0004358913546680434, 0.0004358913546680434]	Loss = 0.61678058 (ave = 0.61910439)

2023-07-06 04:34:35,585 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38780	Time 12.237s / 10iters, (1.224)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.252s / 10iters, (0.825)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.081s / 10iters, (0.008055)
Learning rate = [0.000432703198382459, 0.000432703198382459]	Loss = 0.59106612 (ave = 0.64036106)

2023-07-06 04:34:47,861 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38790	Time 12.276s / 10iters, (1.228)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.293s / 10iters, (0.829)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.074s / 10iters, (0.007416)
Learning rate = [0.0004295124298940501, 0.0004295124298940501]	Loss = 0.64893317 (ave = 0.67430178)

2023-07-06 04:35:00,106 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38800	Time 12.245s / 10iters, (1.225)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.231s / 10iters, (0.823)	Loss Time 2.811s / 10iters, (0.281)	Data load 0.093s / 10iters, (0.009324)
Learning rate = [0.00042631902546478944, 0.00042631902546478944]	Loss = 0.71419382 (ave = 0.64882851)

2023-07-06 04:35:12,336 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38810	Time 12.230s / 10iters, (1.223)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.246s / 10iters, (0.825)	Loss Time 2.809s / 10iters, (0.281)	Data load 0.082s / 10iters, (0.008237)
Learning rate = [0.00042312296094139775, 0.00042312296094139775]	Loss = 0.68923378 (ave = 0.66294461)

2023-07-06 04:35:24,580 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38820	Time 12.243s / 10iters, (1.224)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007415)
Learning rate = [0.00041992421174452124, 0.00041992421174452124]	Loss = 0.64083016 (ave = 0.66336330)

2023-07-06 04:35:36,807 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38830	Time 12.227s / 10iters, (1.223)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.235s / 10iters, (0.824)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007473)
Learning rate = [0.0004167227528575487, 0.0004167227528575487]	Loss = 0.60582089 (ave = 0.64859686)

2023-07-06 04:35:49,080 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38840	Time 12.273s / 10iters, (1.227)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.257s / 10iters, (0.826)	Loss Time 2.846s / 10iters, (0.285)	Data load 0.075s / 10iters, (0.007543)
Learning rate = [0.0004135185588150271, 0.0004135185588150271]	Loss = 0.64299721 (ave = 0.64336734)

2023-07-06 04:36:01,276 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38850	Time 12.196s / 10iters, (1.220)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.230s / 10iters, (0.823)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.075s / 10iters, (0.007500)
Learning rate = [0.0004103116036906771, 0.0004103116036906771]	Loss = 0.64512491 (ave = 0.63535091)

2023-07-06 04:36:13,481 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38860	Time 12.205s / 10iters, (1.221)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.210s / 10iters, (0.821)	Loss Time 2.819s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007567)
Learning rate = [0.00040710186108496716, 0.00040710186108496716]	Loss = 0.64861470 (ave = 0.65972320)

2023-07-06 04:36:25,841 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38870	Time 12.360s / 10iters, (1.236)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.885s / 10iters, (0.289)	Data load 0.084s / 10iters, (0.008358)
Learning rate = [0.00040388930411225496, 0.00040388930411225496]	Loss = 0.68998343 (ave = 0.64492966)

2023-07-06 04:36:38,070 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38880	Time 12.229s / 10iters, (1.223)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.216s / 10iters, (0.822)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007452)
Learning rate = [0.00040067390538745407, 0.00040067390538745407]	Loss = 0.63007247 (ave = 0.64775463)

2023-07-06 04:36:50,378 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38890	Time 12.308s / 10iters, (1.231)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.295s / 10iters, (0.829)	Loss Time 2.837s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007581)
Learning rate = [0.00039745563701222114, 0.00039745563701222114]	Loss = 0.57773930 (ave = 0.63585216)

2023-07-06 04:37:02,639 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38900	Time 12.261s / 10iters, (1.226)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.838s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007511)
Learning rate = [0.000394234470560619, 0.000394234470560619]	Loss = 0.69476974 (ave = 0.65203183)

2023-07-06 04:37:14,942 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38910	Time 12.303s / 10iters, (1.230)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.265s / 10iters, (0.827)	Loss Time 2.864s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007517)
Learning rate = [0.00039101037706425966, 0.00039101037706425966]	Loss = 0.63564235 (ave = 0.63951274)

2023-07-06 04:37:27,313 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38920	Time 12.371s / 10iters, (1.237)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.309s / 10iters, (0.831)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.077s / 10iters, (0.007668)
Learning rate = [0.0003877833269968802, 0.0003877833269968802]	Loss = 0.62610364 (ave = 0.65595498)

2023-07-06 04:37:39,598 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38930	Time 12.285s / 10iters, (1.228)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.840s / 10iters, (0.284)	Data load 0.075s / 10iters, (0.007525)
Learning rate = [0.00038455329025834214, 0.00038455329025834214]	Loss = 0.68200278 (ave = 0.65966491)

2023-07-06 04:37:52,133 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38940	Time 12.535s / 10iters, (1.254)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.426s / 10iters, (0.843)	Loss Time 2.910s / 10iters, (0.291)	Data load 0.076s / 10iters, (0.007600)
Learning rate = [0.00038132023615800286, 0.00038132023615800286]	Loss = 0.68003172 (ave = 0.68185259)

2023-07-06 04:38:04,262 INFO    [trainer_contrastive.py, 272] Train Epoch: 104	Train Iteration: 38950	Time 12.129s / 10iters, (1.213)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.192s / 10iters, (0.819)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.077s / 10iters, (0.007663)
Learning rate = [0.0003780841333974598, 0.0003780841333974598]	Loss = 0.71123475 (ave = 0.62920597)

2023-07-06 04:38:19,384 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 38960	Time 14.934s / 10iters, (1.493)	Forward Time 1.279s / 10iters, (0.128)	Backward Time 8.216s / 10iters, (0.822)	Loss Time 2.706s / 10iters, (0.271)	Data load 2.732s / 10iters, (0.273249)
Learning rate = [0.00037484495005261106, 0.00037484495005261106]	Loss = 0.68705827 (ave = 0.64700630)

2023-07-06 04:38:31,692 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 38970	Time 12.308s / 10iters, (1.231)	Forward Time 1.095s / 10iters, (0.110)	Backward Time 8.223s / 10iters, (0.822)	Loss Time 2.900s / 10iters, (0.290)	Data load 0.090s / 10iters, (0.008976)
Learning rate = [0.00037160265355501865, 0.00037160265355501865]	Loss = 0.69605500 (ave = 0.65332723)

2023-07-06 04:38:43,977 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 38980	Time 12.285s / 10iters, (1.229)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.081s / 10iters, (0.008088)
Learning rate = [0.0003683572106725154, 0.0003683572106725154]	Loss = 0.61177933 (ave = 0.67004091)

2023-07-06 04:38:56,137 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 38990	Time 12.160s / 10iters, (1.216)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.217s / 10iters, (0.822)	Loss Time 2.767s / 10iters, (0.277)	Data load 0.080s / 10iters, (0.008003)
Learning rate = [0.00036510858748904716, 0.00036510858748904716]	Loss = 0.70618153 (ave = 0.65159247)

2023-07-06 04:39:08,413 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39000	Time 12.275s / 10iters, (1.228)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.236s / 10iters, (0.824)	Loss Time 2.859s / 10iters, (0.286)	Data load 0.082s / 10iters, (0.008245)
Learning rate = [0.00036185674938368854, 0.00036185674938368854]	Loss = 0.61141610 (ave = 0.64847651)

2023-07-06 04:39:11,719 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-06 04:39:35,980 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-06 04:39:59,409 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-06 04:40:22,796 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-06 04:40:46,033 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-06 04:41:09,148 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-06 04:41:32,047 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-06 04:41:40,821 INFO    [trainer_contrastive.py, 391] Test Time 149.314s, (2.370)	Loss 0.11693470

2023-07-06 04:41:40,822 INFO    [base.py, 33] Result for seg
2023-07-06 04:41:40,823 INFO    [base.py, 49] Mean IOU: 0.7819054397563313

2023-07-06 04:41:40,825 INFO    [base.py, 50] Pixel ACC: 0.9625929843165899

2023-07-06 04:41:52,855 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39010	Time 164.443s / 10iters, (16.444)	Forward Time 1.146s / 10iters, (0.115)	Backward Time 8.126s / 10iters, (0.813)	Loss Time 2.672s / 10iters, (0.267)	Data load 152.498s / 10iters, (15.249821)
Learning rate = [0.0003586016610088072, 0.0003586016610088072]	Loss = 0.71069926 (ave = 0.65476624)

2023-07-06 04:42:04,862 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39020	Time 12.007s / 10iters, (1.201)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.153s / 10iters, (0.815)	Loss Time 2.639s / 10iters, (0.264)	Data load 0.102s / 10iters, (0.010230)
Learning rate = [0.0003553432862673092, 0.0003553432862673092]	Loss = 0.67191362 (ave = 0.64125322)

2023-07-06 04:42:16,999 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39030	Time 12.137s / 10iters, (1.214)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.254s / 10iters, (0.825)	Loss Time 2.693s / 10iters, (0.269)	Data load 0.086s / 10iters, (0.008596)
Learning rate = [0.0003520815882889487, 0.0003520815882889487]	Loss = 0.61124742 (ave = 0.63153598)

2023-07-06 04:42:29,105 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39040	Time 12.107s / 10iters, (1.211)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.249s / 10iters, (0.825)	Loss Time 2.674s / 10iters, (0.267)	Data load 0.078s / 10iters, (0.007776)
Learning rate = [0.0003488165294056266, 0.0003488165294056266]	Loss = 0.57883251 (ave = 0.65352555)

2023-07-06 04:42:41,287 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39050	Time 12.182s / 10iters, (1.218)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.211s / 10iters, (0.821)	Loss Time 2.746s / 10iters, (0.275)	Data load 0.105s / 10iters, (0.010453)
Learning rate = [0.00034554807112564394, 0.00034554807112564394]	Loss = 0.55445981 (ave = 0.63041471)

2023-07-06 04:42:53,380 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39060	Time 12.093s / 10iters, (1.209)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.141s / 10iters, (0.814)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.086s / 10iters, (0.008591)
Learning rate = [0.00034227617410683027, 0.00034227617410683027]	Loss = 0.57164621 (ave = 0.60138868)

2023-07-06 04:43:05,657 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39070	Time 12.276s / 10iters, (1.228)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.270s / 10iters, (0.827)	Loss Time 2.797s / 10iters, (0.280)	Data load 0.098s / 10iters, (0.009850)
Learning rate = [0.0003390007981285146, 0.0003390007981285146]	Loss = 0.70174009 (ave = 0.65262997)

2023-07-06 04:43:17,853 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39080	Time 12.196s / 10iters, (1.220)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.200s / 10iters, (0.820)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.098s / 10iters, (0.009833)
Learning rate = [0.0003357219020622533, 0.0003357219020622533]	Loss = 0.63612342 (ave = 0.63713183)

2023-07-06 04:43:30,110 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39090	Time 12.256s / 10iters, (1.226)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.247s / 10iters, (0.825)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.093s / 10iters, (0.009254)
Learning rate = [0.0003324394438412615, 0.0003324394438412615]	Loss = 0.61132646 (ave = 0.64095410)

2023-07-06 04:43:42,376 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39100	Time 12.266s / 10iters, (1.227)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.255s / 10iters, (0.825)	Loss Time 2.803s / 10iters, (0.280)	Data load 0.094s / 10iters, (0.009379)
Learning rate = [0.0003291533804284547, 0.0003291533804284547]	Loss = 0.68727702 (ave = 0.65467918)

2023-07-06 04:43:54,585 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39110	Time 12.209s / 10iters, (1.221)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.080s / 10iters, (0.007954)
Learning rate = [0.00032586366778304817, 0.00032586366778304817]	Loss = 0.67252505 (ave = 0.64736127)

2023-07-06 04:44:06,777 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39120	Time 12.192s / 10iters, (1.219)	Forward Time 1.095s / 10iters, (0.109)	Backward Time 8.202s / 10iters, (0.820)	Loss Time 2.818s / 10iters, (0.282)	Data load 0.078s / 10iters, (0.007791)
Learning rate = [0.00032257026082561154, 0.00032257026082561154]	Loss = 0.65240246 (ave = 0.63636380)

2023-07-06 04:44:18,935 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39130	Time 12.158s / 10iters, (1.216)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.202s / 10iters, (0.820)	Loss Time 2.761s / 10iters, (0.276)	Data load 0.080s / 10iters, (0.007998)
Learning rate = [0.0003192731134015031, 0.0003192731134015031]	Loss = 0.62717116 (ave = 0.63612139)

2023-07-06 04:44:31,282 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39140	Time 12.347s / 10iters, (1.235)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.292s / 10iters, (0.829)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.090s / 10iters, (0.009001)
Learning rate = [0.0003159721782425679, 0.0003159721782425679]	Loss = 0.59813339 (ave = 0.67514657)

2023-07-06 04:44:43,511 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39150	Time 12.229s / 10iters, (1.223)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.251s / 10iters, (0.825)	Loss Time 2.786s / 10iters, (0.279)	Data load 0.086s / 10iters, (0.008615)
Learning rate = [0.00031266740692702515, 0.00031266740692702515]	Loss = 0.60591006 (ave = 0.67293409)

2023-07-06 04:44:55,755 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39160	Time 12.244s / 10iters, (1.224)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.242s / 10iters, (0.824)	Loss Time 2.826s / 10iters, (0.283)	Data load 0.075s / 10iters, (0.007498)
Learning rate = [0.00030935874983741284, 0.00030935874983741284]	Loss = 0.66758054 (ave = 0.67206408)

2023-07-06 04:45:07,995 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39170	Time 12.240s / 10iters, (1.224)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.215s / 10iters, (0.821)	Loss Time 2.835s / 10iters, (0.283)	Data load 0.078s / 10iters, (0.007756)
Learning rate = [0.0003060461561164897, 0.0003060461561164897]	Loss = 0.62530035 (ave = 0.65091901)

2023-07-06 04:45:20,287 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39180	Time 12.292s / 10iters, (1.229)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.285s / 10iters, (0.829)	Loss Time 2.825s / 10iters, (0.282)	Data load 0.075s / 10iters, (0.007538)
Learning rate = [0.0003027295736209449, 0.0003027295736209449]	Loss = 0.73090357 (ave = 0.64252935)

2023-07-06 04:45:32,517 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39190	Time 12.230s / 10iters, (1.223)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.250s / 10iters, (0.825)	Loss Time 2.808s / 10iters, (0.281)	Data load 0.075s / 10iters, (0.007518)
Learning rate = [0.0002994089488728092, 0.0002994089488728092]	Loss = 0.58323944 (ave = 0.63572792)

2023-07-06 04:45:44,756 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39200	Time 12.238s / 10iters, (1.224)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.288s / 10iters, (0.829)	Loss Time 2.758s / 10iters, (0.276)	Data load 0.076s / 10iters, (0.007564)
Learning rate = [0.0002960842270083991, 0.0002960842270083991]	Loss = 0.58536941 (ave = 0.64517230)

2023-07-06 04:45:57,060 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39210	Time 12.304s / 10iters, (1.230)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.773s / 10iters, (0.277)	Data load 0.077s / 10iters, (0.007706)
Learning rate = [0.00029275535172465473, 0.00029275535172465473]	Loss = 0.63963425 (ave = 0.62897406)

2023-07-06 04:46:09,298 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39220	Time 12.238s / 10iters, (1.224)	Forward Time 1.133s / 10iters, (0.113)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.756s / 10iters, (0.276)	Data load 0.088s / 10iters, (0.008839)
Learning rate = [0.0002894222652226785, 0.0002894222652226785]	Loss = 0.66537231 (ave = 0.65072522)

2023-07-06 04:46:21,597 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39230	Time 12.298s / 10iters, (1.230)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.330s / 10iters, (0.833)	Loss Time 2.775s / 10iters, (0.277)	Data load 0.076s / 10iters, (0.007594)
Learning rate = [0.0002860849081483237, 0.0002860849081483237]	Loss = 0.64398259 (ave = 0.64140597)

2023-07-06 04:46:33,853 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39240	Time 12.257s / 10iters, (1.226)	Forward Time 1.125s / 10iters, (0.113)	Backward Time 8.284s / 10iters, (0.828)	Loss Time 2.738s / 10iters, (0.274)	Data load 0.109s / 10iters, (0.010897)
Learning rate = [0.000282743219529611, 0.000282743219529611]	Loss = 0.65376455 (ave = 0.66518949)

2023-07-06 04:46:46,033 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39250	Time 12.180s / 10iters, (1.218)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.214s / 10iters, (0.821)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.078s / 10iters, (0.007783)
Learning rate = [0.0002793971367107801, 0.0002793971367107801]	Loss = 0.68068880 (ave = 0.60206786)

2023-07-06 04:46:58,243 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39260	Time 12.209s / 10iters, (1.221)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.248s / 10iters, (0.825)	Loss Time 2.740s / 10iters, (0.274)	Data load 0.099s / 10iters, (0.009851)
Learning rate = [0.000276046595282723, 0.000276046595282723]	Loss = 0.73088491 (ave = 0.65155554)

2023-07-06 04:47:10,531 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39270	Time 12.289s / 10iters, (1.229)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.309s / 10iters, (0.831)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.087s / 10iters, (0.008688)
Learning rate = [0.0002726915290095803, 0.0002726915290095803]	Loss = 0.60695124 (ave = 0.64192156)

2023-07-06 04:47:22,842 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39280	Time 12.311s / 10iters, (1.231)	Forward Time 1.136s / 10iters, (0.114)	Backward Time 8.312s / 10iters, (0.831)	Loss Time 2.768s / 10iters, (0.277)	Data load 0.095s / 10iters, (0.009464)
Learning rate = [0.00026933186975120724, 0.00026933186975120724]	Loss = 0.60261899 (ave = 0.65704635)

2023-07-06 04:47:35,091 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39290	Time 12.249s / 10iters, (1.225)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.772s / 10iters, (0.277)	Data load 0.088s / 10iters, (0.008755)
Learning rate = [0.00026596754738123684, 0.00026596754738123684]	Loss = 0.68036020 (ave = 0.63987194)

2023-07-06 04:47:47,299 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39300	Time 12.208s / 10iters, (1.221)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.269s / 10iters, (0.827)	Loss Time 2.751s / 10iters, (0.275)	Data load 0.079s / 10iters, (0.007941)
Learning rate = [0.0002625984897003984, 0.0002625984897003984]	Loss = 0.64058578 (ave = 0.63096890)

2023-07-06 04:47:59,621 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39310	Time 12.321s / 10iters, (1.232)	Forward Time 1.105s / 10iters, (0.111)	Backward Time 8.298s / 10iters, (0.830)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.082s / 10iters, (0.008242)
Learning rate = [0.00025922462234477723, 0.00025922462234477723]	Loss = 0.60002029 (ave = 0.62586089)

2023-07-06 04:48:11,974 INFO    [trainer_contrastive.py, 272] Train Epoch: 105	Train Iteration: 39320	Time 12.353s / 10iters, (1.235)	Forward Time 1.123s / 10iters, (0.112)	Backward Time 8.373s / 10iters, (0.837)	Loss Time 2.783s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007465)
Learning rate = [0.00025584586868861707, 0.00025584586868861707]	Loss = 0.63618618 (ave = 0.65588639)

2023-07-06 04:48:27,467 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39330	Time 15.278s / 10iters, (1.528)	Forward Time 1.311s / 10iters, (0.131)	Backward Time 8.351s / 10iters, (0.835)	Loss Time 2.742s / 10iters, (0.274)	Data load 2.874s / 10iters, (0.287396)
Learning rate = [0.0002524621497412743, 0.0002524621497412743]	Loss = 0.59614605 (ave = 0.64447404)

2023-07-06 04:48:39,636 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39340	Time 12.170s / 10iters, (1.217)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.739s / 10iters, (0.274)	Data load 0.085s / 10iters, (0.008471)
Learning rate = [0.00024907338403785495, 0.00024907338403785495]	Loss = 0.66473800 (ave = 0.60350095)

2023-07-06 04:48:51,923 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39350	Time 12.287s / 10iters, (1.229)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.262s / 10iters, (0.826)	Loss Time 2.841s / 10iters, (0.284)	Data load 0.081s / 10iters, (0.008082)
Learning rate = [0.00024567948752307676, 0.00024567948752307676]	Loss = 0.65083683 (ave = 0.66188893)

2023-07-06 04:49:04,352 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39360	Time 12.429s / 10iters, (1.243)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.377s / 10iters, (0.838)	Loss Time 2.866s / 10iters, (0.287)	Data load 0.074s / 10iters, (0.007447)
Learning rate = [0.00024228037342780145, 0.00024228037342780145]	Loss = 0.52926320 (ave = 0.66004196)

2023-07-06 04:49:16,618 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39370	Time 12.267s / 10iters, (1.227)	Forward Time 1.104s / 10iters, (0.110)	Backward Time 8.273s / 10iters, (0.827)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.089s / 10iters, (0.008871)
Learning rate = [0.00023887595213767054, 0.00023887595213767054]	Loss = 0.57267529 (ave = 0.63888066)

2023-07-06 04:49:28,849 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39380	Time 12.230s / 10iters, (1.223)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.279s / 10iters, (0.828)	Loss Time 2.776s / 10iters, (0.278)	Data load 0.076s / 10iters, (0.007627)
Learning rate = [0.0002354661310531818, 0.0002354661310531818]	Loss = 0.57800448 (ave = 0.60168097)

2023-07-06 04:49:41,078 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39390	Time 12.229s / 10iters, (1.223)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.277s / 10iters, (0.828)	Loss Time 2.778s / 10iters, (0.278)	Data load 0.083s / 10iters, (0.008272)
Learning rate = [0.0002320508144405341, 0.0002320508144405341]	Loss = 0.66344482 (ave = 0.65189415)

2023-07-06 04:49:53,333 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39400	Time 12.255s / 10iters, (1.225)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.258s / 10iters, (0.826)	Loss Time 2.802s / 10iters, (0.280)	Data load 0.096s / 10iters, (0.009645)
Learning rate = [0.00022862990327244382, 0.00022862990327244382]	Loss = 0.65432054 (ave = 0.65890518)

2023-07-06 04:50:05,630 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39410	Time 12.297s / 10iters, (1.230)	Forward Time 1.096s / 10iters, (0.110)	Backward Time 8.287s / 10iters, (0.829)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.084s / 10iters, (0.008431)
Learning rate = [0.00022520329505809928, 0.00022520329505809928]	Loss = 0.67991525 (ave = 0.62967774)

2023-07-06 04:50:17,943 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39420	Time 12.314s / 10iters, (1.231)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.843s / 10iters, (0.284)	Data load 0.077s / 10iters, (0.007708)
Learning rate = [0.00022177088366129088, 0.00022177088366129088]	Loss = 0.62877542 (ave = 0.64623196)

2023-07-06 04:50:30,188 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39430	Time 12.245s / 10iters, (1.224)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.260s / 10iters, (0.826)	Loss Time 2.809s / 10iters, (0.281)	Data load 0.077s / 10iters, (0.007747)
Learning rate = [0.00021833255910570803, 0.00021833255910570803]	Loss = 0.63211983 (ave = 0.62016258)

2023-07-06 04:50:42,441 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39440	Time 12.253s / 10iters, (1.225)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.261s / 10iters, (0.826)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.078s / 10iters, (0.007848)
Learning rate = [0.00021488820736623122, 0.00021488820736623122]	Loss = 0.71857667 (ave = 0.69755463)

2023-07-06 04:50:54,795 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39450	Time 12.354s / 10iters, (1.235)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.290s / 10iters, (0.829)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.082s / 10iters, (0.008187)
Learning rate = [0.0002114377101449625, 0.0002114377101449625]	Loss = 0.58600986 (ave = 0.65201374)

2023-07-06 04:51:06,996 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39460	Time 12.201s / 10iters, (1.220)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.186s / 10iters, (0.819)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.076s / 10iters, (0.007575)
Learning rate = [0.0002079809446305553, 0.0002079809446305553]	Loss = 0.65617639 (ave = 0.63535520)

2023-07-06 04:51:19,356 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39470	Time 12.359s / 10iters, (1.236)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.884s / 10iters, (0.288)	Data load 0.095s / 10iters, (0.009492)
Learning rate = [0.0002045177832392992, 0.0002045177832392992]	Loss = 0.60178429 (ave = 0.64906616)

2023-07-06 04:51:31,645 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39480	Time 12.290s / 10iters, (1.229)	Forward Time 1.120s / 10iters, (0.112)	Backward Time 8.267s / 10iters, (0.827)	Loss Time 2.818s / 10iters, (0.282)	Data load 0.085s / 10iters, (0.008548)
Learning rate = [0.00020104809333617882, 0.00020104809333617882]	Loss = 0.62118262 (ave = 0.62470505)

2023-07-06 04:51:43,886 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39490	Time 12.241s / 10iters, (1.224)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.244s / 10iters, (0.824)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.078s / 10iters, (0.007758)
Learning rate = [0.0001975717369339642, 0.0001975717369339642]	Loss = 0.60624832 (ave = 0.65287649)

2023-07-06 04:51:56,116 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39500	Time 12.230s / 10iters, (1.223)	Forward Time 1.118s / 10iters, (0.112)	Backward Time 8.230s / 10iters, (0.823)	Loss Time 2.794s / 10iters, (0.279)	Data load 0.088s / 10iters, (0.008789)
Learning rate = [0.00019408857036811025, 0.00019408857036811025]	Loss = 0.51678026 (ave = 0.63474643)

2023-07-06 04:52:08,488 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39510	Time 12.372s / 10iters, (1.237)	Forward Time 1.099s / 10iters, (0.110)	Backward Time 8.334s / 10iters, (0.833)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.086s / 10iters, (0.008556)
Learning rate = [0.00019059844394503302, 0.00019059844394503302]	Loss = 0.66841620 (ave = 0.64997130)

2023-07-06 04:52:20,807 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39520	Time 12.319s / 10iters, (1.232)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.276s / 10iters, (0.828)	Loss Time 2.836s / 10iters, (0.284)	Data load 0.101s / 10iters, (0.010112)
Learning rate = [0.00018710120156096644, 0.00018710120156096644]	Loss = 0.69449133 (ave = 0.65441249)

2023-07-06 04:52:33,122 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39530	Time 12.315s / 10iters, (1.232)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.262s / 10iters, (0.826)	Loss Time 2.874s / 10iters, (0.287)	Data load 0.079s / 10iters, (0.007931)
Learning rate = [0.00018359668028829592, 0.00018359668028829592]	Loss = 0.71166462 (ave = 0.65972648)

2023-07-06 04:52:45,429 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39540	Time 12.307s / 10iters, (1.231)	Forward Time 1.115s / 10iters, (0.112)	Backward Time 8.275s / 10iters, (0.828)	Loss Time 2.822s / 10iters, (0.282)	Data load 0.094s / 10iters, (0.009435)
Learning rate = [0.00018008470992581551, 0.00018008470992581551]	Loss = 0.58831829 (ave = 0.64434708)

2023-07-06 04:52:57,729 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39550	Time 12.300s / 10iters, (1.230)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.236s / 10iters, (0.824)	Loss Time 2.882s / 10iters, (0.288)	Data load 0.079s / 10iters, (0.007889)
Learning rate = [0.00017656511250894468, 0.00017656511250894468]	Loss = 0.60201478 (ave = 0.65529938)

2023-07-06 04:53:10,052 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39560	Time 12.323s / 10iters, (1.232)	Forward Time 1.105s / 10iters, (0.110)	Backward Time 8.227s / 10iters, (0.823)	Loss Time 2.911s / 10iters, (0.291)	Data load 0.080s / 10iters, (0.008025)
Learning rate = [0.00017303770177534312, 0.00017303770177534312]	Loss = 0.65314144 (ave = 0.64397267)

2023-07-06 04:53:22,475 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39570	Time 12.423s / 10iters, (1.242)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.338s / 10iters, (0.834)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.091s / 10iters, (0.009082)
Learning rate = [0.00016950228258077692, 0.00016950228258077692]	Loss = 0.70951486 (ave = 0.64886304)

2023-07-06 04:53:34,858 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39580	Time 12.383s / 10iters, (1.238)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.892s / 10iters, (0.289)	Data load 0.094s / 10iters, (0.009392)
Learning rate = [0.0001659586502593132, 0.0001659586502593132]	Loss = 0.64913785 (ave = 0.66214250)

2023-07-06 04:53:47,254 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39590	Time 12.396s / 10iters, (1.240)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.266s / 10iters, (0.827)	Loss Time 2.915s / 10iters, (0.292)	Data load 0.098s / 10iters, (0.009792)
Learning rate = [0.00016240658992112188, 0.00016240658992112188]	Loss = 0.68108976 (ave = 0.63781930)

2023-07-06 04:53:59,613 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39600	Time 12.359s / 10iters, (1.236)	Forward Time 1.109s / 10iters, (0.111)	Backward Time 8.264s / 10iters, (0.826)	Loss Time 2.888s / 10iters, (0.289)	Data load 0.098s / 10iters, (0.009766)
Learning rate = [0.00015884587568010033, 0.00015884587568010033]	Loss = 0.66873908 (ave = 0.66830549)

2023-07-06 04:54:12,092 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39610	Time 12.480s / 10iters, (1.248)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.402s / 10iters, (0.840)	Loss Time 2.879s / 10iters, (0.288)	Data load 0.091s / 10iters, (0.009053)
Learning rate = [0.00015527626980240056, 0.00015527626980240056]	Loss = 0.68495190 (ave = 0.66220469)

2023-07-06 04:54:24,501 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39620	Time 12.408s / 10iters, (1.241)	Forward Time 1.116s / 10iters, (0.112)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.900s / 10iters, (0.290)	Data load 0.084s / 10iters, (0.008422)
Learning rate = [0.00015169752176549592, 0.00015169752176549592]	Loss = 0.81354386 (ave = 0.72068024)

2023-07-06 04:54:36,818 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39630	Time 12.317s / 10iters, (1.232)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.235s / 10iters, (0.824)	Loss Time 2.889s / 10iters, (0.289)	Data load 0.083s / 10iters, (0.008256)
Learning rate = [0.00014810936721582196, 0.00014810936721582196]	Loss = 0.61422718 (ave = 0.64562556)

2023-07-06 04:54:49,144 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39640	Time 12.326s / 10iters, (1.233)	Forward Time 1.103s / 10iters, (0.110)	Backward Time 8.263s / 10iters, (0.826)	Loss Time 2.871s / 10iters, (0.287)	Data load 0.090s / 10iters, (0.008960)
Learning rate = [0.0001445115268109944, 0.0001445115268109944]	Loss = 0.70464170 (ave = 0.63600193)

2023-07-06 04:55:01,596 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39650	Time 12.452s / 10iters, (1.245)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.317s / 10iters, (0.832)	Loss Time 2.948s / 10iters, (0.295)	Data load 0.075s / 10iters, (0.007500)
Learning rate = [0.00014090370493028345, 0.00014090370493028345]	Loss = 0.71178460 (ave = 0.67478578)

2023-07-06 04:55:14,108 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39660	Time 12.512s / 10iters, (1.251)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.400s / 10iters, (0.840)	Loss Time 2.919s / 10iters, (0.292)	Data load 0.080s / 10iters, (0.007984)
Learning rate = [0.00013728558823413456, 0.00013728558823413456]	Loss = 0.49634370 (ave = 0.63569704)

2023-07-06 04:55:26,448 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39670	Time 12.340s / 10iters, (1.234)	Forward Time 1.100s / 10iters, (0.110)	Backward Time 8.272s / 10iters, (0.827)	Loss Time 2.893s / 10iters, (0.289)	Data load 0.076s / 10iters, (0.007582)
Learning rate = [0.00013365684405014215, 0.00013365684405014215]	Loss = 0.64485651 (ave = 0.64284069)

2023-07-06 04:55:38,844 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39680	Time 12.396s / 10iters, (1.240)	Forward Time 1.127s / 10iters, (0.113)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.906s / 10iters, (0.291)	Data load 0.089s / 10iters, (0.008869)
Learning rate = [0.00013001711855864599, 0.00013001711855864599]	Loss = 0.72024900 (ave = 0.63277158)

2023-07-06 04:55:50,926 INFO    [trainer_contrastive.py, 272] Train Epoch: 106	Train Iteration: 39690	Time 12.082s / 10iters, (1.208)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.153s / 10iters, (0.815)	Loss Time 2.751s / 10iters, (0.275)	Data load 0.085s / 10iters, (0.008540)
Learning rate = [0.00012636603474605802, 0.00012636603474605802]	Loss = 0.70379919 (ave = 0.65341640)

2023-07-06 04:56:06,469 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39700	Time 15.327s / 10iters, (1.533)	Forward Time 1.193s / 10iters, (0.119)	Backward Time 8.412s / 10iters, (0.841)	Loss Time 2.756s / 10iters, (0.276)	Data load 2.966s / 10iters, (0.296573)
Learning rate = [0.00012270319008770618, 0.00012270319008770618]	Loss = 0.71577060 (ave = 0.64135545)

2023-07-06 04:56:18,757 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39710	Time 12.288s / 10iters, (1.229)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.292s / 10iters, (0.829)	Loss Time 2.815s / 10iters, (0.281)	Data load 0.084s / 10iters, (0.008352)
Learning rate = [0.0001190281539142787, 0.0001190281539142787]	Loss = 0.50455898 (ave = 0.65731268)

2023-07-06 04:56:31,083 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39720	Time 12.326s / 10iters, (1.233)	Forward Time 1.119s / 10iters, (0.112)	Backward Time 8.265s / 10iters, (0.827)	Loss Time 2.863s / 10iters, (0.286)	Data load 0.079s / 10iters, (0.007922)
Learning rate = [0.00011534046440623558, 0.00011534046440623558]	Loss = 0.62250793 (ave = 0.63541216)

2023-07-06 04:56:43,595 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39730	Time 12.512s / 10iters, (1.251)	Forward Time 1.150s / 10iters, (0.115)	Backward Time 8.387s / 10iters, (0.839)	Loss Time 2.891s / 10iters, (0.289)	Data load 0.083s / 10iters, (0.008324)
Learning rate = [0.00011163962514848866, 0.00011163962514848866]	Loss = 0.59594971 (ave = 0.66459752)

2023-07-06 04:56:55,873 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39740	Time 12.278s / 10iters, (1.228)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.310s / 10iters, (0.831)	Loss Time 2.770s / 10iters, (0.277)	Data load 0.083s / 10iters, (0.008310)
Learning rate = [0.0001079251011623158, 0.0001079251011623158]	Loss = 0.65054137 (ave = 0.64669920)

2023-07-06 04:57:08,384 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39750	Time 12.511s / 10iters, (1.251)	Forward Time 1.124s / 10iters, (0.112)	Backward Time 8.508s / 10iters, (0.851)	Loss Time 2.804s / 10iters, (0.280)	Data load 0.075s / 10iters, (0.007528)
Learning rate = [0.00010419631431206535, 0.00010419631431206535]	Loss = 0.60626400 (ave = 0.65540304)

2023-07-06 04:57:20,661 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39760	Time 12.276s / 10iters, (1.228)	Forward Time 1.131s / 10iters, (0.113)	Backward Time 8.318s / 10iters, (0.832)	Loss Time 2.745s / 10iters, (0.274)	Data load 0.083s / 10iters, (0.008252)
Learning rate = [0.0001004526379591548, 0.0001004526379591548]	Loss = 0.55979550 (ave = 0.63683448)

2023-07-06 04:57:32,957 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39770	Time 12.297s / 10iters, (1.230)	Forward Time 1.111s / 10iters, (0.111)	Backward Time 8.337s / 10iters, (0.834)	Loss Time 2.774s / 10iters, (0.277)	Data load 0.075s / 10iters, (0.007462)
Learning rate = [9.66933907035255e-05, 9.66933907035255e-05]	Loss = 0.69434661 (ave = 0.65091510)

2023-07-06 04:57:45,211 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39780	Time 12.254s / 10iters, (1.225)	Forward Time 1.094s / 10iters, (0.109)	Backward Time 8.301s / 10iters, (0.830)	Loss Time 2.784s / 10iters, (0.278)	Data load 0.075s / 10iters, (0.007454)
Learning rate = [9.291782901028391e-05, 9.291782901028391e-05]	Loss = 0.65434843 (ave = 0.65596411)

2023-07-06 04:57:57,431 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39790	Time 12.221s / 10iters, (1.222)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.225s / 10iters, (0.822)	Loss Time 2.815s / 10iters, (0.281)	Data load 0.079s / 10iters, (0.007876)
Learning rate = [8.912513846325673e-05, 8.912513846325673e-05]	Loss = 0.62670529 (ave = 0.63977889)

2023-07-06 04:58:09,696 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39800	Time 12.265s / 10iters, (1.226)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.233s / 10iters, (0.823)	Loss Time 2.854s / 10iters, (0.285)	Data load 0.081s / 10iters, (0.008113)
Learning rate = [8.531442331210511e-05, 8.531442331210511e-05]	Loss = 0.61520851 (ave = 0.70721022)

2023-07-06 04:58:22,090 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39810	Time 12.393s / 10iters, (1.239)	Forward Time 1.102s / 10iters, (0.110)	Backward Time 8.329s / 10iters, (0.833)	Loss Time 2.888s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007481)
Learning rate = [8.148469387803068e-05, 8.148469387803068e-05]	Loss = 0.63512093 (ave = 0.63733554)

2023-07-06 04:58:34,409 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39820	Time 12.319s / 10iters, (1.232)	Forward Time 1.090s / 10iters, (0.109)	Backward Time 8.259s / 10iters, (0.826)	Loss Time 2.895s / 10iters, (0.289)	Data load 0.075s / 10iters, (0.007502)
Learning rate = [7.763485124339504e-05, 7.763485124339504e-05]	Loss = 0.65795314 (ave = 0.63923429)

2023-07-06 04:58:46,742 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39830	Time 12.333s / 10iters, (1.233)	Forward Time 1.114s / 10iters, (0.111)	Backward Time 8.274s / 10iters, (0.827)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.086s / 10iters, (0.008581)
Learning rate = [7.376366845585144e-05, 7.376366845585144e-05]	Loss = 0.70794237 (ave = 0.63174404)

2023-07-06 04:58:59,056 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39840	Time 12.314s / 10iters, (1.231)	Forward Time 1.113s / 10iters, (0.111)	Backward Time 8.250s / 10iters, (0.825)	Loss Time 2.850s / 10iters, (0.285)	Data load 0.100s / 10iters, (0.010036)
Learning rate = [6.986976720132868e-05, 6.986976720132868e-05]	Loss = 0.62583822 (ave = 0.63561128)

2023-07-06 04:59:11,432 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39850	Time 12.376s / 10iters, (1.238)	Forward Time 1.145s / 10iters, (0.114)	Backward Time 8.321s / 10iters, (0.832)	Loss Time 2.812s / 10iters, (0.281)	Data load 0.098s / 10iters, (0.009764)
Learning rate = [6.595158850137039e-05, 6.595158850137039e-05]	Loss = 0.60850680 (ave = 0.68904876)

2023-07-06 04:59:23,816 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39860	Time 12.384s / 10iters, (1.238)	Forward Time 1.117s / 10iters, (0.112)	Backward Time 8.341s / 10iters, (0.834)	Loss Time 2.824s / 10iters, (0.282)	Data load 0.101s / 10iters, (0.010143)
Learning rate = [6.200735540234004e-05, 6.200735540234004e-05]	Loss = 0.64575684 (ave = 0.66747550)

2023-07-06 04:59:36,152 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39870	Time 12.336s / 10iters, (1.234)	Forward Time 1.110s / 10iters, (0.111)	Backward Time 8.314s / 10iters, (0.831)	Loss Time 2.830s / 10iters, (0.283)	Data load 0.082s / 10iters, (0.008154)
Learning rate = [5.8035024737434156e-05, 5.8035024737434156e-05]	Loss = 0.63667071 (ave = 0.61679494)

2023-07-06 04:59:48,440 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39880	Time 12.288s / 10iters, (1.229)	Forward Time 1.115s / 10iters, (0.111)	Backward Time 8.238s / 10iters, (0.824)	Loss Time 2.842s / 10iters, (0.284)	Data load 0.094s / 10iters, (0.009357)
Learning rate = [5.403222367044339e-05, 5.403222367044339e-05]	Loss = 0.62250006 (ave = 0.63140123)

2023-07-06 05:00:00,776 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39890	Time 12.337s / 10iters, (1.234)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.296s / 10iters, (0.830)	Loss Time 2.858s / 10iters, (0.286)	Data load 0.075s / 10iters, (0.007505)
Learning rate = [4.9996164544247836e-05, 4.9996164544247836e-05]	Loss = 0.56605870 (ave = 0.62980912)

2023-07-06 05:00:13,189 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39900	Time 12.413s / 10iters, (1.241)	Forward Time 1.121s / 10iters, (0.112)	Backward Time 8.357s / 10iters, (0.836)	Loss Time 2.853s / 10iters, (0.285)	Data load 0.081s / 10iters, (0.008147)
Learning rate = [4.5923527954924374e-05, 4.5923527954924374e-05]	Loss = 0.67609239 (ave = 0.67444820)

2023-07-06 05:00:25,395 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39910	Time 12.206s / 10iters, (1.221)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.208s / 10iters, (0.821)	Loss Time 2.815s / 10iters, (0.282)	Data load 0.076s / 10iters, (0.007556)
Learning rate = [4.1810297800579736e-05, 4.1810297800579736e-05]	Loss = 0.59878874 (ave = 0.62192830)

2023-07-06 05:00:37,681 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39920	Time 12.286s / 10iters, (1.229)	Forward Time 1.098s / 10iters, (0.110)	Backward Time 8.308s / 10iters, (0.831)	Loss Time 2.801s / 10iters, (0.280)	Data load 0.079s / 10iters, (0.007946)
Learning rate = [3.7651520983382583e-05, 3.7651520983382583e-05]	Loss = 0.68794560 (ave = 0.65518902)

2023-07-06 05:00:49,933 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39930	Time 12.252s / 10iters, (1.225)	Forward Time 1.093s / 10iters, (0.109)	Backward Time 8.271s / 10iters, (0.827)	Loss Time 2.814s / 10iters, (0.281)	Data load 0.074s / 10iters, (0.007388)
Learning rate = [3.344094346640836e-05, 3.344094346640836e-05]	Loss = 0.77025151 (ave = 0.63106978)

2023-07-06 05:01:02,311 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39940	Time 12.378s / 10iters, (1.238)	Forward Time 1.101s / 10iters, (0.110)	Backward Time 8.323s / 10iters, (0.832)	Loss Time 2.876s / 10iters, (0.288)	Data load 0.078s / 10iters, (0.007772)
Learning rate = [2.9170431896144472e-05, 2.9170431896144472e-05]	Loss = 0.61266124 (ave = 0.63782632)

2023-07-06 05:01:14,681 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39950	Time 12.370s / 10iters, (1.237)	Forward Time 1.107s / 10iters, (0.111)	Backward Time 8.272s / 10iters, (0.827)	Loss Time 2.913s / 10iters, (0.291)	Data load 0.078s / 10iters, (0.007780)
Learning rate = [2.482899644435909e-05, 2.482899644435909e-05]	Loss = 0.59653455 (ave = 0.65841035)

2023-07-06 05:01:26,987 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39960	Time 12.306s / 10iters, (1.231)	Forward Time 1.112s / 10iters, (0.111)	Backward Time 8.229s / 10iters, (0.823)	Loss Time 2.883s / 10iters, (0.288)	Data load 0.081s / 10iters, (0.008114)
Learning rate = [2.0401001080580785e-05, 2.0401001080580785e-05]	Loss = 0.60509372 (ave = 0.62217953)

2023-07-06 05:01:39,395 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39970	Time 12.407s / 10iters, (1.241)	Forward Time 1.106s / 10iters, (0.111)	Backward Time 8.292s / 10iters, (0.829)	Loss Time 2.927s / 10iters, (0.293)	Data load 0.082s / 10iters, (0.008161)
Learning rate = [1.5862496243535317e-05, 1.5862496243535317e-05]	Loss = 0.58489287 (ave = 0.63667808)

2023-07-06 05:01:51,713 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39980	Time 12.318s / 10iters, (1.232)	Forward Time 1.097s / 10iters, (0.110)	Backward Time 8.313s / 10iters, (0.831)	Loss Time 2.829s / 10iters, (0.283)	Data load 0.079s / 10iters, (0.007861)
Learning rate = [1.1172320172410183e-05, 1.1172320172410183e-05]	Loss = 0.64591318 (ave = 0.64416080)

2023-07-06 05:02:03,821 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 39990	Time 12.108s / 10iters, (1.211)	Forward Time 1.092s / 10iters, (0.109)	Backward Time 8.209s / 10iters, (0.821)	Loss Time 2.733s / 10iters, (0.273)	Data load 0.074s / 10iters, (0.007400)
Learning rate = [6.243087537641842e-06, 6.243087537641842e-06]	Loss = 0.60058665 (ave = 0.67968434)

2023-07-06 05:02:16,088 INFO    [trainer_contrastive.py, 272] Train Epoch: 107	Train Iteration: 40000	Time 12.267s / 10iters, (1.227)	Forward Time 1.108s / 10iters, (0.111)	Backward Time 8.272s / 10iters, (0.827)	Loss Time 2.807s / 10iters, (0.281)	Data load 0.080s / 10iters, (0.007961)
Learning rate = [7.213499529549767e-07, 7.213499529549767e-07]	Loss = 0.55308938 (ave = 0.62186078)

2023-07-06 05:02:16,271 INFO    [data_loader.py, 164] use DefaultLoader for val ...
2023-07-06 05:02:16,278 INFO    [default_loader.py, 38] val 500
2023-07-06 05:02:19,674 INFO    [trainer_contrastive.py, 318] 0 images processed

2023-07-06 05:02:44,077 INFO    [trainer_contrastive.py, 318] 10 images processed

2023-07-06 05:03:07,858 INFO    [trainer_contrastive.py, 318] 20 images processed

2023-07-06 05:03:31,450 INFO    [trainer_contrastive.py, 318] 30 images processed

2023-07-06 05:03:54,966 INFO    [trainer_contrastive.py, 318] 40 images processed

2023-07-06 05:04:18,234 INFO    [trainer_contrastive.py, 318] 50 images processed

2023-07-06 05:04:41,085 INFO    [trainer_contrastive.py, 318] 60 images processed

2023-07-06 05:04:51,301 INFO    [trainer_contrastive.py, 391] Test Time 150.531s, (2.389)	Loss 0.11480688

2023-07-06 05:04:51,301 INFO    [base.py, 33] Result for seg
2023-07-06 05:04:51,302 INFO    [base.py, 49] Mean IOU: 0.7833709809957501

2023-07-06 05:04:51,303 INFO    [base.py, 50] Pixel ACC: 0.9632770872082166

